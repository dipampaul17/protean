# The DAG object; we'll need this to instantiate a DAG
from airflow import DAG
# Operators; we need this to operate!
from airflow.providers.postgres.operators.postgres import PostgresOperator
from airflow.providers.postgres.hooks.postgres import PostgresHook
from airflow.utils.task_group import TaskGroup
from airflow.utils.dates import days_ago
from airflow.decorators import dag, task
# Requests module to make api calls
import requests
# Pandas to transform data
import pandas as pd
from pandas import json_normalize
from pandas import DataFrame
from sqlalchemy import create_engine

# These args will get passed on to each operator
# You can override them on a per-task basis during operator initialization
default_args = {
    'start_date': days_ago(1)
}
# The api that we need to call
NY_API = "https://health.data.ny.gov/resource/xdss-u53e.json?$limit=100000&$order=:id"
# Setting database name
db_name = "userdata"
# Using postgress Hook to get connection url and modifying it to have the right databasename
result = PostgresHook(postgres_conn_id='postgres_new').get_uri().split("/")
result[3] = db_name
dbURI = "/".join(result)

# Creating a list of New York counties to fetch the data for and create tables in Postgres
nycounties = ['Albany', 'Allegany', 'Bronx', 'Broome', 'Cattaraugus', 'Cayuga', 'Chautauqua', 'Chemung', 'Chenango',
              'Clinton', 'Columbia', 'Cortland', 'Delaware', 'Dutchess', 'Erie', 'Essex', 'Franklin', 'Fulton',
              'Genesee', 'Greene', 'Hamilton', 'Herkimer', 'Jefferson', 'Kings', 'Lewis', 'Livingston', 'Madison',
              'Monroe', 'Montgomery', 'Nassau', 'New York', 'Niagara', 'Oneida', 'Onondaga', 'Ontario', 'Orange',
              'Orleans', 'Oswego', 'Otsego', 'Putnam', 'Queens', 'Rensselaer', 'Richmond', 'Rockland', 'Saratoga',
              'Schenectady', 'Schoharie', 'Schuyler', 'Seneca', 'St. Lawrence', 'Steuben', 'Suffolk', 'Sullivan',
              'Tioga', 'Tompkins', 'Ulster', 'Warren', 'Washington', 'Wayne', 'Westchester', 'Wyoming', 'Yates']

# Initializing a counter to use in Task Id under Task groups
totalcounties = 0

with DAG('NY_COVID_INITIAL_LD', schedule_interval='@once', default_args=default_args, catchup=False, template_searchpath='/opt/airflow/') as dag:

    with TaskGroup('INIT_DB_DDL') as createCountyTables:
        for county in nycounties:
            # Increment the counter
            totalcounties = totalcounties + 1
            # Replace space and . in the countyname to create tables
            county = county.replace(" ", "")
            county = county.replace(".", "")
            # Using Postgres Operator to call covid_init.sql
            PostgresOperator(task_id='init_covid_table_' + str(totalcounties),
                             postgres_conn_id='postgres_new',
                             sql="sql/covid_init.sql",
                             params={'countyname': county},
                             database="userdata")

    # Postgres Operator to create function
    createFunction = PostgresOperator(task_id='CREATE_FUNCTION',
                                      postgres_conn_id='postgres_new',
                                      sql="sql/create_trigger.sql",
                                      database="userdata")
    # Creating master table to hold data for all counties
    createMasterTable = PostgresOperator(task_id='CREATE_MASTER',
                                         postgres_conn_id='postgres_new',
                                         sql="sql/create_master.sql",
                                         database="userdata")

    @dag.task
    def get_ny_covid_data_full():
        """
        This function is used to get the full data from the NY Health API.

        (Generated by docly)
        """
        json_data = ""
        # Call New York Api to get data
        result = requests.get(NY_API)
        if result.status_code == 200:
            print("Call to api successful")
            if not result.json():
                raise ValueError(
                    "No Data fetched from API")
            # Getting response in json
            json_data = result.json()
        else:
            print("Error in Api Call")
        return json_data

    @dag.task
    def loaddata(json_data: str):
        """
        load json data

        Args:
            json_data (str) :

        """
        # Pandas DataFrame to read json data
        dataframe: DataFrame = json_normalize(json_data)
        # Printing Dthe dataframe to logs
        print(dataframe.head(2))
        # Creating DB engine
        engine = create_engine(dbURI)
        # Adding new column loaddate to Dataframe
        dataframe['loaddate'] = pd.to_datetime('today')
        # Changing column names to match with database table
        dataframe.rename(columns={"test_date": "testdate", "new_positives": "newpositives",
                                  "cumulative_number_of_positives": "cummpositives", "total_number_of_tests": "totaltests",
                                  "cumulative_number_of_tests": "cummtests",
                                  "test_positive":"testpositive",
                                  "geography":"geography"}, inplace=True)
        # Loading data from dataframe to Postgres table
        dataframe.to_sql("nymaster", engine, index=False, if_exists='append')

    getdata = get_ny_covid_data_full()
    loadtodb = loaddata(getdata)

# Setting Task dependency
createMasterTable >> createCountyTables >> createFunction >> getdata >> loadtodb
