[
  {
    "source": "github:codesearch",
    "url": "https://github.com/kubernetes/community/blob/dd979c1f39933cb14263093d8287ee7a6586d699/committee-code-of-conduct/incident-process.md",
    "title": "incident-process.md",
    "content": "---\ntitle: \"Code of Conduct Committee Incident Reporting and Response Process\"\nweight: 550\naliases: [ \"/coc-process\" ]\ndescription: | \n  Overview of the Code of Conduct Committee's workflow when receiving and\n  responding to an incident report.\n---\n\n# Incident reporting and response process\n\nThis document outlines the Code of Conduct Committee's workflow when receiving and responding to an incident report. As each report is unique, the process is described at a high level.\n\n## When and Where does the Kubernetes Code of Conduct apply?\n\nThe Code of Conduct applies between all community members when interacting about Kubernetes. This primarily addresses official spaces, but if conduct-related issues are affecting our community in unofficial spaces in ways that are likely also affect interpersonal interactions in _official_ spaces, we may be asked to become involved.\n\n### What are the boundaries of the Kubernetes community?\n\nThere are no hard boundaries of the community, but common places we are asked to extend guidance to are:\n\n- Official Kubernetes communication channels\n- Kubernetes events and meetups\n- Media and web presences\n- Social media\n    - In some cases, where individual social media messages are not related to Kubernetes but have been reported to the Code of Conduct Committee and are making project members feel unsafe or unwelcome, we might choose to act.\n\n## Incident Reports\n\n### What is an incident report?\n\nAn **incident report** is a description of an event, interaction, or public statement submitted to the Kubernetes Code of Conduct Committee, which the reporter feels violates the [Kubernetes Code of Conduct](https://kubernetes.io/community/code-of-conduct/). \n\n### Who can submit a report? \n\nThe Code of Conduct Committee accepts reports from everyone who interacts with the Kubernetes project community, contributor or otherwise. This includes, but is not limited to, the following:\n\n- Contributors and maintainers\n- Members of the Kubernetes Slack instance \n- Attendees and vendors at KubeCon/CloudNativeCon\n- CNCF Ambassadors\n- Vendors/companies/projects which use Kubernetes and need to interact with the community as a result\n\nAt times we encourage community members to email us if an incident is ongoing and we have not been contacted.\n\n### Where do private incident reports happen? \n\nThe Code of Conduct Committee's primary means of contact is our email address, conduct@kubernetes.io. \n\nWe can also be reached via Slack direct messages to individual committee members (see [member list](https://github.com/kubernetes/community/tree/master/committee-code-of-conduct#members)) or otherwise, though we might direct you to contact us via email. \n\n### How is the privacy of a report protected?\n\nAll incident-related discussions happen in private spaces between current Code of Conduct Committee members, and all members agree when joining the Committee to maintain the confidentiality of incidents to the extent permitted by law.\n\nWhere incidents relate to _unintentionally_ or _non-consensually_ publicly-visible content or messages, we may, or may request others to, delete that content to help preserve the privacy of involved parties. \n\n### Why does this process exist?\n\nThe reporting process exists to provide the community with mechanisms to keep people safe, and to ensure that poor behavior, regardless of who the initator is, is not accepted.\n\nThe Code of Conduct Committee has unilateral power to address harms as needed and appropriate to restore community safety after any incident(s). We are separate from the Steering Committee and all other bodies in the Kubernetes community to provide a mechanism by which anyone can report, regardless of roles and organizational power dynamics which often lead to systemic underreporting.\n\n## Incident report workflow \n \n### Initial triage \n\nThe Code of Conduct Committee responds to all emails in a timely manner, usually within a few days.\n\nWhen an email is received, it is reviewed for severity. Based on our training, the initial member(s) to review the report and determine severity and urgency. When necessary, we may alert other members and call for an urgent meeting, but in most cases, we discuss asynchronously and develop a response plan.\n\nWe maintain a triage rotation schedule so that there are at least two people watching for incoming reports. This allows us to meet our SLA to the community.\n\n### Recusal \n\nBefore beginning investigation on an incident, members can recuse from (or refuse to pass judgement on) an incident if they feel a relationship with someone in the incident may hinder impartiality or create a perception of impropriety with respect to individuals involved in the reported incident. Some examples of reasons a Code of Conduct Committee member might recuse themselves are:\n\n- Direct reporting relationships, or company work relationships that would cause the investigation to appear inappropriate\n- Close working relationships in the Kubernetes community, for example co-leading a SIG with the reporter or someone else mentioned in the report\n\nIf all members of the Code of Conduct Committee felt the need to recuse themselves from an incident, the incident would be handled by our thid party mediator.\n\nTo reduce the likelihood of recusals, our [election](election.md) process stipulates that we may never have a majority of the Committee from a single employer.\n\n### Building a plan\n\nThe Code of Conduct Committee will privately discuss the incident report, and may or may not decide that we need more information prior to determining whether to take any action.\n\nWe consider the following at this stage:\n\n- Do we need clarification from the reporter beyond the initial report?\n- Do we need clarification from other individuals who may have been involved in, or witnesses to, the incident? \n- Is there a public record of the incident which we can review, such as a chat log or video recording? \n- Are there any privacy or safety considerations that we must take into account? For example, if we reach out to an individual named in the report, could this jeapordize the safety of the reporter or other individuals?\n\n### Reaching out to involved parties\n\nIt is our intention to put as little emotional labor on those who have been harmed as possible, and to protect the safety (both physical and emotional) of all community members. We labor to be supportive and non-judgemental and to make the reporting process as safe and low anxiety as possible.\n\nIn all instances these clarifying discussions are confidential.\n\nClarifying discussions typically take the form of email, Slack DM, or Zoom meeting 1:1 between a member of the Code of Conduct Committee selected during our triaging of an incident report and the individual from whom clarification is sought.  The Code of Conduct Committee member will explicitly identify themselves and indicate they are engaging in conversation as a representative of the Code of Conduct Committee.  If the individual prefers we will endeavor to make the meeting/conversation not 1:1, but rather also include an observer/scribe agreed by both parties and still with all discussion being confidential.\n\n## Incident response workflow\n\n### Reconvening the Committee\n\nWhen we have more information, the Code of Conduct Committee reconvenes, shares all information gathered, and moves on to incident response. \n\nDepending on the complexity and severity of the incident, reaching a consensus may take some time. It may require follow up conversations with affected individuals, or other inquiries.\n\n### Deciding on a Course of Action \n\nWe do not act recklessly, and in deciding on a course of action, we work as a team to include diverse perspectives, support the immediate safety needs of our community members, and support the long-term health of this community.\n\nWhen deciding how to address an incident, the Code of Conduct Committee follows a trauma-informed restorative justice framework. Our decisions on a course of action are informed by the following goals:\n\n- Continuously working towards a community that is a safe and professional space in which individuals from any background can do their best work, authentically and free from harassment\n- Preferring non-punitive punishments when possible\n- Prioritizing the safety of individuals to support the overall health of the community\n- Prioritizing education and coaching for those involved, when possible\n- Prioritizing the protection of contributing members of the Kubernetes project over external parties. This does not mean that we protect people with a higher number of commits or more seniority in the project, however.\n\nIn general, the committee strives for unanimous consensus before taking an action.\n\nFor example, we may choose to do nothing, to issue a private warning, to offer coaching, to recommend organizational changes, or to ban someone from a community platform. \n\n### Taking Actions and Communicating our Recommendations \n\nWhen we have decided on a course of action, we do the following:\n\n- We clearly communicate our decision to those who need to hear it, without violating the confidentiality of those who requested it during an investigative process (if one was undertaken).\n- If and only if it is needed, we work with other leadership bodies (e.g., Steering Committee and the Linux Foundation) \n    - This may be necessary if the incident extends to other communities or event spaces, particularly if we feel there is elevated risk of harm to members of those communities\n    - In rare cases, we might find it necessary to issue a public statement, either jointly or separately\n",
    "timestamp": "2025-05-23T16:29:31.966274",
    "tags": [],
    "severity": "medium",
    "services_affected": [
      "api",
      "web",
      "queue"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "kubernetes",
      "aws",
      "jenkins"
    ],
    "failure_pattern": "resource_exhaustion",
    "timeline_events": [],
    "blast_radius": "partial",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 0.77
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/grafana/developer-advocacy/blob/0f02963ed28e1f722d52330879ca9ee69ebc9315/transcripts/2024-10-24T19:51:55Z-demo-incident-response-management-irm-solution-in-grafana-cloud-observabilitycon-2024.md",
    "title": "2024-10-24T19:51:55Z-demo-incident-response-management-irm-solution-in-grafana-cloud-observabilitycon-2024.md",
    "content": "# Demo: Incident Response Management (IRM) Solution in Grafana Cloud | ObservabilityCON 2024\n\nThis video explores Grafana Cloud's Incident Response Management (IRM) solution. Learn how to streamline your incident ...\n\nPublished on 2024-10-24T19:51:55Z\n\nURL: https://www.youtube.com/watch?v=yyNV4WFsgY8\n\nTranscript: Welcome everyone to a User's\nGuide to Grafana Cloud's... Oh, right. I need this. Grafana\nCloud's end-to-end IRM solution. Sarah Kaplan. I am the\nmanager for the SLO team. Hey, I'm Devin, one of the\nproduct directors here at Grafana. And Devin is actually gonna walk\nus through the IRM solution. But first we're gonna take a little time\nand talk about what end-to-end means. Logistics. You guys know\nthe drill? Snap a pic. Put in your questions. We'll get\nto some of them at the end. Okay. Can I get a thumbs up\nif your engineers, you, your engineers are comfortable\nopening a pull request? Yeah. I should see almost every thumb up.\nI, I really hope. Yeah, right. Okay. Keep it up. If they're just as\ncomfortable declaring an incident. Yeah, that, that one's a little harder.\nI've grappled with that. Is this, is this really an instant? Do I wanna do this whole\nprocess for this little thing? Maybe I just push a fix and no one\nwill know. That leads to bad things, bad things. So at Grafana\nwe want to enable, this is our view of end-to-end is we\nwant to enable your engineers to be as comfortable declaring an incident\nas they are opening a PR. We believe this is essential so that\nyou continue to learn and improve your incident management processes.\nSo how do you do this? How do you make it a routine practice? Something that everyone is\ncomfortable doing? It's kind of hard, but very possible. It is a culture change because\nit goes across tooling, process, and people, you need to be intentional in the\ntooling you choose because you want this tooling to enable the\nfrictionless, easy, blameless, anxiety-free processes that you have\nfor pull requests because then the people get bought in. So we believe this is best\ndone with observability-native IRM. So for us, that means putting your incident\nmanagement processes right with your telemetry data, right next to it. You don't want your engineers to be looking at telemetry to determine if\nthere's an incident and then having to go somewhere else to declare it and then\ncome back here to investigate and then go back here to take notes. If it's all together, it enables\nthis lifecycle of an incident. This is the sweet spot where\nyou detect things early, you can respond quickly,\nall the data's there. And then with the process embedded in it, you capture all of it to\nthen learn, prove detection, improve your response,\nand the cycle continues. You heard a bit of that actually from\nTeleTracking in the earlier call, right? PR's much easier. It enables you to learn more from 'em\nand get that whole response better. However, if any part of\nthis cycle is broken, perhaps your customers are telling you\nwhen there's a problem or it's hard to get the right people involved,\nhard to find the data. Maybe you're doing your post incident\nreports and making action items, but not actually doing those action\nitems. If any of these happen, you're in a reactive state.\nThis is where ACME finds itself every incident, they're diligent,\nthey create an alert for it, they create additional metrics and\nlogging, but that led to alert fatigue, huge number of alerts, what's\nactually relevant. Too much data, hard to find what they need.\nSame problems keep happening. So now Devin's gonna walk us through\nhow Grafana's IRM solution helps them with all of this. Thank you Sarah. Okay, so I'm gonna\nwalk you through about a 15 minute demo. It's gonna be based on a scenario where\na team is owning the payment service. They're gonna set up an\nSLO on the payment service. They're actually going to then respond\nto an issue with that and learn from it. Okay, so we're starting off\nwith the actual SLO builder, and this is in Grafana\nCloud. It's our SLO product. And one of the things we've done outta\nthe box is make it really easy to actually create the SLO with a guided UI. You can see five simple steps to\ncreate the SLO and we start with defining our SLI. So\nservice level indicator. In this example, you can see\nI've created the success metric, which is essentially a Prometheus\nquery that checks to see the number of requests that return successfully\nin less than 200 milliseconds over total number of requests in\nthis case to the payment service. I'm gonna group that by cluster that will\nprobably give us relevant information maybe in the context of an outage\non what cluster is affected. Just a quick shout out to and reference\nback to Asserts yesterday and today. Asserts also provides the ability to\ncreate SLOs. And this is a separate UI, but it's built on top of the SLO platform. This is just another example of how we're\ntrying to bring more opinionation into Grafana Cloud. And you can see here you're guided on\nboth availability and latency SLOs from the Asserts side, but for now,\nwe're gonna stick with our, our general SLO builder and build\nthe SLI off of the Prometheus query. Next up, I am gonna set up the actual SLO\nand corresponding error budget. I'm gonna go with about a 70%\ntarget. That's pretty generous, but this SLI isn't performing that\nwell based on historical data. So I want to give the team some room\nto improve that before they set a more aggressive SLO. We're also gonna name and describe the\nSLO and add labels and labels are gonna be key. As many, many of you're familiar labels are\nkey across the Prometheus and Grafana ecosystem. They're actually gonna\nbe critical for this demo as well. We're gonna use that payment\nlabel, that service name, which is payment to flow information,\nboth from SLOs to Grafana OnCall, and even into the dashboards that we\nreview to learn more from incidents. Finally, I'm gonna create an a rule, a set of alert rules off off this SLO. It's one click and you get a fast\nburn and slow burn alert condition created for you. Again, another example of how we're making it\neasy to get up and running with your SLO. Okay? So that essentially is\ngonna have your SLO built for you. Let me show you what you get.\nOnce you've created that, you also get a dashboard and this prebuilt\ndashboard is gonna help you obviously understand the performance of\nthe SLO over time, but it's, it should work right outta the\nbox after the creation point. So that's gonna give your team the\nability to see what's been happening, change the time window and maybe\neven adjust that SLO at that moment, but they can go back and\nrevisit it over time. All right, one other example that I wanted to give\nyou you're of course gonna likely be creating static alert thresholds as well. And we're investing in Grafana\nalerting ease of use in many places. And one recent release was\naround improving the ability, leverage our notification policy\nwithout having to do some complex label matching. And the way we've achieved that is through\nthe ability to just select a contact point in your alert rule creation. And that is actually gonna build the\nnotification policy in the background. In this case, I've selected an oncall\ncontact point essentially saying, for this alert rule, I wanna send\nthe alert to Grafana Oncall. Okay, that is a quick example of how we're\nhelping you on that detect part of the incident lifecycle. I'm\ngonna move over to respond. One of the key parts of respond is getting\nthe right alert to the right person at the right time. And part of\nthat is your on-call schedule. We offer a product call Grafana\nOnCall, which is part of Grafana IRM, and that allows you to\nmanage your schedules. Here is an example of a\nschedule you can see up here. We actually show where your team is based\non their time zone at a glance you can tell their time zone and obviously that\ncan help in terms of making sure the on-call schedule is adhering to the\nfact that they might be asleep or awake. We have some other\nfeatures as part of this, which is a quality score and\nwarnings around gaps in the schedule. And another example I wanted to highlight\nis our request shift swap feature. So this is essentially making it really\neasy for someone to sh swap a shift with someone on their team. Maybe they\nhave a dentist appointment coming up. You can come in here and hover over\nyour name, request a shift swap, and that's gonna invite someone on\nthe team to actually take their shift. But it's essentially an open invite that's\nperiodically pinging the team saying, Hey, Devin needs someone to take his\nshift. Could you please take that shift? All right. I am gonna switch over to context\nwhere we're actually responding to an alert group. I'm gonna\ndemo the mobile app. So we actually have a mobile\napp if you didn't know. And this mobile app is gonna allow you\nto understand various things including your recent alerts that have been\nsent to you active incidents. You can actually also come\nin and see your schedule. So this was that example\nschedule I just showed. So really nice you can at a glance\nunderstand if you're on call, see who else is on call. But\nI am gonna jump back into the alert groups And show you an example of triggering\nan incident directly from your phone. I created an issue but it\nlooked like it didn't fire, but we'll use this one\nfrom a few hours ago. So this is an alert group that was sent\nto me on actually the payment service SLO. I can look at the glance and see,\nokay, well this is payment service. I know that this is a\nkey service for my users. I think I wanna declare an incident\nproactively to get some help from my team and coordinate and see what's happening. So quickly say it looks\nlike there is an issue here with payment. I'm gonna say I think it's actually a\nmajor issue right now because it affects customers. I'm add a couple labels to help coordinate\nand we say customers are affected and now we're pretty good. Okay, so I've created the\nincident really easily and I'm gonna switch over, oops, to desktop to finish the triage process. Ah. Live demo. No, I guess\nI broke the internet. Or it's hardwired\nactually. Yeah, maybe go. Back to wifi. I dunno. It's the mobile phone demo. Probably\nbroke it. All right, we're back. Maybe. I don't know any jokes. Do you? ?\nThere we go. I got a little laugh. Matt would be proud.\nAll right, here we go. Okay, so this was the issue I\njust declared from my phone. So kind of key highlights\nhere. The incident product. I know TeleTracking did a great job\nof explaining some of the value there, but we automatically run a number\nof routine a number of actions to help your, your team and yourself if\nyou're, if you're running an incident, a PIR doc is created\nautomatically a bridge is created. We create a Slack room or an MS\nteams room for the demo environment, we're using Slack. That's really helpful. That's gonna be part of helping getting\nthe incident declaration to be more routine, having some of this automation happen\nand have your team not have to think about, well what doc do I create?\nWhat room do I do I create? It's all done for you automatically. Another thing which you didn't get to see\nthe loading bar here, but that's fine, is Sift. So Sift is one of the key ways we're demonstrating\nthat observability native IRM message. What does that really mean? Well, Sift is an example of how we're using\nyour telemetry data in combination with the fact that you're running an\nincident workflow in Grafana Cloud. To combine telemetry data with\nthe context of an incident. Better put probably is we run a series\nof checks against your data in the context of this incident.\nSo it inherits the labels and we'll find interesting information\nthat may be relevant contributing causes. So this example we actually\nfind anomalies in your logs. So this is super useful. Customers find the log anomaly pattern\none exp extremely useful for the context of an incident. So you can see here we've found\nfour new patterns in the logs. Obviously get information on the\nchanges that's happening across the, the log patterns. We actually can help\nexplain the log itself and potentially give a user\nremediation steps as well. If I, if I glance at this, I can tell\nthere's some issues with Postgres. It's gonna gimme some more explanation\nhere, so I think that's pretty relevant. So that's sift I'm probably over time. So I'm gonna also assign some roles and role as assignment is critical\npart of incident response. It helps with coordination, it obviously helps with setting up\nplaybooks and guidance to your team on what to do if they\nhave a specific role. You can customize the roles in\nGrafana incident. In this case, we're just gonna have a\ncommander and investigator. We also sync directly\nwith your chat platform. So we have a Slack integration\nand an MS teams integration. We do things like if you write a note\nhere in the incident timeline that's directly translated into Slack\nand or if you're using Slack, you can put that back into the timeline\nas TeleTracking showed you just now. Okay that's a little bit around\nthe incident response aspect. I can also page and pull users\nin directly through OnCall. So Ryan actually is someone that is really\nfamiliar with the payment service and the underlying infrastructure. So I'm\ngonna page him, I can also pull in teams. So let's pull in the app\nenvironment team as well. So Ryan and the team will get paged and\nthe team will be the whoever is on call via the escalation chain that is\nassociated with the app environment team. Okay, I'm gonna go ahead\nand resolve this issue. I think we've solved it\nand move on to the learn aspect of the incident\nlifecycle that Sarah mentioned. So as part of resolution\nprocess and workflow, we actually provide the ability to auto\nsummarize what happened inside of the incident itself. So this is powered by OpenAI and\nhere you can see it's generated a quick summary of what it's seen\nin the timeline. It's pretty good. There's not a lot of data actually\nin the timeline right now, but I think it's done a decent job. Obviously you could edit this as you see\nfit but that's just another example of how we're making it a little bit easier\nfor your team to start following a specific process around incidents. So\nthere we go. We've resolved the issue. And I'm gonna show you a couple other\nexamples of how we're helping you with the learn phase. So I didn't get\nto highlight in the demo, but incident also provides\na task capability. It can create tasks with an incident. You can actually convert those\ninto GitHub issues automatically. And then we show you\nhere a central task list. So this is gonna help you track and\nfollow up on any tasks that you think are identified to prevent\nthe incident reoccurring. We're obviously syncing with GitHub\nthrough that auto assignment piece. And then here you can also see tasks\nif you want to centralize in Grafana incident, you have multiple options. Finally we have a number of dashboards\nthat I've shown you that we build out of the box to help you understand trends. One of these is the SLO\nperformance dashboard. This is showing your performance\nacross all your SLOs here. I've actually scoped it\nto the payment service. We have lots of payment service SLOs\nbecause it's the demo environment, but this is gonna give you a bird's\neye view across all your s SLOs. You can scope that to team\nto service. And then finally both our oncall product and our incident\nproduct come with a trends dashboard. This will show you trends across, in this case the number of people that\nhave been paged incident dashboard will show you trends across\nincidents in this case. I can see that the payment service over\nthe last seven days has at about 14 alerts. It's been about\n20 minutes for MTTR. And I can even go into the\nsquad and users that have been paged around this service. So that's gonna be a great starting point\nto start to have conversations about where your alert and\non-call load is at all. It was a lot, it was quick, but that's,\nit was a lot. That's the demo thanks to. Sarah. It was a true demo 'cause you\nhad a problem. . Okay, so yes, Devin went through a lot of stuff with us. And what I wanna just highlight a few\nthings is in our view of this end-to-end IRM process, we're embedding as many\nbest practices as we can to help you. You noticed he started with SLOs. Awesome. We make that easy in the cloud\nand easy to alert on the SLOs. This is important because it allows\nyou to start your alerting journey, where if you have a lot of noisy alerts, hard to understand what is truly critical, you can start whiting those down and\nhave your alerts just based on your SLOs because those are keyed\noff of customer impacting SLIs things, you know, affect customers. So it'll reduce the noise once\nyou're there. Oh, celebrate woo. And then you can start branching out\nand you can add in predictive alerts. It'll get a little more noisy,\nso be careful, but that, that'll give you even more\nlead time to, to track issues. We saw respond best practices.\nSuper easy to declare an incident, almost like creating a pr. You can\nget the right on-call people engaged. You have all the data you need right\nthere. Observability, native, IRM, you can have runbooks,\nall the best practices. We try and embed it right\nin there for you and learn. Teletracking talked about this\na lot with their PIR process. We try and help you gather as much\nof the data as you need as easily as possible. In the keynote\nyesterday, you saw incident rooms, automatic note taker,\nawesome. All of this is coming and this helps you then\nlearn and get that, get that virtuous cycle going\nand the insights help you look across all your incidents,\nacross the on-call schedules. Where are there problems? Are there\ntrends that you need to be aware of? Do you happen to have problems? Every\ntime there's a configuration change, you can start to, to find\nsome of these bigger things. So we help you at every stage. And our goal in this end-to-end\nprocess is to get this flywheel going, this virtuous cycle. Here's an example. In addition to tele tracking of Clearco, a FinTech company company out\nof Canada having a few problems, one alert fatigue common. They\nalso had hard to read alerts. It was a string of text and\nthey had a manual IRM process. So they moved off PagerDuty, oncall is now super happy and their\nincident processes have greatly improved. You can read more about it on\nour website. So where does, where does that leave us? It's\ngonna be a culture change. It'll be well worth it to get this going. We believe your tooling should be as\nclose to your data as possible. Right now, Grafana is the only observability\nnative IRM solution out there. And that it is a continuous practice. If you wanna get started,\ntalk to your engineers, especially in the context\nof detect, respond, learn. They know where the problems are. This\nwill give you an idea of where to start. And then find one team, team\nwilling to work with you, willing to iterate with\nyou, give you feedback, and get that success story going. So you've seen yesterday with\ncerts incredible tool to, to RCA to respond to an issue. We\nsaw incident rooms yesterday as well. A really exciting capability that's gonna\nreduce toil and capture more context from the incident. Today, I know we had TeleTracking talk\nabout how they're using incident. We talked about the service\nlevel explanation feature, and then you saw today in the brief\ndemo everything from SLO creation to incident response to on-call management\nto even understanding your trends with multiple dashboards. So we're really\nexcited what we've done so far, helping you respond and\nlearn from incidents. And we think we're just getting started. So we're excited to partner with you\nand look forward to building more great products and features with you. Woo. Okay.\n\n",
    "timestamp": "2025-05-23T16:29:52.578684",
    "tags": [],
    "severity": "high",
    "services_affected": [
      "api",
      "web",
      "database",
      "monitoring"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "aws",
      "postgresql",
      "elasticsearch",
      "prometheus",
      "grafana",
      "jenkins"
    ],
    "failure_pattern": "monitoring_blind_spot",
    "timeline_events": [],
    "blast_radius": "localized",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 0.96
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/grafana/act-kit/blob/626b5489c9165951cedf30deaa136385263df90b/docs/incident-response-guide.md",
    "title": "incident-response-guide.md",
    "content": "# Incident Response Guide\n=======\n\n## What is an incident?\n\nAn incident is an issue with a production system where any of\nthe following is true:\n\n* There may be visible impact for customers\n* You need to involve a second team/squad to fix the problem\n* The issue is unresolved after an hour of concentrated analysis\n* There may be significant financial impact\n\n> It's better to declare an incident early and to find a simple fix, than to\n> defer and spin up a larger incident later.\n\n## What is incident response?\n\nIncident response is a broad term which describes the set of processes that we\nmay (if applicable) follow when something unexpected happens.\n\nIn addition to seeking to resolve the symptoms of the issue, these processes\ncover:\n\n* Clearly defining roles and responsibilities and bringing the right people\n  together\n* Communicating internally and externally\n* Keeping track of what’s going on during the incident and preserving evidence\n  to allow us to follow up\n* Creating data and preserving evidence that allows us to understand why\n  incidents occur and how we can avoid them in the future\n\nIncidents can be high pressure, our processes ensure we do the right thing\nquickly and calmly. Good processes are intuitive and develop muscle memory that\nhelps make responding become a low stress part of our work that everyone is\nhappy to contribute to.\n\n\n## Roles within Incident Response\nThe following roles can be delegated to others during the life of an incident,\neither to handle long-running incidents or to transfer the roles to someone\nbetter placed to respond and to provide continuity of ownership. You may only\nlet go of a role when the person stepping into the role has acknowledged that\nthey have taken over.\n\nThese roles give full power and autonomy to those performing the roles. If you\nare not also working an incident, it is assumed that you will give your support\nif called upon by an Incident Commander — declaring an incident grants the\nability to the Incident Commander to commandeer any person within the company at\nany level to help contribute towards the resolution of the incident.\n\n### Investigator\nAn Investigator owns the diagnosis and resolution of the symptoms of the\nincident whilst communicating to the incident commander.\n\nAn Investigator must:\n* Determine degree of impact and the customers and/or systems impacted\n* Identify temporary or permanent fixes to stop the bleeding whilst preserving\n  evidence for what has occurred\n* Identify temporary or permanent fixes to the root cause and deploy the most\n  suitable solution\n* Contributes to the PIR (Post Incident Review) and follow-up\n* Produce one or more hypotheses to isolate a root cause, prove/disprove each\n  hypothesis until we have confidence in one\n\nAn incident has a single named investigator to ensure clear ownership, but other\nengineers may assist as additional investigators if the incident requires it,\nthis is typically the case where the incident involves more than one squad or\nthe investigator asks for assistance.\n\n\n### Incident Commander\nAn Incident Commander who will guide incident response to ensure that we are\ncoordinating, communicating, and documenting by shielding and supporting the\nInvestigator\n\nAn Incident Commander must:\n* Keeps the incident moving towards a resolution.\n* Simplifies the Investigators’ communication to just the incident channel by\n  broadcasting important moments when appropriate\n* Helps with prioritization of tasks to ensure that we stop the bleeding,\n  restore service, and preserve evidence for root-causing\n* Provides escalation and resourcing support to ensure that the right people are\n  brought together or access to systems is obtained\n* Creates an Incident Command Room as a video conference (Zoom or Meet) and\n  ensures the Investigator is present and that the video is open and shared\n  internally\n* Documents progress to facilitate coordination, handover, and a timely PIR\n  (Post Incident Review) document\n* Writes the internal PIR (Post Incident Review) and notifies the Customer\n  Support Engineer when it is ready\n\nAn Incident Commander’s job is to keep the incident moving toward resolution.\nBut an Incident Commander’s job is not to fix the problem, the Investigator is\nthe one who is working to resolve the incident through a temporary or permanent\nsolution (whichever brings the incident to a resolution soonest).\n\n## Declaring an incident\n\nGoals:\n* Communicate that an incident has begun\n* Determine an initial severity (can be adjusted later on)\n* Fill the Incident Commander and Investigator roles\n* Bring all communication about an incident to a single Slack channel\n\nSteps:\n\n> TODO: DEFINE HOW INCIDENT REPORTING WORKS IN YOUR ORGANIZATION\n\nSteps for the on-call engineer (who now becomes the Investigator):\n0. Assign an initial severity by using the following criteria and until you know\n   otherwise assume the higher severity if this is unclear:\n0. Create the incident using Grafana Incident\n0. Assign yourself to the Investigator role within Grafana Incident\n0. Identify an Incident Commander and assign that role within Grafana Incident\n\nSteps for the Incident Commander:\n\nThe Incident Commander should direct all existing conversation to the new\nincident channel. Anyone participating in a conversation about an incident\nshould also move their conversation to the incident channel at the earliest\nopportunity. The Investigator should start sharing what they know at the point.\n\nBy default:\n* The on-call engineer becomes the Investigator\n* If on-call is not available then the secondary becomes the Investigator\n* Secondary on-call becomes the Incident Commander\n* If the secondary is not available Look for an online member of the appropriate\n  squad first\n\n## During an incident\nResolve the incident, whilst communicating to all parties and documenting what\nwe did and why.\n\nGoals:\n* Stop the bleeding, restore service, and preserve evidence for root-causing in\n  a PIR (Post Incident Review) document\n* Communicate internally and document where we are now\n* Communicate externally to provide visibility to customers on something that\n  may be affecting them\n\n> Prioritize mitigation of the symptoms of the incident over fixing the issue in\n> a permanent way within the handling of the incident. The goal is the shortest\n> time to mitigate the impact that the incident produces whilst preserving\n> evidence that aids the investigation.\n\nSteps for the Incident Commander:\n\n* First determine the present status, what is known\n\nThen repeat these steps until the incident is resolved:\n\n0. Ensure that the Investigator has whatever they need, make it your priority to\n   get them whatever they need\n0. Offer support to the Investigator to assist in prioritizing tasks, proposing\n   hypotheses and debugging steps if appropriate\n0. Insulate the Investigator from others, give them space\n\nSteps for the Investigator:\n\n0. Identify and engage an Incident Commander if you have not already done so\n0. Follow a runbook if one exists, if not use your experience to debug or ask\n   for help if you feel stuck.\n0. Communicate to the Incident Commander via the incident channel any actions\n   taken, dashboards that show the problem, what you’re working on now and why.\n   Listen for direction, and feel free to change direction\n0. Periodically introspect on your emotional state; if you feel panicky or\n   overwhelmed, ask the Incident Commander for more support\n\nWhen the impact has been mitigated and we have “stopped the bleeding” then the\nincident in Grafana Incident should be marked as resolved. It is likely that you\nstill need to do a little work to tidy up any actions that you were working on.\n\nAn Investigator can delegate tasks to other individuals, however the\nInvestigator remains the owner of the investigation and other involved\nindividuals should work to support the Investigator.\n## After an incident\nDetermine whether the root cause was fully identified, plan follow-up tasks that\nwill ensure that this incident won’t recur. Communicate internally and\nexternally as needed\n\nGoals:\n* Incidents happen, did we understand what happened and what steps are we taking\n  to ensure it doesn’t happen again?\n* If we learned something, did we communicate it to others?\n* If a customer was impacted, have we communicated the impact to them?\n\nSteps for the Incident Commander:\n* Ensure the PIR (Post Incident Review) document is complete and accurate within\n  1 working day of the incident\n  > TODO LINK YOUR TEMPLATE HERE\n* Ensure follow up actions have been identified and have been added to\n  appropriate systems (Trello, Github, etc) and linked from the PIR (Post\n  Incident Review) document\n* Good follow up actions should address the root cause identified and in complex\n  incidents may also address other factors that contributed to the incident.\n* If an incident warrants it (non-trivial) then schedule a PIR meeting to review\n  the PIR document and dive into the root cause and follow up actions\n\nSteps for the Investigator:\n* Support the Incident Commander in producing the incident report (they write\n  most of it, but will need lots of input from yourself to complete their\n  understanding)\n\nResponsibility for the incident report is with the Incident Commander who should\nknow, at a high level, what happened and when.\n",
    "timestamp": "2025-05-23T16:29:55.048247",
    "tags": [],
    "severity": "low",
    "services_affected": [
      "api",
      "web"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "aws",
      "grafana"
    ],
    "failure_pattern": "resource_exhaustion",
    "timeline_events": [],
    "blast_radius": "global",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 0.7799999999999999
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/alantech/iasql/blob/e192f8d8887d23bfd399b252a6f9ee8d55a288e9/postmortems/005%20-%20Postmortem%20for%20faulty%20Auth0%20Webhook.md",
    "title": "005 - Postmortem for faulty Auth0 Webhook.md",
    "content": "# 005 - Postmortem for faulty Auth0 PostLogin JS webhook\n\n## Level: Internal\n\n## Author(s)\n\n- Luis Fernando De Pombo <l@iasql.com>\n\n## Summary\n\nThe addition of an Auth0 PostLogin JS webhook, which turned out to run during log-in and not after it, caused a redirect loop in the production dashboard and made production unavailable when the webhook failed to run to completion which would happen most of the time.\n\n## Timeline\n\n- **2023-03-14**: @depombo added the faulty Auth0 PostLogin JS webhook\n- **2023-03-15**: @depombo tried to access the production dashboard and noticed that it wasn't possible\n\n## Detection\n\nThe problem was around for roughly 16 hours when the faulty Auth0 PostLogin JS webhook was added until there was an attempt to access the production dashboard for our own usage that did not work.\n\n## Response\n\nOnce we verified the docker logs looked okay and we redeployed production, we noticed the Auth0 logs showed failed attempts to log in.\nThe webhook was removed which fixed the issue immediately.\n\n## Cause\n\nThe Auth0 JS webhook accessed a field within an Auth0 API object that was sometimes `undefined`. Adding a conditional that checked the field was defined made the webhook run the completion every time and fixed the issue. \n\n## Prevention\n\n- Adding a try/catch to all Auth0 JS webhooks.\n- Test Auth0 webhooks work in staging before putting them in production.\n- We currently have periodic checks that alert us if the production or staging docker containers become suddenly unavailable. However, we have no ongoing tests that check if the staging or production dashboards are available. We use to have an integration test that checks if the staging dashboard is up and running, but this only happens during a staging deployment. We can revive and replicate this integration test for production and run it periodically to get alerted when the production dashboard is not accessible.",
    "timestamp": "2025-05-23T16:30:04.426912",
    "tags": [],
    "severity": "low",
    "services_affected": [
      "api",
      "web",
      "auth"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "kubernetes",
      "docker",
      "aws",
      "postgresql",
      "grafana",
      "jenkins"
    ],
    "failure_pattern": "configuration_drift",
    "timeline_events": [],
    "blast_radius": "localized",
    "detection_time": null,
    "mitigation_actions": [
      "production, we noticed the Auth0 logs showed failed attempts to log in"
    ],
    "quality_score": 0.74
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/ruffle-rs/ruffle-rs.github.io/blob/0248c397de3321c6056ae384a80eaa5484af1a77/blog_posts/2023-04-23-mozilla-extension-postmortem.markdown",
    "title": "2023-04-23-mozilla-extension-postmortem.markdown",
    "content": "---\ntitle:  \"A post-mortem of Ruffle's removal from addons.mozilla.org\"\ndate:   2023-04-23 04:07:00 -0400\nauthor: kmeisthax\nicon: /undraw/undraw_feeling_blue_-4-b7q.svg\n---\n\nOn December 11th, 2022, our extension submissions to Firefox's extension repository, addons.mozilla.org (abbreviated as A.M.O), got stuck in review. This was shortly followed up with a far scarier notice a few days later on the 14th:\n\n>Ruffle will be disabled on addons.mozilla.org\n>Due to issues discovered during the review process, one or more versions of your add-on Ruffle will be disabled on addons.mozilla.org in 14 day(s).\n\nWhat followed was a list of every prior submitted version of Ruffle, and a statement requesting corresponding source code. Following this, Ruffle would be unavailable for Firefox users for two months, and we spent an additional month and a half improving our CI processes to support source code review requirements for Mozilla. This is now behind us, but it is important to know why it happened.\n\n---\n\n## The initial response\n\nOur first attempt to satisfy the requirement was very naive: Mike uploads the source repository for the latest submitted version of Ruffle, version 0.1.0.685. He also includes build instructions. What followed was a game of ping-pong between Ruffle's maintainers and Mozilla's extension review team. The first reviewer skipped the `cd web` step and got an error. The second reviewer was able to correctly launch the build system, but hadn't installed a JVM. Our ActionScript 3 support requires Java, as we wrote significant portions of our AS3 builtins in ActionScript itself, which needs to be compiled by a Java binary. However, we'd failed to mention that in our build system documentation. [Oops.](https://github.com/ruffle-rs/ruffle/pull/8959)\n\nAt this point, Ruffle has already been removed from addons.mozilla.org, and [people noticed](https://github.com/ruffle-rs/ruffle/issues/8799#issuecomment-1368047327). divinity76 suggested having Mozilla build Ruffle using Docker, because we could have the `Dockerfile` install all necessary prerequisites - it'd be harder to screw up. This was [merged in](https://github.com/ruffle-rs/ruffle/pull/9066) on January 7th.\n\nI continued pressing on with reviewer ping-pong on Mike's behalf. 0.1.0.685 was already rejected at this point, which meant that I had to submit 0.1.0.712, along with corrected build instructions. This time, the reviewer failed to install rustc instead of the JVM. Since the Dockerfile was part of 0.1.0.712, I suggested using that. The reviewer correctly built Ruffle with the Dockerfile, but the submission was rejected anyway because the compiled source code did not match the XPI we submitted.\n\n## Diffing intensifies\n\nMozilla sent over the version of the extension that they built. My first instinct was to diff all the files in both XPIs. This turns up three major categories of differences:\n\n * Version data embedded in various JavaScript files is wrong.\n * The manifest file is missing the extension ID.\n * The WASM files themselves are different by about four bytes. Because Webpack names the files by hash, this causes knock-on differences with file names elsewhere.\n\nFor my own sanity, I only considered differences \"up to ZIP isomorphism.\" The packaging format used for Firefox extensions, XPI, is a renamed ZIP file with specific contents. This is a common pattern - APK, CRX, EPUB, DOCX, and even Adobe Animate's own XFL format are PKZIP bitstreams with additional constraints. Problem is, ZIP files can have dates in them, and the order in which files are stored will be determined by how the operating system and filesystem enumerate directories. All of which would fail a repro check if Mozilla wanted bit-identical XPIs.\n\nThe first two problems were caused by various build system scripts relying on environment data that is only available during the nightly build process. Said scripts were changed to instead get that information from a version seal file, if available. The nightly build process would also generate special source ZIPs with this version seal present. A [few](https://github.com/ruffle-rs/ruffle/pull/9244) [rounds](https://github.com/ruffle-rs/ruffle/pull/9344) [of](https://github.com/ruffle-rs/ruffle/pull/9353) [back and](https://github.com/ruffle-rs/ruffle/pull/9570) [forth](https://github.com/ruffle-rs/ruffle/pull/9633) with GitHub Actions and this reproducibility hole was filled.\n\nThe WASM files would be more complicated. When building my laptop running Ubuntu, I would only get the four bytes difference in WASM if I built with my clock set ahead by several days. It was two entries in a dispatch table that has been reordered, and this table only existed in *one* of the two WASM files. We'd recently added a \"dual-WASM\" mode that enabled better optimizations for newer browsers. Discussions in maintainer chat considered either disabling dual-WASM (divinity76 was busy [adding it to the Dockerfile](https://github.com/ruffle-rs/ruffle/pull/9121#issuecomment-1396261394)) or writing some complicated \"WASM sorter\" to ensure the table was ordered correctly.\n\nIt turned out that this difference was a fluke. Another test build done on February 2nd was identical across multiple runs. I submitted 0.1.0.742 the next day.\n\n## Reproducible means reproducible!\n\nMozilla took more than a week to review this submission. The first time they looked for the XPI in the wrong place. The second time they caught actually obfuscated code in our extension script:\n\n> Your add-on contains minified, concatenated or otherwise machine-generated code. (boilerplate response omitted)\n> - web/packages/extension/src/content.ts [line 145-147](https://github.com/ruffle-rs/ruffle/pull/9588/files#diff-61744725fdd3172f6802244512c95dca65e7e70a722af0e99224d65d46759d3c)\n\nThe intent of this code was to load parts of our extension's plugin polyfill as early as possible. However, this had been implemented by manually compiling one of our source files and copying the output back into the content script. Not only was this code causing us to fail review, it was also very old. This was fixed by [implementing a proper build step for this](https://github.com/ruffle-rs/ruffle/pull/9588), ensuring that the code would no longer be obfuscated and also remain up to date.\n\nI submitted 0.1.0.758 on February 20th, 2023, and then submitted 0.1.0.760 two days later by accident.\n\nIt's important to remember that during all of this, we're still using the nightly release workflow to submit the extension. This is designed to run every night, but we don't actually want it to do that, since Mozilla no longer approves extension builds that quickly. To deal with this, I'm manually enabling and disabling certain GitHub Actions secrets relating to extension submission so that the build process skips Firefox submission when I don't want it to submit.\n\nFurthermore, we don't actually have the ability to automate extension source code upload - I have to jump in after submission to upload the source code and the build instructions. This causes a problem when I submit two versions by accident. I submit the correct code for 0.1.0.758, and then get an e-mail a few days later complaining that 0.1.0.760 is missing source code, because Mozilla will (rightly) not let you 'queue up' multiple submissions.\n\n0.1.0.760 is approved on February 23rd, marking Ruffle's return to addons.mozilla.org.\n\n## CI\n\nWhile users can now use Ruffle again, we still need our fully automated upload pipeline. Having a maintainer fiddle with our Secrets configuration and upload two files to our addons.mozilla.org account every time we want to release is annoying and error-prone.\n\nProblem is, our extension submission relies on `sign-addon`, a deprecated Mozilla library for submitting addons. This uses version 4 of the addons.mozilla.org API; source code upload is part of version 5. I wrote a PR [to upload source after the fact](https://github.com/ruffle-rs/ruffle/pull/9752) using API version 5 after the version 4 base upload completes. I get an actually helpful comment from diox, an addons.mozilla.org maintainer, explaining that `web-ext` will eventually be getting everything we need. In the meantime I merge in the PR.\n\nAnd [another](https://github.com/ruffle-rs/ruffle/pull/9982), and [another](https://github.com/ruffle-rs/ruffle/pull/10260), and [another](https://github.com/ruffle-rs/ruffle/pull/10276), and [another](https://github.com/ruffle-rs/ruffle/pull/10351). While I probably could have avoided some of these excess PRs with an A.M.O. test environment, or separate credentials for testing, I don't have a good test environment for GitHub Actions itself. And this is part of our normal nightly release workflow, which isn't idempotent and will fail if I run it more than once a day. We also can't stack submissions on A.M.O, so I'm stuck with a week-long edit-test-debug cycle.\n\nThis doesn't particularly *matter* since Ruffle users are getting updates again, but our first fully-automated submission with source code is 0.1.0.798 on March 24th.\n\nAfter I submitted 0.1.0.760 a month ago, I suggested a weekly release cycle for Firefox in maintainer chat, based on Mozilla approving releases once every six days. So the last thing to do is to actually move Firefox to a separate weekly release workflow, so I don't have to manually turn it on and off every Friday. Furthermore, since it's a separate workflow that doesn't create Git tags, I can trigger it as many times as I like for debugging. 0.1.0.807 is submitted using the new process... but for some reason addons.mozilla.org times out and I have to upload manually.\n\nThe next weekly, 0.1.0.813, uploads automatically. The process was so smooth I literally forgot to check if it succeeded - I only noticed after seeing the approval the next Thursday. Firefox is fixed.\n\n## Context\n\nIt's tempting to read into this and get angry at Mozilla, but we also have to look at this from their perspective. Extension review is necessary to keep extensions from turning into data theft and ad-jacking operations, and average users should only be running properly reviewed extensions. We also made several mistakes during our response process that delayed our return to addons.mozilla.org. And the process resulted in genuine problems with our code being found and fixed.\n\nHowever, we are not the only extension that had problems with Mozilla recently. Unwanted YouTube channel blocker BlockTube [was removed for the same reasons we were](https://github.com/amitbl/blocktube/issues/281), but with the added bonus of having to explain to extension review that they need `eval()` to load user-provided blocking JS. Web accessibility auditing extension WAVE [also got flagged for source code](https://discourse.mozilla.org/t/add-on-review-questions/82754/119), with confusing and irrelevant instruction being provided to them. While Mozilla has [plainly documented](https://extensionworkshop.com/documentation/publish/source-code-submission/) their source code submission requirement since at least 2019 (as far back as the Wayback Machine shows), their review staff is still struggling with the source code they are given.\n\nMy hope is that this postmortem will at least serve as a guide for other extension developers trying to pass reproducibility checks when A.M.O reviewers ask for them.\n",
    "timestamp": "2025-05-23T16:30:05.681282",
    "tags": [],
    "severity": "low",
    "services_affected": [
      "api",
      "web",
      "queue"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "docker",
      "aws",
      "azure",
      "jenkins"
    ],
    "failure_pattern": "configuration_drift",
    "timeline_events": [],
    "blast_radius": "global",
    "detection_time": null,
    "mitigation_actions": [
      "[implementing a proper build step for this](https://github"
    ],
    "quality_score": 0.8200000000000001
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/pocket-playlab/pocket-playlab.github.io/blob/54904187f36b80f9cc98fac69dec6aec8dfd8735/_posts/2015-05-06-[POSTMORTEM]-production-dowtime-deploys-nginx-proxy.markdown",
    "title": "2015-05-06-[POSTMORTEM]-production-dowtime-deploys-nginx-proxy.markdown",
    "content": "---\nlayout: post\ntitle:  POST-MORTEM Production services downtime after a deployment\nauthor: Charles Martinot\ndate:   2015-05-06 16:52:00\n---\nFrom now on, we will publish our post-mortems here. We hope that what we learn \nfrom fixing downtimes and incidents will help others in turn.\n\nIf you're not doing post-mortems yet, you should. Here is a [good article][1] \nexplaining why and how to do them.\n\n### Description of the issue: \nThe storage service and backends for all games were unreachable for between 5 \nand 30 minutes\n\n### Effect for the user: \nAll transactions with the backend were unable to be \nprocessed (in-app purchases, loading and saving data...)\n\n### Solution found: \nAn environment variable was missing for one of our unused \nbackend. This variable is used to dynamically reconfigure our nginx-proxy \ncontainer, running on all servers. Its absence was leading to our config having \nthat block: \n\n    upstream  {\n       server XXX.XXX.XXX.XXX:XXXX;\n    }\n\n`upstream` requiring one argument, the reloading of the configuration was \nfailing, and thus all services running on that server were unreachable. We are \nusing a [fork][2] of [jwilder/nginx-proxy][3], so if you don't set your \n`VIRTUAL_ENV` variable for one of your containers exposing a port, you might run \ninto the same issue. Just set a dummy variable if need be.\n\n### How to avoid that situation: \n+  Always set required environment variables before running a container\n+  Make the container fail if the required environment variables are missing\n+  Return errors during the deployment process and notify the team in chat\n\n[1]: https://codeascraft.com/2012/05/22/blameless-postmortems/\n[2]: https://registry.hub.docker.com/u/pocketplaylab/nginx-proxy/\n[3]: https://registry.hub.docker.com/u/jwilder/nginx-proxy/",
    "timestamp": "2025-05-23T16:30:08.266685",
    "tags": [],
    "severity": "high",
    "services_affected": [
      "web",
      "database"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "kubernetes",
      "docker",
      "nginx",
      "jenkins"
    ],
    "failure_pattern": "configuration_drift",
    "timeline_events": [],
    "blast_radius": "localized",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 0.84
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/fga-eps-mds/2019.1-MaisMonitoria/blob/49d6c8ed0f5c60506d80619a40dd60f747e789b1/docs/doc-postmortem.md",
    "title": "doc-postmortem.md",
    "content": "---\nid: doc-postmortem\ntitle: Post Mortem\nsidebar_label: Post Mortem\n---\n## 1. Introdução\n\n<br>\n\nO documento tem como objetivo relatar as experiências vivências no projeto, decidimos então por dividir o documento levantando tópicos que englobam acontecimentos que tiveram grandes impactos ao decorrer do projeto.\n\n## 2. Definição de escopo\n\n<br>\n\nDesde o começo do projeto o escopo foi um problema, com a mudança na disciplina não tínhamos um cliente, a ideia principal da disciplina de desenvolver um chat bot não agradou a equipe, então buscamos utilizar a ideia do projeto realizado na disciplina de Tópicos especiais em jogos, onde seria uma comunidade para disponibilizar as monitorias utilizando técnicas de gameficação, porém existia apenas um plano de gamificação e poucas ideias quanto ao problema a ser solucionado e ao produto a ser feito, então demos início a elicitação dos requisitos, a fim de definir nosso escopo.\n\nAplicamos algumas técnicas, inicialmente fizemos um richpicture para identificar o que havia de entendimento do que seria o projeto, posteriormente a equipe de EPS realizou uma introspecção, onde foi levantado praticamente todo o escopo para o projeto. A equipe de MDS fez uma observação participativa de outros aplicativos, para levantar novos requisitos e ver outras soluções para o problema que nós estávamos procurando resolver.\n\nApós esse levantamento inicial, foi feito o protótipo, onde definimos o design e as telas do produto. Concluímos que o escopo inicialmente englobaria: Gerenciamento de contas de usuário, gerenciamento de monitorias e gameficação, buscando utilizar princípios de redes sociais.\n\n## 3. Definição da metodologia\n\n<br>\n\nSeguindo o que é feito na disciplina a um longo tempo, utilizamos de recursos de diferentes metodologías para definir a nossa. Utilizamos as seguintes metodologías como base: Scrum, Kanbam, Xp e alguns conceitos oriundos do R.U.P.\n\n> Mais detalhes em: https://fga-eps-mds.github.io/2019.1-MaisMonitoria/docs/doc-descricao-metodologia\n\n## 4. Definição das tecnologias\n\n<br>\n\nAs tecnologias utilizadas no projeto foram decididas a partir de discussões entre os membros do grupo, visando a produtividade. Para a configuração e gerenciamento de containers, utilizamos as ferramentas Docker e Docker Compose, visto que possuíamos, apesar de pouco, um certo conhecimento em relação a esta tecnologia. Em relação a análise de código, utilizamos as ferramentas Code Climate e CodeCov, onde o Code Climate nos gerava as métricas necessárias a respeito da saúde do código e o CodeCov sobre a cobertura de testes, as duas ferramentas também possuem interfaces intuitivas e amigáveis. Para a criação da interface do webapp, optamos pelo ReactJS, pois observamos as vantagens que nos traria no desenvolvimento de um PWA. Na escolha da tecnologia para o desenvolvimento das nossas APIs decidimos utilizar o Django Rest, visto que boa parte do grupo já possuía um certo conhecimento a respeito do framework Django e esta ferramenta atenderia ao propósito do projeto. O Firebase é uma ferramenta que abstrai a complexidade da autenticação no webapp, preferimos utilizar uma API externa para tal ao invés de implementar uma solução para esse quesito. O Travis foi escolhido como ferramenta de integração contínua, onde automatiza todo nosso Pipeline. A DigitalOcean é o provedor em nuvem que usamos no projeto, visto que possuímos crédito na plataforma e a mesma atendia as necessidades do projeto. O Rancher é a tecnologia que orquestra os nossos containers na nuvem e possui uma interface intuitiva. Para a comunicação do grupo, decidimos utilizar o Slack, pois o mesmo facilitava a inserção de bots que automatizam algumas tarefas como: responder as Dailys, acompanhar os commits feitos no GitHub e as builds no travis. Para a codificação, usamos o editor VS Code, pois nos auxilia para a programação em pares. Já na parte de versionamento e hospedagem de repositório, o Git e o Github foram utilizados, visto que eram quesitos da disciplina de EPS/MDS e que possuíam integração com outras plataformas como o Code Climate e o Travis. Por fim, o ZenHub foi usado para o gerenciamento da equipe, mostrando o andamento das tarefas de cada membro.\n\n> Mais detalhes sobre as ferramentas, disponíveis em: https://fga-eps-mds.github.io/2019.1-MaisMonitoria/docs/plano-gcs#4-ferramentas\n\n## 5. Definição da arquitetura\n\n<br>\n\nComo sugerido pela professora Carla optamos por utilizar uma arquitetura orientada a microsserviços, ao analisar nosso escopo observamos que ele não era grande e complexo o suficiente para que fosse necessário utilizar tal arquitetura, no entanto visando o aprendizado e o desafio técnico mantivemos a decisão inicial. Após isso procuramos ajuda na internet, com colegas de trabalho, colegas de faculdade e com professores, no intuito de seguir as melhores práticas possíveis dentro da arquitetura, evitar erros bobos e descobrir boas tecnologias para utilizar. Uma vez definida e modelada nossa arquitetura macro, focamos na arquitetura interna dos nossos serviços, que foi modelada de acordo com as tecnologias, frameworks e linguagens que escolhemos utilizar, novamente buscamos ajuda com a mesma intenção de utilizar as melhores práticas possíveis e evitar erros clichês.\n\n## 6. Capacitação da equipe\n\n<br>\n\nNo dia 18/03/2019 demos início aos treinamentos, começamos com git, onde foi dividido em 2 partes, uma teórica, para entenderem a importância do versionamento do código e como o git funciona, focando em já mostrar para eles o que seria a nossa política de branchs e commits, e outra parte prática, para exercitar a programação orientada a objetos com o que foi visto anteriormente.No dia 19/03/2019 realizamos o treinamento para apresentar e explicar a metodologia definida e também um treinamento explicando a utilização do docker no nosso projeto.\n\nApós a definição das outras tecnologias, disponibilizamos dois cursos para que a equipe de MDS se capacitasse para desenvolver o projeto, um curso comprado na plataforma udemy de Django Rest e um curso gratuito de Reactjs na plataforma rocketseat.\n\nEm seguida, realizamos um treinamento a cerca de testes unitários em python, tentando mostrar a importância de testar o código e como realizar a codificação dos testes, utilizando exemplos e prática.\n\n> Mais detalhes disponíveis no plano de gerenciamento de recursos humanos:\nhttps://fga-eps-mds.github.io/2019.1-MaisMonitoria/docs/plano-grh\n\n## 7. Início a codificação\n\n<br>\n\nInfelizmente mesmo após o período de capacitação, a equipe de MDS não atingiu o nível técnico necessário para contribuir de forma independente e eficiente no desenvolvimento, o que acabou obrigando a equipe de EPS a ter que acompanhar muito de perto os membros de MDS e na maioria das vezes codificar por eles as issues. Esse fato acabou sobrecarregando a equipe de EPS principalmente nas proximidades da R1 e de certa forma acomodou os membros de MDS uma vez que a equipe de EPS estava sempre cobrindo o déficit no desenvolvimento do código.\n\n## 8. Entrega da R1\n\n<br>\n\nTivemos a notícia de que apenas a equipe de MDS poderia apresentar, o que nos pegou de surpresa, então iniciamos a preparação para essa entrega, com a equipe de MDS inicialmente dispersa e assustada com a notícia,  a equipe sem ter uma visão alinhada do projeto, tivemos diversas reuniões e ainda sim havia dificuldade de consenso em relação ao produto, então propomos um roteiro para ser seguido e realizamos vários treinamentos e “tira dúvidas” durante a semana que antecedeu a R1, o que surtiu efeito, a equipe se mostrou confiante na apresentação e teve um bom desempenho.\n\nO feedback em geral foi bom, porém tivemos pontos negativos, onde existiam falhas na documentação acerca do produto, onde não definimos bem o que realmente era o produto, e quanto ao desenvolvimento onde a principal crítica foi que a equipe de MDS foi pouco participativa na realização do código.\n\n> Mais informações disponíveis no documento de review da release 1:\nhttps://fga-eps-mds.github.io/2019.1-MaisMonitoria/docs/release1-review\n\n## 9. Mudanças no escopo\n\n<br>\n\nDurante as aulas da professora Carla, em diversos momentos foi discutido o escopo dos projetos em geral, sempre recomendando a diminuição do mesmo, seguindo essa recomendação, analisando a produtividade da equipe e o tempo útil da disciplina, notamos que o escopo inicial era inviável, e iniciamos a refatoração dele.\n\nRetiramos todo o módulo de gameficação, que englobava o sistema de ranking, avaliações e recompensas, também cortamos a funcionalidade de solicitar uma monitoria, adicionamos no lugar uma funcionalidade recomendada pela professora Carla de favoritar uma monitoria, para buscar atender esse problema de uma maneira simplificada, deixando visível para todos os usuários que favoritaram a monitoria, e para o usuário que á favoritou, uma aba de favoritos para facilitar o acesso a mesma.\n\nApós o corte no escopo, fizemos uma refatoração no nosso backlog, onde tentamos corrigir o que foi possível dos erros cometidos anteriormente e deixar nele apenas o que fosse ser possível de entregar ao fim do projeto.\n\n## 10. Amadurecimento da equipe\n\n<br>\n\nAcredito que a métrica do velocity tinha como objetivo motivar a equipe, onde a quantidade de story points feitas por sprint tenderia a ser maior, como uma espécie de desafio para aumentar a motivação e a produtividade do time, porém para o nosso contexto isso não ocorreu.\n\nE como foi citado anteriormente, a equipe de MDS mostrava uma dependência muito grande da equipe de EPS para realizar suas atividades, o que estava gerando uma sobrecarga em cima de EPS, e consequentemente uma desmotivação de toda equipe.\n\nPara solucionar esse problema, utilizamos uma técnica de persuasão, onde consiste em propor um desafio possível, no qual após a realização deste desafio, fosse adquirido confiança e ânimo para o time. Planejamos na [sprint 8](https://fga-eps-mds.github.io/2019.1-MaisMonitoria/docs/sprint8-review) um risco controlado, com atividades mais fáceis de serem realizadas, e os pareamentos para as issues de codificação apenas membros de MDS podendo buscar ajuda de EPS apenas no último dia da sprint.\n\nComo resultado, inicialmente a equipe de MDS se mostrou preocupada e com um certo medo de não conseguirem sozinhos, de forma um pouco tardia, porém ainda sim dentro do tempo planejado tivemos a conclusão de todas as atividades da sprint, e para as próximas a equipe estava mais confiante, acreditando em si mesmo para realizar as issues propostas, sem ter os mesmos pensamentos iniciais: “Não sei fazer”, “Não consigo”. Sem dúvidas essa foi a decisão que mais impactou na realização de todo o processo de desenvolvimento do produto, após essa sprint a equipe de MDS estava mais participativa, o entendimento do problema aumentou e consequentemente junto a produtividade de toda a equipe.\n\n## 11. Bugs encontrados nos testes de usabilidade\n\n<br>\n\nOs testes de usabilidade ocorreram tardiamente, devido a algumas inconstâncias existentes no ambiente de homologação, no dia 07/06/2019 iniciamos os testes, e neles encontramos bugs desconhecidos, onde a aplicação estava criando monitorias e likes sozinha, e não era possível editar o perfil do usuário devido a um erro no uso da foto. Os problemas foram resolvidos e a realização dos testes de usabilidade foi extremamente importante para garantir a qualidade das funcionalidades existentes e coletar feedbacks para melhorar cada vez mais o produto, logo se tivéssemos realizando esses testes de forma mais constante ao longo do projeto, teríamos um produto ainda melhor no fim.\n\n> Teste de usabilidade 2.0, disponível em:\nhttps://fga-eps-mds.github.io/2019.1-MaisMonitoria/docs/doc-teste-usabilidade-2.0\n\n## 12. Testes no frontend\n\n<br>\n\nAo início da codificação do frontend as telas estavam estáticas, sem muitas ações, para elas o teste de renderização a partir do uso de snapshots conseguia cobrir quase que todas as linhas de código, porém com o aumento das funcionalidades e da complexidade do código, os snapshots sozinhos não eram suficientes para cobrir o necessário, então foi proposto para a equipe de MDS a realização do estudo destes testes, e durante esse período aceitamos os pull requests sem se preocupar com o testes no frontend, com a ideia de que eles seriam realizados posteriormente, o que foi um grande erro, pois a equipe de MDS se acomodou e não realizou os estudos dos testes, apenas ignoraram essa tarefa. De forma tardia, tentamos buscar solução para esse problema, a equipe conversou com a professora Bruna e foi recomendado um monitor para buscarmos ajuda, e não tivemos resposta, sendo assim infelizmente não foi possível concluir de forma satisfatória os testes do frontend.\n\n## 13. Bar\n\n<br>\n\n![Bar](assets/bar.png)\n\n<br>\n\n## 14. Sentimentos quanto a execução do projeto\n\n<br>\n\n### 14.1 Sentimos compartilhados:\n\n<br>\n\nLembramos que ao ler o os sentimentos quanto a execução do projeto no post mortem do nosso grupo de GPP quando fizemos MDS,  ficamos na época com a impressão de que era exagero e o que estava escrito não condizia com a verdade, entretanto o sentimento durante a execução do nosso projeto foi o mesmo, vimos em vários momentos um atraso quanto ao cronograma planejado e a equipe dispersa.\n\n<br>\n\n![Relato josué](assets/pmgpp.png)\n\n<br>\n\n### 14.2 Lucas Siqueira\n\n<br>\n\nAlém dos sentimentos compartilhados, durante a execução do projeto na definição do escopo, não existir um cliente inicialmente pareceu algo bom, onde seríamos livres para desenvolver o que propomos, porém na prática não ter um cliente fez com que aumentasse a dificuldade no planejamento e na definição do escopo, um risco muito grande para o projeto, onde a equipe durante um período muito grande de tempo esteve desalinhada quanto as ideias do produto, cada um com uma opinião diferente e uma solução diferente para cada problema, o começo foi extremamente desgastante, com muitas reuniões, discussões e com uma equipe de desenvolvimento improdutiva, uma sobrecarga concentrada em alguns membros e um nível alto de estresse. Para a R2 tivemos uma conversa com a professora Carla, onde foi recomendado a busca de conscientizar a equipe de MDS de suas responsabilidades, a partir desse ponto tomamos a melhor decisão durante o processo que está relatada no tópico 10, a partir daí conseguimos levar o projeto ainda não da melhor maneira possível, porém com mais tranquilidade e produtividade, tendo no fim uma solução satisfatória, um produto que atende o problema levantado, onde é possível visualizar um catálogo de monitorias com horários e temas flexíveis, onde qualquer usuário é um monitor que pode disponibilizar seu tempo para ajudar um colega de curso a partir da interação e troca de conhecimento, terminando o projeto com o sentimento de que dava para ser melhor, porém que o dever foi cumprido.\n\n### 14.3 Caio Oliveira\n\n<br>\n\nA ideia da professora carla de fazer com que a equipe de EPS tenha uma maior autonomia por não ter cliente parecia atrativa no início do projeto, pois tínhamos uma visão diferente, entretanto os problemas começaram a surgir logo no início do projeto, outro ponto que parecia só ter lado positivo mas trouxe alguns problemas foi a amizade entre os membros da equipe, todos se conheciam desde antes da matéria e todos tinham uma amizade grande, exceto com um membro da equipe, que acarretou em problemas da equipe de MDS não acatar sempre as decisões da equipe de EPS, reuniões improdutivas por excesso de brincadeiras, daí surgiu a famosa citação:\n\n> Os cara não leva nada a sério.  Macêdo, Lucas\n\ne o membro que não conhecia o resto da equipe acabava ficando de fora, por vergonha ou timidez, um problema que foi ser resolvido com o amadurecimento da equipe como um todo após a sprint 8 onde deixamos a equipe de MDS mais independente o projeto tomou outro rumo, as historia sendo entregues e a equipe de EPS menos sobrecarregada, ao fim do projeto fico triste com a necessidade da diminuição do escopo porém satisfeito com o resultado, pois a solução encontrada me agradou e resolve o problema proposto, fico feliz com amadurecimento da equipe e pessoal que houve durante o decorrer do projeto.\n\n### 14.4 Lucas Macedo\n\n<br>\n\n\"Os cara não leva nada a sério!\" essa foi minha frase durante o semestre. Infelizmente ao final do projeto não me senti com a sensação de dever cumprido, fiquei bem insatisfeito com a \"arquitetura\" do nosso front-end, no começo do projeto eu como arquiteto confiei na equipe de desenvolvimento, que eles utilizariam o que aprenderam durante a capacitação para criar os componentes e organizar nossas páginas de forma correta e utilizando bom senso, no entanto após passado o sufoco da R1 e o começo meio morno da R2 parei para analisar, revisar, etc... o código e a organização do nosso front-end e me deparei com uma grande bagunça, código sem padrão, com algumas replicações, componentes sem função bem definida e uma estrutura de páginas e rotas confusa para não dizer ruim. Tudo isso cai na minha conta, pois acabei aceitando \"qualquer coisa\" em termos de código e organização durante a R1 por diversos motivos que já foram citados no documento, e depois durante a R2 demorei demais para tomar a atitude de conversar com a equipe de MDS, explicar pra eles quais seriam as melhores práticas e ajudá-los em uma refatoração, uma vez que quando tomei essa decisão ela foi barrada pela equipe de EPS pelos motivos de que o código já estava muito grande e uma refatoração com essas proporções era um risco muito grande para o projeto. No fim, não foi possível cuidar bem do front-end como consegui cuidar das nossas API's, mas fiz o possível para que novos problemas não fossem inseridos no nosso front-end durante a R2.  \n\n### 14.5 Matheus Rodrigues\n\n<br>\n\n> Calma, tá de boa, o projeto tá pronto, só fazer.\n\n## 15. Conclusão\n\n<br>\n\nNo início do projeto foram divididos os papéis e as responsabilidades entre a equipe de EPS e ficou estabelecido que a os membros se ajudam entre si, mesmo que não fosse sua responsabilidade, tudo em pról do produto, para que nós tivéssemos o melhor projeto possível, apesar de desavenças e contradições em alguns aspectos, a amizade e as responsabilidades não deixavam o projeto desandar.\nA experiência vivida na matéria de EPS trouxe para todos os membros do grupo um grande amadurecimento, seja em relação a tecnologias tanto quanto ao gerenciamento de equipe, onde na reunião final os membros conversaram sobre o projeto como um todo e como os erros cometidos no início do projeto voltariam para nos assombrar seja em relação ao uma decisão arquitetural ou um BUG que passou despercebido no code review.\nAo final do projeto vemos um resultado satisfatório, porém com a impressão que de que se tivéssemos percebido e corrigidos nossos erros antes o resultado poderia ter sido melhor, mas o cansaço e o tempo não nos permitem continuar a implementação do escopo definido no início da matéria.\n\n<br>\n\n## Histórico de revisão\n\n<br>\n\n|Data                       |Versão |Descrição       \t      |Autor(es)    |\n|------------------|-----------------|---------------------------------|--------------------|\n| 22/06/2019| 0.1 | Tópicos 1, 2, 14.3, 15 | Caio Oliveira  |\n| 22/06/2019| 0.2 | Tópicos 2, 3, 6, 8, 9, 10, 11, 12, 13, 14.1, 14.2 | Lucas Siqueira |\n| 22/06/2019 | 0.3 | Tópico 4 | Matheus Rodrigues |\n| 22/06/2019 | 0.4 | Tópicos 5, 7 e 14.4 | Lucas Macêdo |\n\n\n\n",
    "timestamp": "2025-05-23T16:30:11.961759",
    "tags": [],
    "severity": "low",
    "services_affected": [
      "api",
      "web",
      "database"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "kubernetes",
      "docker",
      "jenkins"
    ],
    "failure_pattern": null,
    "timeline_events": [],
    "blast_radius": "localized",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 0.47000000000000003
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/KirillTregubov/SoundInsights/blob/ce9c1e5fe29fbb89d359199705af03f1c4e22ce6/docs/A1Postmortem.md",
    "title": "A1Postmortem.md",
    "content": "# Assignment 1 Blameless Postmortem\n\n## What went well\n\n- Backend successfully and reliably reads a sample of our dataset and runs an analysis on it\n- Frontend works and shows Hello World + interactive button\n- Docker was successfully setup\n- Install and build scripts work some of the time on specific machines\n- Both backend and frontend have their own isolated tests that run\n- We had a meeting every week on-time\n\n## What didn't go well\n\n1. We decided to use Python with flask on our backend but didn't install + configure Flask\n   - We talked about it in meeting but no one was assigned so the task was forgotten until after the submission\n   - We didn't plan on implementing or testing communication between the frontend and backend so we didn't notice this functionality was missing\n   - After Assignment 1 we started using GitHub Issues which helped alleviate some of the cause of this, but we are still leaving tasks in minutes and not being proactive with Issue creation and tracking\n   - A subsequent action we are going to implement is add a third role to our rotation of people doing agenda and minutes that is responsible for defining and assigning tasks for the week\n      - Order is \n        ```\n        Agenda > Minutes > Tasks circular rotation\n        Kirill\n        Roger\n        Burt\n        Eddie\n        ```\n\n1. We were unsure about which technology we were using on our frontend \n    - Initially Kirill implemented a Vite+TS+React app, then we pivoted to Burt implementing a frontend Flask app, then we went back to the first stack\n    - We didn't initally research the strengths and weaknesses of our chosen solutions well enough, we had a misunderstanding of what Flask is used for and did not realize we would need JavaScript for client-side interactivity anyways\n    - We did not like the fact that a team member's work was effectively discarded and we found that we repeated this behaviour at least one other time since\n    - The immediate solution is to be more dilligent in researching specifics about the tools and technologies we are using, not just picking them out of familiarity or popularity\n    - A subsequent action we will try to implement is having a research reviewer similar to how we currently require one approval for each pull request.\n      - The person in charge of the task to research the new tool/technology will be expected to tag a member of the team that they think are knowledgeable in the area or are available\n      - Both the assignee and the \"reviewer\" will do research and report their findings / conclusions, if both are satisfied we can move on to integrating / implementing the thing\n\n1. We were not super comfortable with the scripting languages and technologies used\n    - Both Kirill and Eddie who were assigned to implement the scripts did not previously create shell scripts from scratch and rarely used Linux / didn't have a Linux VM installed\n    - After A1 submission we did not have confidence that our scripts worked as intended and we did not test them on machines other than Windows using WSL and Mac using Intel\n    - As a result of working on these tasks, both group members became more familiar with the scripting language and with some tweaks after the submission we have become fairly comfortable in the operation of these scripts\n    - A subsequent action we have already implemented is that multiple group members installed VMs of operating systems we did not natively have access to. For future scripts that we have or will implement, it will be the responsibility of the script maker to test it on all platforms it is advertised to work on unless their computer does not support Virtualization in which case they will have to talk with the team and find a peer to assign the task of testing to.\n\n## Immediate next steps\n\n- Eddie will create a pinned issue that outlines the order and process of our rotation outlined as a subsequent action for the first point that didn't go well\n",
    "timestamp": "2025-05-23T16:30:12.412011",
    "tags": [],
    "severity": "low",
    "services_affected": [
      "web"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "docker",
      "azure",
      "elasticsearch",
      "jenkins"
    ],
    "failure_pattern": null,
    "timeline_events": [],
    "blast_radius": "localized",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 0.54
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/androchentw/blog-hugo/blob/ac7e051a5fbc40e6f7d650541a134b9e4ed86d2e/content/tech/sre/2023-03-25-chatgpt-sre-postmortem.md",
    "title": "2023-03-25-chatgpt-sre-postmortem.md",
    "content": "---\ntitle: \"來點 SRE - 從 ChatGPT 停機公告，學維運事後剖析\"\nurl: chatgpt-sre-postmortem\n# date: 2023-03-25T06:00:00+08:00\ndate: 2023-03-25T08:25:00+08:00\nauthor: androchentw\ntype: post\ncategories:\n  - tech\ntags: \n  - sre\n  - chatgpt\n  - aigc\nshare_img: https://github.com/androchentw/blog-hugo/blob/main/content/tech/sre/2023-03-25-chatgpt-sre-postmortem-cover.png?raw=true\nseries: sre\n---\n\n<img style=\"width:80%;\" src=\"https://github.com/androchentw/blog-hugo/blob/main/content/tech/sre/2023-03-25-chatgpt-sre-postmortem-cover.png?raw=true\">\n<p align=\"center\"><sub><sup>\n  來點 SRE - 從 ChatGPT 停機公告，學維運事後剖析\n</sup></sub></p>\n\n## Overview 概述\n\nChatGPT 在美國時間 3/24(週五) 發布了新的一篇 blog，解釋 3/20(週一) ChatGPT 停機的來龍去脈。\n\n每一次的緊急維修，對於系統維運 SRE 來說都是意義非凡。因為這代表你的服務\n\n1. 重要到用戶會關注\n2. 必要到每分每秒都在產生價值 (不修復會造成損失)\n\n對於很多企業來說，停機好像是永遠不該發生的事。多半是偷偷改掉不讓用戶發現就過了，怎麼可能大張旗鼓地還發部落格？\n\n從這點就可以看出決定性的差異。\n\n🔎 **透明度，及其帶來的信任是關鍵**。「我們正在修，出於什麼原因-人事時地物，之後能怎麼避免」。好用，相信你能夠盡快修復的信任感 (Trust)，奠基於系統服務的穩定 (Reliability)\n\n❓ 提問: 你的團隊在意這些服務體驗嗎？ 一起來看 OpenAI 怎麼示範 SRE 中的 Postmortem (事後剖析)。\n\n<!--more-->\n\n## 什麼是 SRE 網站可靠性工程\n\nSRE (網站可靠性工程, Site Reliability Engineering) 是 Google 早在十年前就提出並且應用的一種[維運管理方法論](https://blog.cloud-ace.tw/application-modernization/devops/about-sre/):\n\n> SRE is what happens when you ask a software engineer to design an operations function. -- Benjamin Treynor Sloss (Vice President, Engineering, Google)\n>\n> SRE 就是當你去問一個軟體工程師如何設計一套維運方法的表現。\n\n[Google 有兩本 SRE 的免費電子書](https://blog.androchen.tw/google-sre-books)，非常推薦維運工程師好好研究。\n\nOpenAI 不是第一個這麼做的單位，事實上這已經是西方主流企業的顯學之一。\n\n## ChatGPT 3/20 停機剖析\n\n<img style=\"width:60%;\" src=\"https://github.com/androchentw/blog-hugo/blob/main/content/tech/sre/2023-03-25-chatgpt-sre-postmortem-post.png?raw=true\">\n<p align=\"center\"><sub><sup>\n  ChatGPT 在美國時間 3/24(週五) 發布了新的一篇 blog，解釋 3/20(週一) ChatGPT 停機的來龍去脈。\n</sup></sub></p>\n\n### Situation Analysis 狀況說明\n\n3/20(週一) ChatGPT 存在開源庫 redis-py 快取的漏洞，導致\n\n1. 部分用戶會看到別人的**聊天標題**\n2. 少了幾個小時的歷史訊息\n3. 在某 9 小時裡，1.2% 的活躍用戶中，ChatGPT Plus 訂閱者的**付款相關資訊**被意外洩露\n4. 包含: 名字、email、付款地址、信用卡號碼**末四碼**及信用卡到期日。完整的信用卡號碼並未曝光。\n\n發現狀況當下 OpenAI 立刻停機進行調查與修復，包括如何復現此狀況，並聯繫受影響的使用者。\n\n### Tech Details 技術細節\n\n簡單來說是 ChatGPT 採用的 Redis Cluster 的 Asyncio redis-py 客戶端，在異常處理時會導致**連線返回錯誤資料**。\n\nRedis 是一個 Cache 快取機制，在後端資料庫 (DB, Database) 跟用戶中間，讓你不用一直去跟 DB 拿資料，這樣 DB 就不會太忙，用戶的存取速度也會大幅提昇。在這個例子中，理應該被拒絕的 request，卻**意外發給了不對的用戶**。如今已透過開源社群的快速 patch 修復。\n\n### Actions 採取措施\n\nOpenAI 也條列了他們已經採取的措施:\n\n1. 大量**測試**，以確保修復。\n2. 增加**冗餘檢查**，以確保 Redis Cache 返回給正確的用戶。\n3. 改善**日誌 Log**，以識別問題並確認已停止。\n4. 識別受影響的用戶，以便**通知**他們。\n5. 增加 Redis cluster 的**穩定性和可擴展性**，減少在極端負載下，連線錯誤的可能性。\n\n身為 IT 從業人員，我只能說望塵莫及。\n\n你說差別在哪？基本上光是這 5 個項目，我只能說在我的周遭觀察過的，多半只做了修復單點 bug。「解完就沒事了」「祈禱他不要再發生」。\n\n* 至於要多少測試？「我先手動測一測就好了」\n* 回頭改善 Log？「那是別人的事」\n* 通知受影響用戶？「我趕快修一修就好」\n* 增加穩定性？「那個很複雜現在沒時間作」\n\n如此簡單易懂的道理，實行起來就是如此困難。而我們能做的只是每一次都盡可能引導身邊的同事，一起加入更有系統、有效率解決問題的行列。\n\n### Incident Managment 事件處理\n\n像是 status page 狀態頁面這類非常常見的可觀測性服務，若沒有將自己的服務視為重要的，那就很可能會忽略掉。\n\n<img style=\"width:60%;\" src=\"https://github.com/androchentw/blog-hugo/blob/main/content/tech/sre/2023-03-25-chatgpt-sre-postmortem-status-page.jpg?raw=true\">\n<p align=\"center\"><sub><sup>\n  Status Page\n</sup></sub></p>\n\n我們很常去談 monitoring 監控的重要性，什麼服務掛了我要自動知道。但是卻很少去談「服務掛了我要怎麼處理、甚至自動修復」。這就牽涉到 **\"Incident Managment 事件處理\" 與 \"Self Repairing 自我修復\"**。一個是讓事件受影響的人與環節能被充分討論，找出根因並徹底防範；另一個是如何減少人為操作成分，盡可能自動化。這些都是 SRE 裡會談的東西，也是我們能真正意義上讓服務自動維運的關鍵。\n\n## 運用工程手段，積極尋求解法\n\n在**一週內修復，並公開事後剖析報告，擬定下一步防範措施**。我想這應該比刻意隱瞞，被抓到了之後再「謝謝指教」來得有說服力的多。\n\n人非聖賢，孰能無過。關鍵是**如何不二過**。坦然面對，運用工程手段，積極尋求解法，這些都是再簡單不過的道理，但能如此自然採取行動的，卻總是少數。\n\n有效的維運管理需要有 \"**主動和解決問題的思維**\"。我想，關鍵在於**心態**:\n\n> **Take ownership and get things done.**\n\n## 你怎麼看?\n\n留下你的想法一起討論吧! 🥳\n\n延伸閱讀\n\n1. [2022 TSMC IT Day - 看台積電 CIO 如何以矽谷軟體公司思維打造 IT 數位轉型之路](https://blog.androchen.tw/2022-tsmc-it-day/)\n2. [DevOpsDays Taipei 2022 - 企業 IT 數位轉型投資成長 + 持續交付高品質可用產品](https://blog.androchen.tw/devopsdays-taipei-2022/)\n3. [AIGC 浪潮翻騰 15 週後的 6 大行為改變](https://blog.androchen.tw/6-behavior-change-after-AIGC-burst-15-weeks)\n\n### Murmur\n\n* 2023-03-25: 態度決定高度、心態決定境界。\n  * 這次還是寫了好久(2.5 hr) 😂, 下次再想想看怎麼拆解加速...\n",
    "timestamp": "2025-05-23T16:30:21.429196",
    "tags": [],
    "severity": "low",
    "services_affected": [
      "database",
      "cache",
      "queue",
      "monitoring"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "aws",
      "postgresql",
      "redis",
      "elasticsearch"
    ],
    "failure_pattern": "monitoring_blind_spot",
    "timeline_events": [],
    "blast_radius": "localized",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 0.8600000000000001
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/graysky/graysky.github.io/blob/7ced24796b0f4cc4bda0f7b2dfabd444aa6d27f6/_posts/2010/_posts/2010-02-08-downtime-postmortem.md",
    "title": "2010-02-08-downtime-postmortem.md",
    "content": "--- \ntitle: Downtime Postmortem\nlayout: post\ncategories: [code]\n---\n\nSince joining <a href=\"http://oneforty.com\">oneforty</a> last summer lots of things have gone well, but the mistakes we've made are usually more educational. The following is an attempt to capture the events that led to a brief site outage and some lessons learned.\n\nA few weeks ago we <a href=\"http://www.techcrunch.com/2010/01/14/oneforty-rolls-out-premium-twitter-app-marketplace-raises-1-9-million/\">rolled out an alpha version of our ecommerce platform</a> and the news was covered on a few blogs, including TechCrunch. At roughly the same time (it seemed) there were alerts about the amount of swap space on one or more of our servers. The alerts would typically flap between a warning and then return to normal levels. I figured the two events were related and that the alerts were due to increased traffic, but not a serious issue. \n\nLater in the evening as the alerts continued I investigated the situation. The site is built on Rails, running in Passenger and hosted on <a href=\"http://www.engineyard.com/\">Engine Yard's EC2-based cloud service</a>. Running <code>passenger-memory-stats</code> on our \"application master\" instance showed that there were about twice as many Rails processes as there should be, and there was a discrepancy between what <code>passenger-memory-stats</code> showed (total rails processes) and what <code>passenger-status</code> revealed (those that Passenger is actively using). There was less than 15MB of free memory and little swap left due to the stale processes. Not good.\n\nThen I put on the straw that broke the camel's back. While trying to kill one of the stale processes, the machine locked up when it ran out of swap space. The Engine Yard configuration has the \"app master\" server double as both an application server and the load balancer, through haproxy, to the other application instances. This means that when that instance became unresponsive, the whole site went down. So now the clock is ticking (and I'm swearing to myself).\n\nEngine Yard's service noticed within 60 seconds that the app master was unresponsive. It automatically killed the existing app master instance, promoted one of the other app clones to be the master and created a fresh app instance to replace the clone. This worked smoothly, except for two issues. When a new instance is created it is added to the load balancer <em>before</em> our gem installation is run, so there is a window of time when it would throw 500 errors. The EY flow of specifying required gems is through their web interface, instead of in our application's git repository. This is less than ideal (and <a href=\"https://cloud-support.engineyard.com/discussions/suggestions/42-make-deployments-programmable\">it appears it might change soon</a>), and we hadn't yet invested in a better workaround. Not wanting to wait for the gems to be installed, I terminated the newly booted clone.\n\nOnce the new app master was promoted, the site was back alive. The second problem was that EY doesn't automatically update the memcached config on each app server when an instance is terminated (<a href=\"https://cloud-support.engineyard.com/discussions/known-issues/4-memcachedyml-not-updated-when-an-app-instance-is-terminated\">also a known issue</a>), so we were suffering increased cache misses that made the site very slow. I fixed the memcached config issue manually and the site was back to full functionality. Total damage was about 10 of downtime, and another 10 minutes of slow-to-unusable site performance.\n\n<h3>Lessons Learned</h3>\n\nI'm a fan of the <a href=\"http://www.startuplessonslearned.com/2008/11/five-whys.html\">idea of proportional investment</a> when reacting to problems like this. The first instinct of most engineers, myself included, is that we need to build a sophisticated monitoring system, remove all single points of failure and have the site failover to redundant systems. Those are good goals, and maybe you eventually get there, but not until that level of investment is truly called for. Instead, we've taken the following steps:\n\n<ul>\n<li>Signed up for a more robust uptime monitor, <a href=\"http://pingdom.com\">Pingdom</a>, for better email/sms alerts.</li>\n\n<li>Fixed the issues causing stale processes. Initially it wasn't clear what was causing them to hang around after a deploy. The first step was to write a quick\ncapistrano task that would kill any detected during deploys. This at least addressed the symptom. After\nmore research (and a helpful pointer from EY's <a href=\"http://twitter.com/ezmobius\">Ezra</a>) it became clear that it was because of an interaction between <a href=\"http://vanity.labnotes.org/\">A/B testing framework vanity's handling of redis connections</a> and Passenger's forking model. A <a href=\"http://gist.github.com/283171\">patch to vanity</a> forced it to stop accidentally sharing a redis connection between processes to fix the underlying problem. (Passenger's model has real advantages but alters the \"shared nothing\" assumption many components make.)</li>\n\n<li>Working to get to a point where alerts and notifications do not become background noise. When they do it is too easy to ignore them and miss real issues. I think this always sounds easier than it is. Webapps have a lot of moving parts and receive many odd requests that can trigger alerts from machines, exception trackers and performance monitoring tools. There will be ongoing work to find the right thresholds and to address issues as they crop up.</li>\n\n</ul>",
    "timestamp": "2025-05-23T16:30:26.082449",
    "tags": [],
    "severity": "high",
    "services_affected": [
      "api",
      "web",
      "cache",
      "monitoring"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "kubernetes",
      "aws",
      "redis",
      "elasticsearch",
      "nginx",
      "haproxy",
      "jenkins"
    ],
    "failure_pattern": "configuration_drift",
    "timeline_events": [],
    "blast_radius": "localized",
    "detection_time": null,
    "mitigation_actions": [
      "traffic, but not a serious issue",
      "cache misses that made the site very slow"
    ],
    "quality_score": 0.9400000000000001
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/Etta-Diego/alx-system_engineering-devops/blob/b60f7661cd49d90332f43891a0ccacb27ec23d26/postmortem_two.md",
    "title": "postmortem_two.md",
    "content": "<!DOCTYPE html>\n<html>\n\n<head>\n  <meta charset=\"utf-8\">\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n  <title>postmortem_two</title>\n  <link rel=\"stylesheet\" href=\"https://stackedit.io/style.css\" />\n</head>\n\n<body class=\"stackedit\">\n  <div class=\"stackedit__html\"><div>  <h2>Postmortem: Nginx Not Listening on Port 80.</h2><h2>  </h2></div>\n<div>\n<img src=\"https://i.imgur.com/VtLKeHd.jpg\" alt=\"a man blocked his ears and a hand with speakers\">\n</div>\n<p><strong>Incident Summary:</strong></p>\n<div>\n  <img src=\"https://i.imgur.com/cO4Lxv9.png\" alt=\"meme of Mr Grub describing the incident\">\n</div>\n<p>Between the hours of 6:00 AM on August 10, 2024, and 10:00 AM on August 10, 2024, our web application experienced an outage. due to Nginx not listening on port 80 on a production server running Ubuntu. This incident was triggered by a misconfiguration change applied at 5:45 AM on August 10, 2024, during a routine server update. The configuration file for Nginx was inadvertently altered, preventing the service from binding to port 80. The issue was detected by our monitoring system, which alerted the on-call engineer. This high-severity incident affected 100% of incoming traffic to our application for approximately 4 hours, leading to a significant impact on user access. During this period, 150 support tickets were submitted, and the issue was widely discussed on social media.</p>\n<p>Leadup</p>\n<p><img src=\"https://i.imgur.com/zWw0qKy.jpg\" alt=\"enter image description here\"></p>\n<p>At 5:45 AM on August 10, 2024, approximately 15 minutes before the customer impact, a routine server update was performed on the production environment. This update included changes to the Nginx configuration file to improve performance. However, an error in the configuration syntax prevented Nginx from successfully binding to port 80, which is essential for handling HTTP requests. This misconfiguration went unnoticed due to the lack of syntax validation before deployment.</p>\n<p>Fault</p>\n<p><img src=\"https://i.imgur.com/kxiERIa.png\" alt=\"enter image description here\"></p>\n<p>The change implemented involved altering the Nginx configuration to adjust the default server block settings. However, a syntax error was introduced in the configuration file, specifically within the <code>listen</code> directive, which caused Nginx to fail in binding to port 80. Consequently, all HTTP requests to the server were rejected, resulting in a complete service outage. This misconfiguration led to 100% of incoming HTTP requests being rejected for the duration of the incident.</p>\n<p>Impact</p>\n<p><img src=\"https://i.imgur.com/YRxwUTH.jpg\" alt=\"enter image description here\"></p>\n<p>For 4 hours between 6:00 AM and 10:00 AM on August 10, 2024, our users experienced a complete outage of our web application due to Nginx not listening on port 80. This incident affected all active users of our web service, with an estimated 10,000 users unable to access the platform. During this period, 150 support tickets were submitted, and the incident was mentioned in over 300 social media posts, highlighting user frustration and concern.</p>\n<p>Detection</p>\n<p><img src=\"https://i.imgur.com/AObIG8j.png\" alt=\"enter image description here\"></p>\n<p>The incident was detected at 6:05 AM by our monitoring system, which triggered an alert due to the sudden drop in incoming traffic to the server. The on-call engineer was paged immediately, but there was a delay of 15 minutes in response time due to the engineer being unfamiliar with the specific configuration error. To improve time-to-detection, we plan to implement more rigorous configuration checks and automated syntax validation in our CI/CD pipeline, which would have cut the detection time by half.</p>\n<p>Response</p>\n<p><img src=\"https://i.imgur.com/55iZgCJ.png\" alt=\"enter image description here\"></p>\n<p>The on-call engineer responded to the page at 6:20 AM and began investigating the issue. However, due to the complexity of the configuration error, a second escalation was required. The escalated engineer, with specific knowledge of Nginx, was alerted at 6:35 AM and began working on the issue. The root cause was identified at 9:00 AM, and a corrected configuration file was deployed at 9:45 AM.</p>\n<p>Recovery</p>\n<p><img src=\"https://i.imgur.com/8hzbUHz.png\" alt=\"enter image description here\"></p>\n<p>The service was restored by reverting the Nginx configuration file to the last known working state and performing a syntax check before restarting the service. The service was fully operational again by 10:00 AM. To improve the time to mitigation, automated tests for configuration changes will be added to the deployment process, which could have potentially cut the recovery time by half.</p>\n<p>Timeline</p>\n<p><img src=\"https://i.imgur.com/9iwX2md.png\" alt=\"enter image description here\"></p>\n<p>5:45 AM UTC<br>\nRoutine server update applied; Nginx configuration file altered.</p>\n<p>6:00 AM UTC<br>\nNginx fails to bind to port 80; service outage begins.</p>\n<p>6:05 AM UTC \t<br>\nMonitoring system detects the issue; on-call engineer is paged.</p>\n<p>6:20 AM UTC<br>\nOn-call engineer responds; begins investigation.</p>\n<p>6:35 AM UTC<br>\nEscalation to a second engineer with Nginx expertise.</p>\n<p>9:00 AM UTC<br>\nRoot cause identified.</p>\n<p>9:45 AM UTC<br>\nCorrected configuration deployed<br>\n.<br>\n10:00 AM UTC<br>\nNginx successfully binds to port 80; service restored.</p>\n<p>Root Cause Identification: The Five Whys</p>\n<p><img src=\"https://i.imgur.com/WSpnPuG.jpg\" alt=\"enter image description here\"></p>\n<p>Why did the application have an outage?<br>\nBecause Nginx was not listening on port 80</p>\n<p>Why was Nginx not listening on port 80?**<br>\nBecause there was a syntax error in the Nginx configuration file.</p>\n<p>Why was there a syntax error in the configuration file?<br>\nBecause a misconfiguration was introduced during a routine update.</p>\n<p>Why was the misconfiguration not detected before deployment?<br>\nBecause there were no automated syntax checks in place during the deployment process.</p>\n<p>Why were there no syntax checks in the deployment process?<br>\nBecause the importance of syntax validation was underestimated in the CI/CD pipeline.</p>\n<p>Root Cause</p>\n<p><img src=\"https://i.imgur.com/TYlHLPg.jpg\" alt=\"enter image description here\"></p>\n<p>The root cause of the incident was a syntax error in the Nginx configuration file, combined with the lack of automated syntax validation in the deployment process.</p>\n<p>Backlog Check</p>\n<p><img src=\"https://i.imgur.com/MwN44iZ.png\" alt=\"enter image description here\"></p>\n<p>There were no specific items in the engineering backlog that could have prevented this incident. However, there were ongoing tasks related to improving the deployment process, including the addition of automated tests, which had not yet been prioritized.</p>\n<p>Recurrence</p>\n<p><img src=\"https://i.imgur.com/xdZZr3c.jpg\" alt=\"enter image description here\"></p>\n<p>A similar incident occurred two months prior, where a configuration error led to a partial outage. The mitigation at the time involved manual checks, which were not effective in preventing this incident. The lack of automated validation has been a recurring issue.</p>\n<p>Lessons Learnt</p>\n<p><img src=\"https://i.imgur.com/KWy29v6.png\" alt=\"enter image description here\"></p>\n<p>What went well:<br>\nThe monitoring system effectively detected the drop in traffic and triggered an alert.<br>\nWhat could have been improved:<br>\nThe response time was delayed due to the lack of familiarity with the configuration issue.<br>\nOpportunities for improvement:<br>\nAutomated syntax validation should be implemented to catch configuration errors before deployment.</p>\n<p>Corrective Actions</p>\n<p><img src=\"https://i.imgur.com/MuyxSLu.jpg\" alt=\"enter image description here\"></p>\n<p>Responsible: DevOps team<br>\nAction: Implement automated syntax validation for Nginx configurations in the CI/CD pipeline.<br>\nDeadline: September 1, 2024<br>\nTracking: Jira Ticket #NGX-7890</p>\n</div>\n</body>\n\n</html>\n",
    "timestamp": "2025-05-23T16:30:31.410625",
    "tags": [],
    "severity": "high",
    "services_affected": [
      "api",
      "web",
      "monitoring"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "kubernetes",
      "postgresql",
      "nginx",
      "jenkins"
    ],
    "failure_pattern": "configuration_drift",
    "timeline_events": [],
    "blast_radius": "global",
    "detection_time": null,
    "mitigation_actions": [
      "at 9:45 AM"
    ],
    "quality_score": 1.0
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/tabbykatz/portfolio/blob/2a5a539b37a7f9eb1916d8a802e0b323632639ff/writings/postmortem.md",
    "title": "postmortem.md",
    "content": "---\ntitle: \"Postmortem\"\ndate: \"2020-10-04\"\nog:\n  description: \"A technical blog entry for Holberton.\"\n  image: \"/postmortem.png\"\nauthor:\n  twitter: \"tabby__katz\"\n  name: \"Tabitha O'Melay\"\n---\n\n_How I Destroyed 3 Servers, Rebuilt Them, and Destroyed Them Again the Next\nDay_\n\n\n# Issue Summary\nI was issued 3 servers at midnight PST on August 14th, 2020 as part of my DevOps training, and directed to configure them as specified. Afterwards, I neglected to preserve my rsa private key upon replacing my laptop, killing all 3 servers. Lessons learned, the rebuild occurred on Sept 30th. During the rebuild I took extensive notes.\n\n\nOn the morning of October 1st, 2020, I destroyed web-01, apparently by locking port 22.\n\n\nThe issue was noticed upon reboot. All attempts to ssh back in failed.\n\n\nThe rebuild went well the day before, and the servers were all functioning as expected that morning. ufw rules were all perfectly set. The final commands I gave to web-01 were:\n\n```bash\nsudo hostnamectl set-hostname 1346-web-01\nsudo vim /etc/hosts [replacing old hostname manually with 1346-web-01 to make it persistent]\nsudo reboot\n```\n\n# Timeline\n\n![](/portmortem.png)\n\n\n- Thu Oct 1 08:48 — successfully logged into all servers from my VM\n- Thu Oct 1 09:15 — it was brought to my attention that I forgot to set persistent hostnames during the rebuild, so I did so following this tutorial, beginning with web-01, using what turned out to be my final commands to the server.\n- Thu Oct 1 09:50 — cannot ssh back into web-01, alert SWE in residence Kristen Loyd.\n- Thu Oct 1 09:55 — attempt to ssh back in after both soft and hard reboot.\n- Thu Oct 1 10:00 — many hours of research ranging from admin access to white hat breaking ufw.\n- Thu Oct 1 16:16 — Our CTO Guillaume Salva suggests he can get back in, gives it his best shot, but declares the server dead.\n- Sun 0ct 4 14:20 — I request a new server, satisfied that I have exhausted all possibilities for repair.\n\n# Root Cause and Resolution\nI am certain that my ufw rules were perfectly in place:\n\n```C\nsudo ufw enable\nsudo ufw status verbose\nsudo ufw default deny incoming\nsudo ufw default allow outgoing\nsudo ufw allow 22/tcp\nsudo ufw allow 443/tcp\nsudo ufw allow 80/tcp\nsudo ufw enable\nsudo ufw status\nsudo ufw allow 8080/tcp\nsudo vim /etc/ufw/before.rules\nsudo ufw enable \nsudo ufw status\n```\n\nI had taken thorough notes while rebuilding these servers, and logged back in as expected on the day in question. While inspecting web-02 after the event, I could see that ufw was working on the twin server.\n\n\nBecause there was no happy resolution to this issue, I surmise that using the command `sudo reboot` somehow reset my ufw rules, although I am baffled that ufw would be changed from the rules above to block port 22 by a simple reboot.\n\n\nThe ultimate “fix” was requesting new server, which I did just now.\n# Corrective and Preventative Measures\nWithout a clear understanding of the cause of this event, I cannot be sure of the best course of action to prevent its like again. What I know for certain is that until I do understand what happened, I will never trust ufw.\n\n\nHowever, there is work to be done now that I have requested a new server. it differs from the work of rebuilding all three servers but is not less work.\n\n- fix ssh configuration in my VM so that I can get into the new web-01 easily.\n- set up web-01 so that nginx is properly installed, and add key for staff access.\n- Set persistent hostname\n- fix my domain A records to reflect the new web-01\n- Add custom response header\n- Fix load balancer to reflect these changes\n- Re-certbot\n- Do not at any point in this process use ufw\n- Fix datadog monitoring for the setup\n# Takeaways\nI have learned a lot from these fiascos. My private key is now protected and saved in LastPass, for example. But the unresolved ufw reboot problem has taught me little. For now, I will keep ufw disabled until I have completed the server-oriented projects from my school.\n",
    "timestamp": "2025-05-23T16:30:32.555414",
    "tags": [],
    "severity": "low",
    "services_affected": [
      "web",
      "monitoring"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "aws",
      "azure",
      "elasticsearch",
      "nginx",
      "jenkins"
    ],
    "failure_pattern": "configuration_drift",
    "timeline_events": [],
    "blast_radius": "global",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 0.88
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/Mehdi-H/WeeklyCuration/blob/15461b102ac30bdb185675e84afd7b967871d794/EVERY_ISSUE.md",
    "title": "EVERY_ISSUE.md",
    "content": "# Every issue\n\n- [Every issue](#every-issue)\n    - [(Engineering) Management 👔](#engineering-management-)\n    - [AI 🤖](#ai-)\n    - [Architecture 📐](#architecture-)\n    - [Blockchain ⛓️](#blockchain-️)\n    - [Cloud ☁️](#cloud-️)\n    - [DDD 📘](#ddd-)\n    - [Data Mesh 🥅](#data-mesh-)\n    - [Data 💾](#data-)\n    - [Database 🧫](#database-)\n    - [DevOps \\& SRE 🛠️](#devops--sre-️)\n    - [FinOps 💸](#finops-)\n    - [Functional programming λ](#functional-programming-λ)\n    - [Living Documentation 📖💗](#living-documentation-)\n    - [MLOps 🧠⚙️](#mlops-️)\n    - [Miscellaneous 🎆](#miscellaneous-)\n    - [Platform📡](#platform)\n    - [Product Management 📦](#product-management-)\n    - [Productivity 👟](#productivity-)\n    - [Python 🐍](#python-)\n    - [QuantumComputing ⚛️](#quantumcomputing-️)\n    - [Security☣️](#security️)\n    - [Software Engineering ⚙️](#software-engineering-️)\n    - [Web Development 🧑‍💻](#web-development-)\n\n\n\n### (Engineering) Management 👔\n\n- 🎙️ [The Managing Managers Podcast - Pat Kua](https://managingmanagers.tech/)\n- 📝 [Engineering Leadership Tactics: Building Alignment (Francisco Trindade)](https://franciscomt.medium.com/leadership-tactics-building-alignment-65ec9d2b4bcf) | #Alignment #Consensus #ImprovementKata #Lean #Metrics #Nemawashi #RFCs\n- 📝 [Netflix’s historic introduction of levels for software engineers - The Pragmatic Engineer (Gergely Orosz)](https://blog.pragmaticengineer.com/netflix-levels/) | #CarreerFramework #IndividualContributor #PrincipalEngineer #SeniorEngineer #StaffEngineer\n- 📝 [Your software architecture is complex as your organization - Dr. Milan Milanovic](https://newsletter.techworld-with-milan.com/p/your-architecture-is-complex-as-your) | #Amazon #CodeQuality #Conway'sLaw #Facebook #Google #Graphs #LinesOfCommunication #Microsoft #OrganizationalStructure\n- 📽️  [Work Anywhere: Managing Remote Engineering Teams at Airbnb (Jessica Tai • YOW! 2022)](https://www.youtube.com/watch?v=7cPOa5FX_Rw&t=1138s) | #DesignDocs #FullRemote #MultipleTimezones #NoAgendaNoMeeting #RFCs #RemoteManager #WorkFromAnywhere\n- 🧰 [Gitlab’s Objectives and Key Results (OKRs) handbook](https://about.gitlab.com/company/okrs/) | #OKR\n- 🧰 [The Engineering in Engineering Manager (slides from StretchCon2023) - Pat Kua](https://speakerdeck.com/patkua/the-engineering-in-engineering-manager?slide=3) | #Definitions #EngineeringManagement #Flow #Performance #Quality #Scope\n\n### AI 🤖\n\n- 🎙️ [E33: The Tiny Model Revolution with Ronen Eldan and Yuanzhi Li of Microsoft Research (The Cognitive Revolution \"How AI Changes Everything”)](https://open.spotify.com/episode/7BqSNRLQP6rAihEp5VexD6) | #HuggingFace #TinyModels\n- 🐦 [François Chollet - Introducing Keras Core: Keras for TensorFlow, JAX, and PyTorch](https://twitter.com/fchollet/status/1678777783848419330) | #JAX #Keras #PyTorch #TensorFlow\n- 🐦 [Hype Cycle of Artificial Intelligence 2023 - Gartner](https://twitter.com/KirkDBorne/status/1686405713713590272) | #ArtificialGeneralIntelligence #CausalAI #GenerativeAI #KnowledgeGraphs #NeuroSymbolicAI #NeuromorphicComputing\n- 🐦 [joonspk-research/generative_agents - Interactive Simulacra of Human Behavior](https://github.com/joonspk-research/generative_agents) | #GenerativeAgents #Simulation #VideoGames\n- 🐦 [kNN using a gzip-based distance metric outperforms BERT and other neural methods for OOD sentence classification (Riley Goodside)](https://twitter.com/goodside/status/1679358632431853568) | #BERT #Benchmark #Gzip #TextClassification\n- 📝 [AI Could Change How Blind People See the World](https://www.wired.com/story/ai-gpt4-could-change-how-blind-people-see-the-world/) | #GPT-4 #R&D\n- 📝 [Actors say Hollywood studios want their AI replicas — for free, forever (2023’s strike)](https://www.theverge.com/2023/7/13/23794224/sag-aftra-actors-strike-ai-image-rights) | #AI #ActorsStrike #Copyright #Industry #Trivia🎈\n- 📝 [Bad numbers in the “gzip beats BERT” paper?](https://kenschutte.com/gzip-knn-paper/)\n- 📝 [Chat your data in Microsoft Fabric with Semantic Kernel | Microsoft Fabric Blog | Microsoft Fabric](https://blog.fabric.microsoft.com/en-GB/blog/chat-your-data-in-microsoft-fabric-with-semantic-kernel/)\n- 📝 [FTC investigates OpenAI over data leak and ChatGPT’s inaccuracy (Washington Post)](https://www.washingtonpost.com/technology/2023/07/13/ftc-openai-chatgpt-sam-altman-lina-khan/) | #ChatGPT #ConsumerProtectionLaws #Industry #OpenAPI #SlidesDeck\n- 📝 [Gartner Identifies Top Trends Shaping the Future of Data Science and Machine Learning](https://www.gartner.com/en/newsroom/press-releases/2023-08-01-gartner-identifies-top-trends-shaping-future-of-data-science-and-machine-learning) | #CloudDataEcosystems #DataCentricAI #EdgeAI #Industry #ResponsibleAI #Trends\n- 📝 [How Alexa learned to speak with an Irish accent](https://www.amazon.science/blog/how-alexa-learned-to-speak-with-an-irish-accent) | #ChatBot🤖🗣️ #TextToSpeech #Trivia🎈\n- 📝 [Improving Image Generation with Better Captions ( DALL-E 3, OpenAI, 2023)](https://cdn.openai.com/papers/dall-e-3.pdf) | #CaptionImprovement #DALL·E #ResearchPaper\n- 📝 [Introducing English as the New Programming Language for Apache Spark](https://www.databricks.com/blog/introducing-english-new-programming-language-apache-spark) | #AI #Data #Databricks #Spark\n- 📝 [Large Language Models: From Prototype to Production (Ines Montani, EuroPython2023 keynote)](https://speakerdeck.com/inesmontani/large-language-models-from-prototype-to-production-europython-keynote) | #LLM #NER #NLP #Prodigy #Spacy\n- 📝 [Llama 2: Open Foundation and Fine-Tuned Chat Models (paper - Meta AI)](https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/) | #Paper #R&D\n- 📝 [Llama 2: Open source, free for research and commercial use (website - Meta AI)](https://ai.meta.com/llama/)\n- 📝 [Llama 2: Statement of Support for Meta’s Open Approach to Today’s AI](https://about.fb.com/news/2023/07/llama-2-statement-of-support/)\n- 📝 [Microsoft says it will take the heat if Copilot AI commercial users get sued - The Verge](https://www.theverge.com/2023/9/7/23863349/microsoft-ai-assume-responsibility-copyright-lawsuit) | #Copyright #GithubCopilot #Industry #Law\n- 📝 [Multimodality and Large Multimodal Models (Chip Huyen)](https://huyenchip.com/2023/10/10/multimodal.html) | #CLIP #Flamingo #MultiModal #Speech #Vision\n- 📝 [NeurIPS 2023 Machine Unlearning Challenge](https://unlearning-challenge.github.io/) | #AI #LLM #Privacy #Regulations #RightToBeForgotten\n- 📝 [Nvidia's new A.I. chip claims it will drop the costs of running LLMs](https://www.cnbc.com/2023/08/08/nvidia-reveals-new-ai-chip-says-cost-of-running-large-language-models-will-drop-significantly-.html?__source=sharebar|linkedin&par=sharebar) | #Cost #Hardware #Industry\n- 📝 [Open challenges in LLM research](https://huyenchip.com/2023/08/16/llm-research-open-challenges.html?utm_source=tldrai) | #GPUAlternatives #Hallucination #LLM #Optimization\n- 📝 [Patterns for building LLM based systems and products (Eugene Yan)](https://eugeneyan.com/writing/llm-patterns/) | #BLEU #Evaluation #FineTuning #Hallucination #ROUGE #RetrievalAugmentedGeneration\n- 📝 [Perspectives on diffusion](https://sander.ai/2023/07/20/perspectives.html) | #AutoEncoders #DiffusionModels #LatentVariables\n- 📝 [Plot Twist : Stack Overflow is announcing OverflowAI](https://stackoverflow.blog/2023/07/27/announcing-overflowai/) | #AI #Agent #Platform\n- 📝 [Reflections on AI Engineer Summit 2023 (Eugene Yan)](https://eugeneyan.com/writing/aieng-reflections/)\n- 📝 [Skyrim Mod Powered by ChatGPT Gives NPCs Memories](https://opendatascience.com/skyrim-mod-powered-by-chatgpt-gives-npcs-memories/) | #ChatGPT #Trivia🎈 #VideoGames\n- 📝 [State of AI 2023 (McKinsey)](https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai-in-2023-generative-ais-breakout-year) | #GenerativeAI #StateOfTheArt\n- 📝 [State of AI Report 2023 (Nathan Benaich, AirStreetCapital)](https://www.stateof.ai/) | #AlphaZero #ComputeIsTheNewOil #DeepMind #DiffusionModels #GPT-4 #GenerativeAI #LLM #LLama🦙 #PaLM-E #RLHF #Robotics\n- 📝 [State of Computer Vision 2023 (Sebastian Raschka)](https://magazine.sebastianraschka.com/p/ahead-of-ai-10-state-of-computer) | #Attention #ComputerVision #DiffusionModels #GenerativeAI #LLM #StateOfTheArt #Transformers\n- 📝 [The Fall of Stack Overflow ? - Diminution of traffic of about 35% in the last year (dataviz)](https://observablehq.com/@ayhanfuat/the-fall-of-stack-overflow) | #Cannibalization #ChatGPT\n- 📝 [The NeverEnding Game: How AI Will Create a New Category of Games (Jonathan Lai)](https://a16z.com/2023/07/19/the-neverending-game-how-ai-will-create-a-new-category-of-games/) | #DynamicWorldBuilding #GenerativeAgents #NarrativeStorytelling #Personalization #VideoGames\n- 📝 [The Rise of Applied AI Engineers and the Shift in AI Skillsets](https://softlandia.fi/en/blog/the-rise-of-applied-ai-engineers-and-the-shift-in-ai-skillsets) | #AI #DataScience #MLOps #SoftwareEngineering\n- 📝 [Urtopia Unveils the World's First Smart E-Bike with ChatGPT Integration at EUROBIKE 2023](https://newurtopia.de/en/blogs/blog/smart-e-bike-with-chatgpt-urtopia-eurobike2023) | #ChatGPT #Trivia🎈\n- 📝 [🇫🇷 Construire son RAG (Retrieval Augmented Generation) grâce à langchain: L’exemple de l’Helpdesk d’OCTO - (Florian BASTIN, Nicolas CAVALLO - Blog OCTO Talks !)](https://blog.octo.com/le-chatbot-docto-langchain-rag-et-code-associe/) | #LangChain #RetrievalAugmentedGeneration\n- 📝 [🇫🇷 Docaposte lance son offre d’IA générative et souveraine (ChannelNews.fr)](https://www.channelnews.fr/docaposte-lance-son-offre-dia-generative-et-souveraine-129266) | #Alfred40B #Europe #GenerativeAI #LaPoste #NumSpot #Outscale #SecNumCloud #SovereignCloud\n- 📽️  [Andrej Karpathy’s state of GPT (@Microsoft Build 2023)](https://www.youtube.com/watch?v=bZQun8Y4L2A) | #ChatGPT #DataCollection #LLM #LLama🦙 #Training\n- 📽️  [Compliant Mechanisms that learn - Mechanical Neural Network Architected Materials](https://www.youtube.com/watch?v=_CwUuyN6NTE&t=3s) | #ArchitectedMaterial #NeuralNetworks #Physics #R&D\n- 📽️  [JupyterCon 2023 videos are available](https://www.youtube.com/playlist?list=PL_1BH3ug7n1Ih_Yy2TmM7MZ2zogSLZvzE) | #Conference #JupyterHub #JupyterLab #JupyterNotebooks\n- 📽️  [Training AI to Play Pokemon with Reinforcement Learning (video & code, Peter Whidden)](https://www.youtube.com/watch?v=DcYLT37ImBY) | #Pokemon #PokemonRed #ReinforcementLearning\n- 🗓️ [First edition of COLM (Conference On Language Models) is announced for Oct. 2024, CFP is open](https://colmweb.org/) | #CFP #Conference #LLM\n- 🗓️ [NeurIPS 2023 will happen Sunday Dec. 10 through Saturday Dec. 16](https://nips.cc/) | #Conference #MachineLearning #NeurIPS #Neuroscience\n- 🗓️ [apply(ops)23 will be 14 November (virtual conference) (Tecton)](https://www.tecton.ai/apply/) | #LLM #MLOps #MachineLearningEngineering #MultiCloud\n- 🚀 [Announcing Mistral 7B (MistralAI)](https://mistral.ai/news/announcing-mistral-7b/) | #128kTokens #FlashAndFurious #OpenSource #OpenSourceCode #OpenSourceWeights #SlidingWindowAttention\n- 🚀 [ChatGPT can now see, hear, and speak (OpenAI)](https://openai.com/blog/chatgpt-can-now-see-hear-and-speak) | #ChatAboutImages #ChatGPT #MultiModal\n- 🚀 [DALL·E 3 is out (OpenAI)](https://openai.com/dall-e-3)\n- 🚀 [Do Machine Learning Models Memorize or Generalize?](https://pair.withgoogle.com/explorables/grokking/)\n- 🚀 [TensorFlow 2.13 and Keras 2.13 are out](https://blog.tensorflow.org/2023/07/whats-new-in-tensorflow-213-and-keras-213.html)\n- 🧰 [AntonOsika/gpt-engineer - Specify what you want it to build, the AI asks for clarification, and then builds it.](https://github.com/AntonOsika/gpt-engineer)\n- 🧰 [Automated code reviews with code-review-gpt](https://github.com/mattzcarey/code-review-gpt) | #CodeReview #DeadCode #ExposedSecrets\n- 🧰 [Compilation of high-profile real-world examples of failed machine learning projects](https://github.com/kennethleungty/Failed-ML) | #BadStartupIdeas #Bias #Fail #Overfit #Trivia🎈\n- 🧰 [It's now possible to block ChatGPT's crawler on any website](https://platform.openai.com/docs/gptbot) | #Robots.txt\n- 🧰 [MilesCranmer/awesome-ml-demos: Curated list of interactive ML demos](https://github.com/MilesCranmer/awesome-ml-demos) | #Code #InteractiveDemo #MachineLearning\n- 🧰 [jason718/awesome-self-supervised-learning: A curated list of awesome self-supervised methods](https://github.com/jason718/awesome-self-supervised-learning) | #ComputerVision #MachineLearning #NLP #SelfSupervised #Speech\n- 🧰 [kelvins/awesome-mlops - A curated list of awesome MLOps tools](https://github.com/kelvins/awesome-mlops) | #AutoML #DataCatalog #MachineLearningPlatform #ModelFairness #Privacy\n\n### Architecture 📐\n\n- 📝 [AWS SQS, SNS, Kinesis, EventBridge : How to choose ?](https://dev.to/onepoint/aws-sqs-sns-kinesis-eventbridge-how-to-choose--32l7) | #AWS #EventBridge #Kinesis #Messaging #Queue #SNS #SQS\n- 📝 [Announcing updates to the AWS Well-Architected Framework guidance (AWS Architecture Blog)](https://aws.amazon.com/fr/blogs/architecture/announcing-updates-to-the-aws-well-architected-framework-guidance/) | #CostOptimization #OperationalExcellence #Reliability #Security #Sustainability\n- 📝 [Building a reliable notification system - (Joseph-Emmanuel Banzio, Contentsquare Engineering Blog)](https://engineering.contentsquare.com/2023/building-a-reliable-notification-system/) | #ContentSquare #Grafana #Kafka #Microservices #Notification #Observability #Scalability #UserJourney\n- 📝 [CAP Theorem: Use It to Choose an Open Source Database - Open Source For You](https://www.opensourceforu.com/2023/09/cap-theorem-use-it-to-choose-an-open-source-database/) | #Availability #CAP #Consistency #PartitionTolerance #Schema&Examples\n- 📝 [Cloudflare is moving away from Nginx (2022)](https://rodneyosodo.medium.com/cloudflare-is-moving-away-from-nginx-248831c3b22) | #Cloudflare #Network #Nginx #Pingora #Rust\n- 📝 [Fallacies of Distributed Systems (Mahdi Yusuf @ ArchitectureNotes)](https://architecturenotes.co/fallacies-of-distributed-systems/) | #Bandwidth #Latency #Network #Schema&Examples #Security\n- 📝 [Goodbye to sequential integers, hello UUIDv7! - Buildkite](https://buildkite.com/blog/goodbye-integers-hello-uuids) | #MillisecondPrecision #TimeOrdered #UUID #v7\n- 📝 [How Zalando migrated their shopping carts to Amazon DynamoDB from Apache Cassandra (AWS Database Blog)](https://aws.amazon.com/fr/blogs/database/how-zalando-migrated-their-shopping-carts-to-amazon-dynamodb-from-apache-cassandra/) | #ApacheCassandra #CaseStudies #DynamoDB #Migration\n- 📝 [How platform teams get stuff done (Pete Hodgson, martinfowler.com)](https://martinfowler.com/articles/platform-teams-stuff-done.html) | #Adoption #Collaboration #Conway'sLaw #Platform #Productivity #TeamTopologies\n- 📝 [How we built Pingora, the proxy that connects Cloudflare to the Internet (Cloudflare)](https://blog.cloudflare.com/how-we-built-pingora-the-proxy-that-connects-cloudflare-to-the-internet/) | #HTTP #Nginx #Optimization #Performance #Proxy #Rust\n- 📝 [Implementing AWS Well-Architected best practices for Amazon SQS – Part 1](https://aws.amazon.com/fr/blogs/compute/implementing-aws-well-architected-best-practices-for-amazon-sqs-part-1/) | #AWS #Cloud #Queue #SQS #event-driven\n- 📝 [Implementing AWS Well-Architected best practices for Amazon SQS – Part 2](https://aws.amazon.com/fr/blogs/compute/implementing-aws-well-architected-best-practices-for-amazon-sqs-part-2/) | #AWS #Cloud #Queue #SQS #event-driven\n- 📝 [Implementing AWS Well-Architected best practices for Amazon SQS – Part 3](https://aws.amazon.com/fr/blogs/compute/implementing-aws-well-architected-best-practices-for-amazon-sqs-part-3/) | #AWS #Cloud #Queue #SQS #event-driven\n- 📝 [Interesting Learnings from Outages (Real-World Engineering Challenges #10)](https://newsletter.pragmaticengineer.com/p/real-world-engineering-10) | #Caching #DNS #Github #Investigation #PostMortem #Reddit #SLI/SLO\n- 📝 [Internal and external events, or how to design event-driven API (Event-Driven.io)](https://event-driven.io/en/internal_external_events/) | #ContextMapping #EventsAsAPI #ExternalEvents #InternalEvents\n- 📝 [Mastodon : How we reduced the cost of building Twitter at Twitter-scale by 100x – Red Planet Labs](https://blog.redplanetlabs.com/2023/08/15/how-we-reduced-the-cost-of-building-twitter-at-twitter-scale-by-100x/) | #100xLessCode #Rama #S3 #Soapbox #Spring\n- 📝 [PostgreSQL: No More VACUUM, No More Bloat (Alexander Korotkov)](https://www.orioledata.com/blog/no-more-vacuum-in-postgresql/) | #Database #LowLevel #PostgreSQL\n- 📝 [RedisGraph End-of-Life Announcement](https://redis.com/blog/redisgraph-eol/) | #Redis #RedisGraph #Sunset\n- 📝 [Scaling Kubernetes to 7,500 nodes (OpenAI)](https://openai.com/research/scaling-kubernetes-to-7500-nodes) | #CLIP #DALL·E #GPT-3 #GPU #Kubernetes #Scalability\n- 📝 [Seven Principles of Cloud-Native Architecture - Alibaba Cloud](https://www.alibabacloud.com/blog/seven-principles-of-cloud-native-architecture_598431) | #DevOps #Elasticity #Observability #Resilience #ServiceOriented #ZeroTrustSecurity\n- 📝 [Twelve-factor app development on Google Cloud (Cloud Architecture Center)](https://cloud.google.com/architecture/twelve-factor-app-development-on-gcp) | #Cloud #GCP #Methodology #TwelveFactorApp\n- 📝 [What Every Programmer Should Know About Memory  (Ulrich Drepper, RedHat - 2007)](https://people.freebsd.org/~lstewart/articles/cpumemory.pdf) | #CPU #Hardware #LowLevel #Memory #RAM\n- 📽️  [Best Kafka Summit vídeos - Recording and slides of talks @ Kafka Summit since 2018 (kafka.apache.org)](https://kafka.apache.org/videos) | #Fundamentals #Internals #Kafka #UseCases\n- 📽️  [Duck Conf 2023 replay is available 🦆🇫🇷](https://www.youtube.com/playlist?list=PLXlbmbYadKH5H6F1Ml3pOqe0hiyknsPkF) | #Analytics #Architecture #Conference #DevOps #GreenIT #InformationSystem #Platform #SRE #SovereignCloud\n- 📽️  [Fabulous Fortunes, Fewer Failures, and Faster Fixes from Functional Fundamentals - Scott Havens (DOES2019 Las Vegas)](https://www.youtube.com/watch?v=FskIb9SariI&t=1s) | #ConferenceTalk #EventSourcing #FunctionalProgrammingλ #Kakfa #Production\n- 📽️  [The lost art of software design (Simon Brown)](https://www.youtube.com/watch?v=UzFpFQgeEyc)\n- 📽️  [[Live coding] C4 Models as Code • Simon Brown • YOW! 2022](https://www.youtube.com/watch?v=4aiAkUm7rzQ) | #C4Model #C4PlantUML #DiagramAsCode #LivingDocumentation #Structurizr\n- 🗓️ [Duck Conf 2024 will be 26th of March 🦆🇫🇷](https://event.inwink.com/la-duck-conf-2024) | #Architecture #Conference\n- 🗓️ [P99 CONF is next week](https://www.p99conf.io/) | #CQRS #Optimization #Performance\n- 🗓️ [PGConf NYC 2023 is this week](https://postgresql.us/events/pgconfnyc2023/schedule/) | #Conference #PostgreSQL\n- 🚀 [Introducing Apache Kafka 3.6 (Confluent)](https://www.confluent.io/blog/introducing-apache-kafka-3-6/?utm_source=twitter&utm_medium=organicsocial&utm_id=tm.devx_ch.bp_introducing-apache-kafka-3-6_content.apache-kafka) | #Kafka #MajorRelease #ZookeeperDeprecated\n- 🧰 [Architecting disaster recovery for cloud infrastructure outages on GCP](https://cloud.google.com/architecture/disaster-recovery) | #Availability #CapabilityMapping #DDDEurope2023 #DisasterRecovery #RPO #RTO #Resilience\n- 🧰 [ByteByteGoHq/system-design-101: Explain complex systems using visuals and simple terms. Help you prepare for system design interviews.](https://github.com/ByteByteGoHq/system-design-101) | #CI/CD #CaseStudies #CommunicationProtocols #Database #FunctionalChecks #SystemDesign\n- 🧰 [Catalog of 65 integration patterns (Enterprise Integration Patterns, Gregor Hohpe)](https://www.enterpriseintegrationpatterns.com/patterns/messaging/toc.html)\n- 🧰 [Software architecture hype cycle (Milan Milanovic)](https://www.linkedin.com/posts/milanmilanovic_technology-softwareengineering-programming-activity-7084818676960440320-f949) | #Adopt #CQRS #Microservices #Serverless #SoftwareEngineering\n- 🧰 [Tech blogs & talks from (at least) 30 companies that run Kafka in production](https://github.com/dttung2905/kafka-in-production) | #Industry #Kafka #Production\n- 🧰 [The Apache Kafka Handbook (Gerard Hynes)](https://www.freecodecamp.org/news/apache-kafka-handbook/) | #CoreConcepts #EventDrivenArchitectures #EventStreaming #Zookeeper\n- 🧰 [Thoughtworks Technology Radar #29 (Sept. 2023)](https://www.thoughtworks.com/content/dam/thoughtworks/documents/radar/2023/09/tr_technology_radar_vol_29_en.pdf) | #AIAssistedSoftwareDevelopment #DataProduct #DataProductThinking #HowProductiveIsMeasuringProductivity #LLM #Radar #RemoteSoftwareDelivery #Technology\n\n### Blockchain ⛓️\n\n- 🐦 [Introducing Polygon 2.0 and transition from MATIC to POL](https://twitter.com/LayerE_Intern/status/1679434845577961472) | #Blockchain #Governance #Polygon #Token\n\n### Cloud ☁️\n\n- 🎙️ [The Promise of Serverless (SaaS for Developers podcast, by Gwen Shapira)](https://open.spotify.com/episode/7n1JuoFviQjKvEeO6uPYiF) | #AWS #FinOps #Performance #S3 #Scalability\n- 📝 [AWS Begins Charging For Public IPv4 Addresses](https://www.lastweekinaws.com/blog/breaking-aws-begins-charging-for-public-ipv4-addresses/)\n- 📝 [Announcing DynamoDB local version 2.0](https://aws.amazon.com/fr/about-aws/whats-new/2023/07/dynamodb-local-version-2-0/) | #AWS\n- 📝 [Azure AD is becoming Microsoft Entra ID](https://azure.microsoft.com/en-us/updates/azure-ad-is-becoming-microsoft-entra-id/) | #Azure\n- 📝 [Building and operating a pretty big storage system called S3](https://www.allthingsdistributed.com/2023/07/building-and-operating-a-pretty-big-storage-system.html) | #AWS #Cost #Performance #S3\n- 📝 [Forbes - The Cloud 100 2023](https://www.forbes.com/lists/cloud100/) | #BillionsOfDollarsValuation #Industry #Ranking #Trivia🎈\n- 📝 [How to choose a containerized service on AWS (AWS documentation)](https://aws.amazon.com/fr/getting-started/decision-guides/containers-on-aws-how-to-choose/)\n- 📝 [Lessons learned - Discontinuation of InfluxDB Cloud in AWS Sydney and GCP Belgium](https://www.influxdata.com/blog/update-from-influxdata-paul-dix-july-10/) | #DataLoss #InfluxDB #MeaCulpa #PostMortem\n- 📝 [Microsoft Azure generated 34b in revenue in FY22, about half of the revenue of AWS](https://www.bigtechwire.com/2023/06/30/microsoft-azure-generated-34b-in-revenue-in-fy22-about-half-of-the-revenue-of-aws/) | #Industry #Trivia🎈\n- 📝 [Prime Day 2023 – All the Numbers (AWS)](https://aws.amazon.com/fr/blogs/aws/prime-day-2023-powered-by-aws-all-the-numbers/) | #AWS #Petabytes #TrillionsOfRequests\n- 📝 [Surfacing performance issues with effective visualization of profiling data (Lily Chen, Datadog)](https://lilychencodes.medium.com/surfacing-performance-issues-with-effective-visualization-of-profiling-data-7ac4430950d3) | #Barbenheimer #CallGraph #FlameGraph #FlameScope #Observability #Performance\n- 📝 [The State of Serverless 2023 (Datadog)](https://www.datadoghq.com/state-of-serverless/) | #AWS #AZF #Adoption #FullyManagedContainerBasedServerless #GCP #Lambda #Serverless\n- 📝 [Top 10 Azure Functions Anti-Patterns | by Tsuyoshi Ushio | Oct, 2023 | Medium](https://tsuyoshiushio.medium.com/top-10-azure-functions-anti-patterns-690ccff04a58)\n- 📝 [Understanding AWS Lambda proactive initialization (Aaron Stuyvenberg)](https://aaronstuyvenberg.com/posts/understanding-proactive-initialization) | #AWS #ColdStart #Lambda #WarmUp\n- 🚀 [Announcing AWS Dedicated Local Zones](https://aws.amazon.com/about-aws/whats-new/2023/08/aws-dedicated-local-zones/)\n- 🚀 [Apache Flink now available on Azure](https://techcommunity.microsoft.com/t5/analytics-on-azure-blog/introducing-apache-flink-on-azure-hdinsight-on-aks/ba-p/3936611)\n- 🚀 [Azure CLI 2.53.0 is out ](https://github.com/MicrosoftDocs/azure-docs-cli/blob/main/docs-ref-conceptual/release-notes-azure-cli.md#september-26-2023) | #Azure #CLI\n- 🚀 [Azure Functions: Node.js v4 programming model is Generally Available (Microsoft)](https://techcommunity.microsoft.com/t5/apps-on-azure-blog/azure-functions-node-js-v4-programming-model-is-generally/ba-p/3929217?wt.mc_id=AZ-MVP-5004195) | #AZF #NodeJS\n- 🚀 [New Seventh-Generation General Purpose Amazon EC2 Instances (M7i-Flex and M7i)](https://aws.amazon.com/fr/blogs/aws/new-seventh-generation-general-purpose-amazon-ec2-instances-m7i-flex-and-m7i/) | #AWS #EC2 #Intel®Xeon®Scalable\n- 🚀 [PostgreSQL 16 Release Candidate 1 is now available in Amazon RDS Database Preview Environment](https://aws.amazon.com/about-aws/whats-new/2023/08/postgresql-16-release-candidate-1-amazon-rds-database-preview-environment/)\n- 🚀 [Support for Python 3.11 in Azure Functions generally available (Microsoft)](https://azure.microsoft.com/fr-fr/updates/ga-support-for-python-311-in-azure-functions/?wt.mc_id=AZ-MVP-5004195) | #AZF #Python\n- 🧰 [State of Cloud 2023 (by Pluralsight)](https://www.pluralsight.com/resource-center/state-of-cloud-2023) | #StateOfTheArt\n\n### DDD 📘\n\n- 🎙️ [🇫🇷 Introduction à Domain-Driven Design avec Nelson da Costa (Podcast Café Craft)](https://podcasts-francais.fr/podcast/cafe-craft/episode-4-domain-driven-design-avec-nelson-da-cost) | #DDD #Introduction\n- 🐦 [CRUD System vs Event Sourcing illustrated (Alex Xu)](https://twitter.com/alexxubyte/status/1707415524374966673) | #DynamicWorldBuilding #EventSourcing\n- 🐦 [DDD Europe 2024  CFP for DDD Foundations is open](https://twitter.com/ddd_eu/status/1715305613549252969) | #CFP #Conference\n- 🐦 [DDDEurope2024’s call for proposal is open](https://twitter.com/ddd_eu/status/1681658780772122624) | #CFP #Conference #SoftwareModelling\n- 📝 [Balancing Coupling in Software Design (Vladik Khononov)](https://speakerdeck.com/vladikk/balancing-coupling-in-software-design-kandddinsky-2022) | #DDDEurope2023 #KanDDDinsky2022 #SoftwareEngineering\n- 📝 [Cloud Automation à la DDD: From stringly typed to affordances (Gregor Hohpe)](https://architectelevator.com/cloud/ddd-technical-domains/)\n- 📝 [Domain-Driven Cloud: Aligning Your Cloud Architecture to Your Business Model (InfoQ - Ryan Shriver & Chris Belyea)](https://www.infoq.com/articles/domain-driven-cloud/) | #BizDevOps #DomainDrivenCloud\n- 📝 [Evolution Patterns of Sociotechnical Systems (Amal Tahri @ DDDEurope2023)](https://speakerdeck.com/amta/ddd-europe-2023-evolution-patterns-of-sociotechnical-systems)\n- 📝 [Systems thinking in large-scale modeling (Xin Yao)](https://speakerdeck.com/xinyao/dddeu2023-keynote-systems-thinking-in-large-scale-modeling) | #DDDEurope2023 #FeedbackLoop #Methodology #OOP23Munich #SystemsThinking\n- 📝 [What is Example-Mapping? - How to coach developers to get a chat with their product experts (Philippe Bourgau)](https://philippe.bourgau.net/how-to-coach-developers-to-get-a-chat-with-their-product-experts/) | #BehaviorDrivenDevelopment #Collaboration #Discussion #Product #Scoping #Workshop\n- 📝 [🇫🇷 Retour sur la conférence EventSourcing Live @ DDD Europe 2023 (Mehdi Houacine, Sofia Calcagno)](https://www.linkedin.com/feed/update/urn:li:activity:7081697211239026690/) | #Architecture #Conference #event-driven\n- 📽️  [A Daily Practice of Empirical Software Design - Kent Beck - DDD Europe 2023 - (YouTube)](https://www.youtube.com/watch?v=yBEcq23OgB4&list=PLf9p-N3ltMTtMHSSGiTPZwdDvn0F2Mmp3)\n- 🧰 [Wardley Mapping templates (Tangible concepts)](https://tangible-concepts.de/wardley-mapping-templates) | #DDD #Toolbox #Wardley map\n\n### Data Mesh 🥅\n\n- 📚 [Implementing Data Mesh - Jean-Georges Perrin, Eric Broda (O'Reilly)](https://learning.oreilly.com/library/view/implementing-data-mesh/9781098156213/)\n- 📝 [Auchan construit sa stratégie Data adaptable autour du Data Mesh (ZDNet)](https://www.zdnet.fr/actualites/auchan-construit-sa-strategie-data-adaptable-autour-du-data-mesh-39961494.htm) | #DataMesh #French #Industry\n- 📝 [Data Mesh Can’t Win Without a Massive Culture Shift - Kim Thies](https://medium.com/profitoptics/data-mesh-is-failing-f60aded05324) | #Change #Culture #DataMesh\n- 📝 [Data Mesh: Suez réconcilie innovation et legacy (Alliancy)](https://www.alliancy.fr/data-mesh-suez-reconcilie-innovation-legacy) | #DataMesh #French #Industry\n- 📝 [Dive into Event Driven Architecture with Dapr](https://www.iamachs.com/p/dive-into-event-driven-architecture-with-dapr/)\n- 📝 [Ecosystem of Data Products > Centralized Data Platform](https://www.linkedin.com/posts/ryan-donnally_datamesh-activity-7064595412061446144-YH8N/) | #Architecture #Data #Governance\n- 📝 [Innovative Implementation of Data Contracts with DBT](https://juhache.substack.com/p/practical-implementation-of-data)\n- 📝 [PayPal open sources its data contract template](https://jgp.ai/2023/05/01/paypal-open-sources-its-data-contract-template/) | #Contract #DataQuality #Schema\n- 📝 [The Data Product Strategy | Becoming Metrics-First - Animesh Kumar, Travis Thomspon, And Samadrita Ghosh](https://moderndata101.substack.com/p/the-data-product-strategy-becoming) | #BCGFramework #DataProduct #FeedbackLoop #MetricModel #Strategy\n- 🧰 [Jacek Majchrzak’s Data Bazaar Workshop](https://twitter.com/JacekMajchrzak_/status/1413069380037005313) | #Methodology #Toolbox\n- 🧰 [datamesh-architecture.com : why, what, and how of Data Mesh with examples](https://www.datamesh-architecture.com/#tech-stacks) | #DataContract #DataProduct #TechStack #Toolbox\n- 🧰 [paypal/data-contract-template - Template for a data contract used in a data mesh](https://github.com/paypal/data-contract-template) | #Contract #DataQuality #Schema #YAML\n\n### Data 💾\n\n- 📝 [A Brief Comparison of Database, Data Warehouse, Data Mart and Data Lake and these services in Azure. - Microsoft Community Hub](https://techcommunity.microsoft.com/t5/nta-techies/a-brief-comparison-of-database-data-warehouse-data-mart-and-data/ba-p/3944981) | #Azure #DataLake #DataMart #DataWarehouse #Database\n- 📝 [Measuring the value of a Data Catalog | Thoughtworks](https://www.thoughtworks.com/insights/blog/data-strategy/measuring-the-value-of-a-data-catalog)\n- 📝 [Scaling Kafka to Support PayPal’s Data Growth | by Monish Koppa (The PayPal Technology Blog)](https://medium.com/paypal-tech/scaling-kafka-to-support-paypals-data-growth-a0b4da420fab) | #ClusterManagement #Kafka #Monitoring #MoreThan85NodesKafkaCluster #Paypal #TrillionsOfMessagesPerDay\n- 📽️  [Airflow Summit 2023 replay is available  (YouTube)](https://www.youtube.com/playlist?list=PLGudixcDaxY29qXIXhd90htHp_BFk-Bqf) | #Airflow\n- 📽️  [Nadieh Bremer—Amidst the visualization and art of data (Keynote, Outlier 2023) - YouTube](https://www.youtube.com/watch?v=QWiy1hSEDls&t=1342s) | #Dataviz #DesignThinking #Satellites #Space\n- 🗓️ [🇫🇷 La Grosse Conf, la conférence Data & IA by OCTO Technology, sera le 27 mars 2023](https://lagrosseconf.com/) | #AI #Data #GenerativeAI #MLOps #ResponsibleAI\n- 🚀 [Apache Spark 3.5.0 is out](https://spark.apache.org/releases/spark-release-3-5-0.html) | #ArrowPythonUDFs #DistributedML #GolangSupport #RocksDB #StructuredStreaming\n- 🚀 [DuckDB 0.9.0 (Undulata) is out](https://duckdb.org/2023/09/26/announcing-duckdb-090.html) | #AWS #Azure #DuckDB #PySpark #WASM\n- 🚀 [Pandas 2.1.0 is out](https://pandas.pydata.org/docs/whatsnew/v2.1.0.html)\n- 🧰 [jqnatividad/qsv: CSVs sliced, diced & analyzed](https://github.com/jqnatividad/qsv) | #CLI #CSVManipulation\n\n### Database 🧫\n\n- 📚 [PostgreSQL 14 internals - Edgar Gorov’s free book to deep dive into the server mechanics](https://postgrespro.com/community/books/internals) | #Architecture #LowLevel #Performance #PostgreSQL\n- 📝 [JunoDB: PayPal’s Key-Value Store Goes Open-Source](https://medium.com/paypal-tech/unlocking-the-power-of-junodb-paypals-key-value-store-goes-open-source-ee85f935bdc1) | #KV store #NoSQL #open-source\n- 📝 [State of databases 2023 (producthunt.com)](https://stateofdb.com/) | #BI #Cost #DataWarehouse #NoSQL #ORM #Popularity #Provider #SQL\n- 📽️  [InfluxDB 3.0 is a rewrite of InfluxDB in Rust (⚠️ video protected by a form)](https://www.influxdata.com/resources/meet-the-founders-an-open-discussion-about-rewriting-using-rust/) | #InfluxDB #LowLevel #Performance #Rust #TSDB\n- 📽️  [ML⇄DB Seminar Series - Implementation details of Machine Learning for databases & DB for ML (Carnegie Mellon University)](https://db.cs.cmu.edu/seminar2023/) | #AI #BigQuery #Databases #Databricks #DuckDB #OLAP #QueryOptimizer #RedShift #Snowflake\n- 🗓️ [PGDay UK 2023 will be on September 12 in London](https://2023.pgday.uk/) | #Conference #PostgreSQL\n- 🚀 [PostgreSQL 16 is out](https://www.postgresql.org/about/news/postgresql-16-released-2715/) | #Localization #Monitoring #Performance #Replication\n- 🧰 [10 Postgres tips for beginners (Nikolay Samokhvalov)](https://postgres.ai/blog/20230722-10-postgres-tips-for-beginners) | #Analyze #AutoVacuum #Checksums #DBeaver #DataGrip #Explain #Logging #PostgreSQL #Postico #Tuples\n\n### DevOps & SRE 🛠️\n\n- 🐦 [Ansible creator teases JetPorch, a new automation project written in Rust](https://laserllama.substack.com/p/a-new-it-automation-project-moving) | #Automation #JetPorch #Platform #Rust\n- 📝 [2023 SRE Report (CatchPoint)](https://www.catchpoint.com/asset/2023-sre-report) | #AIOps #DevOps #SRE\n- 📝 [8 Terraform continuous validation use cases for AWS, Google Cloud, and Azure](https://www.hashicorp.com/blog/8-terraform-continuous-validation-use-cases-for-aws-google-cloud-and-azure) | #AWS #Azure #Cloud #GCP #Terraform\n- 📝 [A Brief, Incomplete and Mostly Wrong Devops Glossary (Earthly Blog)](https://earthly.dev/blog/devops-glossary/) | #IDontKnowWhatSREIsAndAtThisPointImTooAfraidToAsk\n- 📝 [As HashiCorp adopts the BSL, an era of open-source software might be ending (Tom Krazit)](https://www.runtime.news/as-hashicorp-adopts-the-bsl-an-era-of-open-source-software-might-be-ending/)\n- 📝 [Creating Checklists for High Stakes Changes - Major Database Upgrade in Production (Nick Janetakis)](https://nickjanetakis.com/blog/creating-checklists-for-high-stakes-changes) | #Checklist #Communication #Database #FunctionalChecks #Snapshot\n- 📝 [HashiConf 2023 recap.  (by Glen Yu | Oct, 2023, Medium)](https://medium.com/@glen.yu/hashiconf-2023-recap-b90ae64347a1) | #Consul #EphemeralWorkspace #Nomad #Roadmap #Terraform #TestingFramewok #Vault\n- 📝 [HashiCorp announces transition from the Mozilla Public License v2.0 (MPL 2.0) to the Business Source License (BSL, or BUSL) v1.1 for future releases of all products and several libraries (Aug-10)](https://www.hashicorp.com/license-faq#What-did-HashiCorp-announce-today-(Aug-10)) | #FAQ #OfficialCommunication\n- 📝 [How Back Market SREs prepared for Black Friday (Mathieu Garstecki)](https://engineering.backmarket.com/how-back-market-sres-prepared-for-black-friday-5f017f343408)\n- 📝 [How DoorDash Migrated from StatsD to Prometheus - DoorDash Engineering Blog](https://doordash.engineering/2023/08/01/how-doordash-migrated-from-statsd-to-prometheus/) | #Monitoring #Performance #Prometheus #StatsD #UDP\n- 📝 [How to use If-Else in Terraform – Thomas Thornton – Microsoft Azure MVP – HashiCorp Ambassador](https://thomasthornton.cloud/2023/10/16/how-to-use-if-else-in-terraform/)\n- 📝 [Introduction to heredocs in Dockerfiles - Docker](https://www.docker.com/blog/introduction-to-heredocs-in-dockerfiles/) | #Dockerfile #NoMoreRun&& #TodayILearned\n- 📝 [Measuring Git performance with OpenTelemetry - The GitHub Blog](https://github.blog/2023-10-16-measuring-git-performance-with-opentelemetry/)\n- 📝 [OpenTF Announces Fork of Terraform](https://opentf.org/announcement#:~:text=OpenTF%20Announces%20Fork%20of%20Terraform) | #AvailableSoon #Fork #Roadmap #Terraform\n- 📝 [OpenTF, the open-source alternative to Terraform, becomes OpenTofu (Linux Foundation)](https://www.linuxfoundation.org/press/announcing-opentofu?utm_content=264841292&utm_medium=social&utm_source=twitter&hss_channel=tw-14706299)\n- 📝 [Prometheus Now Supports OpenTelemetry Metrics](https://horovits.medium.com/prometheus-now-supports-opentelemetry-metrics-83f85878e46a) | #CNCF #OTLP #OpenTelemetry #Prometheus\n- 📝 [Summary of the AWS Service Event in the Northern Virginia (US-EAST-1) Region (AWS)](https://aws.amazon.com/fr/message/061323/) | #AWS #AWS STS #Lambda #LearningFromIncident #PostMortem\n- 📝 [The balancing act of reliability and availability  (incident.io)](https://incident.io/blog/reliability-vs-availability) | #Availability #Definitions #DisasterRecovery #FaultTolerance #Monitoring #Reliability #The9sOfAvailability\n- 📝 [The rise of open standards in observability: highlights from KubeCon](https://www.cncf.io/blog/2023/07/10/the-rise-of-open-standards-in-observability-highlights-from-kubecon/) | #CNCF #KubeCon #OpenCensus #OpenTelemetry #Prometheus\n- 📝 [What happened at KubeCon Shanghai 2023 (Mauricio Salatino)](https://www.salaboy.com/2023/09/29/kubecon-shanghai-2023/) | #AI #Conference #Dapr #FinOps #KMesh #Koordinator #Kubernetes #Platform #Volcano\n- 📝 [When Taylor Swift crashed Ticketmaster: A lesson on scaling for spikes | by Fahim ul Haq | Dev Learning Daily](https://learningdaily.dev/when-taylor-swift-crashed-ticketmaster-a-lesson-on-scaling-for-spikes-9931e2c888e9)\n- 📝 [Why LFI is a tough sell (Lorin Hochstein @ Surfing Complexity)](https://surfingcomplexity.blog/2023/08/20/why-lfi-is-a-tough-sell/) | #LearningFromIncident #MentalModel #Miscalibration #RootCauseAnalysis #SocioTechnicalSystems #StructuralSecrecy\n- 📝 [Why should I care about OpenTofu? (Marcin Wyszynski)](https://opentofu.org/blog/why-should-i-care-about-opentofu/) | #OpenTofu #Roadmap #Terraform\n- 📝 [hashicorp/terraform 1.6.0 is out](https://github.com/hashicorp/terraform/releases/tag/v1.6.0) | #S3BackendChanges #TerraformTest\n- 📽️  [Replay of HashiDays 2023](https://www.youtube.com/playlist?list=PL81sUbsFNc5YhxNu2De8BWl_1tmEVmLRJ) | #Cloud #Conference #Security #Terraform\n- 📽️  [🇫🇷 Laissez tomber vos Dockerfile, adoptez un buildpack ! (Julien Wittouck, Sunny Tech 2023)](https://www.youtube.com/watch?v=2Zo34sXsMxU) | #Buildpack #Conference #Distroless #Docker #Pack #Paketo #SBOM\n- 📽️  [🇫🇷 Suivez vos applications à la trace grâce à OpenTelemetry (Julien Tanguy, Sunny Tech 2022)](https://www.youtube.com/watch?v=NXYAtkEm_hk) | #Conference #LiveDemo #OTLP #OpenTelemetry\n- 🗓️ [ObservabilityCON 2023 will be in London, 14 - 15 November (GrafanaLabs)](https://grafana.com/about/events/observabilitycon/2023/) | #Grafana #K6 #LGTM-Stack #Logging #Loki #Observability #OpenTelemetry #Performance #SLI/SLO\n- 🗓️ [PromCon EU 2023 will be on September 28 - 29 in Berlin, CFP is still open](https://promcon.io/2023-berlin/) | #Conference #Prometheus #TSDB\n- 🚀 [Docker Announces Docker AI - docker.com](https://www.docker.com/press-release/announces-ai-boosting-developer-productivity-through-automated-guidance/) | #CodeGeneration #ContextSpecific #Docker #LLM\n- 🚀 [Docker init - a new command to initialize dockerfiles](https://www.docker.com/blog/docker-init-initialize-dockerfiles-and-compose-files-with-a-single-cli-command/) | #Docker #DockerCompose #Dockerfile #Dockerignore\n- 🚀 [First release of JQ in the last 5 years](https://github.com/jqlang/jq/releases/tag/jq-1.7rc1) | #DockerImages #GithubActions #JSONQuery #NewMaintainers\n- 🚀 [Keycloak 22.0.0 is out ](https://www.keycloak.org/2023/07/keycloak-2200-released.html)\n- 🚀 [OpenTelemetry Protocol (OTLP) version 1.0 is out (Dotan Horovits)](https://twitter.com/horovits/status/1675946183032729622) | #1.0.0 #OpenTelemetry\n- 🚀 [Task v3.28.0 is out, with the ability to loop over commands + tasks using “for” keyword](https://taskfile.dev/changelog/#v3280---2023-07-24) | #Automation #GNUMake #YAML\n- 🚀 [Terraform 1.6.0-alpha available soon, “test” command not experimental anymore](https://github.com/hashicorp/terraform/releases/tag/v1.6.0-alpha20230719) | #Terraform\n- 🚀 [docker compose 2.20.0 is out](https://github.com/docker/compose/releases/tag/v2.20.0)\n- 🚀 [docker compose v2.22.0 is out](https://github.com/docker/compose/releases/tag/v2.22.0) | #Docker #DockerCompose\n- 🚀 [jqlang/jq 1.7 is out](https://github.com/jqlang/jq/releases)\n- 🧰 [Pants - The ergonomic build system](https://www.pantsbuild.org/) | #Caching #Concurrency #Go #Java #MonorepoCompatible #Python #Scalability #Shell\n- 🧰 [Unleash your inner #SSH ninja! 🥷 with \"SSH Kung Fu\" | Tyblog | SSH Kung Fu](https://blog.tjll.net/ssh-kung-fu/) | #FileSystem #OpenSSH #Proxy #SSH #Tunnelling\n- 🧰 [adriannovegil/awesome-observability](https://github.com/adriannovegil/awesome-observability) | #Practices #Toolbox #Tools\n- 🧰 [alebcay/awesome-shell - A curated list of awesome command-line frameworks, toolkits, guides and gizmos](https://github.com/alebcay/awesome-shell) | #CLI #Productivity #Shells\n- 🧰 [awesome-cloud-native](https://github.com/rootsongjc/awesome-cloud-native) | #CloudNative\n- 🧰 [awesome-prometheus](https://github.com/roaldnefs/awesome-prometheus) | #Alerting #Grafana #Metrics #Monitoring #Prometheus #Toolbox\n- 🧰 [kelseyhightower/kubernetes-the-hard-way](https://github.com/kelseyhightower/kubernetes-the-hard-way) | #KubernetesTheHardWay #LearningResource #Tutorial\n- 🧰 [monorepo.tools - resources and tooling about monorepos](https://monorepo.tools) | #Definitions #Monorepo #NotMonolith #Polyrepo\n- 🧰 [superfly/corrosion: Gossip-based service discovery (and more) for large distributed systems - A Rust alternative to Consul](https://github.com/superfly/corrosion) | #GossipBased #Rust #ServiceDiscovery\n- 🧰 [teivah/sre-roadmap: An Opinionated Roadmap to Become an SRE (Concepts > Tools)](https://github.com/teivah/sre-roadmap) | #Concepts>Tools #Roadmap #SRE\n- 🧰 [terraform-best-practices.com - a collection of best practices (naming, styling, …)](https://www.terraform-best-practices.com/naming) | #BestPractices #Terraform\n- 🧰 [📖 trimstray/the-book-of-secret-knowledge](https://github.com/trimstray/the-book-of-secret-knowledge) | #AdminSys #Bible #DevOps #Hack #Network #PenTest #Shell\n\n### FinOps 💸\n\n- 📝 [How Canva saves millions annually in Amazon S3 costs](https://www.canva.dev/blog/engineering/optimising-s3-savings/) | #AWS #Cloud #FinOps #S3\n- 🧰 [FinOps Principles (FinOps Foundation)](https://www.finops.org/framework/principles/) | #Cloud #FinOps #Methodology\n\n### Functional programming λ\n\n- 📝 [Love Letter To Clojure (Part 1) (Gene Kim, 2019)](https://itrevolution.com/articles/love-letter-to-clojure-part-1/) | #Clojure #FunctionalProgrammingλ #LISP\n- 🧰 [F# for Fun and Profit](https://fsharpforfunandprofit.com/) | #F# #LearningResource\n\n### Living Documentation 📖💗\n\n- 📚 [Living Documentation (Cyrille Martraire)](https://www.goodreads.com/book/show/34927405-living-documentation) | #EvergreenDoc #KnowledgeAugmentation #LivingDocumentation\n- 📝 [JSONSchema](https://json-schema.org/) | #DataContract #DataDocumentation #DataValidation\n- 📝 [coveooss/json-schema-for-humans](https://github.com/coveooss/json-schema-for-humans) | #JSONSchemaToHTML #JSONSchemaToMarkdown\n- 🧰 [Self-Documented Makefile (François Zaninotto)](https://marmelab.com/blog/2016/02/29/auto-documented-makefile.html) | #Automation #DeveloperExperience #GNUMake #LivingDocumentation #RecList #Shell\n\n### MLOps 🧠⚙️\n\n- 📝 [Building LLM applications for production (Chip Huyen’s blog)](https://huyenchip.com/2023/04/11/llm-engineering.html) | #LLM #MLOps\n- 📝 [The Post-Modern Stack, Joining the modern data stack and the modern ML stack](https://towardsdatascience.com/the-post-modern-stack-993ec3b044c1) | #MLOps #Metaflow #ModernDataStack #RecList #S3 #Sagemaker #Snowflake #dbt\n- 📽️  [Building LLM Applications for Production // Chip Huyen @ LLMs in Prod Conference](https://www.youtube.com/watch?v=spamOhG7BOA) | #Conference #LLM #MLOps\n\n### Miscellaneous 🎆\n\n- 🐦 [Vinay Hiremath on X : \"Today @loom is joining @Atlassian\"](https://twitter.com/vhmth/status/1712456811305951676) | #Acquisition #Atlassian #Loom\n- 📝 [Github Issue - New name for the OpenTF project · #296 · opentofu/opentofu](https://github.com/opentofu/opentofu/issues/296) | #Discussion #RenamingOpenTFtoOpenTofu\n- 📝 [Hello, I'm Mr. Null. My Name Makes Me Invisible to Computers](https://www.wired.com/2015/11/null/) | #ImpactOfSoftwareOnRealLife #NullSafe #Trivia🎈\n- 📝 [IBM taps AI to translate COBOL code to Java - TechCrunch](https://techcrunch.com/2023/08/22/ibm-taps-ai-to-translate-cobol-code-to-java/?guccounter=1) | #Cobol #CodeAssistantForIBMZ #IBM #Java\n- 📝 [Toyota’s Japanese production was halted due to insufficient disk space | Ars Technica](https://arstechnica.com/information-technology/2023/09/insufficient-disk-space-caused-2-day-shutdown-of-toyotas-japanese-factories/) | #HighAvailability #SystemMonitoring #Trivia🎈\n- 📝 [Welcoming Loom to the Atlassian team (Atlassian)](https://www.atlassian.com/blog/announcements/atlassian-acquires-loom) | #Acquisition #Atlassian #Loom\n- 📽️  [TypeScript Origins: The Documentary - YouTube](https://www.youtube.com/watch?v=U6s2pdxebSo) | #2HoursLongVideo #TypeScript\n- 🚀 [Exploring Wordle - how to programmatically find eligible answers for a Wordle game using Python (George V. Reilly)](https://www.georgevreilly.com/2023/09/26/ExploringWordle.html) | #Bash #Game #LettersConstraints #Pipes #Python #Wordle\n- 🧰 [GitHub - cloudcommunity/Free-Certifications: A curated list of free courses & certifications.](https://github.com/cloudcommunity/Free-Certifications)\n- 🧰 [Is it Pokémon or Big Data?](https://pixelastic.github.io/pokemonorbigdata/) | #BigData #Game #Pokemon\n- 🧰 [QrGPT - Free Cool-looking AI QR Code generator](https://www.qrgpt.io/) | #OpenSource\n- 🧰 [chebykinn/sedmario: NES Super Mario Bros level 1 written in pure sed!](https://github.com/chebykinn/sedmario)\n\n### Platform📡\n\n- 🐦 [The Platform Maturity Model (by The NewStack)](https://twitter.com/bibryam/status/1702756880236294294/photo/1) | #Adoption #Funding #MaturityModel #OrganizationalStructure #UserExperience\n- 📝 [A Practical Step-by-Step Approach to Building a Platform (The New Stack, Hemanth Kavuluru)](https://thenewstack.io/a-practical-step-by-step-approach-to-building-a-platform/) | #Backstage #DeploymentAsAService #FinOps #Infrastructure #Rafay #Roadmap #SRE #UseCases\n- 📝 [The Modernization Imperative: Shifting left is for suckers. Shift down instead (Richard Seroter, Google Cloud Blog)](https://cloud.google.com/blog/products/application-development/richard-seroter-on-shifting-down-vs-shifting-left?hl=en) | #EmpowerDevelopersThroughPlatformEngineering #ShiftDown #ShiftLeft\n- 📝 [Three Economies, an Introduction - Jabe Bloom](https://blog.jabebloom.com/2020/03/04/the-three-economies-an-introduction/) | #BusinessPlatform #DDD #Differenciation #Scale #Scope\n- 📽️  [Managing Software at Scale: Kelsey Hightower Talks with Niklas Gustavsson about Fleet Management - Spotify Engineering](https://engineering.atspotify.com/2023/10/managing-software-at-scale-googles-kelsey-hightower-talks-with-spotifys-niklas-gustavsson-about-fleet-management/?utm_medium=social&utm_source=linkedIn&utm_campaign=kelsey%20ngn&utm_content=evergreen) | #Backstage #Consensus #DevEx #DeveloperExperience #Fleet #Monorepo #Polyrepo #Spotify #Squad\n- 🗓️ [BackstageCon NA will be in November 2023](https://events.linuxfoundation.org/kubecon-cloudnativecon-north-america/co-located-events/backstagecon/) | #Conference\n- 🚀 [Backstage v1.18.0 is out](https://backstage.io/docs/releases/v1.18.0/) | #DeveloperPlatform #SoftwareCatalog\n\n### Product Management 📦\n\n- 📝 [Ditch Epics & User Stories and Focus on Outcomes (Ant Murphy)](https://www.antmurphy.me/newsletter/from-epics-amp-stories-to-hypotheses-and-problem-statements-shifting-to-outcomes) | #Epics #Experimentation #Hypothesis #Opportunity\n- 📝 [Product Principles at GitLab - Core organizational principles to build world class products](https://about.gitlab.com/handbook/product/product-principles/#prefer-small-primitives) | #AlwaysAllowForDeployingInProduction #AlwaysBeLearning #BeDataDriven #ConventionOverConfiguration #LearnFromFailures #MinimalViableChange #YouAreNotTheCustomer\n- 🧰 [A full list of dead products killed by Google](https://killedbygoogle.com/) | #Apps #Hardware #RIP #Services\n- 🧰 [Misleading roadmap | Honest roadmap | Strategic roadmap](https://twitter.com/carlvellotti/status/1679530059345055751) | #Agility #Linearity #Roadmap #Strategy\n\n### Productivity 👟\n\n- 📝 [Measuring developer productivity? A response to McKinsey (Part 1) - Gergely Orosz & Kent Beck](https://newsletter.pragmaticengineer.com/p/measuring-developer-productivity) | #DORA #Measure #SoftwareEngineeringCycle #Tradeoffs\n- 📝 [Measuring developer productivity? A response to McKinsey (Part 2) - Gergely Orosz & Kent Beck](https://newsletter.pragmaticengineer.com/p/measuring-developer-productivity-part-2) | #CostOfEngineering #Goodhart'sLaw #Management #TeamVsIndividualPerformance\n- 📝 [Yes, you can measure software developer productivity (McKinsey)](https://www.mckinsey.com/industries/technology-media-and-telecommunications/our-insights/yes-you-can-measure-software-developer-productivity)\n- 📽️  [Dave Farley - My Response To The NONSENSE McKinsey Article On Developer Productivity](https://www.youtube.com/watch?v=yuUBZ1pByzM&ab_channel=ContinuousDelivery)\n\n### Python 🐍\n\n- 🐦 [Meta commits to dedicate three engineer-years to implement the removal of the GIL from Python](https://twitter.com/llanga/status/1677648534563086338) | #LowLevel #Performance #SoftwareEngineering\n- 🐦 [Pydantic won't be dropping Python 3.7 support in version 2.4 since they still have 21% (~4m) downloads of 2.3 using it (Pydantic on X/Twitter)](https://twitter.com/pydantic/status/1704787595438215262) | #DataDrivenDecision #DropPython3.7 #Python\n- 📝 [10 Best Practices for Logging in Python (BetterStack)](https://betterstack.com/community/guides/logging/python/python-logging-best-practices/) | #Logging #LoggingConfig #Loguru #StructuredLogging #python-json-logger\n- 📝 [Asyncio Evolved: Enhanced Exception Handling with TaskGroup in Python 3.11(Junya Fukuda, EuroPython 2023)](https://speakerdeck.com/jrfk/asyncio-evolved-enhanced-exception-handling-with-taskgroup-in-python-3-dot-11-europython-2023) | #AynscIO #SlidesDeck #TaskGroup\n- 📝 [Bypassing the GIL for Parallel Processing in Python (Real Python)](https://realpython.com/python-parallel-processing/) | #CPU #Concurrency #GIL #IO #MultiThread #Parallelism\n- 📝 [PEP 710 (draft) – Recording the provenance of installed packages](https://peps.python.org/pep-0710/) | #Auditability #PEP #SBOM #Security\n- 📝 [dabeaz-course/python-mastery](https://github.com/dabeaz-course/python-mastery) | #Concurrency #Coroutines #Generators #LearningResource #Metaprogramming\n- 📝 [🔵 Blue : a somewhat less uncompromising code formatter than ⚫ Black, the OG of Python formatters](https://github.com/grantjenks/blue) | #Lint #Style\n- 📽️  [EuroPython 2023 videos have been released on YouTube](https://www.youtube.com/playlist?list=PL8uoeex94UhFcwvAfWHybD7SfNgIUBRo-) | #Conference #CzechRepublic #EuroPython #VOD\n- 📽️  [Python Web Conf 2023 videos are available](https://www.youtube.com/playlist?list=PLt4L3V8wVnF4GJb8dekLGTNx44FNIFwdv) | #Conference #PWC2023\n- 🗓️ [Airflow summit 2023 will take place on September 19th to 21st](https://airflowsummit.org/sessions/2023/) | #Airflow #Conference #DataMesh\n- 🗓️ [EuroPython2023 conference will be in Prague (July 17-23)](https://ep2023.europython.eu/) | #Architecture #Conference #Design #OpenAPI #Python\n- 🗓️ [It’s time to stop using Python 3.7 (end-of-life, June 2023)](https://pythonspeed.com/articles/stop-using-python-3.7/)\n- 🚀 [Conda’s dependency solver switching to libmamba this month](https://conda.org/blog/2023-07-05-conda-libmamba-solver-rollout/) | #Anaconda #Conda #Mamba #Miniconda #Performance\n- 🚀 [Cython 3.0.0 is out](https://cython.readthedocs.io/en/latest/src/changes.html#major-themes-in-3-0-0) | #C #LowLevel #Performance\n- 🚀 [FastAPI 0.100.0 is out and supports Pydantic V2](https://fastapi.tiangolo.com/release-notes/#01000) | #OpenAPI #Performance #Rust #Web\n- 🚀 [Great Expectations 0.17.5 is out](https://docs.greatexpectations.io/docs/changelog/#0175) | #DataQuality #SoftwareEngineering #open-source\n- 🚀 [Mypy 1.5.0 is out](https://mypy-lang.blogspot.com/2023/08/mypy-15-released.html) | #DropPython3.7\n- 🚀 [Poetry 1.6.0 is out](https://python-poetry.org/blog/announcing-poetry-1.6.0/)\n- 🚀 [Prefect 2.11.0 & 2.11.1 are out](https://github.com/PrefectHQ/prefect/releases/tag/2.11.1) | #Observability #Orchestrator #Piepline\n- 🚀 [Pydantic 2.1.0 & 2.1.1 are out](https://docs.pydantic.dev/latest/changelog/#v210-2023-07-25)\n- 🚀 [Pydantic 2.4.2 is out](https://github.com/pydantic/pydantic/releases/tag/v2.4.2) | #BugFix\n- 🚀 [Python Release Python 3.11.5](https://www.python.org/downloads/release/python-3115/)\n- 🚀 [Ruff v0.1.0 is out](https://astral.sh/blog/ruff-v0.1.0) | #JupyterNotebooksSupport #Lint #Performance #Python #Python3.12 #Rust #WrittenInRust\n- 🚀 [Uvicorn 0.23.0 is out](https://github.com/encode/uvicorn/releases/tag/0.23.0) | #ASGI #WebServer\n- 🧰 [CodeCarbon, a Python library to track carbon emissions from your computer](https://github.com/mlco2/codecarbon) | #GreenIT #SoftwareEngineering\n- 🧰 [satwikkansal/wtfpython - Exploring and understanding Python through surprising snippets](https://github.com/satwikkansal/wtfpython) | #CodeSamplesWithExplanations #Quirks #WTF\n- 🧰 [tiangolo/typer: Typer, build great CLIs. Easy to code. Based on Python type hints. The FastAPI of CLIs](https://github.com/tiangolo/typer) | #CLI #Click #Hug #Pydantic\n\n### QuantumComputing ⚛️\n\n- 📝 [Google Claims Latest Quantum Experiment Would Take Decades on Classical Computer](https://thequantuminsider.com/2023/07/04/google-claims-latest-quantum-experiment-would-take-decades-on-classical-computer/) | #Industry #R&D #Trivia🎈\n\n### Security☣️\n\n- 🐦 [Universal and Transferable Adversarial Attacks on Aligned Language Models (website, paper and code)](https://twitter.com/ItakGol/status/1684858195771060224) | #AI #GPT-4 #Hack #LLM #PaLM-2 #Prompt\n- 📝 [Hacking Github AWS integrations again - Meanderings by Daniel Grzelak](https://dagrz.com/writing/aws-security/hacking-github-aws-oidc/) | #AWSIntegration #CodeSamplesWithExplanations #Github #OIDC\n- 📝 [How Cloudflare mitigated yet another Okta compromise (Cloudflare)](https://blog.cloudflare.com/how-cloudflare-mitigated-yet-another-okta-compromise/) | #Security #TokenCompromised\n- 📝 [How to Find Advanced Persistent Threats in your Security Logs](https://blog.scanner.dev/security-logs-and-apts/) | #AWS CloudTrail #GithubAuditLogs\n- 📝 [PyLoose: Python-based fileless malware targets cloud workloads to deliver cryptominer](https://www.wiz.io/blog/pyloose-first-python-based-fileless-attack-on-cloud-workloads) | #Malware #Python #memfd\n- 📝 [Security Developer-in-Residence – Weekly Report #2 (Seth Larson) - On the importance of having a SBOM (Software Bill of Materials)](https://sethmlarson.dev/security-developer-in-residence-weekly-report-2) | #PEP #PEP710 #SBOM #Security\n- 📝 [The massive bug at the heart of the npm ecosystem](https://blog.vlt.sh/blog/the-massive-hole-in-the-npm-ecosystem) | #NPM #NodeJS #Security\n- 🧰 [Explaining JSON Web Token (JWT) to a 10 year old Kid (ByteByteGo)](https://blog.bytebytego.com/p/ep69-explaining-json-web-token-jwt#%C2%A7explaining-json-web-token-jwt-to-a-year-old-kid) | #Infographics #JWT\n\n### Software Engineering ⚙️\n\n- 🐦 [Codecov is now opensource](https://twitter.com/zeeg/status/1684954865121067008) | #CodeCoverage #CodeQuality\n- 📚 [Culture Test vol. 1 : apprivoisez la complexité](https://publication.octo.com/culture-test-vol-1) | #Culture #OCTOTechnology #WhitePaper\n- 📚 [Your Code as a Crime Scene, Second Edition is out (end of Beta)](https://pragprog.com/titles/atcrime2/your-code-as-a-crime-scene-second-edition/)\n- 📝 [Common design patterns at Stripe (Paul Asjes)](https://dev.to/stripe/common-design-patterns-at-stripe-1hb4) | #AvoidJargon #DesignForExtensibility #PreferEnumsOverBooleans\n- 📝 [Death by a thousand microservices (Andrei Taranchenko)](https://renegadeotter.com/2023/09/10/death-by-a-thousand-microservices.html) | #FAANG #JavaScript #Microservices #MicroservicesHype #Monolith #VentureCapital\n- 📝 [Don't write clean code, write CRISP code (John Arundel)](https://bitfieldconsulting.com/golang/crisp-code) | #Correct #Golang #Idiomatic #Performant #Readable #Simple\n- 📝 [How Google Measures and Manages Tech Debt (Abi Noda)](https://newsletter.abinoda.com/p/measuring-and-managing-tech-debt) | #CodeQuality #MaturityModel #Productivity #SystemsThinking #TechnicalDebt\n- 📝 [How I used GitHub Copilot Chat to build a ReactJS gallery prototype (The GitHub Blog, Senna Parsa)](https://github.blog/2023-09-27-how-i-used-github-copilot-chat-to-build-a-reactjs-gallery-prototype/) | #AIAssistedSoftwareDevelopment #CopilotChat #GithubCopilot #Prompt #Prototype #ReactJS #UnitTests\n- 📝 [How to Eat an Elephant - Kent Beck](https://www.mechanical-orchard.com/post/how-to-eat-an-elephant) | #ComplexityPartitioning #Legacy #Mainframe #Modernization\n- 📝 [How we reduced the size of our JavaScript bundles by 33% (Dropbox, Umair Nadeem and Rich Hong)](https://dropbox.tech/frontend/how-we-reduced-the-size-of-our-javascript-bundles-by-33-percent) | #CodeSplitting #JavaScript #Packaging #Rollup #TreeShaking\n- 📝 [Object Calisthenics (William Durand, 2013)](https://williamdurand.fr/2013/06/03/object-calisthenics/) | #CleanCode #CodeReadability #SOLID #SlidesDeck\n- 📝 [Postman acquires Akita for automated API observability](https://blog.postman.com/postman-acquires-akita-for-automated-api-observability/) | #Industry\n- 📝 [The After Open Source Era Has Started (Bilgin Ibryam)](https://blog.oss.fund/p/open-source-eras) | #License #Monetization #OpenSource #SharedSource #TheCathedralAndTheBazaar\n- 📝 [Why are Cloud Development Environments Spiking in Popularity, Now? (Gergely Orosz)](https://newsletter.pragmaticengineer.com/p/why-are-cloud-development-environments?utm_source=post-email-title&publication_id=458709&post_id=137426746&utm_campaign=email-post-title&isFreemail=true&r=3ucun&utm_medium=email) | #CDE #DevZero #Devpods #Gitpod #Monorepo #Productivity #RemoteSoftwareDelivery #Stackblitz\n- 📝 [Your curated GitHub Universe agenda: AI, ethics, and productivity - The GitHub Blog](https://github.blog/2023-10-17-your-curated-github-universe-agenda-ai-ethics-and-productivity/)\n- 📽️  [ChatGPT & Copilot are NOT Refactoring Tools (Emily Bache on YouTube)](https://www.youtube.com/watch?v=iXGBIX8gudE) | #EmilyBache #LLMsAreNotRefactoringTools\n- 📽️  [Refactoring Skills: Extract Function | Guided Learning Hour (Emily Bache on YouTube)](https://www.youtube.com/watch?v=lOAktlPd8uk) | #Code #EmilyBache #Refactoring #Schema&Examples\n- 🗓️ [DDD Europe 2024 will happen on May 27-31 2024 in Amsterdam](https://twitter.com/ddd_eu/status/1667449494294740998) | #Conference #DDD\n- 🗓️ [Hacktoberfest 2023 has started](https://hacktoberfest.com/) | #10thAnniversary #Hacktoberfest #OpenSource #PullRequests\n- 🚀 [Announcing Rust 1.73.0 | Rust Blog](https://blog.rust-lang.org/2023/10/05/Rust-1.73.0.html)\n- 🚀 [Go 1.21 is out](https://go.dev/doc/go1.21)\n- 🚀 [Go 1.21 is released ](https://go.dev/blog/go1.21)\n- 🚀 [Gradle 8.4 is out](https://docs.gradle.org/8.4/release-notes.html)\n- 🚀 [Python 3.12 is out _ What’s New In Python 3.12 — Python documentation](https://docs.python.org/3.12/whatsnew/3.12.html#:~:text=This%20article%20explains%20the%20new,full%20details%2C%20see%20the%20changelog.)\n- 🧰 [Egoless Crafting: Practicing Software Craftsmanship with Ego-Resiliency](https://egolesscrafting.org/) | #EgolessProgramming #Manifesto #SoftSkills\n- 🧰 [Google Online Security Blog: Scaling Rust Adoption Through Training (Google)](https://security.googleblog.com/2023/09/scaling-rust-adoption-through-training.html) | #Android #BareMetal #Concurrency #Free #LearningResource #Rust\n- 🧰 [How GenAI effects our software delivery practices (Martin Fowler, Birgitta Böckeler)](https://twitter.com/martinfowler/status/1684228057341591553) | #ChatGPT #GPTEngineer #GithubCopilot #Meta'sCodeCompose\n- 🧰 [Resources on TDD (Test-Driven Development) (Sébastien Roccaserra)](https://www.linkedin.com/posts/sroccaserra_testdrivendevelopment-tdd-activity-7109536155645140993-a2Ap/?utm_source=share&utm_medium=member_desktop) | #Design #Mock #Refactoring #TDD #TestDrivenDevelopment\n- 🧰 [SQL join flavors - Anton Zhiyanov](https://antonz.org/sql-join/) | #Cross #Joins #Lateral #Natural #Partitioned #Qualified #SQL\n- 🧰 [TIL - Callouts are available in Github-flavored Markdown](https://github.com/orgs/community/discussions/16925) | #HierarchyOfInformation #LivingDocumentation #Markdown #TodayILearned\n- 🧰 [fraktalio/fmodel-rust: Domain modeling. Event sourcing. CQRS. Functional Domain Modeling with Rust](https://github.com/fraktalio/fmodel-rust) | #DomainModelling #FunctionalProgrammingλ #Rust\n\n### Web Development 🧑‍💻\n\n- 📝 [Serverless Bun vs Node: Benchmarking on AWS Lambda](https://medium.com/@mitchellkossoris/serverless-bun-vs-node-benchmarking-on-aws-lambda-ecd4fe7c2fc2) | #AWS #Benchmark #CloudWatch #Performance #X-Ray\n- 📝 [Speeding up the dbt™ docs by 20x with React Server Components](https://dagster.io/blog/dbt-docs-on-react) | #Lighthouse #NextJS #Performance #ReactServerComponents #SlowLoadTime\n- 🚀 [Bun 1.0 is out](https://bun.sh/blog/bun-v1.0) | #Fast #JavaScript #Lightweight #Runtime\n- 🧰 [➰ Understanding SVG Paths](https://www.nan.fyi/svg-paths) | #Animation #Bezier #Cursor #Demo #Line #SVG\n",
    "timestamp": "2025-05-23T16:30:40.755495",
    "tags": [],
    "severity": "high",
    "services_affected": [
      "api",
      "web",
      "database",
      "cache",
      "queue",
      "monitoring"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "kubernetes",
      "docker",
      "aws",
      "gcp",
      "azure",
      "postgresql",
      "redis",
      "elasticsearch",
      "kafka",
      "nginx",
      "prometheus",
      "grafana",
      "jenkins",
      "terraform"
    ],
    "failure_pattern": "monitoring_blind_spot",
    "timeline_events": [],
    "blast_radius": "global",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 0.98
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/icopy-site/awesome-cn/blob/0eddacc20f874cd654d18c68609cebd2e5572440/docs/awesome/awesome-incident-response.md",
    "title": "awesome-incident-response.md",
    "content": "<div class=\"github-widget\" data-repo=\"meirwah/awesome-incident-response\"></div>\n## Awesome Incident Response [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome) [![Check URLs](https://github.com/meirwah/awesome-incident-response/actions/workflows/check_urls.yml/badge.svg)](https://github.com/meirwah/awesome-incident-response/actions/workflows/check_urls.yml)\n\n> A curated list of tools and resources for security incident response, aimed to help security analysts and [DFIR](http://www.acronymfinder.com/Digital-Forensics%2c-Incident-Response-%28DFIR%29.html) teams.\n\nDigital Forensics and Incident Response (DFIR) teams are groups of people in an organization responsible for managing the response to a security incident, including gathering evidence of the incident, remediating its effects, and implementing controls to prevent the incident from recurring in the future.\n\n\n\n## IR Tools Collection\n\n### Adversary Emulation\n\n* [APTSimulator](https://github.com/NextronSystems/APTSimulator) - Windows Batch script that uses a set of tools and output files to make a system look as if it was compromised.\n* [Atomic Red Team (ART)](https://github.com/redcanaryco/atomic-red-team) - Small and highly portable detection tests mapped to the MITRE ATT&CK Framework.\n* [AutoTTP](https://github.com/jymcheong/AutoTTP) - Automated Tactics Techniques & Procedures. Re-running complex sequences manually for regression tests, product evaluations, generate data for researchers.\n* [Caldera](https://github.com/mitre/caldera) - Automated adversary emulation system that performs post-compromise adversarial behavior within Windows Enterprise networks. It generates plans during operation using a planning system and a pre-configured adversary model based on the Adversarial Tactics, Techniques & Common Knowledge (ATT&CK™) project.\n* [DumpsterFire](https://github.com/TryCatchHCF/DumpsterFire) - Modular, menu-driven, cross-platform tool for building repeatable, time-delayed, distributed security events. Easily create custom event chains for Blue Team drills and sensor /   alert mapping. Red Teams can create decoy incidents, distractions, and lures to support and scale their operations.\n* [Metta](https://github.com/uber-common/metta) - Information security preparedness tool to do adversarial simulation.\n* [Network Flight Simulator](https://github.com/alphasoc/flightsim) - Lightweight utility used to generate malicious network traffic and help security teams to evaluate security controls and network visibility.\n* [Red Team Automation (RTA)](https://github.com/endgameinc/RTA) - RTA provides a framework of scripts designed to allow blue teams to test their detection capabilities against malicious tradecraft, modeled after MITRE ATT&CK.\n* [RedHunt-OS](https://github.com/redhuntlabs/RedHunt-OS) - Virtual machine for adversary emulation and threat hunting.\n\n### All-In-One Tools\n\n* [Belkasoft Evidence Center](https://belkasoft.com/ec) -  The toolkit will quickly extract digital evidence from multiple sources by analyzing hard drives, drive images, memory dumps, iOS, Blackberry and Android backups, UFED, JTAG and chip-off dumps.\n* [CimSweep](https://github.com/PowerShellMafia/CimSweep) - Suite of CIM/WMI-based tools that enable the ability to perform incident response and hunting operations remotely across all versions of Windows.\n* [CIRTkit](https://github.com/byt3smith/CIRTKit) - CIRTKit is not just a collection of tools, but also a framework to aid in the ongoing unification of Incident Response and Forensics investigation processes.\n* [Cyber Triage](http://www.cybertriage.com) - Cyber Triage collects and analyzes host data to determine if it is compromised. It's scoring system and recommendation engine allow you to quickly focus on the important artifacts. It can import data from its collection tool, disk images, and other collectors (such as KAPE). It can run on an examiner's desktop or in a server model. Developed by Sleuth Kit Labs, which also makes Autopsy. \n* [Dissect](https://github.com/fox-it/dissect) - Dissect is a digital forensics & incident response framework and toolset that allows you to quickly access and analyse forensic artefacts from various disk and file formats, developed by Fox-IT (part of NCC Group).\n* [Doorman](https://github.com/mwielgoszewski/doorman) - osquery fleet manager that allows remote management of osquery configurations retrieved by nodes. It takes advantage of osquery's TLS configuration, logger, and distributed read/write endpoints, to give administrators visibility across a fleet of devices with minimal overhead and intrusiveness.\n* [Falcon Orchestrator](https://github.com/CrowdStrike/falcon-orchestrator) - Extendable Windows-based application that provides workflow automation, case management and security response functionality.\n* [Flare](https://github.com/fireeye/flare-vm) - A fully customizable, Windows-based security distribution for malware analysis, incident response, penetration testing.\n* [Fleetdm](https://github.com/fleetdm/fleet) - State of the art host monitoring platform tailored for security experts. Leveraging Facebook's battle-tested osquery project, Fleetdm delivers continuous updates, features and fast answers to big questions.\n* [GRR Rapid Response](https://github.com/google/grr) - Incident response framework focused on remote live forensics. It consists of a python agent (client) that is installed on target systems, and a python server infrastructure that can manage and talk to the agent. Besides the included Python API client, [PowerGRR](https://github.com/swisscom/PowerGRR) provides an API client library in PowerShell working on Windows, Linux and macOS for GRR automation and scripting.\n* [IRIS](https://github.com/dfir-iris/iris-web) - IRIS is a web collaborative platform for incident response analysts allowing to share investigations at a technical level.\n* [Kuiper](https://github.com/DFIRKuiper/Kuiper) - Digital Forensics Investigation Platform\n* [Limacharlie](https://www.limacharlie.io/) - Endpoint security platform composed of a collection of small projects all working together that gives you a cross-platform (Windows, OSX, Linux, Android and iOS) low-level environment for managing and pushing additional modules into memory to extend its functionality.\n* [Matano](https://github.com/matanolabs/matano): Open source serverless security lake platform on AWS that lets you ingest, store, and analyze petabytes of security data into an Apache Iceberg data lake and run realtime Python detections as code.\n* [MozDef](https://github.com/mozilla/MozDef) - Automates the security incident handling process and facilitate the real-time activities of incident handlers.\n* [MutableSecurity](https://github.com/MutableSecurity/mutablesecurity) - CLI program for automating the setup, configuration, and use of cybersecurity solutions.\n* [nightHawk](https://github.com/biggiesmallsAG/nightHawkResponse) - Application built for asynchronous forensic data presentation using ElasticSearch as the backend. It's designed to ingest Redline collections.\n* [Open Computer Forensics Architecture](http://sourceforge.net/projects/ocfa/) - Another popular distributed open-source computer forensics framework. This framework was built on Linux platform and uses postgreSQL database for storing data.\n* [osquery](https://osquery.io/) - Easily ask questions about your Linux and macOS infrastructure using a SQL-like query language; the provided *incident-response pack* helps you detect and respond to breaches.\n* [Redline](https://www.fireeye.com/services/freeware/redline.html) - Provides host investigative capabilities to users to find signs of malicious activity through memory and file analysis, and the development of a threat assessment profile.\n* [SOC Multi-tool](https://github.com/zdhenard42/SOC-Multitool) - A powerful and user-friendly browser extension that streamlines investigations for security professionals.\n* [The Sleuth Kit & Autopsy](http://www.sleuthkit.org) - Unix and Windows based tool which helps in forensic analysis of computers. It comes with various tools which helps in digital forensics. These tools help in analyzing disk images, performing in-depth analysis of file systems, and various other things.\n* [TheHive](https://thehive-project.org/) - Scalable 3-in-1 open source and free solution designed to make life easier for SOCs, CSIRTs, CERTs and any information security practitioner dealing with security incidents that need to be investigated and acted upon swiftly.\n* [Velociraptor](https://github.com/Velocidex/velociraptor) - Endpoint visibility and collection tool\n* [X-Ways Forensics](http://www.x-ways.net/forensics/) - Forensics tool for Disk cloning and imaging. It can be used to find deleted files and disk analysis.\n* [Zentral](https://github.com/zentralopensource/zentral) - Combines osquery's powerful endpoint inventory features with a flexible notification and action framework. This enables one to identify and react to changes on OS X and Linux clients.\n\n### Books\n\n* [Applied Incident Response](https://www.amazon.com/Applied-Incident-Response-Steve-Anson/dp/1119560268/) - Steve Anson's book on Incident Response.\n* [Art of Memory Forensics](https://www.amazon.com/Art-Memory-Forensics-Detecting-Malware/dp/1118825098/) - Detecting Malware and Threats in Windows, Linux, and Mac Memory.\n* [Crafting the InfoSec Playbook: Security Monitoring and Incident Response Master Plan](https://www.amazon.com/Crafting-InfoSec-Playbook-Security-Monitoring/dp/1491949406) - by Jeff Bollinger, Brandon Enright and Matthew Valites.\n* [Digital Forensics and Incident Response: Incident response techniques and procedures to respond to modern cyber threats](https://www.amazon.com/Digital-Forensics-Incident-Response-techniques/dp/183864900X) - by Gerard Johansen.\n* [Introduction to DFIR](https://medium.com/@sroberts/introduction-to-dfir-d35d5de4c180/) - By Scott J. Roberts.\n* [Incident Response & Computer Forensics, Third Edition](https://www.amazon.com/Incident-Response-Computer-Forensics-Third/dp/0071798684/) - The definitive guide to incident response.\n* [Incident Response Techniques for Ransomware Attacks](https://www.amazon.com/Incident-Response-Techniques-Ransomware-Attacks/dp/180324044X) - A great guide to build an incident response strategy for ransomware attacks. By Oleg Skulkin.\n* [Incident Response with Threat Intelligence](https://www.amazon.com/Incident-response-Threat-Intelligence-intelligence-based/dp/1801072957) - Great reference to build an incident response plan based also on Threat Intelligence. By Roberto Martinez.\n* [Intelligence-Driven Incident Response](https://www.amazon.com/Intelligence-Driven-Incident-Response-Outwitting-Adversary-ebook-dp-B074ZRN5T7/dp/B074ZRN5T7) - By Scott J. Roberts, Rebekah Brown.\n* [Operator Handbook: Red Team + OSINT + Blue Team Reference](https://www.amazon.com/Operator-Handbook-Team-OSINT-Reference/dp/B085RR67H5/) - Great reference for incident responders.\n* [Practical Memory Forensics](https://www.amazon.com/Practical-Memory-Forensics-Jumpstart-effective/dp/1801070334) - The definitive guide to practice memory forensics. By Svetlana Ostrovskaya and Oleg Skulkin.\n* [The Practice of Network Security Monitoring: Understanding Incident Detection and Response](http://www.amazon.com/gp/product/1593275099) - Richard Bejtlich's book on IR.\n\n### Communities\n\n* [Digital Forensics Discord Server](https://discordapp.com/invite/JUqe9Ek) - Community of 8,000+ working professionals from Law Enforcement, Private Sector, and Forensic Vendors. Additionally, plenty of students and hobbyists! Guide [here](https://aboutdfir.com/a-beginners-guide-to-the-digital-forensics-discord-server/).\n* [Slack DFIR channel](https://dfircommunity.slack.com) - Slack DFIR Communitiy channel - [Signup here](https://start.paloaltonetworks.com/join-our-slack-community).\n\n### Disk Image Creation Tools\n\n* [AccessData FTK Imager](http://accessdata.com/product-download/?/support/adownloads#FTKImager) - Forensics tool whose main purpose is to preview recoverable data from a disk of any kind. FTK Imager can also acquire live memory and paging file on 32bit and 64bit systems.\n* [Bitscout](https://github.com/vitaly-kamluk/bitscout) - Bitscout by Vitaly Kamluk helps you build your fully-trusted customizable LiveCD/LiveUSB image to be used for remote digital forensics (or perhaps any other task of your choice). It is meant to be transparent and monitorable by the owner of the system, forensically sound, customizable and compact.\n* [GetData Forensic Imager](http://www.forensicimager.com/) - Windows based program that will acquire, convert, or verify a forensic image in one of the following common forensic file formats.\n* [Guymager](http://guymager.sourceforge.net) - Free forensic imager for media acquisition on Linux.\n* [Magnet ACQUIRE](https://www.magnetforensics.com/magnet-acquire/) - ACQUIRE by Magnet Forensics allows various types of disk acquisitions to be performed on Windows, Linux, and OS X as well as mobile operating systems.\n\n### Evidence Collection\n\n* [Acquire](https://github.com/fox-it/acquire) - Acquire is a tool to quickly gather forensic artifacts from disk images or a live system into a lightweight container. This makes Acquire an excellent tool to, among others, speedup the process of digital forensic triage. It uses [Dissect](https://github.com/fox-it/dissect) to gather that information from the raw disk, if possible.\n* [artifactcollector](https://github.com/forensicanalysis/artifactcollector) - The artifactcollector project provides a software that collects forensic artifacts on systems.\n* [bulk_extractor](https://github.com/simsong/bulk_extractor) - Computer forensics tool that scans a disk image, a file, or a directory of files and extracts useful information without parsing the file system or file system structures. Because of ignoring the file system structure, the program distinguishes itself in terms of speed and thoroughness.\n* [Cold Disk Quick Response](https://github.com/rough007/CDQR) - Streamlined list of parsers to quickly analyze a forensic image file (`dd`, E01, `.vmdk`, etc) and output nine reports.\n* [CyLR](https://github.com/orlikoski/CyLR) - The CyLR tool collects forensic artifacts from hosts with NTFS file systems quickly, securely and minimizes impact to the host.\n* [Forensic Artifacts](https://github.com/ForensicArtifacts/artifacts) - Digital Forensics Artifact Repository\n* [ir-rescue](https://github.com/diogo-fernan/ir-rescue) - Windows Batch script and a Unix Bash script to comprehensively collect host forensic data during incident response.\n* [Live Response Collection](https://www.brimorlabs.com/tools/) - Automated tool that collects volatile data from Windows, OSX, and \\*nix based operating systems.\n* [Margarita Shotgun](https://github.com/ThreatResponse/margaritashotgun) - Command line utility (that works with or without Amazon EC2 instances) to parallelize remote memory acquisition.\n* [SPECTR3](https://github.com/alpine-sec/SPECTR3) - Acquire, triage and investigate remote evidence via portable iSCSI readonly access\n* [UAC](https://github.com/tclahr/uac) - UAC (Unix-like Artifacts Collector) is a Live Response collection script for Incident Response that makes use of native binaries and tools to automate the collection of AIX, Android, ESXi, FreeBSD, Linux, macOS, NetBSD, NetScaler, OpenBSD and Solaris systems artifacts.\n\n### Incident Management\n\n* [Catalyst](https://github.com/SecurityBrewery/catalyst) - A free SOAR system that helps to automate alert handling and incident response processes.\n* [CyberCPR](https://www.cybercpr.com) - Community and commercial incident management tool with Need-to-Know built in to support GDPR compliance while handling sensitive incidents.\n* [Cyphon](https://medevel.com/cyphon/) - Cyphon eliminates the headaches of incident management by streamlining a multitude of related tasks through a single platform. It receives, processes and triages events to provide an all-encompassing solution for your analytic workflow — aggregating data, bundling and prioritizing alerts, and empowering analysts to investigate and document incidents.\n* [CORTEX XSOAR](https://www.paloaltonetworks.com/cortex/xsoar) - Paloalto security orchestration, automation and response platform with full Incident lifecycle management and many integrations to enhance automations.\n* [DFTimewolf](https://github.com/log2timeline/dftimewolf) - A framework for orchestrating forensic collection, processing and data export.\n* [DFIRTrack](https://github.com/dfirtrack/dfirtrack) - Incident Response tracking application handling one or more incidents via cases and tasks with a lot of affected systems and artifacts.\n* [Fast Incident Response (FIR)](https://github.com/certsocietegenerale/FIR/) - Cybersecurity incident management platform designed with agility and speed in mind. It allows for easy creation, tracking, and reporting of cybersecurity incidents and is useful for CSIRTs, CERTs and SOCs alike.\n* [RTIR](https://www.bestpractical.com/rtir/) - Request Tracker for Incident Response (RTIR) is the premier open source incident handling system targeted for computer security teams. We worked with over a dozen CERT and CSIRT teams around the world to help you handle the ever-increasing volume of incident reports. RTIR builds on all the features of Request Tracker.\n* [Sandia Cyber Omni Tracker (SCOT)](https://github.com/sandialabs/scot) - Incident Response collaboration and knowledge capture tool focused on flexibility and ease of use. Our goal is to add value to the incident response process without burdening the user.\n* [Shuffle](https://github.com/frikky/Shuffle) - A general purpose security automation platform focused on accessibility.\n* [threat_note](https://github.com/defpoint/threat_note) - Lightweight investigation notebook that allows security researchers the ability to register and retrieve indicators related to their research.\n* [Zenduty](https://www.zenduty.com) - Zenduty is a novel incident management platform providing end-to-end incident alerting, on-call management and response orchestration, giving teams greater control and automation over the incident management lifecycle.\n\n### Knowledge Bases\n\n* [Digital Forensics Artifact Knowledge Base](https://github.com/ForensicArtifacts/artifacts-kb) - Digital Forensics Artifact Knowledge Base\n* [Windows Events Attack Samples](https://github.com/sbousseaden/EVTX-ATTACK-SAMPLES) - Windows Events Attack Samples\n* [Windows Registry Knowledge Base](https://github.com/libyal/winreg-kb) - Windows Registry Knowledge Base\n\n### Linux Distributions\n\n* [The Appliance for Digital Investigation and Analysis (ADIA)](https://forensics.cert.org/#ADIA) - VMware-based appliance used for digital investigation and acquisition and is built entirely from public domain software. Among the tools contained in ADIA are Autopsy, the Sleuth Kit, the Digital Forensics Framework, log2timeline, Xplico, and Wireshark. Most of the system maintenance uses Webmin. It is designed for small-to-medium sized digital investigations and acquisitions. The appliance runs under Linux, Windows, and Mac OS. Both i386 (32-bit) and x86_64 (64-bit) versions are available.\n* [Computer Aided Investigative Environment (CAINE)](http://www.caine-live.net/index.html) - Contains numerous tools that help investigators during their analysis, including forensic evidence collection.\n* [CCF-VM](https://github.com/rough007/CCF-VM) - CyLR CDQR Forensics Virtual Machine (CCF-VM): An all-in-one solution to parsing collected data, making it easily searchable with built-in common searches, enable searching of single and multiple hosts simultaneously.\n* [NST - Network Security Toolkit](https://sourceforge.net/projects/nst/files/latest/download?source=files) - Linux distribution that includes a vast collection of best-of-breed open source network security applications useful to the network security professional.\n* [PALADIN](https://sumuri.com/software/paladin/) - Modified Linux distribution to perform various forensics task in a forensically sound manner. It comes with many open source forensics tools included.\n* [Security Onion](https://github.com/Security-Onion-Solutions/security-onion) - Special Linux distro aimed at network security monitoring featuring advanced analysis tools.\n* [SANS Investigative Forensic Toolkit (SIFT) Workstation](http://digital-forensics.sans.org/community/downloads) - Demonstrates that advanced incident response capabilities and deep dive digital forensic techniques to intrusions can be accomplished using cutting-edge open-source tools that are freely available and frequently updated.\n\n### Linux Evidence Collection\n\n* [FastIR Collector Linux](https://github.com/SekoiaLab/Fastir_Collector_Linux) - FastIR for Linux collects different artifacts on live Linux and records the results in CSV files.\n* [MAGNET DumpIt](https://github.com/MagnetForensics/dumpit-linux) - Fast memory acquisition open source tool for Linux written in Rust. Generate full memory crash dumps of Linux machines.\n\n### Log Analysis Tools\n\n* [AppCompatProcessor](https://github.com/mbevilacqua/appcompatprocessor) - AppCompatProcessor has been designed to extract additional value from enterprise-wide AppCompat / AmCache data beyond the classic stacking and grepping techniques.\n* [APT Hunter](https://github.com/ahmedkhlief/APT-Hunter) - APT-Hunter is Threat Hunting tool for windows event logs.\n* [Chainsaw](https://github.com/countercept/chainsaw) - Chainsaw provides a powerful ‘first-response’ capability to quickly identify threats within Windows event logs.\n* [Event Log Explorer](https://eventlogxp.com/) - Tool developed to quickly analyze log files and other data.\n* [Event Log Observer](https://lizard-labs.com/event_log_observer.aspx) - View, analyze and monitor events recorded in Microsoft Windows event logs with this GUI tool.\n* [Hayabusa](https://github.com/Yamato-Security/hayabusa) - Hayabusa is a Windows event log fast forensics timeline generator and threat hunting tool created by the Yamato Security group in Japan.\n* [Kaspersky CyberTrace](https://support.kaspersky.com/13850) - Threat intelligence fusion and analysis tool that integrates threat data feeds with SIEM solutions. Users can immediately leverage threat intelligence for security monitoring and incident report (IR) activities in the workflow of their existing security operations.\n* [Log Parser Lizard](https://lizard-labs.com/log_parser_lizard.aspx) - Execute SQL queries against structured log data: server logs, Windows Events, file system, Active Directory, log4net logs, comma/tab separated text, XML or JSON files. Also provides a GUI to Microsoft LogParser 2.2 with powerful UI elements: syntax editor, data grid, chart, pivot table, dashboard, query manager and more.\n* [Lorg](https://github.com/jensvoid/lorg) - Tool for advanced HTTPD logfile security analysis and forensics.\n* [Logdissect](https://github.com/dogoncouch/logdissect) - CLI utility and Python API for analyzing log files and other data.\n* [LogonTracer](https://github.com/JPCERTCC/LogonTracer) - Tool to investigate malicious Windows logon by visualizing and analyzing Windows event log.\n* [Sigma](https://github.com/SigmaHQ/sigma) - Generic signature format for SIEM systems already containing an extensive ruleset.\n* [StreamAlert](https://github.com/airbnb/streamalert) - Serverless, real-time log data analysis framework, capable of ingesting custom data sources and triggering alerts using user-defined logic.\n* [SysmonSearch](https://github.com/JPCERTCC/SysmonSearch) - SysmonSearch makes Windows event log analysis more effective and less time consuming by aggregation of event logs.\n* [WELA](https://github.com/Yamato-Security/WELA) - Windows Event Log Analyzer aims to be the Swiss Army knife for Windows event logs.\n* [Zircolite](https://github.com/wagga40/Zircolite) - A standalone and fast SIGMA-based detection tool for EVTX or JSON.\n\n### Memory Analysis Tools\n\n* [AVML](https://github.com/microsoft/avml) - A portable volatile memory acquisition tool for Linux.\n* [Evolve](https://github.com/JamesHabben/evolve) - Web interface for the Volatility Memory Forensics Framework.\n* [inVtero.net](https://github.com/ShaneK2/inVtero.net) - Advanced memory analysis for Windows x64 with nested hypervisor support.\n* [LiME](https://github.com/504ensicsLabs/LiME) - Loadable Kernel Module (LKM), which allows the acquisition of volatile memory from Linux and Linux-based devices, formerly called DMD.\n* [MalConfScan](https://github.com/JPCERTCC/MalConfScan) - MalConfScan is a Volatility plugin extracts configuration data of known malware. Volatility is an open-source memory forensics framework for incident response and malware analysis. This tool searches for malware in memory images and dumps configuration data. In addition, this tool has a function to list strings to which malicious code refers.\n* [Memoryze](https://www.fireeye.com/services/freeware/memoryze.html) - Free memory forensic software that helps incident responders find evil in live memory. Memoryze can acquire and/or analyze memory images, and on live systems, can include the paging file in its analysis.\n* [Memoryze for Mac](https://www.fireeye.com/services/freeware/memoryze.html) - Memoryze for Mac is Memoryze but then for Macs. A lower number of features, however.\n* [MemProcFS] (https://github.com/ufrisk/MemProcFS) - MemProcFS is an easy and convenient way of viewing physical memory as files in a virtual file system.\n* [Orochi](https://github.com/LDO-CERT/orochi) - Orochi is an open source framework for collaborative forensic memory dump analysis.\n* [Rekall](http://www.rekall-forensic.com/) - Open source tool (and library) for the extraction of digital artifacts from volatile memory (RAM) samples.\n* [Volatility](https://github.com/volatilityfoundation/volatility) - Advanced memory forensics framework.\n* [Volatility 3](https://github.com/volatilityfoundation/volatility3) - The volatile memory extraction framework (successor of Volatility)\n* [VolatilityBot](https://github.com/mkorman90/VolatilityBot) - Automation tool for researchers cuts all the guesswork and manual tasks out of the binary extraction phase, or to help the investigator in the first steps of performing a memory analysis investigation.\n* [VolDiff](https://github.com/aim4r/VolDiff) - Malware Memory Footprint Analysis based on Volatility.\n* [WindowsSCOPE](http://www.windowsscope.com/windowsscope-cyber-forensics/) - Memory forensics and reverse engineering tool used for analyzing volatile memory offering the capability of analyzing the Windows kernel, drivers, DLLs, and virtual and physical memory.\n\n### Memory Imaging Tools\n\n* [Linux Memory Grabber](https://github.com/halpomeranz/lmg/) - Script for dumping Linux memory and creating Volatility profiles.\n* [MAGNET DumpIt](https://www.magnetforensics.com/resources/magnet-dumpit-for-windows) - Fast memory acquisition tool for Windows (x86, x64, ARM64). Generate full memory crash dumps of Windows machines.\n* [Magnet RAM Capture](https://www.magnetforensics.com/free-tool-magnet-ram-capture/) - Free imaging tool designed to capture the physical memory of a suspect’s computer. Supports recent versions of Windows.\n* [OSForensics](http://www.osforensics.com/) - Tool to acquire live memory on 32-bit and 64-bit systems. A dump of an individual process’s memory space or physical memory dump can be done.\n\n### OSX Evidence Collection\n\n* [Knockknock](https://objective-see.com/products/knockknock.html) - Displays persistent items(scripts, commands, binaries, etc.) that are set to execute automatically on OSX.\n* [macOS Artifact Parsing Tool (mac_apt)](https://github.com/ydkhatri/mac_apt) - Plugin based forensics framework for quick mac triage that works on live machines, disk images or individual artifact files.\n* [OSX Auditor](https://github.com/jipegit/OSXAuditor) - Free Mac OS X computer forensics tool.\n* [OSX Collector](https://github.com/yelp/osxcollector) - OSX Auditor offshoot for live response.\n* [The ESF Playground](https://themittenmac.com/the-esf-playground/) - A tool to view the events in Apple Endpoint Security Framework (ESF) in real time.\n\n### Other Lists\n\n* [Awesome Event IDs](https://github.com/stuhli/awesome-event-ids) - Collection of Event ID resources useful for Digital Forensics and Incident Response.\n* [Awesome Forensics](https://github.com/cugu/awesome-forensics) - A curated list of awesome forensic analysis tools and resources.\n* [Didier Stevens Suite](https://github.com/DidierStevens/DidierStevensSuite) - Tool collection\n* [Eric Zimmerman Tools](https://ericzimmerman.github.io/) - An updated list of forensic tools created by Eric Zimmerman, an instructor for SANS institute.\n* [List of various Security APIs](https://github.com/deralexxx/security-apis) - Collective list of public JSON APIs for use in security.\n\n### Other Tools\n\n* [Cortex](https://thehive-project.org) - Cortex allows you to analyze observables such as IP and email addresses, URLs, domain names, files or hashes one by one or in bulk mode using a Web interface. Analysts can also automate these operations using its REST API.\n* [Crits](https://crits.github.io/) - Web-based tool which combines an analytic engine with a cyber threat database.\n* [Diffy](https://github.com/Netflix-Skunkworks/diffy) - DFIR tool developed by Netflix's SIRT that allows an investigator to quickly scope a compromise across cloud instances (Linux instances on AWS, currently) during an incident and efficiently triaging those instances for followup actions by showing differences against a baseline.\n* [domfind](https://github.com/diogo-fernan/domfind) - Python DNS crawler for finding identical domain names under different TLDs.\n* [Fileintel](https://github.com/keithjjones/fileintel) - Pull intelligence per file hash.\n* [HELK](https://github.com/Cyb3rWard0g/HELK) - Threat Hunting platform.\n* [Hindsight](https://github.com/obsidianforensics/hindsight) - Internet history forensics for Google Chrome/Chromium.\n* [Hostintel](https://github.com/keithjjones/hostintel) - Pull intelligence per host.\n* [imagemounter](https://github.com/ralphje/imagemounter) - Command line utility and Python package to ease the (un)mounting of forensic disk images.\n* [Kansa](https://github.com/davehull/Kansa/) - Modular incident response framework in PowerShell.\n* [MFT Browser](https://github.com/kacos2000/MFT_Browser) - MFT directory tree reconstruction & record info.\n* [Munin](https://github.com/Neo23x0/munin) - Online hash checker for VirusTotal and other services.\n* [PowerSponse](https://github.com/swisscom/PowerSponse) - PowerSponse is a PowerShell module focused on targeted containment and remediation during security incident response.\n* [PyaraScanner](https://github.com/nogoodconfig/pyarascanner) - Very simple multi-threaded many-rules to many-files YARA scanning Python script for malware zoos and IR.\n* [rastrea2r](https://github.com/rastrea2r/rastrea2r) - Allows one to scan disks and memory for IOCs using YARA on Windows, Linux and OS X.\n* [RaQet](https://raqet.github.io/) - Unconventional remote acquisition and triaging tool that allows triage a disk of a remote computer (client) that is restarted with a purposely built forensic operating system.\n* [Raccine](https://github.com/Neo23x0/Raccine) - A Simple Ransomware Protection\n* [Stalk](https://www.percona.com/doc/percona-toolkit/2.2/pt-stalk.html) - Collect forensic data about MySQL when problems occur.\n* [Scout2](https://nccgroup.github.io/Scout2/) - Security tool that lets Amazon Web Services administrators assess their environment's security posture.\n* [Stenographer](https://github.com/google/stenographer) - Packet capture solution which aims to quickly spool all packets to disk, then provide simple, fast access to subsets of those packets. It stores as much history as it possible, managing disk usage, and deleting when disk limits are hit. It's ideal for capturing the traffic just before and during an incident, without the need explicit need to store all of the network traffic.\n* [sysmon-config](https://github.com/SwiftOnSecurity/sysmon-config) - Sysmon configuration file template with default high-quality event tracing\n* [sysmon-modular](https://github.com/olafhartong/sysmon-modular) - A repository of sysmon configuration modules\n* [traceroute-circl](https://github.com/CIRCL/traceroute-circl) - Extended traceroute to support the activities of CSIRT (or CERT) operators. Usually CSIRT team have to handle incidents based on IP addresses received. Created by Computer Emergency Response Center Luxembourg.\n* [X-Ray 2.0](https://www.raymond.cc/blog/xray/) - Windows utility (poorly maintained or no longer maintained) to submit virus samples to AV vendors.\n\n### Playbooks\n\n* [AWS Incident Response Runbook Samples](https://github.com/aws-samples/aws-incident-response-runbooks/tree/0d9a1c0f7ad68fb2c1b2d86be8914f2069492e21) - AWS IR Runbook Samples meant to be customized per each entity using them. The three samples are: \"DoS or DDoS attack\", \"credential leakage\", and \"unintended access to an Amazon S3 bucket\".\n* [Counteractive Playbooks](https://github.com/counteractive/incident-response-plan-template/tree/master/playbooks) - Counteractive PLaybooks collection.\n* [GuardSIght Playbook Battle Cards](https://github.com/guardsight/gsvsoc_cirt-playbook-battle-cards) - A collection of Cyber Incident Response Playbook Battle Cards\n* [IRM](https://github.com/certsocietegenerale/IRM) - Incident Response Methodologies by CERT Societe Generale.\n* [PagerDuty Incident Response Documentation](https://response.pagerduty.com/) - Documents that describe parts of the PagerDuty Incident Response process. It provides information not only on preparing for an incident, but also what to do during and after. Source is available on [GitHub](https://github.com/PagerDuty/incident-response-docs).\n* [Phantom Community Playbooks](https://github.com/phantomcyber/playbooks) - Phantom Community Playbooks for Splunk but also customizable for other use.\n* [ThreatHunter-Playbook](https://github.com/OTRF/ThreatHunter-Playbook) - Playbook to aid the development of techniques and hypothesis for hunting campaigns.\n\n### Process Dump Tools\n\n* [Microsoft ProcDump](https://docs.microsoft.com/en-us/sysinternals/downloads/procdump) - Dumps any running Win32 processes memory image on the fly.\n\n### Sandboxing/Reversing Tools\n\n* [Any Run](https://app.any.run/) - Interactive online malware analysis service for dynamic and static research of most types of threats using any environment.\n* [CAPA](https://github.com/mandiant/capa) - detects capabilities in executable files. You run it against a PE, ELF, .NET module, or shellcode file and it tells you what it thinks the program can do.\n* [CAPEv2](https://github.com/kevoreilly/CAPEv2) - Malware Configuration And Payload Extraction.\n* [Cuckoo](https://github.com/cuckoosandbox/cuckoo) - Open Source Highly configurable sandboxing tool.\n* [Cuckoo-modified](https://github.com/spender-sandbox/cuckoo-modified) - Heavily modified Cuckoo fork developed by community.\n* [Cuckoo-modified-api](https://github.com/keithjjones/cuckoo-modified-api) - Python library to control a cuckoo-modified sandbox.\n* [Cutter](https://github.com/rizinorg/cutter) - Free and Open Source Reverse Engineering Platform powered by rizin.\n* [Ghidra](https://github.com/NationalSecurityAgency/ghidra) - Software Reverse Engineering Framework.\n* [Hybrid-Analysis](https://www.hybrid-analysis.com/) - Free powerful online sandbox by CrowdStrike.\n* [Intezer](https://analyze.intezer.com/#/) - Intezer Analyze dives into Windows binaries to detect micro-code similarities to known threats, in order to provide accurate yet easy-to-understand results.\n* [Joe Sandbox (Community)](https://www.joesandbox.com/) - Joe Sandbox detects and analyzes potential malicious files and URLs on Windows, Android, Mac OS, Linux, and iOS for suspicious activities; providing comprehensive and detailed analysis reports.\n* [Mastiff](https://github.com/KoreLogicSecurity/mastiff) - Static analysis framework that automates the process of extracting key characteristics from a number of different file formats.\n* [Metadefender Cloud](https://www.metadefender.com) - Free threat intelligence platform providing multiscanning, data sanitization and vulnerability assessment of files.\n* [Radare2](https://github.com/radareorg/radare2) - Reverse engineering framework and command-line toolset.\n* [Reverse.IT](https://www.reverse.it/) - Alternative domain for the Hybrid-Analysis tool provided by CrowdStrike.\n* [Rizin](https://github.com/rizinorg/rizin) - UNIX-like reverse engineering framework and command-line toolset\n* [StringSifter](https://github.com/fireeye/stringsifter) - A machine learning tool that ranks strings based on their relevance for malware analysis.\n* [Threat.Zone](https://app.threat.zone) - Cloud based threat analysis platform which include sandbox, CDR and interactive analysis for researchers.\n* [Valkyrie Comodo](https://valkyrie.comodo.com) - Valkyrie uses run-time behavior and hundreds of features from a file to perform analysis.\n* [Viper](https://github.com/viper-framework/viper) - Python based binary analysis and management framework, that works well with Cuckoo and YARA.\n* [Visualize_Logs](https://github.com/keithjjones/visualize_logs) - Open source visualization library and command line tools for logs (Cuckoo, Procmon, more to come).\n* [Yomi](https://yomi.yoroi.company) - Free MultiSandbox managed and hosted by Yoroi.\n\n### Scanner Tools\n\n* [Fenrir](https://github.com/Neo23x0/Fenrir) - Simple IOC scanner. It allows scanning any Linux/Unix/OSX system for IOCs in plain bash. Created by the creators of THOR and LOKI.\n* [LOKI](https://github.com/Neo23x0/Loki) - Free IR scanner for scanning endpoint with yara rules and other indicators(IOCs).\n* [Spyre](https://github.com/spyre-project/spyre) - Simple YARA-based IOC scanner written in Go\n\n### Timeline Tools\n\n* [Aurora Incident Response](https://github.com/cyb3rfox/Aurora-Incident-Response) - Platform developed to build easily a detailed timeline of an incident.\n* [Highlighter](https://www.fireeye.com/services/freeware/highlighter.html) - Free Tool available from Fire/Mandiant that will depict log/text file that can highlight areas on the graphic, that corresponded to a key word or phrase. Good for time lining an infection and what was done post compromise.\n* [Morgue](https://github.com/etsy/morgue) - PHP Web app by Etsy for managing postmortems.\n* [Plaso](https://github.com/log2timeline/plaso) -  a Python-based backend engine for the tool log2timeline.\n* [Timesketch](https://github.com/google/timesketch) - Open source tool for collaborative forensic timeline analysis.\n\n### Videos\n\n* [The Future of Incident Response](https://www.youtube.com/watch?v=bDcx4UNpKNc) - Presented by Bruce Schneier at OWASP AppSecUSA 2015.\n\n### Windows Evidence Collection\n\n* [AChoir](https://github.com/OMENScan/AChoir) - Framework/scripting tool to standardize and simplify the process of scripting live acquisition utilities for Windows.\n* [Crowd Response](http://www.crowdstrike.com/community-tools/) - Lightweight Windows console application designed to aid in the gathering of system information for incident response and security engagements. It features numerous modules and output formats.\n* [Cyber Triage](http://www.cybertriage.com) - Cyber Triage has a lightweight collection tool that is free to use. It collects source files (such as registry hives and event logs), but also parses them on the live host so that it can also collect the executables that the startup items, scheduled, tasks, etc. refer to. It's output is a JSON file that can be imported into the free version of Cyber Triage. Cyber Triage is made by Sleuth Kit Labs, which also makes Autopsy. \n* [DFIR ORC](https://dfir-orc.github.io/) - DFIR ORC is a collection of specialized tools dedicated to reliably parse and collect critical artifacts such as the MFT, registry hives or event logs. DFIR ORC collects data, but does not analyze it: it is not meant to triage machines. It provides a forensically relevant snapshot of machines running Microsoft Windows. The code can be found on [GitHub](https://github.com/DFIR-ORC/dfir-orc).\n* [FastIR Collector](https://github.com/SekoiaLab/Fastir_Collector) - Tool that collects different artifacts on live Windows systems and records the results in csv files. With the analyses of these artifacts, an early compromise can be detected.\n* [Fibratus](https://github.com/rabbitstack/fibratus) - Tool for exploration and tracing of the Windows kernel.\n* [Hoarder](https://github.com/muteb/Hoarder) - Collecting the most valuable artifacts for forensics or incident response investigations.\n* [IREC](https://binalyze.com/products/irec-free/) - All-in-one IR Evidence Collector which captures RAM Image, $MFT, EventLogs, WMI Scripts, Registry Hives, System Restore Points and much more. It is FREE, lightning fast and easy to use.\n* [Invoke-LiveResponse](https://github.com/mgreen27/Invoke-LiveResponse) -  Invoke-LiveResponse is a live response tool for targeted collection.\n* [IOC Finder](https://www.fireeye.com/services/freeware/ioc-finder.html) - Free tool from Mandiant for collecting host system data and reporting the presence of Indicators of Compromise (IOCs). Support for Windows only. No longer maintained. Only fully supported up to Windows 7 / Windows Server 2008 R2.\n* [IRTriage](https://github.com/AJMartel/IRTriage) - Incident Response Triage - Windows Evidence Collection for Forensic Analysis.\n* [KAPE](https://www.kroll.com/en/services/cyber-risk/incident-response-litigation-support/kroll-artifact-parser-extractor-kape) - Kroll Artifact Parser and Extractor (KAPE) by Eric Zimmerman. A triage tool that finds the most prevalent digital artifacts and then parses them quickly. Great and thorough when time is of the essence.\n* [LOKI](https://github.com/Neo23x0/Loki) - Free IR scanner for scanning endpoint with yara rules and other indicators(IOCs).\n* [MEERKAT](https://github.com/TonyPhipps/Meerkat) - PowerShell-based triage and threat hunting for Windows.\n* [Panorama](https://github.com/AlmCo/Panorama) - Fast incident overview on live Windows systems.\n* [PowerForensics](https://github.com/Invoke-IR/PowerForensics) - Live disk forensics platform, using PowerShell.\n* [PSRecon](https://github.com/gfoss/PSRecon/) - PSRecon gathers data from a remote Windows host using PowerShell (v2 or later), organizes the data into folders, hashes all extracted data, hashes PowerShell and various system properties, and sends the data off to the security team. The data can be pushed to a share, sent over email, or retained locally.\n* [RegRipper](https://github.com/keydet89/RegRipper3.0) - Open source tool, written in Perl, for extracting/parsing information (keys, values, data) from the Registry and presenting it for analysis.\n",
    "timestamp": "2025-05-23T16:30:55.490605",
    "tags": [],
    "severity": "high",
    "services_affected": [
      "api",
      "web",
      "database",
      "cache",
      "queue",
      "monitoring"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "docker",
      "aws",
      "azure",
      "postgresql",
      "redis",
      "elasticsearch",
      "prometheus",
      "grafana",
      "jenkins"
    ],
    "failure_pattern": "configuration_drift",
    "timeline_events": [],
    "blast_radius": "partial",
    "detection_time": null,
    "mitigation_actions": [
      "with a purposely built forensic operating system"
    ],
    "quality_score": 0.98
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/HichamZineb/alx-system_engineering-devops/blob/73b51404c801cf500cc013f9cb52417994b04ee7/0x19-postmortem/postmortem.md",
    "title": "postmortem.md",
    "content": "# Postmortem: MySQL Database Outage\n\n<p align=\"center\">\n<img src=\"postmortem.jpg\" width=100% height=100% />\n</p>\n\n<p align=\"center\"><b>Choose your Databases wisely, read on to see what happened ...</b></p>\n\n## Issue Summary\n\n- **Duration**: November 10, 2023, 8:00 PM - November 11, 2023, 2:00 AM (UTC)\n  \n- **Impact**: The MySQL database experienced an outage, affecting user authentication. Approximately 20% of users were unable to log in during the outage.\n\n- **Root Cause**: The database server ran out of disk space due to an unexpected increase in log file sizes.\n\n## Timeline\n\n- **Issue Detection (November 10, 2023, 8:00 PM)**: Users reported login failures, and monitoring indicated a sudden increase in database response times.\n\n- **Actions Taken (November 10, 2023, 8:30 PM)**: The DevOps team initiated an investigation, focusing on the database server. Assumed root cause to be a potential database query optimization issue.\n\n- **Misleading Paths (November 10, 2023, 9:00 PM)**: Initial investigation erroneously focused on query optimization, delaying the identification of the disk space issue.\n\n- **Escalation (November 10, 2023, 9:30 PM)**: The incident was escalated to senior DevOps members as the database issue persisted.\n\n- **Resolution (November 11, 2023, 2:00 AM)**: By this time, the root cause was identified as insufficient disk space. Temporary files were cleared, and log rotation settings were adjusted to prevent future occurrences.\n\n## Root Cause and Resolution\n\n- **Root Cause Explanation**: The database server ran out of disk space due to an unexpected surge in log file sizes, causing essential database operations to fail.\n\n- **Resolution Explanation**: Temporary files were cleared to free up disk space, and log rotation settings were adjusted to prevent log files from growing excessively.\n\n## Corrective and Preventative Measures\n\n- **Improvements/Fixes**: \n  - Implement proactive monitoring for disk space usage on critical servers.\n  - Review and optimize log rotation settings.\n\n- **Specific Tasks**: \n  - Conduct a database server capacity review.\n  - Implement automated alerts for abnormal increases in log file sizes.\n  - Document and share learnings with the team to improve incident response.\n",
    "timestamp": "2025-05-23T16:31:00.394687",
    "tags": [],
    "severity": "high",
    "services_affected": [
      "database",
      "auth",
      "monitoring"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "postgresql"
    ],
    "failure_pattern": "resource_exhaustion",
    "timeline_events": [
      {
        "timestamp": "8:00 PM",
        "event": "November 11, 2023, 2:00 AM (UTC)"
      }
    ],
    "blast_radius": "localized",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 0.85
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/flaviut/flaviut.github.io/blob/ff5cf5cfe3f7cfcbe4652fbbf51d68e80b5da0a6/_posts/2017-04-06-hackgsu-postmortem.md",
    "title": "2017-04-06-hackgsu-postmortem.md",
    "content": "---\nlayout: post\ntags: [hackathon, hackgsu, hardware]\ntitle: 'SmartBar: Computer-assisted curls (HackGSU S17)'\n---\n\nI attended [HackGSU][] last weekend, and it was my first hackathon. I worked in\na team with Kevin Aiken, Lee Klarich, and Cameron McRae, all of whom are\nfriends from [GSMST][]. We produced the [SmartBar][], a barbell which counted\nthe number of reps done and measured imbalances. Our project [won the Covello\nPrize for the best sports hack][win].\n\n{% include image.html\n    url=\"/assets/images/2017-04-06-hackgsu-postmortem/2.jpg\"\n    description=\"The SmartBar being held by M. Cole Jones of covello. Photo: Lee Klarich\" %}\n\nI had a great time, although it was incredibly draining. 3 hours of sleep in 48\nhours is not healthy--I became more irritable and less able to think, and I\nalso experienced physical effects, like nausea and a sore throat. If I'm going\nto do this again, I'm going to have to sleep more.\n\nOur first hardware implementation (which I worked on) used two [Grove\nAccelerometers (MMA7660FC)][grove-accel]. That didn't really work out because:\n\n1. The accelerometer is a piece of crap. Six bits per axis ([spec\nsheet][mma7660fc]), including the sign bit. -31 to 31 is not enough precision…\nfor anything really. It was also very noisy, the value would constantly (on\nevery read) toggle ±1.\n2. You can only attach one device with a specific I2C slave address to one bus,\nand we needed two devices. We could have \"contact[ed] the factory to request a\ndifferent I2C slave address,\"[^1] but we had a time limit (and a budget of $0).\nThe workaround I worked on was to attach one of them directly to the Pi's I2C\nport, but I gave up on that after realizing that the poor resolution made it\npointless.\n\n[^1]: [spec sheet][mma7660fc], p. 23, section \"The Slave Address\"\n\nI also had trouble connecting the sensor to the Arduino. Turns out the problem\nwas some bad jumper wires. **Lesson learned: never assume that anything is to\nsimple to fail--even if it's a wire with no visible physical damage.**\n\nSo we tried to use an Arduino 101 that we borrowed from downstairs, but it was\nbroken. We couldn't figure out what was wrong, but then we finally ended up\nexchanging it and the new one worked fine. The resolution on the 101's\naccelerometer is really great, and we had no problems with noise. Kevin graphed\nthe data on LibreOffice Calc, and used the graph for guidance while writing [the\ndetection code][detect-source].\n\n{% include image.html\n    url=\"/assets/images/2017-04-06-hackgsu-postmortem/1.png\"\n    description=\"Newer version of Kevin's graph. Note the lack of noise!\" %}\n\nCameron worked on the [Android app][android-source]. We had a lot of trouble\nwith it, because none of us had ever worked on an Android app or Android\nBluetooth. I learned that a) copy-pasting code without understand it doesn't\nwork, and b) we shouldn't choose technologies that none of us have even\ntouched. **A hackathon is not the time to learn a complicated system like\nAndroid from scratch.**\n\nMe and Lee set up the website. Lee initially implemented it in PHP & MySQL, but\nthen [we rewrote it][website-source] in Python 3, Flask, SQLAlchemy, and\nPostgreSQL. Writing the website was pretty straightforward. Even though we were\nnot familiar with Flask or SQLAlchemy, we were familiar with web development in\nPython, so we didn't run into any issues.\n\n{% include image.html\n    url=\"/assets/images/2017-04-06-hackgsu-postmortem/3.png\"\n    description=\"Final version of the website, loaded with random data.\" %}\n\nLee tried to set up Apache2 on the EC2 server to host the server. We spent a\nfew hours trying to get that to work. We eventually just gave up and set up a\ndev server with Nginx proxying port 80 to port 6000. The lesson here is to\n**not bother setting things up correctly, just get them working.** Polish,\nreliability, or security is not a priority for hackathon software, **all that\nmatters is that the demo seems to work.**\n\n\n[HackGSU]: https://hackgsu-spring-2017.devpost.com/\n[GSMST]: http://www.gsmst.org/\n[SmartBar]: https://github.com/KevinAiken/Smart-Bar\n[win]: https://hackgsu-spring-2017.devpost.com/submissions/search?utf8=✓&terms=SmartBar\n[grove-accel]: http://wiki.seeed.cc/Grove-3-Axis_Digital_Accelerometer-1.5g/\n[mma7660fc]: http://www.nxp.com/assets/documents/data/en/data-sheets/MMA7660FC.pdf\n[android-source]: https://github.com/KevinAiken/Smart-Bar/tree/master/android-app\n[website-source]: https://github.com/KevinAiken/Smart-Bar/tree/master/hsus\n[detect-source]: https://github.com/KevinAiken/Smart-Bar/tree/master/read-accel\n",
    "timestamp": "2025-05-23T16:31:00.820936",
    "tags": [],
    "severity": "high",
    "services_affected": [
      "web"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "aws",
      "postgresql",
      "elasticsearch",
      "nginx"
    ],
    "failure_pattern": null,
    "timeline_events": [],
    "blast_radius": "localized",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 0.62
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/AbdelazizAdrehmi/alx-system_engineering-devops/blob/88b1471d1d90d6e0e5ea0e1f563c8a7851c121d6/0x19-postmortem/Postmortem_Report_Webstack_Debugging.md",
    "title": "Postmortem_Report_Webstack_Debugging.md",
    "content": "Postmortem Report\nIncident Report for 504 Error / Site Outage\n\nSummary:\nOn September 24th, 2024, at 00:00 PST, users experienced a 504 error while trying to access the website. The server, which uses a LAMP stack, had an issue due to a wrong file name in the wp-settings.php file.\n\nTimeline:\n\n00:00 PST: Users encounter a 504 error when accessing the website.\n00:05 PST: Apache and MySQL services are checked and found to be running.\n00:10 PST: Website still not loading; server and database are working correctly.\n00:12 PST: Restarted Apache server, returned a 200 OK status.\n00:18 PST: Started reviewing error logs to find the issue.\n00:25 PST: Apache server was shutting down unexpectedly; no PHP error logs were available.\n00:30 PST: Found PHP error logging was turned off; enabled it.\n00:32 PST: Restarted Apache and reviewed new PHP error logs.\n00:36 PST: Discovered a misspelled file name (.phpp instead of .php) in wp-settings.php.\n00:38 PST: Fixed the typo and restarted the server.\n00:40 PST: Server and website returned to normal operation.\nRoot Cause and Resolution:\n\nThe issue was caused by a typo in the wp-settings.php file, where a file was referenced with .phpp instead of .php. Once error logging was turned on, the typo was identified and corrected. After restarting the server, the website was restored.\n\nCorrective and Preventive Measures:\n\nAlways enable error logging to quickly find and fix problems.\nTest websites locally before deploying to prevent issues.\nRegularly monitor error logs to catch potential problems early.\n",
    "timestamp": "2025-05-23T16:31:03.868472",
    "tags": [],
    "severity": "high",
    "services_affected": [
      "api",
      "web",
      "database"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "postgresql"
    ],
    "failure_pattern": null,
    "timeline_events": [],
    "blast_radius": "localized",
    "detection_time": null,
    "mitigation_actions": [
      "Apache and reviewed new PHP error logs",
      "the server",
      "Apache server, returned a 200 OK status"
    ],
    "quality_score": 0.43
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/Minte123/alx-system_engineering-devops/blob/f10b628ef1e5175b4c2981928a0881cdad898b69/0x19-postmortem/Postmortem_Report.md",
    "title": "Postmortem_Report.md",
    "content": "# Postmortem Report\n\n## 504 Error while accessing a given URL\n\n<p align=\"center\">\n<img src=\"https://camo.githubusercontent.com/2a4a053fc0aba4178e4ad01e4810f5f2b0e4d592613ae91e3dba4f431c95c444/68747470733a2f2f692e70696e696d672e636f6d2f353634782f37342f36382f35362f37343638353639313937306262623265306331623263373137366662356430352e6a7067\" width=100% height=100% />\n</p>\n\n## Incident report for [504 error / Site Outage]\n\n### Summary\n\nOn September 11th, 2021 at midnight the server access went down resulting in 504 error for anyone trying to access a website. Background on the server being based on a LAMP stack.\n\n### Timeline\n\n- **00:00 PST** - 500 error for anyone trying to access the website\n- **00:05 PST** - Ensuring Apache and MySQL are up and running.\n- **00:10 PST** - The website was not loading properly which on background check revealed that the server was working properly as well as the database.\n- **00:12 PST** - After quick restart to Apache server returned a status of 200 and OK while trying to curl the website.\n- **00:18 PST** - Reviewing error logs to check where the error might be coming from.\n- **00:25 PST** - Check /var/log to see that the Apache server was being prematurely shut down. The error log for PHP were nowhere to be found.\n- **00:30 PST** - Checking php.ini settings revealed all error logging had been turned off. Turning the error logging on.\n- **00:32 PST** - Restarting apache server and going to the error logs to check what is being logged into the php error logs.\n- **00:36 PST** - Reviewing error logs for php revealed a mistyped file name which was resulting in incorrect loading and premature closing of apache.\n- **00:38 PST** - Fixing file name and restarting Apache server.\n- **00:40 PST** - Server is now running normally and the website is loading properly.\n\n\n### Root Cause and Resolution\n\nThe issue was connected with a wrong file name being reffered to in the wp-settings.php file. The error was raised when trying to curl the server, wherein the server responded with 500 error. By checking the error logs it was found that no error log file was being created for the php errors and reading the default error log for apache did not result in much information regarding the premature closing of the server. Once understood that the errors for php logs were not being directed anywhere the engineer chose to review the error log setting for the php in the php.ini file and found that all error logging was turned off. Once turned on, the error logging the apache server was restarted to check if any errors were being registerd in the log. As suspected, the php log showed that a file with a .phpp extension was not found in the wp-settings.php file. This was clearly a misspelled error that resulted in the error to site access. As this was one server that the error was found in, this error might have been replicated in other servers as well. An easy fix by changing the file extension by puppet would result in the fix being made to other servers as well. A quick deployment of the puppet code replaced all misspelled file extensions with the right one and restarting of the server resulted in properly loading of the site and server.\n\n### Corrective and Preventive Measures\n\n- All servers and sites should have error logging turned on to easily identify errors if anything goes wrong.\n- All servers and sites should be tested locally before deploying on a multi-server setup this will result in correcting errors before going live resulting in less fixing time if site goes down.\n",
    "timestamp": "2025-05-23T16:31:04.277964",
    "tags": [],
    "severity": "high",
    "services_affected": [
      "api",
      "web",
      "database"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "kubernetes",
      "postgresql",
      "jenkins"
    ],
    "failure_pattern": "configuration_drift",
    "timeline_events": [],
    "blast_radius": "localized",
    "detection_time": null,
    "mitigation_actions": [
      "to check if any errors were being registerd in the log"
    ],
    "quality_score": 0.9299999999999999
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/pope-h/alx-system_engineering-devops/blob/3d8d846caf9a50b7eced96190a17164db89e5fb7/0x19-postmortem/Postmortem_Blog.md",
    "title": "Postmortem_Blog.md",
    "content": "# Postmortem Report\n\n![They never stop coming](non_stop.gif)\n\n## Issue Summary:\n\nDuration: The issue occurred on May 20, 2023, at around 10 AM UTC and was resolved by May 23, 2023, at approximately 12 PM UTC.\nImpact: The SSH permission denied (publickey) error affected my ability to log in to web server 02. As a result, I was unable to perform checks for my ALX project \"0x14-sql.\" The server downtime only affected me, as the website was still under development and not accessed by users.\nRoot Cause: The root cause of the issue was an incomplete uninstallation of MySQL version 8 on web server 02, leading to conflicts during the installation of the correct version.\n\n## Timeline:\n\nThe issue was detected on May 20, 2023, around 10 AM UTC when I encountered the SSH permission denied (publickey) error while attempting to log in to web server 02.\nI initially attempted to resolve the issue through basic methods such as restarting my Linux environment and checking other servers, but these did not succeed.\nSeeking help online, including from search engines and chat platforms, provided misleading information and pointed me to contact the administrators.\nI escalated the issue to mentors who confirmed the server's irreparability, resulting in the need to request a new server.\nDuring the server restoration process from May 20-23, 2023, I encountered challenges while installing the correct version of MySQL, causing extended downtime.\nThe issue was ultimately resolved on May 23, 2023, when I completely removed MySQL version 8 and successfully installed the appropriate version on web server 02.\n\n![No idea what i'm doing](no_idea.gif)\n\n## Root Cause and Resolution:\n\nRoot Cause: The incomplete uninstallation of MySQL version 8 on web server 02 caused conflicts during the installation of the correct version.\nResolution: I resolved the issue by completely removing the remnants of MySQL version 8 and installing the correct version on web server 02.\n\n## Corrective and Preventative Measures:\n\nTo prevent similar incidents in the future, the following measures have been implemented:\n       \t+ Establishing inter-server connectivity to enable login from any server, not just the working environment.\n       \t+ Thoroughly documenting installation steps and procedures for web servers and other installations to avoid following erroneous instructions\n       \t+ Ensuring comprehensive and accurate removal of software components to prevent conflicts during future installations.\n       \t+ Implementing proper monitoring and alerting mechanisms to detect and address issues promptly.\n       \t+ Conducting regular system audits and reviewing best practices for system administration and troubleshooting.\n\n![Let's call it a truce](truce.gif)\n",
    "timestamp": "2025-05-23T16:31:04.930649",
    "tags": [],
    "severity": "high",
    "services_affected": [
      "api",
      "web",
      "auth",
      "monitoring"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "postgresql",
      "elasticsearch",
      "prometheus",
      "grafana"
    ],
    "failure_pattern": "monitoring_blind_spot",
    "timeline_events": [],
    "blast_radius": "global",
    "detection_time": null,
    "mitigation_actions": [
      "May 23, 2023, at approximately 12 PM UTC"
    ],
    "quality_score": 0.98
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/unb-mds/2024-1-Squad08/blob/1b6af7aa2f4be5d9b193ba8e2e21d78414ffb1dd/docs/postmortem/postmortem_ptbr.md",
    "title": "postmortem_ptbr.md",
    "content": "5.000 / 5.000\n# Squad8 Postmortem: uma breve análise sobre falhas e teorias sobre como evitar falhar duas vezes da mesma forma.\n\n## Resumo do problema\nO Squad 8 falhou em entregar um produto satisfatório.\n\nAo falhar em lidar com as restrições de tempo e retornar ao trabalho no projeto após o fim da greve da universidade, o squad 8 da disciplina MDS não conseguiu\nalcançar os resultados desejados para este software: um aplicativo de aluguel funcional e completo, capaz de conectar, receber e enviar informações para um banco de dados.\n\n## Linha do tempo\n> **22/03/24 :** O Squad foi formado, com os seguintes membros: Bruno, João, Pedro, Renan e Ryan.\n>\n> **28/03/24 :** Foi decidido que o Squad tentaria desenvolver um aplicativo de aluguel.\n>\n> **01/04/24 :** A arquitetura básica e os requisitos foram levantados. Muito mais tarde descobriríamos que essa arquitetura era falha, a API deveria conter também o\nwebscrapper. Também dividimos as pilhas e tarefas entre os membros, primeiro focando em aprender as principais tecnologias que seriam usadas ao longo do projeto. a API também nunca chegou perto de ser implementada adequadamente nem completamente ou vagamente compreendida.\n>\n> **02/04/24 :** As escolhas de tecnologia iniciais foram selecionadas nesse dia. Apesar da falta de experiência com os membros para desenvolvimento web com nodeJS, por popularidade na indústria, foi a linguagem selecionada, juntamente com as frameworks React e Express para, respectivamente, o frontend e o backend. A escolha inicial do banco de dados seria o postgreSQL, mas foi posteriormente alterada para o MySQL, dado que o MySQL é o padrão que é ensinado dentro da nossa instituição. Tais escolhas impactariam no ciclo de desenvolvimento diretamente, pois a grande parcela dos engenheiros não tinham experiência em nenhuma das escolhas feitas, o que dificultou os ciclos de aprendizagem e implementação futuros.\n>\n> **04/04/24 :** O Github Actions foi implementado pela primeira vez neste dia. Um ticket informal para implementar isso foi postado no WhatsApp. Isso fornece o primeiro insight sobre o que deu errado. Levaria 4 meses até uma implementação mais adequada, pois não havia urgência, já que isso era encarado como um aspecto opcional do projeto.\n>\n> **06/04/24 :** Um dos engenheiros encarregados de desenvolver a API aprendeu HTML, o que consumiu um tempo precioso para aprender tecnologias de API. Mesmo assim, isso ajudaria mais tarde, pois o engenheiro encarregado de construir o front-end deixaria o projeto mais tarde.\n>\n> **08/04/24 :** A greve da universidade foi anunciada. Neste ponto, a maior parte do projeto ainda estava em seus primeiros passos, mas ainda tinha possibilidade de ser finalizada. No entanto, a greve e a decisão do esquadrão de trabalhar somente quando a greve terminasse findaria sendo uma péssima ideia.\n>\n> **26/04/24 :** A primeira versão do frontend foi finalizada. Embora ainda bastante rudimentar, foi um bom começo e teoricamente teriamos tempo para finalizá-la.\n>\n> **28/04/24 :** Após uma perda de tempo com o postgreSQL, em reunião, o squad decidiu por utilizar o MySQL como tecnologia de banco de dados, em razão de, como já explicado, este ser o padrão de ensino na nossa instituição.\n>\n> **07/05/24 :** Chegou ao conhecimento do esquadrão que nenhuma outra apresentação ocorreria até que a greve chegasse ao fim. A maioria das alterações no projeto base foi feita durante este período.\n>\n> **17/05/24 :** O engenheiro líder do frontend deixou o projeto. Sem mais ninguém totalmente capaz de trabalhar com HTML e entender os designs, este foi o primeiro prego no caixão. Como a maioria das outras disciplinas estavam lançando seus projetos e testes finais durante o período seguinte, o restante dos membros sentiu mais urgência em se concentrar nas disciplinas ativas. Com raras exceções, nenhuma reunião foi realizada durante esse período.\n>\n> **01/07/24 :** Depois que a greve finalmente acabou, os scripts do banco de dados foram concluídos, mas o esquadrão não tinha ideia de como usar ou conectar o banco de dados, junto com a maioria das ideias de como construir a API, que dependia do banco de dados para suas operações. Isso colocaria outro prego no caixão.\n>\n> **15/07/24 :** O esquadrão decidiu se reunir três vezes por semana para compensar o tempo perdido no vazio da greve. Embora inicialmente tenha funcionado como pretendido, forçando os engenheiros a interagir e mostrar precisamente o que estava sendo feito e o que não estava, o plano acabou fracassando. Os engenheiros não conseguiram acompanhar as reuniões nem o ritmo de desenvolvimento necessário para consertar o produto a tempo para entrega. Fora a implementação do framework React para o front-end, até o prazo final, nenhuma grande mudança foi feita no projeto principal. Ele estagnou completamente.\n>\n> **31/07/24 :** A fusão do branch react no principal foi a última grande mudança feita no projeto e foi feita nesse dia.\n>\n> **02/08/24 :** Um pouco de funcionamento do CI foi finalmente colocado no principal. Ao mesmo tempo, metade da equipe se sentiu excluída do trabalho e alienada do projeto.\n>\n> **09/08/24 :** Depois de pedir ajuda a nossa mentora, um esforço foi colocado em movimento para reintegrar essa metade da equipe novamente ao projeto. Embora isso tenha se mostrado tarde demais, pois a metade integrada já estava esgotada.\n>\n> **15/08/24 :** Um dos principais engenheiros de React decidiu deixar o projeto. Este foi o último prego no caixão.\n\n## Causa raiz\nUma nítida falta de urgência, organização, força de trabalho, comunicação e conhecimento de know-how fez com que este projeto fosse enterrado. Utilizaremos o sistema \"5 Why's\" para identificar a causa raiz.\n\n**1. Por que não havia urgência?** - Os cronogramas mudavam constantemente, o que tornava difícil prever quando exatamente o esquadrão deveria focar no projeto ou relaxar e focar em outras matérias. \n\n**2. Por que não havia organização?** - Com a greve durando dois meses, passou tempo suficiente sem trabalho e prática para que a maioria dos membros\nperdesse o domínio sobre a tecnologia utilizada, forçando o esquadrão a reaprender as habilidades do início do semestre. Isso levou à frustração e à eventual perda de\noutro membro devido ao progresso lento e nenhuma esperança de entregar o produto com sucesso.\n\n**3. Por que não havia força de trabalho?** - Já sendo um dos esquadrões menores, a perda do primeiro engenheiro forçou outros a aprender HTML e CSS\ndo zero, o que provou ser um ponto único de falha. Não havia redundância de conhecimento desde o início, ou seja, qualquer perda na equipe seria um mal presságio imediato.\n\n**4. Por que houve menos comunicação?** - Inicialmente, durante a greve, nenhuma comunicação real foi necessária. Quando a greve terminou, a comunicação subsequente foi recebida com dificuldade.\n\n**5. Por que não havia conhecimento de know-how?** - O esquadrão fora formado sem genuínos veteranos em nenhuma das tecnologias que seriam usadas, o que significa\nque a maior parte do aprendizado precisaria ser construída do zero. Isso também diz respeito a aproveitar ao máximo as Metodologias Ágeis ensinadas durante as palestras, dado que os membros tiveram a maior parte de sua experiência acadêmica com software até este ponto em projetos e avaliações individuais.\n\nPodemos concluir que a causa raiz desta morte foi um longo período sem trabalho no projeto, levando a uma espécie de \"ferrugem\". A greve foi um dos principais contribuintes para esta condição, o que levou à interrupção do trabalho pelo referido longo período de tempo.\n\n## Resolução e recuperação\n\nNenhuma resolução nem recuperação foi alcançada. O projeto permanece inacabado no momento da escrita do presente documento e permanecerá assim indefinidamente.\nO projeto pode ser concluído após uma bifurcação, mas o repositório atual provavelmente permanecerá como está para documentar essa falha inicial.\n\n## Medidas corretivas e preventivas\nO restante do esquadrão 8 analisa as seguintes medidas preventivas para facilitar projetos futuros:\n\n**1. Nenhuma sprint deve ser pulada.** Isso atrapalha o fluxo do projeto e recuperar o atraso é muito mais difícil\nna prática do que na teoria. Não mais trabalho do que o que pode ser completado em uma sprint deve ser passado para um engenheiro.\n\n**2. A comunicação deve ser, como o XP garante que é muito melhor, pessoalmente.** Trabalhar com outras pessoas é muito mais fácil em um ambiente físico\ndo que em um virtual, isso é simplesmente um fator de trabalhar com outros seres humanos. E, acima de tudo, **a comunicação adequada deve ser garantida com a maior prioridade possível.**\n\n**3. Buscar ajuda assim que um obstáculo for encontrado** será exponencialmente mais rápido do que consertá-lo sozinho. A equipe deve trabalhar em conjunto para compartilhar\nconhecimento. Isso pode evitar alienação e/ou isolamento dos engenheiros.\n\n**4. Utilizar as Issues para corretamente mapear as necessidades do projeto** evita o estranho fenômeno onde o engenheiro quer trabalhar mas não tem certeza de onde realizar o serviço. É uma **poderosa** ferramenta de comunicação e _deve_ ser usada como tal, o que ajuda com a medida preventiva (2).\n\n**5. Issues precisam ser curtas, diretas e completáveis em uma sprint.** Issues grandes sobrecarregam os engenheiros e causam desmotivação quando inevitavelmente não forem completadas.\n\n\nComo as medidas corretivas envolveriam terminar o trabalho iniciado, elas não serão citadas por razões explicadas na sessão de _Resolução e recuperação_.\n",
    "timestamp": "2025-05-23T16:31:05.349337",
    "tags": [],
    "severity": "low",
    "services_affected": [
      "api",
      "web"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "kubernetes",
      "postgresql"
    ],
    "failure_pattern": null,
    "timeline_events": [],
    "blast_radius": "localized",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 0.42000000000000004
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/Aissamab/alx-system_engineering-devops/blob/23e8965999ee7ddc3518b01ad98160023477b7d3/0x19-postmortem/Postmortem_Webstack_Debugging.md",
    "title": "Postmortem_Webstack_Debugging.md",
    "content": "# Postmortem Report\n\n## 504 Error while accessing a given URL\n\n<p align=\"center\">\n<img src=\"https://github.com/Aissamab/alx-system_engineering-devops/blob/master/0x19-postmortem/image.gif?raw=true\" width=100% height=100% />\n</p>\n\n### Incident report for [504 error / Site Outage]\n\n#### Summary\n\nOn April 9th, 2024 at midnight the server access went down resulting in 504 error for anyone trying to access a website. Background on the server being based on a LAMP stack.\n\n#### Timeline\n\n- **00:00 PST** - 500 error for anyone trying to access the website\n- **00:05 PST** - Ensuring Apache and MySQL are up and running.\n- **00:10 PST** - The website was not loading properly which on background check revealed that the server was working properly as well as the database.\n- **00:12 PST** - After quick restart to Apache server returned a status of 200 and OK while trying to curl the website.\n- **00:18 PST** - Reviewing error logs to check where the error might be coming from.\n- **00:25 PST** - Check /var/log to see that the Apache server was being prematurely shut down. The error log for PHP were nowhere to be found.\n- **00:30 PST** - Checking php.ini settings revealed all error logging had been turned off. Turning the error logging on.\n- **00:32 PST** - Restarting apache server and going to the error logs to check what is being logged into the php error logs.\n- **00:36 PST** - Reviewing error logs for php revealed a mistyped file name which was resulting in incorrect loading and premature closing of apache.\n- **00:38 PST** - Fixing file name and restarting Apache server.\n- **00:40 PST** - Server is now running normally and the website is loading properly.\n\n\n#### Root Cause and Resolution\n\nThe issue was connected with a wrong file name being reffered to in the wp-settings.php file. The error was raised when trying to curl the server, wherein the server responded with 500 error. By checking the error logs it was found that no error log file was being created for the php errors and reading the default error log for apache did not result in much information regarding the premature closing of the server. Once understood that the errors for php logs were not being directed anywhere the engineer chose to review the error log setting for the php in the php.ini file and found that all error logging was turned off. Once turned on, the error logging the apache server was restarted to check if any errors were being registerd in the log. As suspected, the php log showed that a file with a .phpp extension was not found in the wp-settings.php file. This was clearly a misspelled error that resulted in the error to site access. As this was one server that the error was found in, this error might have been replicated in other servers as well. An easy fix by changing the file extension by puppet would result in the fix being made to other servers as well. A quick deployment of the puppet code replaced all misspelled file extensions with the right one and restarting of the server resulted in properly loading of the site and server.\n\n#### Corrective and Preventive Measures\n\n- All servers and sites should have error logging turned on to easily identify errors if anything goes wrong.\n- All servers and sites should be tested locally before deploying on a multi-server setup this will result in correcting errors before going live resulting in less fixing time if site goes down.\n",
    "timestamp": "2025-05-23T16:31:06.206146",
    "tags": [],
    "severity": "high",
    "services_affected": [
      "api",
      "web",
      "database"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "kubernetes",
      "postgresql",
      "jenkins"
    ],
    "failure_pattern": "configuration_drift",
    "timeline_events": [],
    "blast_radius": "localized",
    "detection_time": null,
    "mitigation_actions": [
      "to check if any errors were being registerd in the log"
    ],
    "quality_score": 0.9299999999999999
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/kamva-hanisi/alx-system_engineering-devops/blob/a625c634df1624feccc2d5592ff67137df514c95/0x19-postmortem/Postmortem_Webstack_Debugging.md",
    "title": "Postmortem_Webstack_Debugging.md",
    "content": "### Postmortem Info\n\n### 504 Error while accessing a given URL\n\n<img src=\"unknown-story.png\" alt=\"Postmortem\">\n\n### Incident report for 504 error / Site Outage\n\n### Summary\n\nOn 25 July, 2020 at midnight the server access went down resulting in 504 error for anyone trying to access a website. Background on the server being based on a MEAN stack and LAMP stack.\n\n### Timeline\n\n- 00:00 PST - 500 error for anyone trying to access the website\n- 00:05 PST - Ensuring Apache and MySQL are up and running.\n- 00:10 PST - The website was not loading properly which on background check revealed that the server was working properly as well as the database.\n- 00:12 PST - After quick restart to Apache server returned a status of 200 and OK while trying to curl the website.\n- 00:18 PST - Reviewing error logs to check where the error might be coming from.\n- 00:25 PST - Check /var/log to see that the Apache server was being prematurely shut down. The error log for PHP were nowhere to be found.\n- 00:30 PST - Checking php.ini settings revealed all error logging had been turned off. Turning the error logging on.\n- 00:32 PST - Restarting apache server and going to the error logs to check what is being logged into the php error logs.\n- 00:36 PST - Reviewing error logs for php revealed a mistyped file name which was resulting in incorrect loading and premature closing of apache.\n- 00:38 PST - Fixing file name and restarting Apache server.\n- 00:40 PST - Server is now running normally and the website is loading properly.\n\n### Root Cause and Resolution\n\nThe issue was connected with a wrong file name being reffered to in the wp-settings.php file. The error was raised when trying to curl the server, wherein the server responded with 500 error. By checking the error logs it was found that no error log file was being created for the php errors and reading the default error log for apache did not result in much information regarding the premature closing of the server. Once understood that the errors for php logs were not being directed anywhere the engineer chose to review the error log setting for the php in the php.ini file and found that all error logging was turned off. Once turned on, the error logging the apache server was restarted to check if any errors were being registerd in the log. As suspected, the php log showed that a file with a .phpp extension was not found in the wp-settings.php file. This was clearly a misspelled error that resulted in the error to site access. As this was one server that the error was found in, this error might have been replicated in other servers as well. An easy fix by changing the file extension by puppet would result in the fix being made to other servers as well. A quick deployment of the puppet code replaced all misspelled file extensions with the right one and restarting of the server resulted in properly loading of the site and server.\n\n###  Corrective and Preventive Measures\n\n- All servers and sites should have error logging turned on to easily identify errors if anything goes wrong.\n- All servers and sites should be tested locally before deploying on a multi-server setup this will result in correcting errors before going live resulting in less fixing time if site goes down.\n",
    "timestamp": "2025-05-23T16:31:07.142411",
    "tags": [],
    "severity": "high",
    "services_affected": [
      "api",
      "web",
      "database"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "kubernetes",
      "postgresql",
      "jenkins"
    ],
    "failure_pattern": "configuration_drift",
    "timeline_events": [],
    "blast_radius": "localized",
    "detection_time": null,
    "mitigation_actions": [
      "to check if any errors were being registerd in the log"
    ],
    "quality_score": 0.9299999999999999
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/alantech/iasql/blob/e192f8d8887d23bfd399b252a6f9ee8d55a288e9/postmortems/001%20-%20Postmortem%20for%20v0.0.19%20Deployment%20Failure.md",
    "title": "001 - Postmortem for v0.0.19 Deployment Failure.md",
    "content": "# 000 - Postmortem for v0.0.19 Deployment Failure\n\n## Level: Internal\n\n## Author(s)\n\n- David Ellis <david@iasql.com>\n\n## Summary\n\nThe `v0.0.19` release could not be deployed despite the test suite succeeding. A combination of a new deployment mechanism and gaps in the test suite actually *prevented* a worse outage of deploying broken code, but feature development was significantly slowed trying to figure out what exactly broke. It turned out to be a mistake in the `iasql_upgrade` logic, made more difficult to figure out due to separate-but-unrelated bugs with the new `default_aws_region` postgres function. The new deployment mechanism exercises `iasql_upgrade` and therefore hit this bug and prevented rollout of the faulty release.\n\n## Timeline\n\n- **2022-09-05**: Release day for `v0.0.19`, rushing to get desired features out the door, but were unable to. Release was delayed rather than skip these features.\n- **2022-09-07**: [Actual attempted release for `v0.0.19`](https://github.com/alantech/iasql-engine/tree/v0.0.19), tests are passing on the `main` branch, and manual testing locally did not uncover any issues. There *was* an error in the staging deploy earlier in the day, but it was assumed caused by other experiments. After the `staging` IaSQL database was cleaned up, further staging deploys were successful, so it was assumed that the `production` deployment would be the same. Instead the `production` deploy failed, and an investigation began.\n- **2022-09-09**: [Actual root cause found and fixed, and new test written to verify no regressions occur](https://github.com/alantech/iasql-engine/pull/1241). A few bugs unrelated to the root cause in the `default_aws_region` function are also fixed in the process.\n- **2022-09-12**: Release day for `v0.0.20`, but being extra cautious and it was also put on hold because of an error in the Prisma Example end-to-end test, and investigation into this occurs.\n- **2022-09-13**: [Improved logging in the Prisma example deployment](https://github.com/alantech/iasql-engine/pull/1270), but cause of this issue not found.\n- **2022-09-14**: [Root cause of Prisma end-to-end test found](https://github.com/alantech/iasql-engine/pull/1272): The test account was not properly cleaned. Adding a pre-clean script however, also broke things, and an issue in the `delete_all_records` postgres function was discovered. Adding `aws_regions` to a blacklist to that function resolved that issue. Deployment of `v0.0.20` successfully occurred after that and the Prisma end-to-end test fix was not truly necessary as `delete_all_records` is not meant for general consumption (yet).\n- **2022-09-16**: A strange behavior was detected in the production instance. `main` was not clean at that point and it was assumed it was related to that, so the code was cleaned and an out-of-band production deploy was done, and the problem was apparently resolved.\n- **2022-09-19**: An investigation determined that was not the root cause, [the issue was reproduced and then fixed](https://github.com/alantech/iasql-engine/pull/1297) and a second out-of-band deploy occurred, resolving the outage completely.\n\n## Detection\n\nWe tried to deploy `v0.0.19` to production and it failed.\n\n## Response\n\n`v0.0.19` was intended to be the first release beginning multi-region support for AWS accounts, which altered several core assumptions in the codebase and was expected to be potentially difficult to deploy. Care was taken to getting a full test suite passed and staging deployments working, as well as manual testing of the upgrade path, but that manual testing was incomplete. Roughly a week from detection to resolution occurred, though it could have been successfully deployed a couple of days earlier, but another error, which turned out to be unrelated, was detected and also resolved before deployment of `v0.0.20`.\n\nTo attempt to minimize the impact on the team, only David worked on this issue, while feature development continued for others.\n\n## Cause\n\nThe issue was due to a recent internal behavior change for the IaSQL functions to mitigate a problem discovered by a user. Most of the postgres functions exposed by `iasql_functions` now automatically fail to execute if an `iasql_upgrade` function call is running in the background, to prevent accidental corruption of the database during the upgrade. The `iasql-engine` side of the `iasql_upgrade` function uses these functions to do its work, and must manually turn off this protection logic to successfully call them. A new call to `iasql_sync` introduced by the multi-region support did not do so.\n\nThis was not detected by the test suite because we had no upgrade test, and it was not detected by the manual upgrade test because it only affected testing *after* the `aws_account` module was re-installed, not before it, and had no apparent impact if the default AWS region was chosen to be `us-east-1`. The manual testing did not install any other modules or use a different AWS region, and so never experienced the issue.\n\nOur production and staging IaSQL databases do not use `us-east-1` and have more than just the `aws_account` installed, so they did run into this issue when the deploy logic upgraded them to the latest version of the engine.\n\nAfter that, an issue with the `Context` object within the engine was discovered due to a new usage of it inside of the refactored `aws_account`. The issue was with the caching of the context object not being completely eliminated between requests due to shallow copies being made. This was also not discovered in the test suite because we have not tested concurrent, separate tests in the exact same running engine.\n\n## Prevention\n\nThe mitigation for this exact issue has already been performed to get `v0.0.20` released, and an explicit test to confirm the full flow of an `iasql_upgrade` call works has been written.\n\nAll of the errors were due to missing test cases to prevent regression of functionality:\n\n- `iasql_upgrade` didn't have a formal test case at all.\n- The new `default_aws_region` only had partial coverage of its use-cases.\n- `delete_all_records` never had a test that utilized an IaSQL database *after* it was run on it.\n- The `Context` construction had never been tested with multiple different databases being manipulated in the same test suite before.\n\nSome of these were obvious, such as not having test coverage for a user-accessible feature at all and relying on manual testing, but some are not obvious due to the inherent complexities that arise from Turing-complete syntaxes and unexpected starting states for the code to execute on. We therefore cannot expect all of these cases to be caught ahead of time, but we can minimize the impact by following a few extra rules with feature development:\n\n1. All features have a test, or they can't be merged.\n2. All bugfixes start with a test that triggers the bug, and end with the fix that prevents it and causes the test to pass.\n3. End-to-end tests that utilize more and more modules in different ways to help prevent cross-module interaction regressions.",
    "timestamp": "2025-05-23T16:31:12.324636",
    "tags": [],
    "severity": "high",
    "services_affected": [
      "web",
      "database"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "kubernetes",
      "aws",
      "postgresql",
      "jenkins"
    ],
    "failure_pattern": "configuration_drift",
    "timeline_events": [],
    "blast_radius": "global",
    "detection_time": null,
    "mitigation_actions": [
      "despite the test suite succeeding",
      "a couple of days earlier, but another error, which turned out to be unrelated, was detected and also resolved before deployment of `v0"
    ],
    "quality_score": 0.98
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/hernantz/blog/blob/9d39b6d7f51830f7945f11266a5d9b725e6ba404/content/deploying-at-6am-a-postmortem.md",
    "title": "deploying-at-6am-a-postmortem.md",
    "content": "Title: Deploying at 6am, a postmortem\nDate: 2020-06-09\nCategory: Programming\nTags: devops, postgresql\nSummary: Another chapter in the IT nightmare stories.\n\n![Graph of number of active users](/images/demand.png \"Graph of number of active users\")\n\nOur webapp has a pretty predictable demand. We thought it is best to run deployments very early or at very late hours. If they require downtime that is.\n\nThis time we needed to delete a few tables that were growing too much and adding too little with features that no one uses (think of event logs etc) which we replaced with logs, duh!\n\nSo anyway at 6 am I started the deploy, once the app builds it runs the migrations, I put the site in maintenance mode, and the Django release command got stuck in running migrations.\n\nI knew that drop table queries shouldn't take too long, they simply remove a directory from the disk. \n\nAfter waiting for more than 15 minutes it was time to check what the postgresql db was doing.\n\nYou can basically check the logs or run queries against the `pg_stat_activity` table to get an idea of what's going on.\n\n```sql\nproddb=> SELECT pg_blocking_pids(pid) AS blocked_by FROM pg_stat_activity WHERE cardinality(pg_blocking_pids(pid)) > 0;\n-[ RECORD 1 ]-------\nblocked_by | {24484}\n-[ RECORD 2 ]-------\nblocked_by | {25741}\n```\n\nLet's inspect those pids:\n\n```sql\nproddb=> SELECT * FROM pg_stat_activity WHERE pid = 24484;\n-[ RECORD 1 ]----\ndatid            | 16402\ndatname          | proddb\npid              | 24484\nusesysid         | 16384\nusename          | produser\napplication_name | Heroku Postgres Backups\nclient_addr      | 52.73.131.14\nclient_hostname  | \nclient_port      | 38811\nbackend_start    | 2020-06-09 09:09:20.920488+00\nxact_start       | 2020-06-09 09:09:20.935983+00\nquery_start      | 2020-06-09 09:09:38.067414+00\nstate_change     | 2020-06-09 09:09:38.067415+00\nwait_event_type  | Client\nwait_event       | ClientWrite\nstate            | active\nbackend_xid      | \nbackend_xmin     | 72354912\nquery            | COPY \"public\".\"field_history_fieldhistory\" (\"id\", \"object_id\", \"field_name\", \"serialized_data\", \"date_created\", \"content_type_id\", \"user_id\") TO stdout;\nbackend_type     | client backend\n```\n\nThere is the culprit. I can see on `query_start` that it started just ten minutes after I began the deploy and the `application_name` is the Heroku automatic backups service. \n\nTurns out that when the site has low activity it is also a good time to run our db backups.\n\nAfter checking the timestamps for previous backups I noticed they take two hours to complete.\n\nI couldn't wait that long with the site down. So I killed the query with:\n\n```sql\nproddb=>  SELECT pg_cancel_backend(24484);\n pg_cancel_backend \n-------------------\n t\n```\n\nImmediately after, the lock was freed and the release finished successfully.\n\n",
    "timestamp": "2025-05-23T16:31:14.171928",
    "tags": [],
    "severity": "high",
    "services_affected": [
      "web",
      "database"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "kubernetes",
      "postgresql",
      "jenkins"
    ],
    "failure_pattern": "configuration_drift",
    "timeline_events": [
      {
        "timestamp": "09:09",
        "event": "20.920488+00"
      },
      {
        "timestamp": "09:09",
        "event": "20.935983+00"
      },
      {
        "timestamp": "09:09",
        "event": "38.067414+00"
      },
      {
        "timestamp": "09:09",
        "event": "38.067415+00"
      },
      {
        "timestamp": "2020-06-09 09:09",
        "event": "20.920488+00"
      },
      {
        "timestamp": "2020-06-09 09:09",
        "event": "20.935983+00"
      },
      {
        "timestamp": "2020-06-09 09:09",
        "event": "38.067414+00"
      },
      {
        "timestamp": "2020-06-09 09:09",
        "event": "38.067415+00"
      }
    ],
    "blast_radius": "global",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 0.97
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/bigwhite/gopherdaily/blob/20f7b1db888185489d0c4dab21448f3165382398/202408/issue-20240819.md",
    "title": "issue-20240819.md",
    "content": "# Go 1.23中值得关注的几个变化 | Gopher Daily (20240819)ʕ◔ϖ◔ʔ\n\n>每日一谚：You often do not need frameworks in Go. What you need is a couple of pkgs to do your dirty work\n\n## Go技术生态\n\n\n- 1. Go 1.23中值得关注的几个变化 - https://tonybai.com/2024/08/19/some-changes-in-go-1-23/\n\n- 2. 从零开始编程，Go语言真的适合新手吗（sponsor） - https://t.zsxq.com/ixPoT\n\n- 3. Go test的工作原理 - https://matttproud.com/blog/posts/go-testing-harness.html\n\n- 4. 超越自我：构建高性能且可靠的Go应用程序 - https://blog.zomato.com/go-beyond-building-performant-and-reliable-golang-applications\n\n- 5. Go后端clean架构 - https://outcomeschool.com/blog/go-backend-clean-architecture\n\n- 6. 函数关键字参数（和默认值）的一两个缺点 - https://utcc.utoronto.ca/~cks/space/blog/programming/AgainstFunctionKeywordArguments\n\n- 7. 构建高性能文件系统 - https://grantslatton.com/filesystems\n\n- 8. 我在 Google 的 9 年旅程的事后分析 - https://tinystruggles.com/posts/google_postmortem\n\n\n## 云原生技术\n\n\n- 1. Kubernetes 1.31：作业的 Pod 失败策略正式发布 - https://kubernetes.io/blog/2024/08/19/kubernetes-1-31-pod-failure-policy-for-jobs-goes-ga/\n\n- 2. Copilot Autofix：AI 对代码漏洞问题的解决 - https://thenewstack.io/copilot-autofix-ais-answer-to-code-vulnerability-woes/\n\n- 3. 使用 PostgreSQL 简化您的技术堆栈 - https://medium.com/@roma.gordeev/simplifying-your-tech-stack-with-postgresql-19030dc84f2c\n\n\n## 人工智能\n\n\n- 1. Dify.AI x TiDB：使用知识库构建可扩展的 AI 代理 - https://www.pingcap.com/blog/dify-tidb-build-scalable-ai-agent-with-knowledge-base/\n\n\n## 流行项目与工具\n\n\n- 1. DiceDB/dice - https://github.com/DiceDB/dice\n\n- 2. SagerNet/sing-box - https://github.com/SagerNet/sing-box\n\n- 3. danielmiessler/fabric - https://github.com/danielmiessler/fabric\n\n- 4. schollz/croc - https://github.com/schollz/croc\n\n- 5. amitshekhariitbhu/go-backend-clean-architecture - https://github.com/amitshekhariitbhu/go-backend-clean-architecture\n\n- 6. evcc-io/evcc - https://github.com/evcc-io/evcc\n\n- 7. rusq/slackdump - https://github.com/rusq/slackdump\n\n- 8. ethereum/go-ethereum - https://github.com/ethereum/go-ethereum\n\n- 9. authelia/authelia - https://github.com/authelia/authelia\n\n- 10. qdm12/gluetun - https://github.com/qdm12/gluetun\n\n- 11. prometheus/prometheus - https://github.com/prometheus/prometheus\n\n- 12. AdguardTeam/AdGuardHome - https://github.com/AdguardTeam/AdGuardHome\n\n- 13. navidrome/navidrome - https://github.com/navidrome/navidrome\n\n- 14. tailscale/tailscale - https://github.com/tailscale/tailscale\n\n- 15. v2rayA/v2rayA - https://github.com/v2rayA/v2rayA\n\n- 16. smallstep/certificates - https://github.com/smallstep/certificates\n\n- 17. XTLS/Xray-core - https://github.com/XTLS/Xray-core\n\n- 18. v2fly/v2ray-core - https://github.com/v2fly/v2ray-core\n\n- 19. avelino/awesome-go - https://github.com/avelino/awesome-go\n\n- 20. juanfont/headscale - https://github.com/juanfont/headscale\n\n- 21. Melkeydev/go-blueprint - https://github.com/Melkeydev/go-blueprint\n\n- 22. owncast/owncast - https://github.com/owncast/owncast\n\n\n----\n\n- 编辑：Tony Bai\n- [编辑主页](https://tonybai.com)：https://tonybai.com\n- [GopherDaily主页](https://gopherdaily.tonybai.com)：gopherdaily.tonybai.com\n- [GopherDaily项目](https://github.com/bigwhite/gopherdaily)：github.com/bigwhite/gopherdaily\n- [订阅GopherDaily](https://gopherdaily.tonybai.com/subscribe)\n- [取消订阅GopherDaily](https://gopherdaily.tonybai.com/unsubscribe)\n- [另一个邮件列表](https://gopher-daily.com): https://gopher-daily.com\n\nCopyright 2023 GopherDaily\n",
    "timestamp": "2025-05-23T16:31:15.856837",
    "tags": [],
    "severity": "low",
    "services_affected": [
      "web",
      "database"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "kubernetes",
      "postgresql",
      "prometheus",
      "jenkins"
    ],
    "failure_pattern": null,
    "timeline_events": [],
    "blast_radius": "localized",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 0.52
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/labprogsam/front-tracos/blob/04a6300812eacd0ed03fb029e82ec4171d267386/Documents/Postmortem_Tracos.md",
    "title": "Postmortem_Tracos.md",
    "content": "\n# Documento de Postmortem - Projeto Traços\n\n## Visão Geral\n\n- **Período do Projeto**: Dezembro/2024 a Abril/2025  \n- **Equipe**: 4 integrantes (Product Owner, Front-end, Back-end, Design)  \n- **Tecnologias**: React, Node.js, Express, PostgreSQL, Sequelize, Figma  \n\n## Resultados Atingidos\n\n| Área              | Resultado                                                                                                                                 |\n|-------------------|-------------------------------------------------------------------------------------------------------------------------------------------|\n| MVP               | Entregue com login, perfil do tatuador, portfólio de tatuadores, Central de Controle de Agendamentos, Menu Explorar                                                          |\n| Design            | Protótipos de alta fidelidade validados no Figma                                                                                         |\n| Testes            | Cobertura de 100% no back-end com Jest, testes de integração com Postman/Newman            |\n| Gestão de Projeto | Adoção bem-sucedida do Trello com etiquetagem e sinalização de dependências após março                                                  |\n\n## Pontos Fortes\n\n### Comunicação e Organização\n\n- Reuniões semanais produtivas com atas registradas\n- Decisões rápidas e colaborativas via WhatsApp\n- Gestão das tarefas através do Trello\n\n### Técnicos\n\n- Arquitetura escalável com autenticação via JWT e uso de middlewares\n- Banco de dados hospedado desde o início no Render\n- Estrutura de testes definida e aplicada (Jest, Postman/Newman)\n\n### Design\n\n- Guia de identidade visual completo (cores, fontes, layout)\n- Navegação intuitiva\n- Protótipos validados pelo time feitos no Figma\n\n## Principais Desafios\n\n| Problema                               | Causa Identificada                        | Impacto no Projeto                        |\n|----------------------------------------|-------------------------------------------|-------------------------------------------|\n| Falta de centralização na gestão       | Ausência de PO nas etapas iniciais        | Retrabalho e baixa priorização            |\n| Desorganização no início do projeto    | Falta de ferramenta de gestão estruturada | Atrasos e tarefas paralelas mal definidas |\n| Integração de tecnologias              | Curva de aprendizado com ORM e testes     | Atrasos no back-end                       |\n| Requisitos de cadastro indefinidos     | Discussões tardias com o time técnico     | Retrabalho em endpoints                   |\n| Prioridades indefinidas para MVP       | Falta de escopo detalhado no início       | Funcionalidades críticas atrasadas        |\n\n## Lições Aprendidas\n\n### Gestão e Planejamento\n\n- Ter um **Product Owner ativo desde o início** evita retrabalhos e aumenta a clareza de escopo\n- Adoção do Trello com colunas específicas (\"Em Progresso\", \"Revisão\", \"Dependências\") facilita a visualização do fluxo\n\n### Desenvolvimento e Testes\n\n- Iniciar **testes unitários com Jest** junto ao primeiro CRUD reduz bugs e melhora a cobertura desde o início\n- A organização dos testes por controller facilitou a manutenção e isolamento de erros\n- A estrutura de testes incluiu:\n  - **Jest** para testes unitários do back-end\n  - **SuperTest + Newman** para testes de integração com a API\n  - **Cypress** para testes E2E simulando o comportamento do usuário\n- Indicadores de desempenho (KPIs) foram definidos para cobertura e taxa de sucesso dos testes\n\n### Design\n\n- Iniciar os protótipos em alta definição evitou refações em tela\n- Fluxos validados antes do desenvolvimento garantiram mais alinhamento com os devs\n\n## Ações de Melhoria\n\n- **Ação 1**: Implementar o fluxo completo do cliente na plataforma. Atualmente, ele existe apenas no protótipo (Figma) e não foi incorporado ao MVP. Isso inclui telas de perfil, agendamentos e a funcionalidade de marcar tatuagem, que ainda não estão disponíveis no ambiente real.  \n  - **Responsável**: Samuel  \n  - **Prazo**: 14/04/2025\n\n- **Ação 2**: Adicionar microinterações no fluxo do tatuador. Isso envolve construção de modais, animações de carregamento (lazy loading) e mensagens de erro amigáveis (ex: “Tente novamente mais tarde”) para melhorar a experiência do usuário durante falhas ou carregamentos.  \n  - **Responsável**: Juliana e José Luiz\n  - **Prazo**: 15/04/2025\n\n- **Ação 3**: Desenvolver a funcionalidade de Perfil de Estúdio, permitindo que vários tatuadores estejam vinculados a um mesmo perfil. Com isso, será possível estruturar pequenos estúdios dentro da plataforma, com visualização unificada e gestão compartilhada.  \n  - **Responsável**: José Luiz  \n  - **Prazo**: 20/04/2025\n\n- **Ação 4**: Implementar a estratégia de monetização da plataforma:  \n  - Conta Premium com métricas exclusivas (ex: quem visualizou o perfil, tags pesquisadas);  \n  - Promoção de conteúdo (para destaque na listagem e recomendações);  \n  - Cobrança de taxa para desbloqueio de novos leads (acesso a contatos em agendamentos);  \n  - Inserção de anúncios intersticiais nas transições de telas.  \n  - **Responsável**: Juliana \n  - **Prazo**: 22/04/2025\n\n- **Ação 5**: Implementar a funcionalidade de Notificações para clientes e tatuadores. Embora o back-end já tenha suporte, a integração não foi realizada no front-end. A proposta é notificar sobre curtidas, reações, validação de perfil e demais interações dentro da plataforma.  \n  - **Responsável**: Yasmin  \n  - **Prazo**: 18/04/2025\n\n- **Ação 6**: Realizar a integração completa entre front-end e back-end. Hoje, diversas ações (como curtir/descurtir) não persistem após o refresh da página. É necessário garantir que todas as interações estejam conectadas ao banco de dados e atualizadas em tempo real.  \n  - **Responsáveis**: Samuel e Yasmin  \n  - **Prazo**: 16/04/2025\n \n- **Ação 7**: Propor e iniciar implementação do perfil de administrador. Atualmente, a plataforma não possui um perfil de administrador. Será iniciada a implementação dessa funcionalidade, permitindo que um admin possa **gerenciar a plataforma**, incluindo: **aprovação de perfis de tatuadores**, **validação de documentos** e, futuramente, **gestão de denúncias e moderação de conteúdo**. Essa melhoria visa aumentar o controle e a confiabilidade do sistema.\n  - **Responsável**: José Luiz da Silva Neto  \n  - **Prazo**: 16/04/2025\n\n\n## Linha do Tempo\n\n```mermaid\ntimeline\n  title Linha do Tempo - Projeto Traços\n  section Fase 1\n    Dez/2024 : Definição do tema\n    Jan/2025 : Protótipos no Figma\n  section Fase 2\n    Mar/2025 : PO oficializado\n    26/Mar : 80% do back-end concluído\n  section Fase 3\n    03/Abr : Integração com CI/CD\n    07/Abr : Entrega final\n```\n\n## Considerações Finais do Projeto Traços\n\n### Custo Total do Projeto\n\n| Tipo de Custo            | Detalhes                                              | Valor/Horas                          |\n|--------------------------|-------------------------------------------------------|--------------------------------------|\n| **Financeiro Direto**     | -                                                     | **R$ 0**                              |\n| **Infraestrutura (Render)** | Plano Free (Front-End)                    | **750 horas free/mês** (após 7 dias, deploys serão pausados) |\n| **Horas Totais Investidas** | Equipe de 4 pessoas                                  | **420 horas**                        |\n\n### Distribuição Detalhada de Horas\n\n- **Gestão & Planejamento**: 80h (19%) – Inclui reuniões, definições de negócio, documentação e backlog  \n- **Prototipação (Figma)**: 80h (19%) – Prototipação baixa e alta e fluxos UX\n- **Identidade Visual**: 20h (4.7%) - Criação da identidade visual e conceituação de marca\n- **Front-end (React)**: 120h (28.5%) – Telas, rotas e integração com API  \n- **Back-end (Node.js)**: 80h (19%) – API, autenticação JWT e migrations  \n- **Testes/CI-CD**: 40h (9.6%) – Jest, Newman e deploy automatizado\n\n\n---\n\n**Assinaturas**:  \nJosé Luiz (PO) | Juliana (Design) | Samuel (Front-end) | Yasmin (Back-end)  \n**Data**: 07/04/2025\n",
    "timestamp": "2025-05-23T16:31:18.216795",
    "tags": [],
    "severity": "low",
    "services_affected": [
      "api",
      "web",
      "auth"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "postgresql"
    ],
    "failure_pattern": null,
    "timeline_events": [],
    "blast_radius": "localized",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 0.38999999999999996
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/theandrew168/sbs-website/blob/007aa674a907121e44fde043dd3d7a4b6b601315/content/posts/bloggulus-outage-postmortem.md",
    "title": "bloggulus-outage-postmortem.md",
    "content": "---\ndate: 2024-06-09\ntitle: \"Bloggulus Outage Postmortem\"\nslug: \"bloggulus-outage-postmortem\"\ntags: [\"Bloggulus\"]\n---\n\nOn June 4, 2024, [Bloggulus](https://bloggulus.com) was down for just under 7 hours.\nDespite being offline for so long, the immediate fix only took only ~30 minutes to find and apply once I became aware of the issue.\nThis post details how I went about fixing the problem and then digs deeper into what actually happened.\nI also discuss a few gaps in server monitoring and notification delivery.\n\n![Downtime of roughly seven hours](/images/20240609/downtime.webp)\n\n## Bloggulus is Down\n\nI didn't actually become aware of the site being down until I visited it myself and received a `502 Bad Gateway`.\nThis response is sent from [Caddy](https://caddyserver.com/) when it cannot communicate with the service it is proxying (the Bloggulus web server).\nWhy didn't I know about this sooner?\n\nDespite my [UptimeRobot](https://uptimerobot.com/) monitor going red within 5 minutes of the outage, I have the notifications configured to be sent to my primary [shallowbrooksoftware.com](https://shallowbrooksoftware.com/) email address.\nHowever, since I don't have this inbox configured on my phone (since it isn't managed via Google), I had no way to know about it unless I checked for emails on my personal laptop.\n\nAnyhow, back to the action!\nThe first I did was SSH into the server and check the `systemd` logs:\n\n```\nJun 04 14:51:39 bloggulus systemd[1]: Starting bloggulus...\nJun 04 14:51:39 bloggulus bloggulus[37755]: 2024/06/04 14:51:39 ERROR failed to connect to `host=localhost user=bloggulus database=bloggulus`: dial error (dial tcp 127.0.0.1:5432)\nJun 04 14:51:39 bloggulus systemd[1]: bloggulus.service: Main process exited, code=exited, status=1/FAILURE\nJun 04 14:51:39 bloggulus systemd[1]: bloggulus.service: Failed with result 'exit-code'.\nJun 04 14:51:39 bloggulus systemd[1]: Failed to start bloggulus.\nJun 04 14:51:45 bloggulus systemd[1]: bloggulus.service: Scheduled restart job, restart counter is at 4702.\nJun 04 14:51:45 bloggulus systemd[1]: Stopped bloggulus.\n```\n\nThe error here is pretty clear: Bloggulus is unable to connect to the database (which runs on the same machine).\nLet's see what's going on with [PostgreSQL](https://www.postgresql.org/).\n\n## PostgreSQL is Down\n\nIt is important to understand the architecture of Bloggulus: the Caddy reverse proxy, the Go-based web app, and the PostgreSQL database all run on a single [DigitalOcean](https://www.digitalocean.com/) droplet.\nCaddy proxies traffic between the internet and Bloggulus while PostgreSQL stores all of the application's persistent data (blogs, posts, etc).\n\nChecking the database logs confirm that it is also dead:\n\n```\nJun 04 14:51:36 bloggulus systemd[1]: Starting PostgreSQL Cluster 14-main...\nJun 04 14:51:36 bloggulus postgresql@14-main[37742]: perl: warning: Setting locale failed.\nJun 04 14:51:36 bloggulus postgresql@14-main[37742]: perl: warning: Please check that your locale settings:\nJun 04 14:51:36 bloggulus postgresql@14-main[37742]:         LANGUAGE = (unset),\nJun 04 14:51:36 bloggulus postgresql@14-main[37742]:         LC_ALL = (unset),\nJun 04 14:51:36 bloggulus postgresql@14-main[37742]:         LANG = \"en_US.UTF-8\"\nJun 04 14:51:36 bloggulus postgresql@14-main[37742]:     are supported and installed on your system.\nJun 04 14:51:36 bloggulus postgresql@14-main[37742]: perl: warning: Falling back to the standard locale (\"C\").\nJun 04 14:51:36 bloggulus postgresql@14-main[37742]: Error: /usr/lib/postgresql/14/bin/pg_ctl /usr/lib/postgresql/14/bin/pg_ctl start -D /mnt/bloggulus_db/data -l /var/log/postg>\nJun 04 14:51:36 bloggulus postgresql@14-main[37742]: 2024-06-04 14:51:36.657 UTC [37747] LOG:  invalid value for parameter \"lc_messages\": \"en_US.UTF-8\"\nJun 04 14:51:36 bloggulus postgresql@14-main[37742]: 2024-06-04 14:51:36.657 UTC [37747] LOG:  invalid value for parameter \"lc_monetary\": \"en_US.UTF-8\"\nJun 04 14:51:36 bloggulus postgresql@14-main[37742]: 2024-06-04 14:51:36.657 UTC [37747] LOG:  invalid value for parameter \"lc_numeric\": \"en_US.UTF-8\"\nJun 04 14:51:36 bloggulus postgresql@14-main[37742]: 2024-06-04 14:51:36.657 UTC [37747] LOG:  invalid value for parameter \"lc_time\": \"en_US.UTF-8\"\nJun 04 14:51:36 bloggulus postgresql@14-main[37742]: 2024-06-04 14:51:36.657 UTC [37747] FATAL:  configuration file \"/etc/postgresql/14/main/postgresql.conf\" contains errors\nJun 04 14:51:36 bloggulus postgresql@14-main[37742]: pg_ctl: could not start server\nJun 04 14:51:36 bloggulus postgresql@14-main[37742]: Examine the log output.\nJun 04 14:51:36 bloggulus systemd[1]: postgresql@14-main.service: Can't open PID file /run/postgresql/14-main.pid (yet?) after start: Operation not permitted\nJun 04 14:51:36 bloggulus systemd[1]: postgresql@14-main.service: Failed with result 'protocol'.\nJun 04 14:51:36 bloggulus systemd[1]: Failed to start PostgreSQL Cluster 14-main.\n```\n\nWhat's up with those `locale` warnings?\nI don't recall ever seeing them before but my [Ansible automation](https://github.com/theandrew168/devops/blob/ae25c0a6333e8cfb3b6dd091b329342da7e545ba/roles/server/tasks/main.yml#L169-L187) generates and sets `en_US.UTF-8` as the default locale for all new servers.\nThinking that this might be weird fluke or something, I rebooted the server.\nUnfortunately, that didn't make a difference: PostgreSQL was still failing to start.\n\nMaybe the server's baseline configuration got messed up somehow?\nI decided re-run the [playbook](https://github.com/theandrew168/devops/blob/main/bloggulus.yml) that manages the Bloggulus server and all of its components.\nSince my Ansible roles are idempotent, anything out of alignment should get straightened out and reset to the desired state.\n\n## Running Ansible\n\nEverything was green (unchanged) except for one task:\n\n```yaml\n- name: Ensure en_US.UTF-8 locale is available\n  locale_gen:\n    name: en_US.UTF-8\n    state: present\n  become: yes\n  become_user: root\n```\n\nThat's pretty peculiar.\nThis task invokes `locale-gen` to generate the data for the `en_US.UTF-8` locale and ultimately store it in `/usr/lib/locale/locale-archive`.\nThat being said, the server's default locale _config_ didn't change: just the underlying binary data did.\nVery odd.\nWhat happens if I try to perform the `locale-gen` manually?\n\n## Manual Locale Generation\n\nLet's give it a shot:\n\n```\nroot@bloggulus:~# locale-gen \"en_US.UTF-8\"\nGenerating locales (this might take a while)...\n  en_US.UTF-8.../usr/sbin/locale-gen: line 177: 15179 Killed                  localedef $no_archive -i $input -c -f $charset $locale_alias $locale\n done\nGeneration complete.\n```\n\nWhoa, what happened there?\nThe `locale-gen` command got killed.\nWas it from the [OOM killer](https://www.kernel.org/doc/gorman/html/understand/understand016.html)?\nLet's check [dmesg](https://man7.org/linux/man-pages/man1/dmesg.1.html):\n\n```\nroot@bloggulus:~# dmesg | grep -i kill\n[115633.247115] Out of memory: Killed process 15179 (localedef) total-vm:146420kB, anon-rss:134440kB, file-rss:1756kB, shmem-rss:0kB, UID:0 pgtables:328kB oom_score_adj:0\n```\n\nYep, it sure was!\nDoes this always happen, though?\nOr does this program only get OOM killed _sometimes_?\n\n```\nroot@bloggulus:~# locale-gen \"en_US.UTF-8\"\nGenerating locales (this might take a while)...\nen_US.UTF-8... done\nGeneration complete.\n```\n\nInteresting.\nEverything worked fine the second time which indicates that `locale-gen` can be non-deterministically killed due to the server being out of memory.\nThis led me to my next question: are there ever package updates (via unattended upgrades) that require locales to be regenerated?\nPerhaps locale data changes every once in a while similar to time zone data.\n\n## The Smoking Gun\n\nLet's check the [apt](https://ubuntu.com/server/docs/package-management) logs:\n\n```\nLog started: 2024-05-31 07:00:43\n(Reading database ... 102795 files and directories currently installed.)\nPreparing to unpack .../locales_2.35-0ubuntu3.8_all.deb ...\nUnpacking locales (2.35-0ubuntu3.8) over (2.35-0ubuntu3.7) ...\nSetting up locales (2.35-0ubuntu3.8) ...\nGenerating locales (this might take a while)...\nen_US.UTF-8.../usr/sbin/locale-gen: line 177: 183068 Killed localedef $no_archive -i $input -c -f $charset $locale_alias $locale\ndone\nGeneration complete.\nProcessing triggers for man-db (2.10.2-1) ...\nLog ended: 2024-05-31 07:00:48\n```\n\nThere it is!\nOn May 31, 2024, after updating the `locales` package, the `locale-gen` process was killed (most likely by the OOM killer).\nThis means that the server was in an unstable state since May 31 but didn't \"fail\" until June 4 when the server (and therefore PostgreSQL) restarted.\nThis leads me to the root cause of this problem: the server needs more RAM!\n\n## Moving Foward\n\nAt the bottom of everything, the server ran out of memory.\nOn the surface, however, the problem presented itself more like a small [Rube Goldberg machine](https://en.wikipedia.org/wiki/Rube_Goldberg_machine):\n\n1. The OOM killer caused `locale-gen` to fail after upgrading the `locales` package.\n2. The lack of a valid `en_US.UTF-8` locale caused PostgreSQL to fail to start.\n3. The lack of a running database caused Bloggulus to fail to start.\n\nRegardless of _how_ it happened, the outcome is clear: the server needs more memory.\nAs a direct result of this incident, I've bumped the droplet's RAM from 512MB ($4/month) to 1GB ($6/month).\nI also installed the [UptimeRobot app](https://play.google.com/store/apps/details?id=com.uptimerobot&hl=en_US) and enabled push notifications.\nIn the future, I might redeploy [Prometheus](https://prometheus.io/) and start collecting core server metrics again (CPU, RAM, and storage).\nThat way, I can capacity plan proactively and fix these critical problems _before_ they cause 7 hours of downtime.\n\nThanks for reading!\n",
    "timestamp": "2025-05-23T16:31:19.541276",
    "tags": [],
    "severity": "high",
    "services_affected": [
      "api",
      "web",
      "database",
      "monitoring"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "azure",
      "postgresql",
      "elasticsearch",
      "nginx",
      "prometheus"
    ],
    "failure_pattern": "resource_exhaustion",
    "timeline_events": [
      {
        "timestamp": "14:51",
        "event": "39 bloggulus systemd[1]: Starting bloggulus..."
      },
      {
        "timestamp": "14:51",
        "event": "39 bloggulus bloggulus[37755]: 2024/06/04 14:51:39 ERROR failed to connect to `host=localhost user=bloggulus database=bloggulus`: dial error (dial tcp 127.0.0.1:5432)"
      },
      {
        "timestamp": "14:51",
        "event": "39 bloggulus systemd[1]: bloggulus.service: Main process exited, code=exited, status=1/FAILURE"
      },
      {
        "timestamp": "14:51",
        "event": "39 bloggulus systemd[1]: bloggulus.service: Failed with result 'exit-code'."
      },
      {
        "timestamp": "14:51",
        "event": "39 bloggulus systemd[1]: Failed to start bloggulus."
      },
      {
        "timestamp": "14:51",
        "event": "45 bloggulus systemd[1]: bloggulus.service: Scheduled restart job, restart counter is at 4702."
      },
      {
        "timestamp": "14:51",
        "event": "45 bloggulus systemd[1]: Stopped bloggulus."
      },
      {
        "timestamp": "14:51",
        "event": "36 bloggulus systemd[1]: Starting PostgreSQL Cluster 14-main..."
      },
      {
        "timestamp": "14:51",
        "event": "36 bloggulus postgresql@14-main[37742]: perl: warning: Setting locale failed."
      },
      {
        "timestamp": "14:51",
        "event": "36 bloggulus postgresql@14-main[37742]: perl: warning: Please check that your locale settings:"
      },
      {
        "timestamp": "14:51",
        "event": "36 bloggulus postgresql@14-main[37742]:         LANGUAGE = (unset),"
      },
      {
        "timestamp": "14:51",
        "event": "36 bloggulus postgresql@14-main[37742]:         LC_ALL = (unset),"
      },
      {
        "timestamp": "14:51",
        "event": "36 bloggulus postgresql@14-main[37742]:         LANG = \"en_US.UTF-8\""
      },
      {
        "timestamp": "14:51",
        "event": "36 bloggulus postgresql@14-main[37742]:     are supported and installed on your system."
      },
      {
        "timestamp": "14:51",
        "event": "36 bloggulus postgresql@14-main[37742]: perl: warning: Falling back to the standard locale (\"C\")."
      },
      {
        "timestamp": "14:51",
        "event": "36 bloggulus postgresql@14-main[37742]: Error: /usr/lib/postgresql/14/bin/pg_ctl /usr/lib/postgresql/14/bin/pg_ctl start -D /mnt/bloggulus_db/data -l /var/log/postg>"
      },
      {
        "timestamp": "14:51",
        "event": "36 bloggulus postgresql@14-main[37742]: 2024-06-04 14:51:36.657 UTC [37747] LOG:  invalid value for parameter \"lc_messages\": \"en_US.UTF-8\""
      },
      {
        "timestamp": "14:51",
        "event": "36 bloggulus postgresql@14-main[37742]: 2024-06-04 14:51:36.657 UTC [37747] LOG:  invalid value for parameter \"lc_monetary\": \"en_US.UTF-8\""
      },
      {
        "timestamp": "14:51",
        "event": "36 bloggulus postgresql@14-main[37742]: 2024-06-04 14:51:36.657 UTC [37747] LOG:  invalid value for parameter \"lc_numeric\": \"en_US.UTF-8\""
      },
      {
        "timestamp": "14:51",
        "event": "36 bloggulus postgresql@14-main[37742]: 2024-06-04 14:51:36.657 UTC [37747] LOG:  invalid value for parameter \"lc_time\": \"en_US.UTF-8\""
      }
    ],
    "blast_radius": "global",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 1.0
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/obsoke/obsoke.github.io/blob/501a60da8c550d3f529b6016f1190605095feafe/_posts/2014-12-31-giffy_postmortem.md",
    "title": "2014-12-31-giffy_postmortem.md",
    "content": "---\nlayout: post\ntitle: Giffy&#58; A Postmortem\ntags: [open-source, giffy, projects, postmortem]\ndate: 2014-12-31 17:05:00\n---\nI've recently finished up a small side project that I started quite a\nwhile ago called [Giffy](http://giffy.dale.io). It wasn't a particularly large or complex\nproject but the motivation to continue working on it diminished\nshortly after starting. Now that the project is done, I wanted to\nwrite a post discussing some of the challenges I faced and thoughts I\nhad.\n\n### On Side Projects\n\nWorking on a side project is a great way for any developer to learn\nabout a new technology, further develop an existing skill or just get\nsome creative juices flowing. However, I've found it much easier to\nstart a project than to actually finish one. There can be many reasons\nwhy finishing a side project can be hard. For Giffy, those reasons\nwere feature creep, scope and changing personal thoughts on images on\nthe web. While side projects can be a great place to experiment, too\nmuch experimenting led to a feature list that was much too long. This\ncan be mentally draining when done close to the beginning of a\nproject. I wouldn't recommend it. I've learned a lot about looking at\na feature and breaking it down into smaller features. Working in\nsmaller chunks makes it easier for me to focus on the current\nobjective and to experience the thrill of seeing a feature come to\nlife more frequently.\n\n### What is Giffy?\n\nGiffy is simply an image hosting service for gifs. You can tag gifs\nthat has been uploaded, and find similarly tagged gifs. If you don't\nhave any gifs to upload, you can create one in the browser using your\nwebcam. Once you've created your gif, you have the option to upload it\ndirectly to Giffy.\n\nSome features, such as adding & deleting tags, require an account. One\nof the features I ended up cutting was a permissions system that would\nlet the admin define roles and associated permitted & forbidden\nactions (eg: upload a gif, delete a tag). Bits and pieces of the\npermissions system exist in the code, but it was never finished.\n\nThere were a bunch of social-networky features I cut from the feature\nlist. I had to step back and remember what my goals were for this\nproject:\n1.  Learn more about Angular\n2.  Learn how to upload images directly to an Amazon S3 bucket from the\n    browser via CORS\n3.  Learn how to create a gif from a webcam using WebRTC and upload\n    that gif directly to S3\n\nHere on the other side of the project, I feel that I've completed\nthese goals. Learning not only how to cut unnecessary fat from the\nfeature list, but also how to divide my main tasks into smaller, more\nmanageable sub tasks was important to keep me going towards the finish\nline. Focusing on the important features to cut can be hard in a\nproject that exists solely for learning and experimenting, but for\nsome people it may be necessary if that project is ever going to see\nthe light of day.\n\n### The Backend\n\nThere is not a whole lot of magic happening on the backend. All it is\nreally doing is serving HTTP requests and fetching data from the\ndatabase. I'm using the [Bookshelf ORM](http://bookshelfjs.org/) to handle all things database,\nbacked by Postgres. It's a pretty nice ORM that makes mapping models\nto database tables incredibly easy. While I found that it lacked some\nbasic features such as limiting the amount of rows returned, it's\npossible to use the underlying [Knex.js](http://knexjs.org/) library to perform raw SQL\nqueries. Other libraries I use are bcrypt for password salting,\nshortid to generate a unique file name for gifs and Amazon's AWS\nlibrary for Node.js\n\nIn terms of design, I make heavy use of promises instead of callbacks\nin my API code. Promises are very easy to use and, in my opinion, make\nones code much more readable (goodbye, callback hell).\n\nOne design choice I regret is choosing session-based authentication\nover token-based. The way I originally designed the application was a\nstandalone API that would be able to handle requests by clients on any\nkind of device. I ended up with more of a Rails-type monolithic app so\ncookie-based sessions were pretty easy to implement. From my limited\nunderstanding, cookie-based authentication doesn't work very well on\nmobile devices. A much simpler solution would be to include a token\nthat identifies the user with each request. Ah well, lesson learned\nfor my next side project!\n\n### Angular\n\nIt really bothers me that I need to use a [plugin](https://github.com/angular-ui/ui-router) for a framework just\nto do something as simple as nested views. I feel like a framework\nthat focuses on building single-page apps like Angular should have\nthis built in. Perhaps I'm being nit-picky but it's a design choice I\nfind baffling. Also, the way Angular differentiates services,\nfactories and providers is a little strange and seems arbitrary.\n\nAside from those points, using Angular has been mostly painless and\nmade developing the web app portion of Giffy easy. I don't think I was\npushing the limits of the framework or anything. Most of the\nchallenges I faced came with getting sessions to work between Angular\nand Express, or routing static assets; nothing specific to Angular\ncompared to other single-page app frameworks.\n\nIn the end, I was mostly pleased with Angular, and would consider it\nin future projects.\n\n**EDIT (2015-01-17):** After some consideration, I'm not too sure if I\n  would actually use Angular for another personal project. I'm not a\n  huge fan of how Angular 2 is looking.\n\n### Direct to S3 Upload\n\nOne feature I really wanted in Giffy was the ability to upload a file\ndirectly to an Amazon S3 bucket directly from the browser. I wanted\nthe API behind Giffy to solely handle requests and to fetch the\nappropriate data from the database. I found [an article on Heroku's dev\ncentre](https://devcenter.heroku.com/articles/s3-upload-node) on the subject, which makes use of Amazon's AWS library for\nNode.js. The library is used to create the proper signature for the\nupload request, which contains information like where in the bucket to\nput the file, expected file size, and authentication to the\nbucket. Once the image is successfully uploaded, a call to the API is\nmade to register the newly uploaded gif in the Giffy database.\n\nThe Heroku article also included a link to a [client-side S3 uploading\nscript](https://github.com/flyingsparx/s3upload-coffee-javascript). I quickly ran into some limits with the script though, such as\nnot getting as much metadata as I would have liked about the file with\nthe upload completion callback, or not supporting the ability to\nupload a binary image blob to S3. I ended up forking the repo and made\nthe necessary adjustments, which you can find [here](https://github.com/obsoke/s3upload-coffee-javascript).\n\nWhile this solution is novel, I kind of regret designing it this\nway. This has to due with how I now feel about gifs in general. Gifs\ncan cause unnecessary repaints in some browsers, which can greatly\naffect performance. For Giffy, where I could potentially have a page\nfull of gifs, I was worried that performance on some older desktop and\nlaptops or mobile devices would suffer.\n\nThere have been some interesting ways of solving this problem. For\ninstance, Twitter [converts gifs to mp4](http://blog.embed.ly/post/89265229166/what-twitter-isnt-telling-you-about-gifs) and shows users the video file\ninstead. I thought this was a pretty neat solution. Not only will a\nmp4 file be much smaller than the average gif, but the user also gets\ncontrol over the playback of the image. This is most likely the\nsolution I would have chosen for Giffy as well. However, since Giffy\nuploads the image directly to S3, it wasn't feasible for this\niteration of the project. If I decide to return to the project, it\nwould be the first thing I would change.\n\n### Create gif from webcam\n\nThe final feature I wanted to implement was the ability to use one's\nown webcam to create a gif. When I was working as a contractor for\nMozilla Webmaker last year, this was an idea the frontend team played\naround with for the Webmaker Profiles feature. I thought it was fun\nand decided to implement it into Giffy.\n\nMy implementation is pretty simple. The creation of gifs is done by\ncapturing frames via button click. I found a [gif encoder written in\nJavaScript](http://jnordberg.github.io/gif.js/) that I use to create the gifs. When one clicks the\n\\`Capture\\` button, the current frame displayed in the video tag is\ncopied pixel by pixel to a canvas. The image data stored in the canvas\nis used by gif.js to create one frame of the gif. gif.js uses web\nworkers to create the gif in the background, leaving the interface\nresponsive.\n\nFor one crazy second, I actually considered writing my own gif encoder\nin JavaScript. It would have been an interesting project, but way out\nof the scope for Giffy. Other things I would have liked to add would\nhave been some tacky Instagramish filters and the ability to record a\ngif for N seconds, rather than having to add each frame manually.\n\n### Final Thoughts\n\nSome other features that were cut from the list were allowing users to\nadd gifs to a favourites list, unit tests, and allowing user\ncomments. The ability to search by tag was another feature I cut. In\nretrospect, none of these features would be particularly difficult to\nimplement at this point but you have to draw the line somewhere on\nsome personal projects or they will never end. There are other\npotential projects that I am currently more interested in spending my\ntime on.\n\nI learned quite a bit from working on Giffy. Aside from the numerous\ntechnical and design lessons I learned, the lessons about scope and\nfeature creep are what really hit me: breaking big features up into\nsmaller ones and setting attainable milestones that end with some\nfeature that can be demonstrated in at least a small fashion. Working\non Giffy one huge feature at a time made it feel like a chore, but now\nthat it's finally over, the satisfaction of putting the 'Complete'\nlabel on a project makes it all feel worth it. Kinda weird how that\nhappens.\n\nFeel free to check out the source code [on my GitHub repo](https://github.com/obsoke/giffy). A [demo of\nGiffy](http://giffy.dale.io/) is also available. I'll be writing a cron script to clean out\nthe database & S3 bucket every few days. Please don't abuse the demo\nsite! Feel free to fork, open pull requests, or leave feedback!\n",
    "timestamp": "2025-05-23T16:31:20.050818",
    "tags": [],
    "severity": "high",
    "services_affected": [
      "api",
      "web",
      "database",
      "auth"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "aws",
      "postgresql",
      "elasticsearch",
      "jenkins"
    ],
    "failure_pattern": null,
    "timeline_events": [],
    "blast_radius": "global",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 0.62
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/fike/www.fernandoike.com/blob/970ec66e8a696083deed676bd14a599b782e7318/content/portuguese/post/gitlab_postmortem.md",
    "title": "gitlab_postmortem.md",
    "content": "+++\ntitle = \"O Postmortem da Gitlab\"\ndescription = \"Análise e lições do Postmortem da Gitlab\"\ncategories = [\"devops\", \"portugues\", \"sre\"]\ntags = [\"devops\", \"portugues\", \"sre\", \"blameless\", \"postmortem\", \"gitlab\", \"netflix\", \"google\", ]\ndraft = false\ndate = \"2017-02-13T15:34:54-02:00\"\n\n+++\nRelatórios Postmortem públicos são de grande valor para todos que querem aprender a partir de incidentes já ocorridos. De certa forma, eles são parecido com os relatórios sobre acidentes de avião. Identifica-se a(s) causa(s) do acidente e quais a recomendações para que não ocorra novamente. A diferença entre um relatório de um acidente de avião e postmortem de TI é que o segundo não irá culpar pessoas nominalmente (**blameless**) pelo problema, mas indicar o que deve ser feito do ponto de vista de processo, arquitetura de software, etc.\n\nBlameless é muito importante para cultura **DevOps** e também para **SRE**, ela possibilita criar um ambiente na organização analisar um incidente ou um bug sem culpar pessoas pelo problema e identifica a causa raiz; como também as lições aprendidas para que não ocorra novamente. Algumas empresas com as quais conversei sobre DevOps fazem relatórios Postmortem mas os mantém em privado, contudo, existe um movimento cada ver maior nas empresas do exterior tanto  em tornar seus relatórios públicos como forma de explicar para os clientes porque aconteceu um incidente, como também as lições aprendidas para que outros não tenham o mesmo tipo de problema.\n\nO livro SRE do Google tem um capítulo específico ([Postmortem Culture: Learning from failure](https://landing.google.com/sre/book/chapters/postmortem-culture.html)), outro texto interessante sobre **Postmortem** e **Blameless** é do [John Allspaw](https://twitter.com/allspaw) ([Blameless PostMortems and a Just Culture](https://codeascraft.com/2012/05/22/blameless-postmortems/)). Ao menos para mim, [um dos mais interessantes relatórios Postmortem](https://about.gitlab.com/2017/02/10/postmortem-of-database-outage-of-january-31/) é do [Gitlab](https://about.gitlab.com/), eles tiveram uma indisponibilidade no banco de dados no dia 31 de janeiro de 2017. Abaixo algumas notas minhas sobre o incidente.\n\nA causa raiz foi executar o \"***rm -rf***\" no servidor de banco de dados ([PostgreSQL](https://www.postgresql.org/)) principal, o objetivo ao rodar o comando no servidor de banco secundário era limpar a base e reiniciar a replicação entre eles que tinha parado. A replicação parou por causa de uma sobrecarga, o servidor primário removia os WAL segments antes que o servidor secundário pudesse aplicá-los.\n\nA recuperação do backup foi demasiadamente lenta (18 horas), isso porque a recuperação via backups feitos pelo pg_dump (9.2) foram realizado na versão diferente do banco em produção (9.6). A outra forma de tentarem recuperar foi usando os snapshot do LVM e também dos discos do Azure, a demora ocorreu porque os discos no serviço padrão são lentos como a maioria dos IaaS. A não ser que seja contratado discos mais rápidos (e caros) ou adote baremetal.\n\nAntes de você tirar conclusões a partir daqui, recomendo que leia o relatório do Gitlab, eles detalham tudo que aconteceu e o que estão fazendo para melhorar. No relatório, eles usam o **5 Whys** (**5 porquês**) para identificar porque ocorreu a indisponibilidade do servidor de banco de dados e porque demorou para recuperar o serviço. [5 Whys](https://www.toyota-global.com/company/toyota_traditions/quality/mar_apr_2006.html) é uma técnica interrogativa [iterativa](https://pt.m.wiktionary.org/wiki/iterativo) para identificar a causa raiz de um defeito, é parte do [Toyota Production System](https://www.toyota-global.com/company/vision_philosophy/toyota_production_system/). Abaixo uma tradução livre de uma das análises usando 5 Whys.\n\n1 - **Por que o Gitlab.com ficou fora do ar?**\n\n>O diretório do banco de dados primário foi removido acidentalmente, ao invés de >remover o diretório do banco de dados secundário.\n\n2 - **Por que o diretório do banco de dados foi removido?**\n\n>A replicação do banco de dados parou, foi necessário refazer o banco >secundário. Para isso, é necessários que o dados do diretório do PostgreSQL >esteja vazio. A restauração dele é um trabalho manual, porque isso não foi >automatizado, nem foi documento apropriadamente.\n\n3 - **Por que a replicação parou?**\n\n>Uma sobrecarga fez o processo de replicação parar. Isso aconteceu porque o >banco de dados primário removeu os segmentos WAL antes do banco de dados >secundário pudesse replicá-los.\n\n4 - **Por que a carga do banco de dados cresceu?**\n\n>Ela foi causada por dois eventos que aconteceram ao mesmo tempo: aumento no >spam em conjunto ao processo de remoção executado por funcionário da Gitlab e >os dados associados.\n\n5 - **Por que um funcionário da Gitlab estava designado para remover?**\n\n>O funcionário recebeu uma notificação de abuso por um troll. O sistema atual >para responder notificação de abuso torna muito fácil ignorar os detalhes da >notificação. Como resultado, o funcionário designado removeu acidentalmente.\n\n\nEspecificamente sobre PostgreSQL, existem muitas formas de replicação que poderiam evitar ou minimizar um incidente deste tipo. Este não é o ponto deste texto (quem sabe num outro), uma das formas de melhor rapidamente a resiliência de um serviço é através do Game Day, identificando gargalhos e problemas de disponibilidade nos serviços através de testes de carga/resiliência. Este processo também é chamado de Engenharia de resiliência, [Jesse Robins](https://twitter.com/jesserobbins) falou sobre isso na Usenix Conference: *[GameDay: Creating Resiliency Through Destruction](https://www.youtube.com/watch?v=zoz0ZjfrQ9s)*\n\nGameDay é bem interessante, tem um estudo de caso em que Jesse Robbins, Kripa Krishnan, John Allspaw, e Tom Limoncelli tem um estudo de caso em que discutem sobre ele em [Resilience Engineering: Learning to Embrace Failure](https://queue.acm.org/detail.cfm?id=2371297). Em trecho da conversa Jesse Robins comenta:\n\n> ... você não pode escolher se vai ter ou não falhas, elas irão acontecer, não importa o que você faça, em muitos casos você pode escolher quando irá aprender as lições.\n\nJá participei de testes similares para duas instituições financeiras. Na ocasião, o objetivo era melhorar o processo de mitigação de ataques DDoS, para isso eram realizadas simulações de diversos tipos de ataques DDoS. A cada teste era identificado um equipamento, serviço, processo ou sistema que deveria ser revisto pois algum tipo de ataque não era mitigado. Após vários testes, essas instituições sofreram vários ataques DDoS reais que foram mitigados sem grande impacto para os clientes delas.\n\n**Referências**:\n\n**Gitlab** - **Postmortem of database outage of January 31**:\nhttps://about.gitlab.com/2017/02/10/postmortem-of-database-outage-of-january-31/\n\n**Livro - Google SRE**: https://landing.google.com/sre/book/chapters/postmortem-culture.html\n\n**John Allspaw** - **Blameless PostMortems and a Just Culture**: https://codeascraft.com/2012/05/22/blameless-postmortems/\n\n**Jesse Robins** - **GameDay: Creating Resiliency Through Destruction** - https://www.youtube.com/watch?v=zoz0ZjfrQ9s\n\n**Resilience Engineering**: **Learning to Embrace Failure**: https://queue.acm.org/detail.cfm?id=2371297\n\n **5 Whys**: https://www.toyota-global.com/company/toyota_traditions/quality/mar_apr_2006.html\n\n**Google Compute Engine Incident #16007**:   https://status.cloud.google.com/incident/compute/16007?post-mortem\n\n**Netflix - Post-mortem of October 22,2012 AWS degradation**: https://techblog.netflix.com/2012/10/post-mortem-of-october-222012-aws.html\n",
    "timestamp": "2025-05-23T16:31:21.281911",
    "tags": [],
    "severity": "high",
    "services_affected": [
      "api",
      "web",
      "database",
      "queue"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "kubernetes",
      "aws",
      "gcp",
      "azure",
      "postgresql"
    ],
    "failure_pattern": "data_corruption",
    "timeline_events": [],
    "blast_radius": "global",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 0.9400000000000001
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/xem/miniBook/blob/bcc97c42ee7f79673d61112140d5794d6a60fcff/ANALYSIS.md",
    "title": "ANALYSIS.md",
    "content": "Compression tests\n===\n\n- uncompressed: 5201kb\n- zip + zopfli : 1844kb\n- rar: 1629kb\n- 7z: 1513kb\n- bzip: 1426kb\n- BCM: 1191kb\n- paq8px: 1085kb\n- paq8hp12: 1035kb, according to [HN](https://news.ycombinator.com/item?id=14825226)\n\n\nText Analysis\n===\n\n**Typos**\n\n- 1289 punctuation marks (.!?) are not followed by a capitalized letter (but 90590 are).\n- A parenthesis is closed by a bracket (l.78316): ````Dance. Exeunt (all but Don John, Borachio, and Claudio].````. It's probably a typo.\n- The two occurrences of \"}\" also look like typos (l.75165): ````  MRS. FORD. } Away, away.```` , ````  MRS. PAGE. } Away, away.````\n\n\n**Character frequency:**\n\n````\n\" \": 1266627\n\"e\": 403878\n\"t\": 289404\n\"o\": 280908\n\"a\": 244270\n\"h\": 218201\n\"n\": 215560\n\"s\": 214680\n\"r\": 208489\n\"i\": 197778\n\"l\": 145920\n\"d\": 133557\n\"\\n\": 119231\n\"u\": 114637\n\"m\": 95436\n\"y\": 85140\n\",\": 82413\n\".\": 77054\n\"w\": 72843\n\"f\": 68671\n\"c\": 66478\n\"g\": 56951\n\"I\": 47303\n\"b\": 46455\n\"p\": 46404\n\"A\": 39767\n\"T\": 34375\n\"v\": 33941\n\"E\": 32070\n\"'\": 31067\n\"k\": 29179\n\"S\": 28196\n\"O\": 25170\n\"N\": 22632\n\"R\": 21383\n\"L\": 19398\n\";\": 17194\n\"C\": 16804\n\"H\": 15780\n\"W\": 15358\n\"M\": 13183\n\"B\": 12510\n\"U\": 12107\n\"D\": 11664\n\"?\": 10475\n\"F\": 10360\n\"G\": 9801\n\"P\": 9459\n\"!\": 8827\n\"-\": 7841\n\"Y\": 6863\n\"K\": 5749\n\"x\": 4621\n\"V\": 2904\n\"j\": 2691\n\"q\": 2400\n\"[\": 2071\n\"]\": 2063\n\"J\": 1844\n\":\": 1810\n\"Q\": 1177\n\"z\": 1094\n\"Z\": 532\n'\"': 450\n\"X\": 380\n\"1\": 241\n\"(\": 165\n\")\": 164\n\"2\": 123\n\"3\": 99\n\"4\": 88\n\"5\": 78\n\"_\": 68\n\"6\": 59\n\"9\": 54\n\"0\": 45\n\"7\": 37\n\"8\": 33\n\"|\": 33\n\"<\": 29\n\"&\": 21\n\"}\": 2\n\">\": 1\n````\n\n**Word frequency (only words that appear more than once):**\n\n````\n\"adders\": 5\n\"stalls\": 4\n\"speak\": 994\n\"ll\": 2409\n\"our\": 2688\n\"take\": 1002\n\"cannot\": 714\n\"t\": 1171\n\"us\": 1666\n\"Ay\": 689\n\"think\": 977\n\"these\": 1097\n\"Come\": 951\n\"been\": 682\n\"It\": 974\n\"He\": 1558\n\"tis\": 760\n\"There\": 706\n\"am\": 2102\n\"man\": 1926\n\"We\": 882\n\"heart\": 1015\n\"My\": 1648\n\"KING\": 1340\n\"OF\": 818\n\"lord\": 1999\n\"by\": 2929\n\"Enter\": 1988\n\"come\": 1552\n\"King\": 1306\n\"sir\": 1743\n\"d\": 8897\n\"we\": 2730\n\"Exit\": 965\n\"Exeunt\": 1014\n\"That\": 2983\n\"upon\": 1429\n\"out\": 1227\n\"s\": 7463\n\"God\": 824\n\"men\": 892\n\"never\": 896\n\"them\": 1957\n\"But\": 2610\n\"as\": 4298\n\"the\": 23220\n\"good\": 2263\n\"should\": 1421\n\"time\": 1000\n\"have\": 5440\n\"father\": 1017\n\"had\": 1274\n\"You\": 1639\n\"know\": 1639\n\"his\": 6315\n\"again\": 748\n\"thou\": 4585\n\"then\": 1519\n\"to\": 15904\n\"here\": 1671\n\"own\": 770\n\"your\": 6003\n\"you\": 12103\n\"can\": 1052\n\"st\": 1057\n\"thy\": 3632\n\"go\": 1192\n\"Sir\": 725\n\"with\": 6787\n\"Let\": 944\n\"away\": 680\n\"a\": 12647\n\"would\": 2021\n\"where\": 681\n\"As\": 1422\n\"me\": 7692\n\"at\": 2270\n\"I\": 22176\n\"O\": 2293\n\"most\": 988\n\"too\": 1163\n\"any\": 694\n\"Thou\": 953\n\"that\": 8299\n\"art\": 855\n\"now\": 1971\n\"such\": 1250\n\"love\": 2001\n\"No\": 1083\n\"And\": 7450\n\"hath\": 1648\n\"may\": 1424\n\"well\": 1562\n\"like\": 1510\n\"life\": 834\n\"Is\": 923\n\"Who\": 721\n\"By\": 823\n\"true\": 726\n\"Why\": 1206\n\"in\": 9958\n\"hear\": 790\n\"or\": 1743\n\"day\": 740\n\"this\": 5449\n\"from\": 2291\n\"be\": 6375\n\"To\": 3349\n\"up\": 1032\n\"do\": 3289\n\"death\": 824\n\"and\": 18560\n\"thee\": 3145\n\"When\": 848\n\"than\": 1454\n\"one\": 1589\n\"shall\": 3122\n\"for\": 5841\n\"With\": 993\n\"In\": 1106\n\"hand\": 832\n\"let\": 1418\n\"their\": 1932\n\"they\": 1932\n\"was\": 2024\n\"what\": 2248\n\"so\": 3997\n\"on\": 2956\n\"no\": 2702\n\"A\": 1940\n\"o\": 737\n\"of\": 15668\n\"there\": 1491\n\"him\": 5131\n\"which\": 1410\n\"Then\": 694\n\"very\": 757\n\"did\": 1384\n\"all\": 3405\n\"th\": 1080\n\"Which\": 901\n\"must\": 1351\n\"What\": 2547\n\"say\": 1522\n\"how\": 988\n\"yet\": 1142\n\"great\": 815\n\"an\": 1594\n\"give\": 1011\n\"The\": 4017\n\"are\": 3118\n\"How\": 1172\n\"much\": 989\n\"more\": 2057\n\"doth\": 816\n\"but\": 3651\n\"If\": 1661\n\"So\": 1029\n\"her\": 3646\n\"This\": 1141\n\"fair\": 698\n\"Of\": 976\n\"mine\": 1062\n\"will\": 4503\n\"he\": 5106\n\"my\": 10827\n\"she\": 1864\n\"make\": 1469\n\"For\": 1781\n\"some\": 1097\n\"not\": 7991\n\"were\": 1390\n\"if\": 1838\n\"made\": 756\n\"when\": 1203\n\"see\": 1320\n\"is\": 8375\n\"Now\": 798\n\"tell\": 887\n\"it\": 6711\n\"Or\": 679\n\"Here\": 646\n\"Go\": 539\n\"Good\": 548\n\"face\": 413\n\"eyes\": 675\n\"France\": 409\n\"blood\": 626\n\"thine\": 435\n\"other\": 677\n\"hold\": 376\n\"Tis\": 646\n\"er\": 593\n\"noble\": 584\n\"brother\": 587\n\"Your\": 650\n\"night\": 640\n\"mother\": 396\n\"old\": 622\n\"house\": 518\n\"whose\": 379\n\"honour\": 606\n\"both\": 521\n\"dear\": 406\n\"who\": 564\n\"better\": 564\n\"bear\": 497\n\"Shall\": 471\n\"two\": 626\n\"His\": 537\n\"Not\": 475\n\"She\": 534\n\"friend\": 429\n\"Well\": 580\n\"best\": 433\n\"-\": 409\n\"name\": 648\n\"answer\": 397\n\"heaven\": 570\n\"find\": 501\n\"die\": 449\n\"myself\": 506\n\"SECOND\": 465\n\"call\": 628\n\"LORD\": 378\n\"little\": 473\n\"into\": 554\n\"live\": 482\n\"GLOUCESTER\": 436\n\"FIRST\": 617\n\"against\": 454\n\"might\": 452\n\"Than\": 426\n\"Thy\": 400\n\"before\": 624\n\"stand\": 461\n\"sweet\": 649\n\"lady\": 561\n\"world\": 664\n\"full\": 376\n\"nothing\": 534\n\"himself\": 432\n\"till\": 414\n\"dead\": 497\n\"Duke\": 545\n\"HENRY\": 380\n\"those\": 463\n\"SCENE\": 655\n\"daughter\": 413\n\"All\": 401\n\"keep\": 431\n\"tongue\": 394\n\"hast\": 526\n\"DUKE\": 552\n\"wife\": 485\n\"fear\": 617\n\"pray\": 546\n\"none\": 409\n\"many\": 529\n\"down\": 622\n\"long\": 422\n\"Caesar\": 432\n\"They\": 591\n\"ever\": 572\n\"young\": 403\n\"woman\": 396\n\"master\": 494\n\"first\": 457\n\"Prince\": 475\n\"gone\": 448\n\"son\": 645\n\"QUEEN\": 414\n\"leave\": 602\n\"comes\": 589\n\"way\": 559\n\"look\": 665\n\"friends\": 453\n\"else\": 382\n\"Where\": 660\n\"Yet\": 418\n\"put\": 441\n\"part\": 491\n\"head\": 501\n\"Have\": 452\n\"done\": 648\n\"set\": 418\n\"Be\": 495\n\"every\": 455\n\"eye\": 417\n\"word\": 491\n\"peace\": 390\n\"could\": 555\n\"being\": 542\n\"Nay\": 521\n\"off\": 479\n\"Lord\": 669\n\"place\": 420\n\"poor\": 551\n\"words\": 406\n\"Do\": 528\n\"soul\": 451\n\"king\": 377\n\"still\": 487\n\"show\": 439\n\"thus\": 596\n\"though\": 394\n\"Will\": 488\n\"nor\": 612\n\"fool\": 382\n\"Cumberland\": 4\n\"bid\": 282\n\"Grace\": 318\n\"hence\": 310\n\"hour\": 306\n\"has\": 338\n\"forth\": 364\n\"without\": 282\n\"another\": 368\n\"Master\": 331\n\"RICHARD\": 338\n\"Nor\": 357\n\"dost\": 334\n\"after\": 323\n\"enough\": 288\n\"home\": 329\n\"fall\": 327\n\"England\": 327\n\"hither\": 290\n\"FALSTAFF\": 358\n\"back\": 327\n\"meet\": 310\n\"indeed\": 355\n\"kill\": 305\n\"fellow\": 292\n\"does\": 285\n\"whom\": 333\n\"CLOWN\": 294\n\"sword\": 344\n\"hope\": 351\n\"hands\": 317\n\"ere\": 287\n\"power\": 300\n\"ring\": 297\n\"truth\": 331\n\"shalt\": 287\n\"mean\": 287\n\"faith\": 313\n\"thing\": 352\n\"BRUTUS\": 302\n\"lie\": 287\n\"once\": 372\n\"thousand\": 319\n\"even\": 316\n\"state\": 303\n\"Give\": 329\n\"thought\": 367\n\"stay\": 373\n\"makes\": 311\n\"please\": 330\n\"i\": 312\n\"play\": 328\n\"Aside\": 336\n\"Upon\": 329\n\"Hath\": 292\n\"From\": 351\n\"use\": 305\n\"Are\": 321\n\"madam\": 322\n\"end\": 295\n\"said\": 373\n\"mind\": 360\n\"Ham\": 358\n\"PAGE\": 298\n\"gentleman\": 289\n\"gentle\": 336\n\"matter\": 347\n\"shame\": 288\n\"rest\": 345\n\"John\": 345\n\"earth\": 309\n\"news\": 304\n\"right\": 320\n\"came\": 295\n\"husband\": 320\n\"heard\": 335\n\"rather\": 285\n\"unto\": 358\n\"within\": 333\n\"lords\": 324\n\"turn\": 323\n\"cause\": 333\n\"An\": 284\n\"Rome\": 342\n\"therefore\": 362\n\"Queen\": 370\n\"nature\": 329\n\"red\": 282\n\"Our\": 373\n\"about\": 355\n\"three\": 329\n\"since\": 284\n\"crown\": 292\n\"things\": 304\n\"ANTONY\": 295\n\"boy\": 344\n\"swaggering\": 6\n\"CLEOPATRA\": 244\n\"light\": 249\n\"Look\": 268\n\"Even\": 250\n\"Re-enter\": 248\n\"sure\": 264\n\"IAGO\": 273\n\"far\": 270\n\"bed\": 263\n\"OTHELLO\": 276\n\"welcome\": 271\n\"tears\": 270\n\"seen\": 266\n\"yourself\": 268\n\"war\": 250\n\"help\": 274\n\"near\": 252\n\"spirit\": 252\n\"reason\": 278\n\"TIMON\": 244\n\"youth\": 272\n\"false\": 274\n\"mistress\": 258\n\"fortune\": 260\n\"SIR\": 272\n\"arms\": 247\n\"YORK\": 259\n\"wrong\": 266\n\"SERVANT\": 257\n\"last\": 249\n\"kind\": 264\n\"fight\": 266\n\"court\": 244\n\"why\": 256\n\"lost\": 247\n\"means\": 261\n\"grace\": 273\n\"Would\": 274\n\"sent\": 252\n\"Therefore\": 262\n\"only\": 250\n\"thank\": 280\n\"body\": 276\n\"ye\": 266\n\"saw\": 254\n\"wit\": 258\n\"honest\": 269\n\"gods\": 277\n\"fire\": 247\n\"follow\": 281\n\"CAMBRIDGE\": 8\n\"Were\": 199\n\"wilt\": 230\n\"prove\": 231\n\"told\": 224\n\"under\": 200\n\"land\": 202\n\"devil\": 229\n\"More\": 222\n\"lose\": 201\n\"SYRACUSE\": 229\n\"service\": 216\n\"gold\": 212\n\"Was\": 219\n\"May\": 213\n\"MRS\": 214\n\"care\": 207\n\"sleep\": 238\n\"lay\": 239\n\"found\": 213\n\"ANTIPHOLUS\": 204\n\"less\": 215\n\"Did\": 241\n\"Some\": 239\n\"left\": 235\n\"ne\": 203\n\"sun\": 228\n\"looks\": 202\n\"ACT\": 227\n\"swear\": 238\n\"mad\": 236\n\"S\": 235\n\"Henry\": 230\n\"GENTLEMAN\": 201\n\"Lear\": 232\n\"knows\": 205\n\"Though\": 232\n\"high\": 212\n\"grief\": 208\n\"kiss\": 208\n\"strange\": 239\n\"York\": 233\n\"pardon\": 242\n\"fly\": 209\n\"seem\": 203\n\"wish\": 243\n\"FORD\": 217\n\"desire\": 207\n\"get\": 231\n\"On\": 214\n\"yours\": 241\n\"itself\": 232\n\"people\": 209\n\"villain\": 224\n\"thoughts\": 233\n\"letter\": 242\n\"bloody\": 218\n\"Whose\": 234\n\"At\": 233\n\"foul\": 209\n\"new\": 199\n\"beauty\": 220\n\"same\": 217\n\"times\": 202\n\"MACBETH\": 208\n\"company\": 202\n\"MESSENGER\": 223\n\"says\": 232\n\"Before\": 209\n\"Till\": 205\n\"lies\": 222\n\"business\": 230\n\"Pray\": 206\n\"These\": 223\n\"Antony\": 220\n\"cousin\": 233\n\"child\": 221\n\"present\": 236\n\"send\": 218\n\"beseech\": 205\n\"horse\": 222\n\"alone\": 230\n\"together\": 237\n\"Speak\": 199\n\"through\": 226\n\"talk\": 215\n\"Take\": 207\n\"breath\": 226\n\"royal\": 201\n\"WARWICK\": 243\n\"break\": 236\n\"return\": 222\n\"worth\": 200\n\"seek\": 210\n\"ROSALIND\": 217\n\"ill\": 219\n\"gave\": 219\n\"Comment\": 4\n\"Highness\": 185\n\"One\": 197\n\"charge\": 195\n\"joy\": 188\n\"loves\": 194\n\"ear\": 189\n\"brought\": 186\n\"age\": 197\n\"sit\": 185\n\"JOHN\": 197\n\"Kent\": 190\n\"Farewell\": 192\n\"pity\": 198\n\"worthy\": 190\n\"purpose\": 198\n\"wear\": 190\n\"Edward\": 193\n\"DROMIO\": 187\n\"dare\": 194\n\"late\": 189\n\"sister\": 192\n\"between\": 193\n\"Like\": 187\n\"law\": 189\n\"days\": 197\n\"each\": 191\n\"sight\": 196\n\"Her\": 187\n\"Majesty\": 198\n\"half\": 193\n\"Most\": 192\n\"Say\": 198\n\"sea\": 197\n\"lives\": 186\n\"Brainford\": 6\n\"cold\": 184\n\"happy\": 184\n\"years\": 184\n\"cry\": 184\n\"proud\": 184\n\"uncle\": 184\n\"Tell\": 184\n\"eke\": 7\n\"soldiers\": 160\n\"sorrow\": 180\n\"Gloucester\": 171\n\"fault\": 167\n\"sons\": 160\n\"Warwick\": 180\n\"SHALLOW\": 163\n\"EDWARD\": 178\n\"PROTEUS\": 163\n\"ho\": 170\n\"comfort\": 173\n\"known\": 182\n\"holy\": 182\n\"Yes\": 177\n\"BUCKINGHAM\": 178\n\"hearts\": 173\n\"praise\": 177\n\"free\": 174\n\"sake\": 172\n\"while\": 174\n\"heavy\": 163\n\"foot\": 166\n\"given\": 183\n\"PRINCE\": 178\n\"side\": 172\n\"warrant\": 175\n\"Richard\": 182\n\"TOBY\": 170\n\"further\": 181\n\"pass\": 179\n\"Thus\": 179\n\"need\": 179\n\"work\": 178\n\"run\": 171\n\"CITIZEN\": 179\n\"SUFFOLK\": 176\n\"MENENIUS\": 181\n\"virtue\": 177\n\"TITUS\": 174\n\"em\": 169\n\"CORIOLANUS\": 177\n\"LADY\": 177\n\"bound\": 165\n\"patience\": 160\n\"hell\": 162\n\"goes\": 162\n\"PANDARUS\": 171\n\"field\": 183\n\"BEROWNE\": 170\n\"Make\": 164\n\"II\": 168\n\"hang\": 180\n\"knave\": 171\n\"Brutus\": 180\n\"grave\": 175\n\"ground\": 162\n\"DESDEMONA\": 167\n\"wind\": 174\n\"CRESSIDA\": 166\n\"TROILUS\": 160\n\"gracious\": 182\n\"VALENTINE\": 167\n\"general\": 183\n\"strong\": 179\n\"queen\": 183\n\"thyself\": 181\n\"read\": 175\n\"CAESAR\": 169\n\"air\": 183\n\"Alas\": 179\n\"marry\": 179\n\"ask\": 171\n\"Lady\": 182\n\"knew\": 161\n\"hate\": 174\n\"certain\": 165\n\"arm\": 164\n\"Rom\": 163\n\"pleasure\": 177\n\"merry\": 164\n\"draw\": 175\n\"sound\": 172\n\"doubt\": 161\n\"mercy\": 163\n\"Ah\": 167\n\"maid\": 175\n\"weep\": 163\n\"serve\": 183\n\"PAROLLES\": 163\n\"ANTONIO\": 176\n\"HELENA\": 169\n\"French\": 170\n\"PETRUCHIO\": 178\n\"others\": 182\n\"farewell\": 161\n\"money\": 175\n\"believe\": 182\n\"country\": 178\n\"Marry\": 183\n\"Away\": 176\n\"enemy\": 165\n\"Madam\": 182\n\"enquire\": 7\n\"women\": 159\n\"music\": 159\n\"next\": 159\n\"lov\": 159\n\"Since\": 159\n\"English\": 159\n\"THIRD\": 159\n\"sick\": 159\n\"holiness\": 6\n\"soldier\": 144\n\"rich\": 156\n\"didst\": 145\n\"fit\": 152\n\"themselves\": 157\n\"dog\": 144\n\"born\": 157\n\"duty\": 149\n\"III\": 145\n\"change\": 147\n\"cut\": 155\n\"sin\": 153\n\"voice\": 153\n\"common\": 150\n\"mark\": 146\n\"remember\": 148\n\"wise\": 157\n\"Mistress\": 146\n\"question\": 148\n\"person\": 146\n\"sovereign\": 147\n\"Should\": 152\n\"haste\": 148\n\"worse\": 148\n\"Can\": 158\n\"something\": 149\n\"neither\": 153\n\"command\": 158\n\"Romeo\": 154\n\"en\": 146\n\"EPHESUS\": 155\n\"servant\": 144\n\"trust\": 155\n\"PORTIA\": 153\n\"black\": 144\n\"to-morrow\": 151\n\"palace\": 151\n\"Hector\": 150\n\"drink\": 148\n\"LUCIUS\": 157\n\"brave\": 146\n\"Had\": 153\n\"took\": 153\n\"gentlemen\": 148\n\"canst\": 146\n\"straight\": 144\n\"hard\": 156\n\"over\": 148\n\"door\": 144\n\"save\": 154\n\"Pedro\": 155\n\"sad\": 151\n\"ears\": 153\n\"ISABELLA\": 153\n\"deed\": 146\n\"Within\": 154\n\"course\": 155\n\"n\": 157\n\"hot\": 147\n\"Fal\": 151\n\"touch\": 154\n\"Fame\": 4\n\"withal\": 133\n\"VIOLA\": 137\n\"Their\": 142\n\"OLIVIA\": 141\n\"valiant\": 142\n\"appear\": 133\n\"coming\": 140\n\"city\": 137\n\"twenty\": 138\n\"ORLANDO\": 138\n\"liege\": 137\n\"Out\": 139\n\"Must\": 139\n\"base\": 143\n\"London\": 136\n\"Peace\": 142\n\"LEONTES\": 139\n\"presently\": 136\n\"self\": 137\n\"Bene\": 133\n\"already\": 136\n\"spoke\": 137\n\"eat\": 139\n\"Cassio\": 142\n\"open\": 138\n\"justice\": 140\n\"oath\": 142\n\"wars\": 133\n\"ANGELO\": 136\n\"needs\": 142\n\"CASSIUS\": 140\n\"tender\": 139\n\"SICINIUS\": 135\n\"note\": 138\n\"content\": 140\n\"ENOBARBUS\": 140\n\"point\": 140\n\"Sweet\": 143\n\"hours\": 135\n\"suit\": 139\n\"PISTOL\": 143\n\"Against\": 140\n\"almost\": 139\n\"IMOGEN\": 140\n\"past\": 134\n\"prithee\": 136\n\"Such\": 139\n\"grow\": 134\n\"married\": 142\n\"flesh\": 134\n\"report\": 142\n\"soon\": 136\n\"way-\": 4\n\"CASSIO\": 111\n\"behold\": 116\n\"woe\": 115\n\"thanks\": 122\n\"bold\": 132\n\"children\": 119\n\"fast\": 126\n\"Stand\": 120\n\"COUNTESS\": 111\n\"water\": 132\n\"Hamlet\": 113\n\"four\": 132\n\"Nurse\": 119\n\"PRINCESS\": 113\n\"LUCIO\": 117\n\"DUCHESS\": 118\n\"BARDOLPH\": 123\n\"SEBASTIAN\": 120\n\"PROSPERO\": 132\n\"just\": 124\n\"walk\": 130\n\"Harry\": 114\n\"FRANCE\": 115\n\"traitor\": 131\n\"lips\": 132\n\"having\": 121\n\"often\": 118\n\"Love\": 122\n\"action\": 111\n\"prince\": 117\n\"SOLDIER\": 119\n\"strike\": 116\n\"letters\": 121\n\"CLARENCE\": 113\n\"met\": 131\n\"glad\": 121\n\"IV\": 121\n\"enter\": 117\n\"become\": 131\n\"fell\": 119\n\"ELIZABETH\": 113\n\"deep\": 131\n\"banish\": 116\n\"act\": 117\n\"speed\": 111\n\"rage\": 119\n\"ha\": 120\n\"wouldst\": 112\n\"conscience\": 117\n\"deliver\": 116\n\"moon\": 114\n\"heavens\": 128\n\"whole\": 119\n\"Never\": 113\n\"pay\": 132\n\"Being\": 115\n\"lordship\": 124\n\"SPEED\": 125\n\"truly\": 121\n\"beat\": 117\n\"bad\": 120\n\"confess\": 131\n\"Friar\": 114\n\"counsel\": 129\n\"CELIA\": 123\n\"DEMETRIUS\": 117\n\"office\": 126\n\"ARMADO\": 112\n\"sing\": 126\n\"behind\": 112\n\"either\": 115\n\"enemies\": 111\n\"to-night\": 130\n\"hair\": 114\n\"to-day\": 129\n\"knight\": 119\n\"BOLINGBROKE\": 113\n\"deny\": 124\n\"sport\": 117\n\"slain\": 123\n\"Claudio\": 132\n\"slave\": 124\n\"Call\": 122\n\"watch\": 131\n\"mouth\": 126\n\"white\": 122\n\"strength\": 119\n\"above\": 123\n\"MARGARET\": 125\n\"bosom\": 129\n\"sense\": 120\n\"pluck\": 115\n\"Glou\": 118\n\"speaks\": 124\n\"lead\": 123\n\"Hero\": 125\n\"dream\": 126\n\"loss\": 116\n\"JULIA\": 119\n\"spirits\": 119\n\"THE\": 117\n\"Doth\": 123\n\"learn\": 113\n\"deeds\": 118\n\"town\": 124\n\"revenge\": 129\n\"hundred\": 111\n\"wonder\": 113\n\"battle\": 115\n\"ten\": 132\n\"Yea\": 132\n\"Jul\": 117\n\"yield\": 128\n\"oft\": 132\n\"mock\": 115\n\"vile\": 112\n\"morning\": 129\n\"Leon\": 120\n\"POMPEY\": 119\n\"BASTARD\": 129\n\"LAFEU\": 113\n\"living\": 118\n\"got\": 114\n\"See\": 131\n\"want\": 131\n\"Beat\": 117\n\"favour\": 119\n\"ready\": 125\n\"aside\": 128\n\"stands\": 132\n\"loving\": 114\n\"gives\": 111\n\"Claud\": 125\n\"speech\": 125\n\"BERTRAM\": 126\n\"sworn\": 130\n\"pale\": 118\n\"God-a-mercy\": 6\n\"pride\": 106\n\"Hot\": 107\n\"MARIA\": 106\n\"Signior\": 110\n\"Ha\": 110\n\"plain\": 108\n\"tale\": 107\n\"morrow\": 110\n\"EMILIA\": 110\n\"ANNE\": 109\n\"heads\": 107\n\"APEMANTUS\": 110\n\"seems\": 106\n\"along\": 108\n\"fortunes\": 109\n\"ourselves\": 107\n\"CYMBELINE\": 107\n\"pretty\": 108\n\"Hor\": 109\n\"form\": 106\n\"case\": 107\n\"win\": 109\n\"laugh\": 109\n\"souls\": 107\n\"witness\": 108\n\"chamber\": 107\n\"marriage\": 108\n\"parts\": 107\n\"Scene\": 110\n\"issue\": 110\n\"EVANS\": 106\n\"lack\": 110\n\"noise\": 106\n\"mighty\": 107\n\"fashion\": 107\n\"infectious\": 6\n\"bears\": 101\n\"write\": 105\n\"longer\": 105\n\"subject\": 103\n\"paper\": 102\n\"Kate\": 105\n\"COSTARD\": 101\n\"TRANIO\": 105\n\"Saint\": 101\n\"worship\": 104\n\"chance\": 102\n\"Hark\": 103\n\"offer\": 103\n\"jest\": 104\n\"fetch\": 103\n\"woo\": 103\n\"Mark\": 102\n\"worst\": 103\n\"five\": 103\n\"KATHERINA\": 102\n\"attend\": 103\n\"passion\": 105\n\"twas\": 103\n\"kings\": 105\n\"Lucius\": 104\n\"scorn\": 104\n\"begin\": 102\n\"suffer\": 101\n\"guard\": 105\n\"e\": 104\n\"ladies\": 103\n\"Because\": 105\n\"heir\": 105\n\"Timon\": 102\n\"Roman\": 105\n\"force\": 102\n\"gates\": 101\n\"presence\": 103\n\"feel\": 105\n\"hide\": 105\n\"entreat\": 105\n\"Page\": 103\n\"kingdom\": 101\n\"de\": 101\n\"defeated\": 4\n\"judgment\": 98\n\"Clarence\": 98\n\"anything\": 99\n\"died\": 99\n\"Edg\": 98\n\"least\": 100\n\"HASTINGS\": 98\n\"weak\": 99\n\"valour\": 99\n\"excellent\": 100\n\"respect\": 99\n\"grant\": 98\n\"lion\": 98\n\"fools\": 98\n\"second\": 99\n\"honourable\": 98\n\"THERSITES\": 99\n\"awhile\": 100\n\"Fortune\": 99\n\"going\": 99\n\"KATHARINE\": 98\n\"promise\": 99\n\"presumption\": 6\n\"humour\": 88\n\"went\": 94\n\"V\": 97\n\"ALL\": 97\n\"Welcome\": 92\n\"teach\": 91\n\"CLOTEN\": 90\n\"POSTHUMUS\": 97\n\"curse\": 95\n\"quarrel\": 95\n\"patient\": 88\n\"IACHIMO\": 89\n\"BOYET\": 89\n\"WOLSEY\": 93\n\"close\": 94\n\"throw\": 90\n\"wisdom\": 91\n\"quick\": 94\n\"move\": 96\n\"twere\": 92\n\"danger\": 97\n\"ESCALUS\": 88\n\"feast\": 95\n\"plague\": 88\n\"Troy\": 93\n\"title\": 88\n\"prison\": 88\n\"taken\": 89\n\"vow\": 89\n\"ass\": 90\n\"ACHILLES\": 88\n\"low\": 95\n\"army\": 88\n\"poison\": 89\n\"health\": 89\n\"tent\": 92\n\"virtuous\": 91\n\"PROVOST\": 92\n\"Troilus\": 89\n\"writ\": 96\n\"fine\": 90\n\"bless\": 97\n\"Under\": 88\n\"Nothing\": 94\n\"Mine\": 94\n\"Jove\": 88\n\"Talbot\": 91\n\"herself\": 91\n\"buy\": 96\n\"Think\": 88\n\"fearful\": 89\n\"order\": 89\n\"foolish\": 93\n\"Th\": 97\n\"Whom\": 90\n\"harm\": 94\n\"year\": 93\n\"Iago\": 89\n\"match\": 96\n\"forget\": 90\n\"AGUECHEEK\": 91\n\"Earl\": 96\n\"Flourish\": 95\n\"pains\": 91\n\"won\": 95\n\"anon\": 92\n\"Falstaff\": 93\n\"Dost\": 93\n\"Great\": 90\n\"labour\": 91\n\"ta\": 92\n\"short\": 95\n\"MALVOLIO\": 97\n\"Hear\": 90\n\"shows\": 94\n\"quickly\": 93\n\"shake\": 90\n\"MOTH\": 95\n\"Cassius\": 89\n\"HORTENSIO\": 88\n\"Emperor\": 90\n\"Pompey\": 90\n\"understand\": 97\n\"book\": 88\n\"dangerous\": 96\n\"NORTHUMBERLAND\": 96\n\"hurt\": 89\n\"breast\": 94\n\"perceive\": 91\n\"SALISBURY\": 96\n\"mortal\": 94\n\"ULYSSES\": 94\n\"Paris\": 97\n\"choose\": 97\n\"Unless\": 88\n\"kept\": 94\n\"Know\": 91\n\"troth\": 91\n\"beg\": 88\n\"Stay\": 88\n\"SHYLOCK\": 90\n\"toward\": 94\n\"Faith\": 91\n\"LUCENTIO\": 90\n\"Into\": 88\n\"offence\": 93\n\"takes\": 89\n\"faults\": 97\n\"angry\": 92\n\"beard\": 95\n\"Osric\": 7\n\"masters\": 87\n\"Hold\": 87\n\"ADRIANA\": 87\n\"r\": 87\n\"laid\": 87\n\"sorry\": 87\n\"measure\": 87\n\"Both\": 87\n\"fill\": 87\n\"shape\": 87\n\"consent\": 87\n\"ballads\": 4\n\"Fool\": 86\n\"cast\": 86\n\"Fie\": 86\n\"honesty\": 86\n\"First\": 86\n\"seal\": 86\n\"dinner\": 86\n\"Cardinal\": 86\n\"SENATOR\": 86\n\"golden\": 86\n\"Pol\": 86\n\"piece\": 86\n\"soothe\": 4\n\"BAPTISTA\": 85\n\"QUICKLY\": 85\n\"BASSANIO\": 85\n\"1\": 85\n\"soft\": 85\n\"calls\": 85\n\"gainst\": 85\n\"try\": 85\n\"alive\": 85\n\"summer\": 85\n\"TOUCHSTONE\": 85\n\"COMINIUS\": 85\n\"drum\": 85\n\"forward\": 85\n\"Corrupt\": 4\n\"FLORIZEL\": 56\n\"AUTOLYCUS\": 73\n\"stain\": 58\n\"Alarum\": 61\n\"bestow\": 60\n\"POLIXENES\": 68\n\"mayst\": 65\n\"ry\": 60\n\"priest\": 58\n\"opinion\": 81\n\"CAMILLO\": 83\n\"proper\": 61\n\"dry\": 60\n\"wast\": 69\n\"nose\": 63\n\"wound\": 70\n\"Without\": 81\n\"folly\": 77\n\"fare\": 56\n\"possible\": 57\n\"scarce\": 65\n\"SILVIA\": 73\n\"offend\": 57\n\"street\": 79\n\"perform\": 70\n\"LAUNCE\": 75\n\"wench\": 57\n\"cross\": 84\n\"rogue\": 78\n\"led\": 60\n\"rude\": 68\n\"ransom\": 58\n\"gift\": 64\n\"Proteus\": 58\n\"Silvia\": 56\n\"Christian\": 69\n\"silver\": 60\n\"throne\": 67\n\"flow\": 64\n\"FABIAN\": 67\n\"Please\": 59\n\"boys\": 75\n\"ones\": 57\n\"clock\": 79\n\"Prithee\": 80\n\"unless\": 64\n\"legs\": 70\n\"meat\": 69\n\"rough\": 63\n\"friar\": 61\n\"wives\": 58\n\"ancient\": 72\n\"AJAX\": 66\n\"camp\": 74\n\"AGAMEMNON\": 68\n\"2\": 77\n\"AENEAS\": 57\n\"lawful\": 59\n\"weary\": 70\n\"monstrous\": 64\n\"courage\": 56\n\"DIOMEDES\": 84\n\"CHARMIAN\": 79\n\"thief\": 67\n\"TAMORA\": 62\n\"AARON\": 72\n\"march\": 81\n\"birth\": 84\n\"Attendants\": 63\n\"train\": 79\n\"pow\": 65\n\"majesty\": 67\n\"wine\": 81\n\"remain\": 58\n\"hearing\": 83\n\"borne\": 75\n\"spite\": 59\n\"Fare\": 80\n\"heat\": 61\n\"steal\": 78\n\"ways\": 66\n\"sudden\": 78\n\"occasion\": 72\n\"Lest\": 76\n\"nay\": 61\n\"kneel\": 62\n\"green\": 78\n\"swords\": 67\n\"fellows\": 67\n\"sort\": 67\n\"safe\": 75\n\"feet\": 57\n\"SATURNINUS\": 59\n\"natural\": 57\n\"Captain\": 80\n\"dance\": 67\n\"lover\": 64\n\"abroad\": 59\n\"wounds\": 79\n\"among\": 69\n\"rs\": 59\n\"doors\": 61\n\"ARIEL\": 76\n\"While\": 70\n\"Wherefore\": 65\n\"dust\": 59\n\"Time\": 70\n\"argument\": 66\n\"bones\": 75\n\"vain\": 76\n\"MIRANDA\": 60\n\"knee\": 63\n\"aught\": 75\n\"affection\": 69\n\"Save\": 57\n\"CALIBAN\": 61\n\"brothers\": 72\n\"crowns\": 57\n\"GONZALO\": 59\n\"Indeed\": 80\n\"Pardon\": 67\n\"messenger\": 57\n\"choice\": 69\n\"depart\": 61\n\"ours\": 83\n\"shouldst\": 72\n\"trumpet\": 77\n\"pain\": 66\n\"manners\": 69\n\"fie\": 67\n\"GRUMIO\": 73\n\"purse\": 80\n\"BIONDELLO\": 61\n\"stars\": 67\n\"Bid\": 60\n\"Put\": 58\n\"stood\": 82\n\"leisure\": 63\n\"blows\": 67\n\"GREMIO\": 69\n\"William\": 78\n\"yea\": 56\n\"hadst\": 80\n\"methinks\": 83\n\"blame\": 81\n\"fat\": 64\n\"Sirrah\": 71\n\"True\": 59\n\"taste\": 74\n\"forgive\": 59\n\"evil\": 61\n\"wicked\": 61\n\"greater\": 80\n\"round\": 71\n\"damn\": 76\n\"sirrah\": 75\n\"Mer\": 62\n\"brief\": 82\n\"foes\": 70\n\"stol\": 58\n\"wrongs\": 73\n\"liberty\": 71\n\"Athens\": 70\n\"cried\": 60\n\"tear\": 73\n\"defend\": 65\n\"quoth\": 61\n\"follows\": 66\n\"rain\": 60\n\"Unto\": 72\n\"obey\": 76\n\"Ben\": 64\n\"princes\": 69\n\"knowledge\": 75\n\"thrive\": 56\n\"grows\": 72\n\"seat\": 59\n\"fought\": 65\n\"possess\": 59\n\"PAULINA\": 69\n\"Get\": 73\n\"Tybalt\": 65\n\"rose\": 57\n\"secret\": 64\n\"safety\": 73\n\"Jack\": 76\n\"request\": 64\n\"greatness\": 75\n\"Besides\": 59\n\"yourselves\": 73\n\"warlike\": 57\n\"because\": 81\n\"wherefore\": 75\n\"tyrant\": 57\n\"gain\": 62\n\"Ajax\": 60\n\"Twas\": 58\n\"paid\": 62\n\"blessed\": 71\n\"Heaven\": 77\n\"citizens\": 57\n\"study\": 59\n\"princely\": 74\n\"liv\": 75\n\"stuff\": 63\n\"desires\": 68\n\"dark\": 76\n\"stir\": 75\n\"keeps\": 68\n\"clear\": 63\n\"drawn\": 79\n\"ay\": 77\n\"BIANCA\": 66\n\"RODERIGO\": 60\n\"Lords\": 56\n\"JAQUES\": 72\n\"LORDS\": 81\n\"CHARLES\": 69\n\"Count\": 73\n\"dull\": 80\n\"shepherd\": 67\n\"memory\": 58\n\"twice\": 60\n\"thither\": 78\n\"Desdemona\": 61\n\"Othello\": 59\n\"bright\": 66\n\"trial\": 57\n\"endure\": 73\n\"Charles\": 56\n\"asleep\": 58\n\"oaths\": 68\n\"bearing\": 60\n\"rise\": 65\n\"treason\": 84\n\"sometime\": 59\n\"monster\": 68\n\"large\": 68\n\"remembrance\": 61\n\"Am\": 59\n\"discourse\": 57\n\"chain\": 66\n\"judge\": 83\n\"niece\": 61\n\"feed\": 75\n\"terms\": 73\n\"smile\": 69\n\"precious\": 73\n\"Leonato\": 62\n\"powers\": 57\n\"swift\": 63\n\"motion\": 79\n\"Benedick\": 69\n\"Poor\": 77\n\"fiend\": 63\n\"drown\": 82\n\"Two\": 64\n\"melancholy\": 69\n\"loud\": 64\n\"effect\": 67\n\"dispatch\": 76\n\"broke\": 83\n\"deserve\": 58\n\"breathe\": 59\n\"forest\": 60\n\"sigh\": 59\n\"HERMIA\": 58\n\"Only\": 61\n\"tune\": 60\n\"hit\": 58\n\"madness\": 67\n\"manner\": 80\n\"BOTTOM\": 57\n\"seven\": 62\n\"song\": 59\n\"LYSANDER\": 62\n\"fail\": 65\n\"several\": 79\n\"THESEUS\": 56\n\"wealth\": 72\n\"gate\": 60\n\"Wilt\": 76\n\"bond\": 72\n\"walls\": 83\n\"wall\": 62\n\"Ford\": 68\n\"fain\": 61\n\"burn\": 77\n\"neck\": 70\n\"murder\": 57\n\"prisoner\": 82\n\"sooner\": 60\n\"wood\": 56\n\"claim\": 64\n\"forbid\": 70\n\"Another\": 84\n\"Hence\": 56\n\"quite\": 72\n\"leaves\": 69\n\"Angelo\": 77\n\"blow\": 76\n\"falls\": 66\n\"receive\": 78\n\"malice\": 68\n\"wretched\": 65\n\"drunk\": 67\n\"Hast\": 58\n\"Bring\": 74\n\"HOST\": 75\n\"CAIUS\": 80\n\"foe\": 62\n\"MARCIUS\": 60\n\"winter\": 64\n\"AUFIDIUS\": 60\n\"Art\": 80\n\"vows\": 65\n\"VOLUMNIA\": 67\n\"cruel\": 69\n\"SLENDER\": 70\n\"whence\": 58\n\"thence\": 84\n\"Marcius\": 83\n\"wert\": 83\n\"creature\": 69\n\"catch\": 71\n\"Titus\": 56\n\"host\": 65\n\"bitter\": 72\n\"guilty\": 68\n\"courtesy\": 61\n\"proof\": 74\n\"Made\": 67\n\"easy\": 62\n\"honours\": 67\n\"reasons\": 64\n\"prayers\": 84\n\"STEPHANO\": 73\n\"rascal\": 57\n\"Fair\": 62\n\"Antonio\": 84\n\"Still\": 63\n\"Those\": 80\n\"BELARIUS\": 77\n\"GUIDERIUS\": 73\n\"trumpets\": 64\n\"ARVIRAGUS\": 61\n\"doing\": 61\n\"trouble\": 72\n\"Alack\": 56\n\"fresh\": 83\n\"wild\": 83\n\"beast\": 70\n\"LORENZO\": 57\n\"PISANIO\": 78\n\"GRATIANO\": 79\n\"wretch\": 59\n\"widow\": 67\n\"colours\": 58\n\"knock\": 64\n\"fury\": 62\n\"colour\": 76\n\"anger\": 58\n\"third\": 71\n\"pleas\": 66\n\"nurse\": 70\n\"sharp\": 62\n\"Reads\": 72\n\"Could\": 70\n\"cheer\": 77\n\"Juliet\": 70\n\"wanton\": 59\n\"betray\": 56\n\"finger\": 62\n\"Laer\": 62\n\"Oph\": 58\n\"horses\": 57\n\"Wherein\": 65\n\"Valentine\": 66\n\"drop\": 72\n\"bow\": 58\n\"join\": 77\n\"Lancaster\": 75\n\"lend\": 69\n\"Percy\": 64\n\"Northumberland\": 56\n\"Edmund\": 69\n\"Poins\": 70\n\"Bardolph\": 70\n\"spend\": 67\n\"struck\": 72\n\"dies\": 71\n\"Moor\": 82\n\"able\": 56\n\"Bolingbroke\": 65\n\"holds\": 73\n\"yonder\": 59\n\"captain\": 59\n\"story\": 66\n\"single\": 57\n\"Jew\": 78\n\"silence\": 61\n\"instant\": 61\n\"Macbeth\": 83\n\"cheeks\": 70\n\"table\": 56\n\"wherein\": 66\n\"goodly\": 73\n\"humble\": 63\n\"whereof\": 59\n\"fame\": 66\n\"WESTMORELAND\": 56\n\"CHIEF\": 64\n\"aid\": 57\n\"MACDUFF\": 80\n\"JUSTICE\": 70\n\"clouds\": 57\n\"Helen\": 62\n\"cheek\": 75\n\"stop\": 84\n\"double\": 73\n\"HOSTESS\": 75\n\"brain\": 82\n\"HECTOR\": 71\n\"Venice\": 64\n\"dreadful\": 59\n\"spent\": 67\n\"cunning\": 72\n\"always\": 57\n\"Hang\": 57\n\"due\": 71\n\"food\": 62\n\"Too\": 60\n\"ROSALINE\": 74\n\"coward\": 84\n\"approach\": 63\n\"carry\": 80\n\"HOLOFERNES\": 60\n\"EXETER\": 72\n\"FLUELLEN\": 77\n\"stone\": 58\n\"brow\": 69\n\"DUMAIN\": 62\n\"LEWIS\": 57\n\"Dauphin\": 74\n\"few\": 59\n\"lest\": 70\n\"glory\": 83\n\"fled\": 82\n\"Alb\": 58\n\"owe\": 71\n\"Either\": 56\n\"pure\": 68\n\"room\": 64\n\"Reg\": 73\n\"After\": 81\n\"glass\": 57\n\"Edm\": 79\n\"commend\": 57\n\"Suffolk\": 82\n\"forgot\": 83\n\"tongues\": 73\n\"Ere\": 77\n\"To-morrow\": 60\n\"former\": 63\n\"wash\": 69\n\"bastard\": 66\n\"CARDINAL\": 66\n\"quiet\": 73\n\"SOMERSET\": 79\n\"excuse\": 72\n\"TALBOT\": 81\n\"Tower\": 65\n\"advantage\": 70\n\"simple\": 67\n\"SHEPHERD\": 57\n\"sum\": 56\n\"PUCELLE\": 66\n\"forsworn\": 60\n\"jewel\": 57\n\"beggar\": 70\n\"Somerset\": 68\n\"view\": 80\n\"steel\": 67\n\"private\": 66\n\"Margaret\": 83\n\"fears\": 72\n\"CLIFFORD\": 75\n\"shadow\": 71\n\"CADE\": 70\n\"adieu\": 61\n\"embrace\": 61\n\"affairs\": 65\n\"Buckingham\": 78\n\"Anne\": 67\n\"MURDERER\": 71\n\"thinks\": 57\n\"god\": 73\n\"Clifford\": 64\n\"Achilles\": 78\n\"Methinks\": 69\n\"blind\": 77\n\"NORFOLK\": 82\n\"remedy\": 58\n\"heels\": 72\n\"whilst\": 59\n\"awake\": 62\n\"idle\": 65\n\"broken\": 59\n\"held\": 79\n\"towards\": 58\n\"subjects\": 58\n\"FLAVIUS\": 57\n\"wits\": 79\n\"wait\": 56\n\"HUBERT\": 62\n\"MARCUS\": 84\n\"small\": 82\n\"smoking\": 4\n\"brains\": 45\n\"HERMIONE\": 45\n\"ride\": 51\n\"lock\": 45\n\"swore\": 50\n\"commission\": 48\n\"begins\": 53\n\"ends\": 46\n\"Show\": 50\n\"chide\": 45\n\"repent\": 52\n\"window\": 47\n\"LUCETTA\": 54\n\"PHILIP\": 52\n\"hereafter\": 45\n\"Has\": 45\n\"estate\": 48\n\"Believe\": 55\n\"condition\": 55\n\"innocent\": 49\n\"list\": 53\n\"mere\": 55\n\"limbs\": 47\n\"THURIO\": 48\n\"meant\": 50\n\"main\": 47\n\"receiv\": 54\n\"Thanks\": 49\n\"protest\": 50\n\"post\": 49\n\"promis\": 52\n\"ignorant\": 47\n\"CHAMBERLAIN\": 53\n\"Very\": 55\n\"spake\": 45\n\"hers\": 49\n\"treasure\": 52\n\"deadly\": 48\n\"PATROCLUS\": 47\n\"NESTOR\": 49\n\"Truly\": 48\n\"party\": 48\n\"serv\": 46\n\"AGRIPPA\": 46\n\"happiness\": 55\n\"civil\": 49\n\"Egypt\": 48\n\"aim\": 45\n\"Myself\": 54\n\"Montague\": 53\n\"proclaim\": 50\n\"wake\": 48\n\"heavenly\": 53\n\"streets\": 50\n\"CLAUDIO\": 48\n\"sacred\": 46\n\"CHIRON\": 45\n\"names\": 48\n\"grown\": 55\n\"spare\": 48\n\"mirth\": 50\n\"wings\": 54\n\"delight\": 55\n\"Doctor\": 51\n\"Help\": 49\n\"kindness\": 49\n\"contrary\": 47\n\"tidings\": 51\n\"meaning\": 52\n\"Andronicus\": 47\n\"WITCH\": 50\n\"victory\": 46\n\"dearest\": 55\n\"bought\": 50\n\"knife\": 54\n\"whether\": 55\n\"cost\": 45\n\"tide\": 47\n\"Leave\": 47\n\"jealous\": 48\n\"early\": 46\n\"attendants\": 48\n\"Lo\": 54\n\"Whiles\": 51\n\"ALCIBIADES\": 46\n\"Once\": 45\n\"deal\": 52\n\"intend\": 51\n\"you-\": 45\n\"taught\": 48\n\"intent\": 48\n\"encounter\": 51\n\"loved\": 47\n\"TRINCULO\": 46\n\"lovers\": 55\n\"prepare\": 48\n\"bare\": 54\n\"ALONSO\": 48\n\"nine\": 52\n\"supper\": 52\n\"Follow\": 55\n\"throat\": 49\n\"absence\": 55\n\"demand\": 53\n\"gown\": 50\n\"entertain\": 55\n\"Caius\": 52\n\"Marcus\": 54\n\"horns\": 50\n\"quality\": 53\n\"Sound\": 46\n\"Romans\": 54\n\"modesty\": 50\n\"six\": 50\n\"Between\": 46\n\"employ\": 45\n\"thrice\": 54\n\"thunder\": 50\n\"meeting\": 48\n\"Cap\": 55\n\"below\": 50\n\"merit\": 51\n\"constant\": 47\n\"blest\": 49\n\"breed\": 45\n\"ship\": 48\n\"doom\": 53\n\"freely\": 51\n\"consider\": 45\n\"Set\": 46\n\"ruin\": 46\n\"following\": 46\n\"nought\": 54\n\"count\": 47\n\"authority\": 51\n\"shore\": 48\n\"Capulet\": 45\n\"shut\": 51\n\"empty\": 48\n\"storm\": 50\n\"satisfied\": 47\n\"challenge\": 47\n\"followers\": 47\n\"cap\": 47\n\"la\": 50\n\"CATESBY\": 49\n\"rule\": 48\n\"girl\": 51\n\"Keep\": 55\n\"blush\": 52\n\"loose\": 46\n\"fancy\": 52\n\"trick\": 51\n\"wrath\": 54\n\"Makes\": 45\n\"spoken\": 51\n\"particular\": 53\n\"undone\": 52\n\"shed\": 46\n\"top\": 51\n\"maiden\": 47\n\"durst\": 45\n\"servants\": 55\n\"dishonour\": 48\n\"Protector\": 53\n\"painted\": 51\n\"counterfeit\": 53\n\"warm\": 49\n\"season\": 45\n\"traitors\": 53\n\"virtues\": 49\n\"mend\": 53\n\"AUMERLE\": 51\n\"obedience\": 45\n\"condemn\": 45\n\"Bianca\": 51\n\"outward\": 49\n\"visit\": 50\n\"Roderigo\": 47\n\"skill\": 50\n\"guess\": 50\n\"Salisbury\": 49\n\"number\": 50\n\"neighbour\": 50\n\"rank\": 52\n\"smell\": 50\n\"DIANA\": 52\n\"gentlewoman\": 48\n\"faces\": 53\n\"slander\": 48\n\"Gon\": 53\n\"FRENCH\": 54\n\"OLIVER\": 49\n\"flies\": 52\n\"WILLIAM\": 46\n\"vice\": 51\n\"winds\": 48\n\"Cupid\": 52\n\"lands\": 53\n\"Dog\": 53\n\"Rosalind\": 47\n\"flowers\": 46\n\"weeping\": 52\n\"desperate\": 49\n\"envy\": 49\n\"slow\": 50\n\"Beatrice\": 55\n\"Pyramus\": 45\n\"saying\": 50\n\"angel\": 52\n\"tree\": 52\n\"denied\": 52\n\"Demetrius\": 49\n\"liest\": 45\n\"Bear\": 46\n\"church\": 52\n\"Dear\": 45\n\"frown\": 50\n\"QUINCE\": 47\n\"sides\": 45\n\"credit\": 50\n\"buried\": 53\n\"Hermia\": 46\n\"plot\": 51\n\"brings\": 51\n\"Shallow\": 51\n\"PUCK\": 50\n\"teeth\": 54\n\"CONSTABLE\": 46\n\"knees\": 51\n\"sighs\": 50\n\"hollow\": 46\n\"wide\": 53\n\"FERDINAND\": 45\n\"LONGAVILLE\": 49\n\"vengeance\": 47\n\"suddenly\": 48\n\"undertake\": 45\n\"bids\": 53\n\"Death\": 55\n\"flight\": 51\n\"flood\": 46\n\"seeming\": 53\n\"GREY\": 48\n\"degree\": 45\n\"LUCIANA\": 55\n\"kinsman\": 45\n\"Each\": 47\n\"reign\": 45\n\"maintain\": 48\n\"becomes\": 50\n\"pound\": 51\n\"ducats\": 50\n\"weigh\": 49\n\"Fear\": 52\n\"hopes\": 54\n\"thrust\": 47\n\"goodness\": 54\n\"naked\": 49\n\"reverend\": 54\n\"sickness\": 50\n\"execution\": 48\n\"triumph\": 46\n\"Whilst\": 55\n\"enjoy\": 49\n\"twixt\": 55\n\"womb\": 53\n\"greatest\": 51\n\"Humphrey\": 51\n\"Might\": 47\n\"minds\": 53\n\"cup\": 45\n\"Corn\": 55\n\"prize\": 46\n\"Norfolk\": 48\n\"humbly\": 53\n\"besides\": 48\n\"George\": 49\n\"March\": 48\n\"voices\": 55\n\"sign\": 52\n\"fond\": 53\n\"None\": 54\n\"public\": 53\n\"tonight\": 47\n\"proceed\": 47\n\"cure\": 53\n\"assure\": 46\n\"ease\": 54\n\"divine\": 48\n\"NERISSA\": 48\n\"rare\": 54\n\"sack\": 55\n\"drops\": 49\n\"me-\": 51\n\"gallant\": 54\n\"daughters\": 53\n\"Hastings\": 51\n\"BOY\": 45\n\"charity\": 53\n\"officer\": 52\n\"frame\": 45\n\"Britain\": 53\n\"Three\": 53\n\"cries\": 51\n\"LAUNCELOT\": 54\n\"appears\": 48\n\"wont\": 47\n\"sometimes\": 48\n\"despair\": 46\n\"tomb\": 54\n\"therein\": 47\n\"Wales\": 51\n\"sits\": 46\n\"alas\": 45\n\"burden\": 45\n\"disgrace\": 46\n\"turns\": 47\n\"spring\": 53\n\"heed\": 53\n\"learned\": 49\n\"Horatio\": 47\n\"Laertes\": 47\n\"Castle\": 55\n\"Ros\": 45\n\"Old\": 48\n\"realm\": 53\n\"perfect\": 55\n\"garments\": 48\n\"griefs\": 55\n\"conduct\": 46\n\"fiery\": 45\n\"MISTRESS\": 45\n\"Thomas\": 54\n\"lovely\": 53\n\"Mortimer\": 49\n\"Nature\": 53\n\"countenance\": 55\n\"Amen\": 55\n\"stones\": 54\n\"making\": 54\n\"image\": 45\n\"castle\": 51\n\"gross\": 52\n\"ROSS\": 51\n\"Whither\": 50\n\"flatter\": 50\n\"ARCHBISHOP\": 45\n\"EARL\": 46\n\"bark\": 48\n\"sail\": 48\n\"lusts\": 4\n\"saucy\": 32\n\"CASCA\": 40\n\"BANQUO\": 34\n\"visage\": 34\n\"PERDITA\": 33\n\"Hubert\": 34\n\"wreck\": 35\n\"Milan\": 40\n\"tall\": 35\n\"discover\": 38\n\"Bohemia\": 34\n\"purposes\": 39\n\"honor\": 40\n\"guarded\": 32\n\"recover\": 33\n\"monument\": 37\n\"tread\": 40\n\"rotten\": 35\n\"mouths\": 35\n\"zeal\": 32\n\"prick\": 37\n\"cares\": 36\n\"kindly\": 34\n\"blessing\": 41\n\"Adieu\": 39\n\"3\": 44\n\"Anon\": 33\n\"chang\": 33\n\"thereof\": 36\n\"CONSTANCE\": 40\n\"beaten\": 44\n\"nobility\": 36\n\"confirm\": 33\n\"Francis\": 40\n\"heartily\": 36\n\"wants\": 37\n\"MOWBRAY\": 38\n\"Whether\": 41\n\"vessel\": 32\n\"Julia\": 34\n\"month\": 40\n\"debt\": 42\n\"slept\": 36\n\"sounds\": 44\n\"deceiv\": 40\n\"mountain\": 33\n\"cease\": 42\n\"special\": 37\n\"dagger\": 44\n\"tarry\": 35\n\"whither\": 38\n\"store\": 38\n\"travel\": 33\n\"faint\": 43\n\"pieces\": 36\n\"equal\": 42\n\"ARTHUR\": 32\n\"pocket\": 35\n\"behalf\": 43\n\"Men\": 40\n\"cat\": 34\n\"Banquo\": 41\n\"bend\": 43\n\"Hercules\": 35\n\"villainy\": 37\n\"drums\": 36\n\"perish\": 32\n\"glorious\": 40\n\"bounty\": 40\n\"Wor\": 35\n\"Malvolio\": 32\n\"Tut\": 33\n\"Camillo\": 39\n\"afraid\": 41\n\"threat\": 35\n\"LOVELL\": 32\n\"Toby\": 36\n\"unhappy\": 34\n\"solemn\": 38\n\"Hal\": 42\n\"whisper\": 32\n\"Windsor\": 37\n\"silent\": 36\n\"moved\": 34\n\"Plantagenet\": 41\n\"flourish\": 42\n\"ripe\": 38\n\"Gentlemen\": 43\n\"Full\": 39\n\"Music\": 40\n\"plead\": 40\n\"waste\": 43\n\"toil\": 32\n\"tedious\": 43\n\"familiar\": 34\n\"sooth\": 38\n\"assur\": 37\n\"tells\": 40\n\"shot\": 42\n\"sleeps\": 35\n\"ELBOW\": 33\n\"speaking\": 41\n\"Send\": 39\n\"Commend\": 32\n\"serves\": 33\n\"Douglas\": 41\n\"twill\": 42\n\"satisfaction\": 33\n\"amiss\": 35\n\"Richmond\": 37\n\"Having\": 33\n\"sins\": 36\n\"horn\": 33\n\"apparel\": 39\n\"dumb\": 39\n\"Lay\": 43\n\"loath\": 32\n\"utter\": 41\n\"chair\": 39\n\"glove\": 35\n\"leg\": 35\n\"puts\": 41\n\"quit\": 43\n\"Blunt\": 33\n\"vantage\": 38\n\"barren\": 37\n\"Westmoreland\": 38\n\"sorrows\": 42\n\"lusty\": 33\n\"LEPIDUS\": 43\n\"EROS\": 37\n\"pitch\": 34\n\"sceptre\": 32\n\"Lavinia\": 41\n\"bent\": 37\n\"SURREY\": 37\n\"infinite\": 38\n\"hanging\": 32\n\"MENAS\": 44\n\"hazard\": 38\n\"jealousy\": 35\n\"Clown\": 40\n\"rate\": 38\n\"beauteous\": 36\n\"Cleopatra\": 34\n\"GOWER\": 41\n\"otherwise\": 33\n\"SOOTHSAYER\": 34\n\"LAVINIA\": 34\n\"IRAS\": 34\n\"dar\": 43\n\"twain\": 37\n\"MALCOLM\": 41\n\"delay\": 33\n\"temper\": 42\n\"Although\": 41\n\"Behold\": 44\n\"Gent\": 43\n\"length\": 37\n\"finds\": 38\n\"dogs\": 41\n\"tame\": 37\n\"Baptista\": 33\n\"tempest\": 40\n\"reward\": 33\n\"pair\": 41\n\"conference\": 32\n\"POINS\": 33\n\"hill\": 39\n\"seas\": 42\n\"RIVERS\": 32\n\"minister\": 38\n\"revolt\": 41\n\"favours\": 38\n\"RICHMOND\": 34\n\"peril\": 42\n\"PEMBROKE\": 32\n\"modest\": 35\n\"witch\": 43\n\"prayer\": 35\n\"murther\": 44\n\"darkness\": 36\n\"bade\": 38\n\"practice\": 40\n\"stronger\": 37\n\"abuse\": 43\n\"Cressid\": 38\n\"crave\": 40\n\"Casca\": 33\n\"convey\": 40\n\"Cor\": 32\n\"Mar\": 32\n\"burning\": 44\n\"rock\": 38\n\"dignity\": 37\n\"fox\": 34\n\"Grecian\": 33\n\"cur\": 41\n\"vouchsafe\": 37\n\"violent\": 41\n\"scene\": 34\n\"smooth\": 38\n\"Cannot\": 44\n\"wing\": 33\n\"Polonius\": 36\n\"nephew\": 35\n\"hardly\": 36\n\"nobly\": 34\n\"kin\": 32\n\"sweat\": 37\n\"PAINTER\": 35\n\"bravely\": 32\n\"star\": 41\n\"commanded\": 35\n\"Every\": 36\n\"surely\": 34\n\"attended\": 42\n\"language\": 35\n\"babe\": 37\n\"Italy\": 34\n\"beasts\": 33\n\"mov\": 44\n\"sends\": 37\n\"attempt\": 34\n\"prisoners\": 43\n\"firm\": 40\n\"wolf\": 33\n\"success\": 44\n\"lamb\": 34\n\"Jupiter\": 33\n\"STANLEY\": 37\n\"reading\": 32\n\"felt\": 34\n\"slaughter\": 34\n\"pour\": 37\n\"search\": 42\n\"befall\": 35\n\"big\": 39\n\"PETER\": 34\n\"offended\": 43\n\"POET\": 39\n\"ignorance\": 37\n\"Soft\": 35\n\"Ghost\": 38\n\"Worthy\": 34\n\"defence\": 37\n\"fruit\": 36\n\"pleasures\": 34\n\"ned\": 40\n\"Draw\": 34\n\"govern\": 38\n\"About\": 44\n\"salt\": 43\n\"twelve\": 43\n\"stroke\": 39\n\"flower\": 40\n\"friendly\": 35\n\"honey\": 32\n\"custom\": 42\n\"groan\": 35\n\"odds\": 43\n\"Tranio\": 33\n\"trade\": 37\n\"strain\": 33\n\"sore\": 40\n\"cell\": 39\n\"inform\": 35\n\"farther\": 42\n\"Many\": 43\n\"scape\": 35\n\"elder\": 39\n\"Turn\": 35\n\"DOLL\": 35\n\"eternal\": 37\n\"bite\": 38\n\"punish\": 36\n\"morn\": 35\n\"deserv\": 38\n\"misery\": 36\n\"everything\": 40\n\"Lie\": 33\n\"betwixt\": 38\n\"stranger\": 40\n\"forsooth\": 40\n\"esteem\": 35\n\"Capitol\": 43\n\"reputation\": 43\n\"forces\": 42\n\"dew\": 33\n\"sentence\": 39\n\"sour\": 34\n\"KEEPER\": 40\n\"Shakespeare\": 38\n\"fairest\": 40\n\"thieves\": 35\n\"services\": 34\n\"Orleans\": 32\n\"dish\": 35\n\"rous\": 39\n\"deer\": 39\n\"written\": 33\n\"Bassanio\": 42\n\"cover\": 38\n\"Petruchio\": 38\n\"plays\": 32\n\"garden\": 43\n\"discretion\": 32\n\"profit\": 38\n\"parted\": 41\n\"knaves\": 44\n\"SALERIO\": 43\n\"weight\": 43\n\"pleasant\": 33\n\"shallow\": 40\n\"shortly\": 44\n\"Strike\": 38\n\"ladyship\": 43\n\"spoil\": 33\n\"Lucentio\": 40\n\"creatures\": 35\n\"acquaintance\": 36\n\"lieutenant\": 32\n\"worn\": 36\n\"months\": 36\n\"gifts\": 44\n\"Didst\": 38\n\"sell\": 37\n\"re\": 38\n\"dread\": 44\n\"impossible\": 34\n\"Remember\": 38\n\"fathers\": 40\n\"laws\": 36\n\"dst\": 36\n\"fairer\": 36\n\"hark\": 44\n\"perforce\": 43\n\"figure\": 41\n\"raise\": 43\n\"shine\": 41\n\"minute\": 35\n\"Boy\": 35\n\"alike\": 41\n\"isle\": 37\n\"tailor\": 34\n\"contempt\": 42\n\"fate\": 37\n\"wondrous\": 32\n\"Hail\": 38\n\"Long\": 35\n\"whore\": 44\n\"difference\": 36\n\"desert\": 41\n\"Wife\": 36\n\"friendship\": 41\n\"regard\": 41\n\"maids\": 40\n\"dares\": 44\n\"pick\": 32\n\"Young\": 36\n\"beyond\": 43\n\"OLD\": 41\n\"lip\": 36\n\"shoulders\": 32\n\"moment\": 32\n\"forbear\": 44\n\"huge\": 34\n\"Arthur\": 42\n\"stage\": 37\n\"mischief\": 41\n\"sway\": 44\n\"places\": 37\n\"miss\": 33\n\"Empress\": 36\n\"lean\": 37\n\"Mother\": 35\n\"native\": 43\n\"prevail\": 43\n\"apt\": 39\n\"Pistol\": 39\n\"Gives\": 34\n\"apart\": 39\n\"PARIS\": 40\n\"express\": 43\n\"bride\": 34\n\"advice\": 43\n\"Does\": 39\n\"ALENCON\": 32\n\"staff\": 39\n\"fish\": 43\n\"Verona\": 35\n\"greet\": 41\n\"page\": 37\n\"bred\": 42\n\"devils\": 37\n\"JESSICA\": 37\n\"midnight\": 41\n\"lord-\": 43\n\"savage\": 32\n\"Naples\": 32\n\"attending\": 40\n\"REIGNIER\": 35\n\"sky\": 39\n\"ning\": 41\n\"gall\": 34\n\"displeasure\": 41\n\"Watch\": 41\n\"sold\": 40\n\"odd\": 32\n\"wither\": 32\n\"Brother\": 40\n\"affections\": 40\n\"Edgar\": 35\n\"wears\": 36\n\"dearly\": 41\n\"willing\": 36\n\"armour\": 41\n\"height\": 34\n\"iron\": 42\n\"conceit\": 37\n\"deserves\": 32\n\"nobles\": 36\n\"stomach\": 40\n\"CAPTAIN\": 36\n\"hangs\": 34\n\"retire\": 32\n\"MAYOR\": 37\n\"companion\": 36\n\"RATCLIFF\": 35\n\"bleed\": 35\n\"blown\": 33\n\"fairy\": 40\n\"clothes\": 40\n\"until\": 41\n\"Man\": 41\n\"hateful\": 39\n\"Don\": 44\n\"yond\": 35\n\"reveng\": 32\n\"charm\": 37\n\"moe\": 37\n\"PLANTAGENET\": 35\n\"brows\": 44\n\"account\": 44\n\"ambition\": 44\n\"rhyme\": 34\n\"wed\": 33\n\"Goneril\": 32\n\"wrought\": 40\n\"signs\": 32\n\"WINCHESTER\": 39\n\"instrument\": 37\n\"Much\": 40\n\"parley\": 33\n\"Diomed\": 35\n\"courtier\": 42\n\"Regan\": 32\n\"furnish\": 38\n\"Rather\": 32\n\"partly\": 33\n\"rail\": 35\n\"miserable\": 33\n\"lines\": 33\n\"bird\": 44\n\"crack\": 43\n\"rob\": 33\n\"Padua\": 41\n\"Thisby\": 37\n\"Troyan\": 34\n\"dwell\": 40\n\"Robert\": 36\n\"dress\": 34\n\"bodies\": 43\n\"calm\": 36\n\"benefit\": 39\n\"GAUNT\": 34\n\"dreams\": 43\n\"pen\": 38\n\"appetite\": 37\n\"edge\": 40\n\"passage\": 35\n\"Emilia\": 38\n\"necessity\": 34\n\"seeing\": 39\n\"Senate\": 42\n\"slaves\": 35\n\"corn\": 32\n\"bury\": 34\n\"numbers\": 42\n\"graces\": 37\n\"Soldiers\": 39\n\"Peter\": 44\n\"weapons\": 39\n\"MARIANA\": 40\n\"add\": 34\n\"whoreson\": 39\n\"weeds\": 42\n\"afterwards\": 38\n\"WIDOW\": 44\n\"VIRGILIA\": 35\n\"island\": 32\n\"prey\": 41\n\"Aufidius\": 37\n\"banished\": 35\n\"LODOVICO\": 34\n\"Through\": 36\n\"suspect\": 35\n\"nights\": 37\n\"tyranny\": 33\n\"Hereford\": 38\n\"CORIN\": 32\n\"grieve\": 39\n\"object\": 39\n\"SILVIUS\": 34\n\"fairly\": 43\n\"Burgundy\": 44\n\"Coriolanus\": 38\n\"substance\": 41\n\"END\": 37\n\"LARTIUS\": 33\n\"boast\": 34\n\"strife\": 32\n\"unknown\": 39\n\"cool\": 32\n\"pawn\": 32\n\"virgin\": 35\n\"compass\": 37\n\"fatal\": 40\n\"sleeping\": 41\n\"avoid\": 34\n\"Came\": 39\n\"chaste\": 36\n\"reverence\": 39\n\"although\": 35\n\"villains\": 41\n\"accuse\": 34\n\"doctor\": 32\n\"complexion\": 40\n\"stays\": 34\n\"brook\": 41\n\"envious\": 35\n\"device\": 41\n\"disposition\": 44\n\"coz\": 35\n\"earnest\": 37\n\"Bora\": 37\n\"Princess\": 41\n\"sees\": 42\n\"mistake\": 34\n\"acquainted\": 37\n\"circumstance\": 32\n\"marvel\": 34\n\"hid\": 44\n\"DAUPHIN\": 39\n\"remains\": 35\n\"slew\": 37\n\"policy\": 44\n\"dying\": 43\n\"banishment\": 39\n\"SENIOR\": 35\n\"books\": 35\n\"usurp\": 32\n\"damned\": 43\n\"falsehood\": 32\n\"humours\": 33\n\"abide\": 34\n\"despite\": 44\n\"followed\": 37\n\"giving\": 32\n\"possession\": 32\n\"committed\": 33\n\"roar\": 40\n\"repair\": 38\n\"also\": 38\n\"bell\": 34\n\"woes\": 42\n\"Until\": 35\n\"draws\": 32\n\"Sings\": 43\n\"TITANIA\": 32\n\"chase\": 34\n\"OBERON\": 37\n\"runs\": 36\n\"Osw\": 38\n\"sought\": 35\n\"faithful\": 33\n\"Lysander\": 41\n\"suck\": 35\n\"Greek\": 33\n\"senses\": 35\n\"OFFICER\": 41\n\"wounded\": 36\n\"picture\": 42\n\"fits\": 40\n\"bottom\": 35\n\"ambitious\": 33\n\"Mars\": 41\n\"press\": 44\n\"belly\": 39\n\"Scotland\": 36\n\"line\": 42\n\"thinking\": 41\n\"cave\": 37\n\"sheep\": 43\n\"habit\": 39\n\"peers\": 38\n\"task\": 33\n\"devise\": 44\n\"BEDFORD\": 38\n\"bawd\": 35\n\"hat\": 36\n\"KATHERINE\": 37\n\"Father\": 35\n\"willingly\": 34\n\"bind\": 37\n\"Brook\": 39\n\"marks\": 37\n\"smiles\": 42\n\"fierce\": 37\n\"disdain\": 33\n\"pause\": 34\n\"league\": 34\n\"Dromio\": 36\n\"groans\": 36\n\"allow\": 42\n\"entertainment\": 36\n\"sings\": 39\n\"ORLEANS\": 40\n\"passing\": 33\n\"snow\": 34\n\"BURGUNDY\": 35\n\"lust\": 43\n\"gait\": 33\n\"root\": 42\n\"countrymen\": 38\n\"hunt\": 32\n\"pomp\": 33\n\"fingers\": 43\n\"unnatural\": 35\n\"SIMPLE\": 39\n\"Cousin\": 36\n\"birds\": 33\n\"seest\": 43\n\"NYM\": 41\n\"angels\": 35\n\"MERCHANT\": 33\n\"WILLIAMS\": 32\n\"guest\": 33\n\"render\": 43\n\"doings\": 5\n\"AEGEON\": 20\n\"conjure\": 28\n\"terrible\": 26\n\"rites\": 21\n\"Play\": 23\n\"rack\": 21\n\"them-\": 21\n\"ELY\": 24\n\"diseases\": 20\n\"According\": 21\n\"bore\": 29\n\"share\": 25\n\"according\": 24\n\"THOMAS\": 21\n\"NATHANIEL\": 27\n\"bargain\": 21\n\"lark\": 24\n\"whiles\": 28\n\"promised\": 22\n\"HUMPHREY\": 20\n\"BISHOP\": 24\n\"cloud\": 26\n\"human\": 24\n\"nuptial\": 21\n\"climb\": 25\n\"hall\": 26\n\"Die\": 21\n\"tremble\": 29\n\"banquet\": 30\n\"raven\": 22\n\"GAOLER\": 24\n\"amongst\": 27\n\"Him\": 30\n\"carried\": 30\n\"whit\": 21\n\"careful\": 22\n\"gently\": 29\n\"mild\": 29\n\"spread\": 22\n\"smiling\": 30\n\"yes\": 26\n\"Something\": 30\n\"guiltless\": 20\n\"crest\": 20\n\"spleen\": 28\n\"ugly\": 24\n\"accident\": 23\n\"cloak\": 27\n\"towns\": 29\n\"WALES\": 24\n\"yellow\": 27\n\"Slender\": 30\n\"ape\": 21\n\"today\": 24\n\"hated\": 27\n\"likewise\": 26\n\"stick\": 29\n\"talking\": 23\n\"beholding\": 27\n\"shoulder\": 27\n\"Break\": 22\n\"advise\": 31\n\"censure\": 27\n\"doubtful\": 22\n\"guests\": 20\n\"Duncan\": 21\n\"hairs\": 30\n\"south\": 22\n\"fleet\": 25\n\"undo\": 27\n\"defy\": 24\n\"axe\": 20\n\"sitting\": 22\n\"goose\": 28\n\"breaks\": 27\n\"bread\": 21\n\"gather\": 25\n\"ANTIGONUS\": 25\n\"dine\": 24\n\"fields\": 27\n\"bush\": 25\n\"CANTERBURY\": 25\n\"secrets\": 24\n\"Better\": 29\n\"grey\": 20\n\"east\": 27\n\"granted\": 29\n\"immortal\": 23\n\"mourning\": 20\n\"gar\": 30\n\"dowry\": 22\n\"goods\": 23\n\"alarum\": 27\n\"Beshrew\": 21\n\"temple\": 22\n\"safely\": 22\n\"Goths\": 31\n\"suitor\": 25\n\"spit\": 25\n\"contents\": 27\n\"hie\": 27\n\"sleeve\": 20\n\"Fetch\": 21\n\"giddy\": 28\n\"gallows\": 20\n\"LENNOX\": 23\n\"restore\": 20\n\"AUSTRIA\": 20\n\"score\": 29\n\"Cry\": 31\n\"Villain\": 24\n\"Proceed\": 25\n\"sue\": 26\n\"creep\": 21\n\"backward\": 20\n\"keen\": 23\n\"resolve\": 23\n\"boot\": 30\n\"trifle\": 25\n\"chin\": 22\n\"conclude\": 27\n\"Pluck\": 23\n\"Swear\": 24\n\"mountains\": 20\n\"writing\": 21\n\"eight\": 29\n\"box\": 24\n\"Among\": 25\n\"corrupt\": 25\n\"bay\": 29\n\"converse\": 23\n\"proportion\": 23\n\"tied\": 25\n\"Isabel\": 26\n\"arrest\": 23\n\"swears\": 25\n\"wholesome\": 31\n\"Athenian\": 24\n\"kindred\": 30\n\"ALICE\": 26\n\"dainty\": 20\n\"unjust\": 21\n\"thin\": 23\n\"wills\": 29\n\"push\": 22\n\"ope\": 27\n\"advis\": 27\n\"slay\": 25\n\"rul\": 26\n\"Ireland\": 31\n\"feeling\": 30\n\"closet\": 26\n\"rid\": 28\n\"direct\": 25\n\"High\": 21\n\"players\": 21\n\"cock\": 30\n\"conditions\": 26\n\"freedom\": 30\n\"bar\": 30\n\"ran\": 29\n\"fee\": 28\n\"Hugh\": 25\n\"voyage\": 20\n\"bottle\": 23\n\"dote\": 29\n\"Katherine\": 30\n\"bosoms\": 26\n\"ago\": 30\n\"Lewis\": 31\n\"Live\": 30\n\"DULL\": 21\n\"blunt\": 27\n\"severally\": 23\n\"likeness\": 23\n\"divide\": 21\n\"journey\": 28\n\"stubborn\": 23\n\"chastity\": 20\n\"gilded\": 20\n\"weather\": 29\n\"est\": 21\n\"beds\": 25\n\"y\": 21\n\"swain\": 23\n\"bounds\": 20\n\"unkindness\": 21\n\"conquer\": 27\n\"rememb\": 30\n\"signior\": 25\n\"wooing\": 22\n\"le\": 31\n\"actions\": 23\n\"madman\": 23\n\"ought\": 21\n\"tempt\": 29\n\"lower\": 22\n\"doublet\": 25\n\"sat\": 29\n\"unkind\": 24\n\"busy\": 27\n\"shade\": 24\n\"infant\": 20\n\"afar\": 20\n\"wand\": 23\n\"calf\": 24\n\"crying\": 27\n\"fever\": 23\n\"Nym\": 22\n\"dam\": 30\n\"Twill\": 21\n\"hose\": 22\n\"OUTLAW\": 30\n\"saint\": 22\n\"Drum\": 26\n\"lodging\": 24\n\"breaking\": 25\n\"sensible\": 22\n\"fright\": 31\n\"directly\": 26\n\"piteous\": 21\n\"woeful\": 27\n\"Almost\": 22\n\"physic\": 30\n\"Davy\": 24\n\"wak\": 22\n\"discharge\": 27\n\"threw\": 22\n\"saved\": 20\n\"Exeter\": 26\n\"mourn\": 31\n\"oak\": 25\n\"rebel\": 24\n\"forty\": 25\n\"beloved\": 26\n\"deaths\": 23\n\"record\": 22\n\"ent\": 26\n\"lodge\": 23\n\"subtle\": 29\n\"value\": 25\n\"remorse\": 26\n\"dukedom\": 24\n\"Making\": 26\n\"coat\": 31\n\"curs\": 27\n\"fed\": 28\n\"kingdoms\": 23\n\"elements\": 23\n\"rapier\": 28\n\"sisters\": 23\n\"disease\": 28\n\"preserve\": 23\n\"Ant\": 22\n\"everlasting\": 20\n\"physician\": 27\n\"urg\": 24\n\"renown\": 25\n\"suits\": 31\n\"except\": 22\n\"torture\": 31\n\"Con\": 23\n\"Gentleman\": 25\n\"decay\": 25\n\"working\": 20\n\"filthy\": 20\n\"adventure\": 21\n\"appointed\": 30\n\"Constable\": 21\n\"design\": 20\n\"shun\": 20\n\"scurvy\": 24\n\"urge\": 24\n\"Ne\": 23\n\"Canst\": 26\n\"wisely\": 31\n\"miles\": 21\n\"rebellion\": 28\n\"flout\": 20\n\"venom\": 22\n\"Revenge\": 24\n\"leap\": 24\n\"rejoice\": 24\n\"shoot\": 29\n\"level\": 25\n\"contented\": 27\n\"treasons\": 20\n\"refuse\": 27\n\"treacherous\": 26\n\"rend\": 24\n\"bondage\": 20\n\"herein\": 21\n\"kills\": 25\n\"beguile\": 24\n\"Orlando\": 26\n\"stamp\": 30\n\"Marg\": 26\n\"Justice\": 27\n\"deputy\": 24\n\"resign\": 20\n\"apace\": 26\n\"swearing\": 21\n\"houses\": 27\n\"scruple\": 22\n\"Apollo\": 25\n\"whip\": 30\n\"ev\": 23\n\"breach\": 31\n\"Witness\": 20\n\"shines\": 28\n\"l\": 20\n\"altogether\": 24\n\"access\": 21\n\"vous\": 20\n\"nimble\": 22\n\"Ye\": 22\n\"Dian\": 20\n\"peasant\": 20\n\"ELINOR\": 28\n\"flame\": 23\n\"grievous\": 24\n\"begot\": 23\n\"aunt\": 24\n\"PANDULPH\": 28\n\"youngest\": 23\n\"space\": 29\n\"perjur\": 23\n\"lying\": 30\n\"Shrewsbury\": 21\n\"orchard\": 31\n\"Thurio\": 24\n\"sweetly\": 25\n\"perhaps\": 30\n\"husbands\": 27\n\"grieves\": 21\n\"legions\": 20\n\"manage\": 23\n\"error\": 30\n\"theirs\": 29\n\"school\": 28\n\"jewels\": 26\n\"Adam\": 25\n\"Hadst\": 21\n\"PHEBE\": 29\n\"hideous\": 22\n\"leads\": 30\n\"Dramatis\": 20\n\"Personae\": 20\n\"Tribunes\": 22\n\"compare\": 20\n\"distance\": 27\n\"YOUNG\": 25\n\"Fly\": 30\n\"HERALD\": 22\n\"fearing\": 23\n\"Rousillon\": 26\n\"ragged\": 24\n\"rights\": 20\n\"pleasing\": 22\n\"crow\": 30\n\"BRABANTIO\": 31\n\"rt\": 21\n\"scope\": 29\n\"innocence\": 22\n\"grandam\": 24\n\"Servant\": 22\n\"LIEUTENANT\": 26\n\"4\": 31\n\"FREDERICK\": 27\n\"Glend\": 24\n\"exile\": 25\n\"earthly\": 31\n\"robb\": 23\n\"funeral\": 20\n\"VALERIA\": 20\n\"hue\": 26\n\"swallow\": 22\n\"rouse\": 25\n\"Servants\": 25\n\"Corioli\": 26\n\"lesser\": 26\n\"looking\": 23\n\"Officers\": 28\n\"requite\": 22\n\"needful\": 29\n\"touches\": 23\n\"MONTANO\": 25\n\"poet\": 22\n\"FENTON\": 28\n\"Florence\": 20\n\"yesterday\": 24\n\"Item\": 28\n\"worm\": 29\n\"drinks\": 20\n\"basket\": 29\n\"deserts\": 21\n\"departure\": 20\n\"kingly\": 25\n\"beams\": 24\n\"verse\": 31\n\"shown\": 30\n\"provided\": 26\n\"satisfy\": 22\n\"shadows\": 28\n\"CINNA\": 21\n\"lift\": 21\n\"instruments\": 27\n\"dispose\": 20\n\"merchant\": 29\n\"arise\": 23\n\"livery\": 21\n\"purchase\": 27\n\"destruction\": 25\n\"Welsh\": 27\n\"inward\": 28\n\"stretch\": 30\n\"Neither\": 30\n\"famous\": 28\n\"harsh\": 26\n\"cruelty\": 21\n\"pitiful\": 28\n\"monarch\": 20\n\"forms\": 25\n\"lately\": 30\n\"clean\": 20\n\"Jesu\": 21\n\"tribunes\": 27\n\"beggars\": 22\n\"wedding\": 21\n\"wail\": 25\n\"Volsces\": 22\n\"promises\": 21\n\"wink\": 29\n\"SENATORS\": 20\n\"forc\": 22\n\"carries\": 22\n\"qualities\": 24\n\"shapes\": 28\n\"stocks\": 22\n\"dove\": 21\n\"lament\": 21\n\"flattery\": 22\n\"lions\": 20\n\"weeps\": 30\n\"House\": 22\n\"PANTHINO\": 20\n\"Helena\": 25\n\"affect\": 23\n\"Council\": 28\n\"sirs\": 24\n\"likely\": 23\n\"Cordelia\": 30\n\"wishes\": 31\n\"dat\": 21\n\"Patience\": 25\n\"garland\": 23\n\"afoot\": 23\n\"resolution\": 29\n\"Beseech\": 20\n\"Host\": 27\n\"conclusion\": 28\n\"sting\": 26\n\"gaze\": 26\n\"Fall\": 23\n\"Ulysses\": 20\n\"Mowbray\": 28\n\"mile\": 30\n\"BUSHY\": 20\n\"bleeding\": 29\n\"begun\": 27\n\"Oxford\": 25\n\"duties\": 20\n\"contract\": 24\n\"titles\": 20\n\"hungry\": 24\n\"remove\": 27\n\"imagination\": 25\n\"milk\": 24\n\"Read\": 25\n\"Twere\": 30\n\"mask\": 23\n\"Silence\": 24\n\"wheel\": 22\n\"pinch\": 27\n\"changes\": 21\n\"Five\": 23\n\"natures\": 24\n\"butcher\": 24\n\"noted\": 23\n\"rogues\": 20\n\"Aeneas\": 25\n\"miseries\": 21\n\"torch\": 23\n\"strive\": 28\n\"knot\": 27\n\"losing\": 20\n\"Deliver\": 22\n\"veins\": 26\n\"council\": 21\n\"blue\": 20\n\"robe\": 20\n\"perpetual\": 20\n\"Macduff\": 30\n\"fix\": 25\n\"evils\": 23\n\"approve\": 25\n\"roses\": 27\n\"addition\": 26\n\"charg\": 24\n\"Dies\": 31\n\"obedient\": 26\n\"correction\": 20\n\"WATCH\": 31\n\"virginity\": 20\n\"Aumerle\": 20\n\"din\": 22\n\"Gaunt\": 31\n\"fifty\": 30\n\"plant\": 21\n\"example\": 30\n\"grew\": 29\n\"unworthy\": 31\n\"DERBY\": 23\n\"owes\": 25\n\"sadness\": 23\n\"direction\": 22\n\"Bless\": 22\n\"joyful\": 31\n\"Run\": 25\n\"backs\": 20\n\"dismiss\": 24\n\"T\": 31\n\"soundly\": 20\n\"expedition\": 24\n\"5\": 20\n\"commonwealth\": 28\n\"jot\": 21\n\"metal\": 26\n\"troop\": 26\n\"sights\": 20\n\"writes\": 23\n\"muse\": 20\n\"quarter\": 27\n\"consul\": 29\n\"betimes\": 23\n\"lads\": 23\n\"breeds\": 21\n\"enterprise\": 31\n\"provide\": 25\n\"goddess\": 25\n\"peevish\": 27\n\"armed\": 30\n\"society\": 25\n\"Lorenzo\": 24\n\"create\": 21\n\"Sleep\": 22\n\"liking\": 27\n\"commons\": 28\n\"likes\": 27\n\"forehead\": 23\n\"stopp\": 23\n\"strangely\": 24\n\"Belike\": 20\n\"terror\": 30\n\"drive\": 30\n\"north\": 28\n\"determine\": 23\n\"offences\": 23\n\"expect\": 29\n\"acts\": 21\n\"standing\": 28\n\"Gratiano\": 20\n\"swell\": 21\n\"JAQUENETTA\": 20\n\"pearl\": 26\n\"Enough\": 22\n\"guide\": 22\n\"instruct\": 23\n\"boots\": 26\n\"falling\": 23\n\"shift\": 26\n\"ocean\": 29\n\"combat\": 24\n\"lightning\": 26\n\"curses\": 28\n\"choler\": 23\n\"youthful\": 31\n\"stock\": 26\n\"Publius\": 21\n\"infection\": 20\n\"fires\": 20\n\"yoke\": 29\n\"blessings\": 20\n\"current\": 25\n\"effects\": 25\n\"price\": 28\n\"Monsieur\": 28\n\"confusion\": 27\n\"MESSALA\": 22\n\"preparation\": 28\n\"nest\": 24\n\"praises\": 28\n\"Catesby\": 23\n\"Ho\": 25\n\"it-\": 22\n\"running\": 26\n\"necessary\": 20\n\"flat\": 22\n\"pronounce\": 24\n\"desir\": 24\n\"Berowne\": 27\n\"telling\": 25\n\"Agamemnon\": 31\n\"allegiance\": 24\n\"Mercutio\": 26\n\"redress\": 28\n\"loyalty\": 23\n\"withdraw\": 27\n\"Answer\": 23\n\"greeting\": 23\n\"build\": 22\n\"received\": 25\n\"nation\": 29\n\"coin\": 23\n\"heirs\": 20\n\"learning\": 28\n\"craves\": 21\n\"conqueror\": 22\n\"Arm\": 21\n\"Serv\": 30\n\"rais\": 22\n\"Perchance\": 22\n\"forfeit\": 29\n\"Laurence\": 22\n\"bowels\": 22\n\"divers\": 20\n\"ATTENDANTS\": 30\n\"brown\": 20\n\"Launcelot\": 28\n\"continue\": 29\n\"mutiny\": 23\n\"destroy\": 24\n\"perfection\": 25\n\"Ross\": 21\n\"burst\": 27\n\"cowards\": 26\n\"manhood\": 25\n\"SON\": 31\n\"beheld\": 24\n\"Uncle\": 20\n\"graves\": 27\n\"knights\": 29\n\"afford\": 20\n\"mightst\": 27\n\"Albany\": 20\n\"phrase\": 26\n\"Trust\": 20\n\"Joan\": 22\n\"Cornwall\": 23\n\"fourteen\": 22\n\"assurance\": 28\n\"breathing\": 22\n\"chief\": 29\n\"eldest\": 26\n\"renowned\": 22\n\"ships\": 22\n\"Return\": 23\n\"moral\": 23\n\"Rosaline\": 20\n\"apparent\": 23\n\"merely\": 21\n\"thereby\": 24\n\"varlet\": 21\n\"hourly\": 20\n\"cherish\": 25\n\"surety\": 20\n\"week\": 28\n\"accept\": 26\n\"Up\": 29\n\"wore\": 25\n\"Mantua\": 25\n\"observe\": 27\n\"begg\": 25\n\"Samp\": 20\n\"trunk\": 23\n\"Shylock\": 20\n\"Bishop\": 20\n\"suspicion\": 28\n\"amity\": 22\n\"sinews\": 22\n\"loyal\": 29\n\"called\": 22\n\"couldst\": 26\n\"Alexander\": 20\n\"FOURTH\": 30\n\"younger\": 30\n\"Cyprus\": 28\n\"Lies\": 21\n\"Winchester\": 27\n\"DOCTOR\": 28\n\"Gentle\": 27\n\"Eros\": 27\n\"Pope\": 20\n\"corse\": 29\n\"Ever\": 20\n\"strongly\": 29\n\"began\": 30\n\"division\": 21\n\"pursue\": 26\n\"Takes\": 20\n\"wag\": 21\n\"increase\": 27\n\"Sure\": 27\n\"Par\": 23\n\"knit\": 31\n\"PORTER\": 24\n\"Open\": 22\n\"instance\": 22\n\"Imogen\": 26\n\"delivered\": 29\n\"GOBBO\": 24\n\"wax\": 28\n\"prepar\": 29\n\"shook\": 28\n\"disguised\": 22\n\"persuade\": 24\n\"west\": 29\n\"verses\": 21\n\"wept\": 26\n\"Lend\": 24\n\"mar\": 27\n\"roaring\": 23\n\"Zounds\": 22\n\"escape\": 20\n\"troubled\": 29\n\"ink\": 26\n\"absent\": 30\n\"signify\": 25\n\"whipt\": 22\n\"deaf\": 24\n\"offices\": 31\n\"OFFICERS\": 28\n\"miracle\": 26\n\"commit\": 30\n\"repose\": 23\n\"CROMWELL\": 26\n\"spy\": 27\n\"burnt\": 20\n\"injury\": 30\n\"PHILARIO\": 20\n\"interest\": 28\n\"clerk\": 20\n\"Jessica\": 22\n\"behaviour\": 26\n\"moves\": 21\n\"stream\": 31\n\"luck\": 26\n\"poverty\": 22\n\"Posthumus\": 31\n\"Y\": 29\n\"imperial\": 23\n\"front\": 22\n\"deceive\": 26\n\"sounded\": 24\n\"caught\": 30\n\"HELEN\": 22\n\"cuckold\": 29\n\"comforts\": 24\n\"SERVANTS\": 30\n\"kisses\": 30\n\"unfold\": 25\n\"troops\": 30\n\"VII\": 20\n\"throats\": 25\n\"exchange\": 31\n\"aboard\": 26\n\"handkerchief\": 31\n\"amorous\": 23\n\"Pisanio\": 24\n\"tricks\": 31\n\"MURTHERER\": 31\n\"neglect\": 21\n\"SLY\": 28\n\"VINCENTIO\": 31\n\"amends\": 24\n\"notwithstanding\": 20\n\"speeches\": 21\n\"Me\": 25\n\"liberal\": 28\n\"Priam\": 30\n\"prevent\": 24\n\"happily\": 23\n\"confound\": 28\n\"thirty\": 24\n\"torment\": 30\n\"recompense\": 27\n\"Above\": 23\n\"fairies\": 25\n\"election\": 20\n\"spur\": 29\n\"Ten\": 22\n\"senators\": 30\n\"marching\": 21\n\"VI\": 28\n\"Garter\": 20\n\"belike\": 22\n\"Lead\": 25\n\"lights\": 24\n\"redeem\": 30\n\"dozen\": 31\n\"borrow\": 28\n\"SOLANIO\": 28\n\"knocks\": 20\n\"delicate\": 28\n\"rescue\": 26\n\"tribute\": 25\n\"message\": 31\n\"government\": 25\n\"General\": 23\n\"Patroclus\": 26\n\"park\": 27\n\"spurn\": 26\n\"pack\": 28\n\"CURTIS\": 23\n\"concerns\": 21\n\"YOU\": 23\n\"PEDANT\": 28\n\"SANDYS\": 21\n\"Down\": 28\n\"GARDINER\": 29\n\"kissing\": 20\n\"answers\": 24\n\"hung\": 20\n\"slight\": 29\n\"wager\": 22\n\"pierce\": 23\n\"seldom\": 26\n\"exceeding\": 21\n\"cursed\": 28\n\"conceive\": 25\n\"siege\": 31\n\"Hortensio\": 30\n\"Sit\": 28\n\"Methought\": 22\n\"serpent\": 31\n\"start\": 30\n\"murd\": 27\n\"beats\": 20\n\"Gremio\": 23\n\"slip\": 22\n\"foreign\": 28\n\"game\": 25\n\"Other\": 23\n\"Cloten\": 20\n\"Grumio\": 23\n\"herald\": 31\n\"presume\": 20\n\"lap\": 21\n\"invisible\": 30\n\"conquest\": 31\n\"commands\": 29\n\"Find\": 26\n\"strokes\": 23\n\"VENICE\": 22\n\"nice\": 28\n\"County\": 25\n\"Strikes\": 20\n\"river\": 23\n\"shield\": 20\n\"eagle\": 25\n\"petition\": 20\n\"invention\": 29\n\"lays\": 20\n\"asham\": 26\n\"proclamation\": 21\n\"tooth\": 22\n\"require\": 20\n\"amen\": 28\n\"PERCY\": 23\n\"shrewd\": 26\n\"tales\": 20\n\"forswear\": 26\n\"Provost\": 21\n\"henceforth\": 25\n\"Messala\": 25\n\"steps\": 24\n\"Whereof\": 23\n\"Octavia\": 24\n\"Thersites\": 26\n\"stoop\": 28\n\"Greeks\": 29\n\"sweetest\": 24\n\"Giving\": 26\n\"aloft\": 21\n\"wipe\": 22\n\"token\": 28\n\"yielded\": 23\n\"vulgar\": 24\n\"drew\": 30\n\"waters\": 26\n\"theme\": 27\n\"hap\": 26\n\"aged\": 24\n\"supply\": 25\n\"Thine\": 22\n\"CRANMER\": 28\n\"Quickly\": 20\n\"seeks\": 24\n\"barbarous\": 20\n\"nobleman\": 21\n\"secure\": 28\n\"prov\": 26\n\"grandsire\": 25\n\"scratch\": 21\n\"nails\": 28\n\"worms\": 21\n\"sovereignty\": 23\n\"points\": 28\n\"notes\": 22\n\"penny\": 23\n\"matters\": 25\n\"beget\": 21\n\"stirring\": 20\n\"ghost\": 30\n\"Else\": 30\n\"proceeding\": 24\n\"charms\": 21\n\"alack\": 20\n\"SIMPCOX\": 20\n\"soil\": 29\n\"forsake\": 22\n\"extremity\": 26\n\"venture\": 28\n\"stern\": 31\n\"mak\": 21\n\"intelligence\": 25\n\"beastly\": 21\n\"lad\": 25\n\"mount\": 23\n\"taking\": 29\n\"scorns\": 20\n\"GEORGE\": 23\n\"joys\": 27\n\"wot\": 30\n\"d-\": 31\n\"higher\": 30\n\"Stands\": 22\n\"Venus\": 21\n\"aloud\": 25\n\"Right\": 26\n\"bidding\": 24\n\"murderer\": 23\n\"upright\": 21\n\"fares\": 29\n\"beware\": 20\n\"stale\": 26\n\"BOTH\": 29\n\"DICK\": 26\n\"Trumpets\": 21\n\"DAVY\": 21\n\"Cade\": 27\n\"Princes\": 30\n\"methought\": 20\n\"oracle\": 25\n\"privilege\": 30\n\"estimation\": 21\n\"shoes\": 20\n\"burns\": 25\n\"SILENCE\": 26\n\"parting\": 27\n\"him-\": 30\n\"Sicilia\": 28\n\"Noble\": 28\n\"sets\": 24\n\"hail\": 31\n\"audience\": 31\n\"Denmark\": 25\n\"Apemantus\": 23\n\"Lepidus\": 27\n\"BASSIANUS\": 24\n\"Thane\": 28\n\"suppose\": 22\n\"royalty\": 25\n\"carriage\": 22\n\"Rosencrantz\": 26\n\"prais\": 26\n\"strikes\": 27\n\"Guildenstern\": 29\n\"newly\": 29\n\"stole\": 21\n\"faction\": 22\n\"Ophelia\": 29\n\"Stanley\": 22\n\"employment\": 21\n\"Titinius\": 26\n\"pate\": 30\n\"Charmian\": 24\n\"Elsinore\": 23\n\"curst\": 26\n\"notice\": 28\n\"Ber\": 20\n\"reach\": 25\n\"officers\": 29\n\"Fran\": 22\n\"afternoon\": 27\n\"sacrifice\": 21\n\"hears\": 27\n\"guilt\": 28\n\"wonderful\": 24\n\"bonds\": 23\n\"Glendower\": 26\n\"strew\": 23\n\"prosperous\": 21\n\"mettle\": 27\n\"merrily\": 22\n\"instantly\": 22\n\"amaz\": 28\n\"Tamora\": 28\n\"opposite\": 25\n\"Things\": 24\n\"evermore\": 21\n\"rightly\": 23\n\"beside\": 25\n\"OXFORD\": 30\n\"riches\": 21\n\"sole\": 22\n\"alter\": 29\n\"profess\": 29\n\"Son\": 22\n\"thrown\": 29\n\"rebels\": 30\n\"pays\": 22\n\"Saw\": 22\n\"ld\": 20\n\"horrible\": 22\n\"rash\": 29\n\"palm\": 27\n\"thick\": 27\n\"et\": 27\n\"wenches\": 21\n\"Portia\": 31\n\"Octavius\": 25\n\"drinking\": 25\n\"MONTAGUE\": 20\n\"senseless\": 22\n\"enforce\": 29\n\"absolute\": 27\n\"history\": 21\n\"hostess\": 27\n\"laughter\": 29\n\"growing\": 27\n\"mass\": 25\n\"vex\": 28\n\"babes\": 22\n\"wander\": 22\n\"works\": 22\n\"Guil\": 29\n\"term\": 30\n\"pace\": 27\n\"expectation\": 23\n\"serious\": 23\n\"punishment\": 21\n\"lo\": 20\n\"Archbishop\": 27\n\"melt\": 25\n\"dearer\": 21\n\"middle\": 21\n\"perchance\": 27\n\"not-\": 27\n\"Cawdor\": 22\n\"Ask\": 20\n\"sufferance\": 23\n\"diest\": 22\n\"belov\": 28\n\"advance\": 23\n\"hounds\": 22\n\"quench\": 28\n\"LADIES\": 23\n\"seize\": 25\n\"duke\": 29\n\"Alexandria\": 25\n\"Mess\": 26\n\"ceremony\": 25\n\"pit\": 22\n\"strumpet\": 26\n\"tend\": 25\n\"OCTAVIA\": 21\n\"aspect\": 26\n\"petty\": 29\n\"steward\": 22\n\"ended\": 30\n\"Bassianus\": 21\n\"knowest\": 24\n\"skin\": 22\n\"willow\": 21\n\"ALEXAS\": 24\n\"burial\": 20\n\"event\": 26\n\"knowing\": 31\n\"Osr\": 25\n\"key\": 28\n\"weapon\": 30\n\"ministers\": 22\n\"dismal\": 21\n\"DOLABELLA\": 31\n\"VARRO\": 30\n\"MAECENAS\": 25\n\"treachery\": 23\n\"haply\": 28\n\"SCARUS\": 20\n\"walks\": 24\n\"Aaron\": 25\n\"car\": 22\n\"mistook\": 20\n\"feeble\": 21\n\"Seek\": 25\n\"resolv\": 30\n\"OCTAVIUS\": 22\n\"cam\": 26\n\"nightly\": 20\n\"step\": 27\n\"Walter\": 20\n\"trees\": 31\n\"divorce\": 21\n\"breeding\": 25\n\"Dead\": 26\n\"injuries\": 23\n\"couch\": 22\n\"lent\": 24\n\"easily\": 28\n\"blot\": 22\n\"abus\": 28\n\"accus\": 21\n\"MENELAUS\": 20\n\"afeard\": 29\n\"Worcester\": 28\n\"pin\": 22\n\"feather\": 23\n\"band\": 31\n\"justly\": 26\n\"weakness\": 24\n\"daily\": 31\n\"rush\": 24\n\"Tom\": 30\n\"sink\": 28\n\"waking\": 21\n\"Comes\": 27\n\"check\": 31\n\"hole\": 26\n\"Hotspur\": 27\n\"Reigns\": 4\n\"ABHORSON\": 18\n\"shames\": 18\n\"THYREUS\": 18\n\"helm\": 18\n\"Prove\": 19\n\"liquor\": 19\n\"attendant\": 18\n\"vanity\": 19\n\"Messenger\": 19\n\"OVERDONE\": 19\n\"constable\": 18\n\"confident\": 19\n\"demands\": 19\n\")\": 18\n\"April\": 18\n\"Fulvia\": 18\n\"aloof\": 18\n\"Excellent\": 19\n\"joint\": 19\n\"sheets\": 18\n\"complete\": 18\n\"CASSANDRA\": 18\n\"dispos\": 19\n\"vassal\": 18\n\"CAMPEIUS\": 19\n\"coronation\": 19\n\"sex\": 18\n\"craft\": 19\n\"arriv\": 18\n\"moving\": 18\n\"Michael\": 19\n\"robes\": 18\n\"MARTIUS\": 19\n\"QUINTUS\": 19\n\"trespass\": 18\n\"Fellow\": 19\n\"persons\": 18\n\"Cut\": 18\n\"stuck\": 19\n\"chose\": 18\n\"harmony\": 18\n\"Peto\": 18\n\"Duchess\": 18\n\"chid\": 19\n\"rot\": 18\n\"crowned\": 19\n\"Frenchmen\": 18\n\"Cinna\": 19\n\"deceit\": 19\n\"rear\": 18\n\"style\": 19\n\"Murder\": 19\n\"Knock\": 19\n\"practise\": 18\n\"distress\": 19\n\"SAY\": 18\n\"Lucilius\": 18\n\"deserved\": 18\n\"vanish\": 19\n\"article\": 18\n\"Angiers\": 18\n\"thankful\": 19\n\"mood\": 19\n\"cook\": 18\n\"execute\": 18\n\"semblance\": 18\n\"Cromwell\": 18\n\"ourself\": 19\n\"lets\": 19\n\"Talk\": 19\n\"canker\": 19\n\"grossly\": 18\n\"Milford\": 19\n\"Maine\": 19\n\"blushing\": 19\n\"mischance\": 19\n\"amend\": 18\n\"rocks\": 19\n\"velvet\": 18\n\"stout\": 18\n\"patch\": 19\n\"mongst\": 19\n\"sadly\": 18\n\"ingratitude\": 18\n\"coxcomb\": 19\n\"North\": 18\n\"articles\": 18\n\"sufficient\": 18\n\"Olivia\": 19\n\"Vincentio\": 18\n\"destiny\": 19\n\"GHOST\": 18\n\"prophesy\": 18\n\"board\": 18\n\"used\": 19\n\"certainly\": 18\n\"pledge\": 19\n\"narrow\": 18\n\"SONG\": 18\n\"delights\": 19\n\"Neptune\": 19\n\"DUNCAN\": 19\n\"Turk\": 18\n\"grass\": 19\n\"religious\": 18\n\"Mayor\": 18\n\"process\": 18\n\"thousands\": 18\n\"Twixt\": 19\n\"naught\": 18\n\"Ned\": 19\n\"exercise\": 18\n\"reply\": 19\n\"tried\": 19\n\"LA\": 19\n\"date\": 19\n\"fighting\": 18\n\"speedy\": 19\n\"executed\": 19\n\"harbour\": 18\n\"load\": 19\n\"Tush\": 18\n\"pull\": 18\n\"wet\": 18\n\"sir-\": 18\n\"errand\": 18\n\"retreat\": 19\n\"prefer\": 18\n\"locks\": 18\n\"thread\": 18\n\"roof\": 18\n\"battles\": 18\n\"household\": 18\n\"eats\": 18\n\"Malcolm\": 19\n\"VERNON\": 18\n\"evening\": 19\n\"multitude\": 19\n\"BRAKENBURY\": 18\n\"respects\": 18\n\"mothers\": 19\n\"Alarums\": 18\n\"hasty\": 19\n\"stake\": 18\n\"setting\": 19\n\"Proud\": 19\n\"utmost\": 19\n\"penance\": 19\n\"Write\": 19\n\"mankind\": 19\n\"hack\": 19\n\"Oswald\": 18\n\"Sebastian\": 19\n\"sup\": 19\n\"Nerissa\": 18\n\"belongs\": 18\n\"flint\": 19\n\"Knocking\": 19\n\"keeping\": 19\n\"boar\": 18\n\"frail\": 18\n\"consequence\": 18\n\"bull\": 18\n\"convenient\": 18\n\"Wouldst\": 19\n\"confession\": 18\n\"lived\": 19\n\"precedent\": 19\n\"scholar\": 18\n\"pine\": 19\n\"mocks\": 18\n\"Cominius\": 19\n\"Alencon\": 18\n\"Philip\": 18\n\"ladder\": 19\n\"dreamt\": 18\n\"awe\": 18\n\"counsels\": 18\n\"Hie\": 19\n\"neighbours\": 18\n\"drunken\": 19\n\"perjury\": 19\n\"etc\": 18\n\"Thee\": 19\n\"intents\": 18\n\"LE\": 19\n\"BEAU\": 19\n\"ROMAN\": 18\n\"AUDREY\": 18\n\"pernicious\": 19\n\"prodigal\": 18\n\"nearer\": 19\n\"enmity\": 19\n\"Whereto\": 18\n\"steep\": 18\n\"Verg\": 18\n\"became\": 18\n\"Sometime\": 18\n\"je\": 19\n\"moan\": 19\n\"meddle\": 19\n\"Robin\": 18\n\"Urs\": 19\n\"character\": 19\n\"flock\": 18\n\"nobler\": 18\n\"raging\": 19\n\"Doug\": 19\n\"pox\": 19\n\"appeal\": 19\n\"ABBESS\": 19\n\"Ready\": 18\n\"persuaded\": 18\n\"purge\": 19\n\"sickly\": 19\n\"medicine\": 19\n\"ROBIN\": 19\n\"entrance\": 19\n\"hire\": 18\n\"sav\": 19\n\"persuasion\": 18\n\"messengers\": 18\n\"joints\": 18\n\"Grey\": 19\n\"pitied\": 18\n\"coats\": 18\n\"Phebe\": 18\n\"MAMILLIUS\": 18\n\"Sirs\": 18\n\"ancestors\": 19\n\"holp\": 19\n\"integrity\": 19\n\"lungs\": 19\n\"smoke\": 19\n\"infected\": 19\n\"HIPPOLYTA\": 19\n\"fray\": 18\n\"Use\": 19\n\"drift\": 19\n\"elbow\": 18\n\"reasonable\": 19\n\"relish\": 18\n\"rings\": 19\n\"Fenton\": 18\n\"understanding\": 18\n\"import\": 19\n\"tents\": 19\n\"bachelor\": 18\n\"windows\": 19\n\"Betwixt\": 18\n\"Judas\": 18\n\"RUGBY\": 18\n\"mart\": 18\n\"silk\": 19\n\"Greece\": 18\n\"bliss\": 18\n\"eaten\": 19\n\"chosen\": 19\n\"prologue\": 18\n\"compound\": 18\n\"bending\": 18\n\"SCROOP\": 19\n\"Meantime\": 18\n\"Hermione\": 18\n\"ashes\": 19\n\"hey\": 18\n\"trusty\": 18\n\"borrowed\": 18\n\"sullen\": 18\n\"dancing\": 18\n\"admit\": 18\n\"forlorn\": 18\n\"homicide\": 4\n\"putting\": 17\n\"diet\": 17\n\"noon\": 17\n\"devotion\": 17\n\"homage\": 17\n\"muster\": 17\n\"ebb\": 17\n\"violence\": 17\n\"witchcraft\": 17\n\"partner\": 17\n\"dangers\": 17\n\"invite\": 17\n\"sails\": 17\n\"parents\": 17\n\"market-place\": 17\n\"surpris\": 17\n\"Diana\": 17\n\"extend\": 17\n\"scourge\": 17\n\"impatience\": 17\n\"lief\": 17\n\"grain\": 17\n\"cheerful\": 17\n\"statue\": 17\n\"heel\": 17\n\"depos\": 17\n\"revenue\": 17\n\"potent\": 17\n\"Appear\": 17\n\"exploit\": 17\n\"uses\": 17\n\"noblest\": 17\n\"charitable\": 17\n\"self-same\": 17\n\"hangman\": 17\n\"jests\": 17\n\"discord\": 17\n\"humility\": 17\n\"torches\": 17\n\"slumber\": 17\n\"commodity\": 17\n\"trim\": 17\n\"dame\": 17\n\"com\": 17\n\"hind\": 17\n\"haunt\": 17\n\"baseness\": 17\n\"GUARD\": 17\n\"Lives\": 17\n\"imagine\": 17\n\"profession\": 17\n\"ADAM\": 17\n\"abhor\": 17\n\"Whence\": 17\n\"hates\": 17\n\"ribs\": 17\n\"road\": 17\n\"worser\": 17\n\"eleven\": 17\n\"nigh\": 17\n\"salute\": 17\n\"ward\": 17\n\"sober\": 17\n\"bill\": 17\n\"bait\": 17\n\"reap\": 17\n\"harvest\": 17\n\"bald\": 17\n\"wonders\": 17\n\"answered\": 17\n\"heinous\": 17\n\"quarrels\": 17\n\"COURTEZAN\": 17\n\"dire\": 17\n\"plainly\": 17\n\"Beyond\": 17\n\"reproach\": 17\n\"garment\": 17\n\"forthwith\": 17\n\"famish\": 17\n\"function\": 17\n\"scandal\": 17\n\"TRIBUNES\": 17\n\"nam\": 17\n\"Ladies\": 17\n\"brethren\": 17\n\"AEDILE\": 17\n\"pounds\": 17\n\"SERVINGMAN\": 17\n\"Prepare\": 17\n\"leading\": 17\n\"singing\": 17\n\"fixed\": 17\n\"ravish\": 17\n\"constancy\": 17\n\"stops\": 17\n\"shores\": 17\n\"linen\": 17\n\"deck\": 17\n\"Sing\": 17\n\"apprehend\": 17\n\"ado\": 17\n\"ambassador\": 17\n\"hunting\": 17\n\"tail\": 17\n\"mantle\": 17\n\"sums\": 17\n\"bounteous\": 17\n\"countryman\": 17\n\"frowns\": 17\n\"hatred\": 17\n\"Happy\": 17\n\"rue\": 17\n\"tomorrow\": 17\n\"Car\": 17\n\"Gads\": 17\n\"Thursday\": 17\n\"GENTLEMEN\": 17\n\"smallest\": 17\n\"curtain\": 17\n\"limit\": 17\n\"Monmouth\": 17\n\"worthless\": 17\n\"broad\": 17\n\"prime\": 17\n\"enrich\": 17\n\"contain\": 17\n\"Albans\": 17\n\"Fifth\": 17\n\"agree\": 17\n\"drowsy\": 17\n\"Regent\": 17\n\"removed\": 17\n\"succession\": 17\n\"LUCY\": 17\n\"painting\": 17\n\"Anjou\": 17\n\"Dover\": 17\n\"wanting\": 17\n\"prevented\": 17\n\"STAFFORD\": 17\n\"brass\": 17\n\"HUGH\": 17\n\"bethink\": 17\n\"Juno\": 17\n\"Nestor\": 17\n\"DORSET\": 17\n\"waves\": 17\n\"weed\": 17\n\"LUCILIUS\": 17\n\"honorable\": 17\n\"SIWARD\": 17\n\"race\": 17\n\"Lucio\": 17\n\"ornament\": 17\n\"bootless\": 17\n\"Stephano\": 17\n\"Haply\": 17\n\"THISBY\": 17\n\"GREEN\": 17\n\"unseen\": 17\n\"manly\": 17\n\"Cesario\": 17\n\"CAPHIS\": 17\n\"Ariel\": 17\n\"divided\": 17\n\"Tyb\": 17\n\"Benvolio\": 17\n\"sustain\": 17\n\"conceal\": 17\n\"suitors\": 17\n\"cozen\": 17\n\"encount\": 17\n\"crimes\": 17\n\"wearing\": 17\n\"fortunate\": 17\n\"ice\": 17\n\"courteous\": 17\n\"nod\": 17\n\"Mort\": 17\n\"pleases\": 17\n\"Receive\": 17\n\"ergo\": 4\n\"acknowledge\": 16\n\"MOPSA\": 16\n\"Topas\": 16\n\"Paulina\": 16\n\"FLAMINIUS\": 16\n\"Polixenes\": 16\n\"BOATSWAIN\": 16\n\"loathsome\": 16\n\"outlive\": 16\n\"scar\": 16\n\"whipp\": 16\n\"Kill\": 16\n\"fan\": 16\n\"supposed\": 16\n\"leaden\": 16\n\"Saturnine\": 16\n\"beneath\": 16\n\"thereto\": 16\n\"Jaques\": 16\n\"tainted\": 16\n\"expense\": 16\n\"marvellous\": 16\n\"ah\": 16\n\"longing\": 16\n\"female\": 16\n\"bereft\": 16\n\"composition\": 16\n\"meed\": 16\n\"lofty\": 16\n\"choke\": 16\n\"DRAMATIS\": 16\n\"despise\": 16\n\"moiety\": 16\n\"PERSONAE\": 16\n\"proves\": 16\n\"Balthasar\": 16\n\"patiently\": 16\n\"Belmont\": 16\n\"scarcely\": 16\n\"settled\": 16\n\"fifteen\": 16\n\"merciful\": 16\n\"PROCULEIUS\": 16\n\"gentleness\": 16\n\"Barnardine\": 16\n\"latter\": 16\n\"cannon\": 16\n\"feasts\": 16\n\"candle\": 16\n\"worthiness\": 16\n\"Pity\": 16\n\"envoy\": 16\n\"complain\": 16\n\"pilgrimage\": 16\n\"falsely\": 16\n\"infect\": 16\n\"confidence\": 16\n\"nuncle\": 16\n\"mocking\": 16\n\"Gainst\": 16\n\"seeking\": 16\n\"accent\": 16\n\"heap\": 16\n\"foil\": 16\n\"ample\": 16\n\"Over\": 16\n\"belong\": 16\n\"Oft\": 16\n\"wedded\": 16\n\"rising\": 16\n\"pursuit\": 16\n\"flattering\": 16\n\"vent\": 16\n\"extreme\": 16\n\"hare\": 16\n\"concluded\": 16\n\"gloves\": 16\n\"NURSE\": 16\n\"m\": 16\n\"minion\": 16\n\"Rutland\": 16\n\"inch\": 16\n\"harms\": 16\n\"hatch\": 16\n\"clown\": 16\n\"storms\": 16\n\"reports\": 16\n\"tutor\": 16\n\"alliance\": 16\n\"Antipholus\": 16\n\"bully\": 16\n\"les\": 16\n\"swelling\": 16\n\"softly\": 16\n\"tie\": 16\n\"Virtue\": 16\n\"baby\": 16\n\"PROLOGUE\": 16\n\"be-\": 16\n\"MONTJOY\": 16\n\"whereon\": 16\n\"CHORUS\": 16\n\"bail\": 16\n\"prays\": 16\n\"stirs\": 16\n\"Phoebus\": 16\n\"occasions\": 16\n\"&c\": 16\n\"motive\": 16\n\"prosper\": 16\n\"starve\": 16\n\"Westminster\": 16\n\"dram\": 16\n\"welkin\": 16\n\"Doll\": 16\n\"stabb\": 16\n\"Ursula\": 16\n\"plac\": 16\n\"experience\": 16\n\"Pomfret\": 16\n\"passions\": 16\n\"attends\": 16\n\"porter\": 16\n\"rags\": 16\n\"brawl\": 16\n\"heav\": 16\n\"Masters\": 16\n\"imprisonment\": 16\n\"empire\": 16\n\"anointed\": 16\n\"straw\": 16\n\"silken\": 16\n\"disturb\": 16\n\"howl\": 16\n\"abused\": 16\n\"description\": 16\n\"vault\": 16\n\"Bard\": 16\n\"stab\": 16\n\"GENTLEWOMAN\": 16\n\"playing\": 16\n\"Citizens\": 16\n\"bridegroom\": 16\n\"acquaint\": 16\n\"Draws\": 16\n\"assault\": 16\n\"Honour\": 16\n\"descend\": 16\n\"Canterbury\": 16\n\"horror\": 16\n\"capable\": 16\n\"lute\": 16\n\"Scot\": 16\n\"caps\": 16\n\"Julius\": 16\n\"deserving\": 16\n\"Philippi\": 16\n\"mystery\": 16\n\"overthrow\": 16\n\"gilt\": 16\n\"Heavens\": 16\n\"split\": 16\n\"judgement\": 16\n\"flatterer\": 16\n\"offers\": 16\n\"spurs\": 16\n\"visitation\": 16\n\"warriors\": 16\n\"rascals\": 16\n\"deceived\": 16\n\"arrant\": 16\n\"shout\": 16\n\"profane\": 16\n\"impatient\": 16\n\"Awake\": 16\n\"Throw\": 16\n\"brace\": 16\n\"Kneels\": 16\n\"strict\": 16\n\"Black\": 16\n\"excellence\": 16\n\"steed\": 16\n\"passes\": 16\n\"Content\": 16\n\"emperor\": 16\n\"minutes\": 16\n\"affliction\": 16\n\"corner\": 16\n\"proceedings\": 16\n\"Attend\": 16\n\"sire\": 16\n\"skull\": 16\n\"everywhere\": 16\n\"Together\": 16\n\"degrees\": 16\n\"crows\": 16\n\"owl\": 16\n\"pillow\": 16\n\"Meet\": 16\n\"distemper\": 16\n\"trembling\": 16\n\"dwells\": 16\n\"latest\": 16\n\"sweeter\": 16\n\"affected\": 16\n\"Women\": 16\n\"hush\": 16\n\"CORNELIUS\": 16\n\"rebuke\": 16\n\"fore\": 16\n\"lt\": 16\n\"assay\": 16\n\"Except\": 16\n\"Lieutenant\": 16\n\"growth\": 16\n\"yielding\": 16\n\"talents\": 16\n\"idly\": 16\n\"deeply\": 16\n\"nobody\": 16\n\"aspire\": 4\n\"compell\": 15\n\"princess\": 15\n\"horrid\": 15\n\"mutual\": 15\n\"vouch\": 15\n\"neat\": 15\n\"landed\": 15\n\"discipline\": 15\n\"undergo\": 15\n\"opportunity\": 15\n\"reported\": 15\n\"Forgive\": 15\n\"Command\": 15\n\"keys\": 15\n\"bulk\": 15\n\"Leonatus\": 15\n\"corrupted\": 15\n\"determin\": 15\n\"bands\": 15\n\"sands\": 15\n\"coast\": 15\n\"wronged\": 15\n\"bigger\": 15\n\"tempted\": 15\n\"debts\": 15\n\"flying\": 15\n\"intended\": 15\n\"wasted\": 15\n\"rated\": 15\n\"killing\": 15\n\"beautiful\": 15\n\"cudgel\": 15\n\"companions\": 15\n\"readiness\": 15\n\"crush\": 15\n\"lacks\": 15\n\"scars\": 15\n\"Yield\": 15\n\"stomachs\": 15\n\"aye\": 15\n\"gladly\": 15\n\"Henceforth\": 15\n\"grandfather\": 15\n\"worldly\": 15\n\"captains\": 15\n\"rod\": 15\n\"Italian\": 15\n\"furious\": 15\n\"ruffian\": 15\n\"obtain\": 15\n\"cradle\": 15\n\"period\": 15\n\"Kisses\": 15\n\"print\": 15\n\"Fortinbras\": 15\n\"Norway\": 15\n\"coffin\": 15\n\"fellowship\": 15\n\"False\": 15\n\"religion\": 15\n\"author\": 15\n\"inherit\": 15\n\"endeavour\": 15\n\"clamour\": 15\n\"prophet\": 15\n\"profound\": 15\n\"ballad\": 15\n\"cuckoo\": 15\n\"Four\": 15\n\"happier\": 15\n\"bank\": 15\n\"created\": 15\n\"untimely\": 15\n\"Eastcheap\": 15\n\"feature\": 15\n\"toe\": 15\n\"weal\": 15\n\"Near\": 15\n\"Christendom\": 15\n\"gage\": 15\n\"Menenius\": 15\n\"sung\": 15\n\"confine\": 15\n\"Becomes\": 15\n\"reckoning\": 15\n\"Woe\": 15\n\"tax\": 15\n\"Mercury\": 15\n\"observance\": 15\n\"reads\": 15\n\"enters\": 15\n\"priests\": 15\n\"breakfast\": 15\n\"forgotten\": 15\n\"cowardly\": 15\n\"impediment\": 15\n\"reproof\": 15\n\"slanders\": 15\n\"approaches\": 15\n\"built\": 15\n\"Knowing\": 15\n\"dislike\": 15\n\"egg\": 15\n\"rope\": 15\n\"apply\": 15\n\"Nell\": 15\n\"added\": 15\n\"toys\": 15\n\"peep\": 15\n\"revels\": 15\n\"oblivion\": 15\n\"pregnant\": 15\n\"corruption\": 15\n\"cowardice\": 15\n\"touching\": 15\n\"hides\": 15\n\"surfeit\": 15\n\"beating\": 15\n\"excursions\": 15\n\"suppos\": 15\n\"Wednesday\": 15\n\"causes\": 15\n\"warning\": 15\n\"wond\": 15\n\"Rouen\": 15\n\"que\": 15\n\"papers\": 15\n\"procure\": 15\n\"discontent\": 15\n\"Vouchsafe\": 15\n\"politic\": 15\n\"mightily\": 15\n\"curtsy\": 15\n\"AMIENS\": 15\n\"MORTIMER\": 15\n\"herd\": 15\n\"fruitful\": 15\n\"wolves\": 15\n\"thee-\": 15\n\"purpos\": 15\n\"Rivers\": 15\n\"E\": 15\n\"MAN\": 15\n\"antique\": 15\n\"Steward\": 15\n\"Dorset\": 15\n\"liver\": 15\n\"inclin\": 15\n\"Yonder\": 15\n\"dash\": 15\n\"courses\": 15\n\"paint\": 15\n\"frowning\": 15\n\"bide\": 15\n\"limb\": 15\n\"control\": 15\n\"assembly\": 15\n\"dried\": 15\n\"sugar\": 15\n\"fantastical\": 15\n\"shoe\": 15\n\"feeding\": 15\n\"usurping\": 15\n\"oppression\": 15\n\"nobleness\": 15\n\"bills\": 15\n\"wakes\": 15\n\"crept\": 15\n\"Messengers\": 15\n\"Dunsinane\": 15\n\"survey\": 15\n\"commandment\": 15\n\"MARDIAN\": 15\n\"instinct\": 15\n\"vein\": 15\n\"performance\": 15\n\"Andrew\": 15\n\"Pandarus\": 15\n\"block\": 15\n\"ridiculous\": 15\n\"FLUTE\": 15\n\"careless\": 15\n\"truer\": 15\n\"PYRAMUS\": 15\n\"highly\": 15\n\"Dispatch\": 15\n\"toad\": 15\n\"snatch\": 15\n\"woods\": 15\n\"strangers\": 15\n\"celestial\": 15\n\"Alcibiades\": 15\n\"region\": 15\n\"thorns\": 15\n\"Orsino\": 15\n\"offender\": 15\n\"Trinculo\": 15\n\"shameful\": 15\n\"kinsmen\": 15\n\"Greg\": 15\n\"homely\": 15\n\"wiser\": 15\n\"Brabantio\": 15\n\"ranks\": 15\n\"patrimony\": 4\n\"bestowed\": 14\n\"swoon\": 14\n\"disguis\": 14\n\"heal\": 14\n\"torn\": 14\n\"buds\": 14\n\"fountain\": 14\n\"boldness\": 14\n\"napkin\": 14\n\"goest\": 14\n\"states\": 14\n\"heavier\": 14\n\"amain\": 14\n\"seiz\": 14\n\"balm\": 14\n\"<Exeunt\": 14\n\"<Exit\": 14\n\"wat\": 14\n\"unruly\": 14\n\"madly\": 14\n\"truce\": 14\n\"proverb\": 14\n\"attach\": 14\n\"Arise\": 14\n\"dropp\": 14\n\"bringing\": 14\n\"attain\": 14\n\"lance\": 14\n\"diamond\": 14\n\"meanest\": 14\n\"throng\": 14\n\"distracted\": 14\n\"grim\": 14\n\"abbey\": 14\n\"coldly\": 14\n\"heaviness\": 14\n\"ADRIAN\": 14\n\"accidents\": 14\n\"steals\": 14\n\"asunder\": 14\n\"cities\": 14\n\"helps\": 14\n\"shirt\": 14\n\"vision\": 14\n\"holding\": 14\n\"suff\": 14\n\"grove\": 14\n\"superfluous\": 14\n\"prosperity\": 14\n\"rises\": 14\n\"chiefest\": 14\n\"intends\": 14\n\"proved\": 14\n\"cheap\": 14\n\"safer\": 14\n\"oppose\": 14\n\"apprehension\": 14\n\"Just\": 14\n\"detested\": 14\n\"PLEBEIANS\": 14\n\"Moon\": 14\n\"universal\": 14\n\"instruction\": 14\n\"throws\": 14\n\"boldly\": 14\n\"prate\": 14\n\"Whereon\": 14\n\"bowl\": 14\n\"oppos\": 14\n\"Cymbeline\": 14\n\"pipe\": 14\n\"circle\": 14\n\"requests\": 14\n\"owner\": 14\n\"leaf\": 14\n\"negligence\": 14\n\"pangs\": 14\n\"truant\": 14\n\"Comfort\": 14\n\"witty\": 14\n\"arras\": 14\n\"bastards\": 14\n\"groom\": 14\n\"theft\": 14\n\"yon\": 14\n\"leader\": 14\n\"security\": 14\n\"gentry\": 14\n\"believ\": 14\n\"Quite\": 14\n\"love-\": 14\n\"To-day\": 14\n\"figures\": 14\n\"insolence\": 14\n\"villainous\": 14\n\"richer\": 14\n\"threats\": 14\n\"walking\": 14\n\"pastime\": 14\n\"Gone\": 14\n\"oil\": 14\n\"confer\": 14\n\"silly\": 14\n\"rheum\": 14\n\"Thank\": 14\n\"branches\": 14\n\"descent\": 14\n\"harmless\": 14\n\"driven\": 14\n\"disguise\": 14\n\"Gertrude\": 14\n\"address\": 14\n\"lists\": 14\n\"sweets\": 14\n\"Whate\": 14\n\"Murther\": 14\n\"stockings\": 14\n\"knocking\": 14\n\"agreed\": 14\n\"Honest\": 14\n\"indifferent\": 14\n\"airy\": 14\n\"is-\": 14\n\"Vernon\": 14\n\"Chief\": 14\n\"affords\": 14\n\"footing\": 14\n\"ale\": 14\n\"hinder\": 14\n\"allay\": 14\n\"Got\": 14\n\"melted\": 14\n\"highest\": 14\n\"Knight\": 14\n\"Ver\": 14\n\"haughty\": 14\n\"studied\": 14\n\"proudest\": 14\n\"worthier\": 14\n\"assistance\": 14\n\"keeper\": 14\n\"penitent\": 14\n\"giant\": 14\n\"moreover\": 14\n\"parliament\": 14\n\"sauce\": 14\n\"underneath\": 14\n\"extremes\": 14\n\"husbandry\": 14\n\"remov\": 14\n\"eunuch\": 14\n\"dim\": 14\n\"now-\": 14\n\"admirable\": 14\n\"revel\": 14\n\"clay\": 14\n\"Pucelle\": 14\n\"infirmity\": 14\n\"dignities\": 14\n\"Reignier\": 14\n\"accursed\": 14\n\"relent\": 14\n\"idleness\": 14\n\"Fore\": 14\n\"Brave\": 14\n\"Forbear\": 14\n\"Enobarbus\": 14\n\"laughing\": 14\n\"Thunder\": 14\n\"defeat\": 14\n\"million\": 14\n\"fertile\": 14\n\"GRIFFITH\": 14\n\"BIGOT\": 14\n\"bone\": 14\n\"Last\": 14\n\"waiting\": 14\n\"Pindarus\": 14\n\"port\": 14\n\"Light\": 14\n\"powerful\": 14\n\"marble\": 14\n\"bud\": 14\n\"provoke\": 14\n\"revenges\": 14\n\"CANIDIUS\": 14\n\"tokens\": 14\n\"property\": 14\n\"branch\": 14\n\"gravity\": 14\n\"trifles\": 14\n\"Rugby\": 14\n\"SNOUT\": 14\n\"assured\": 14\n\"embassy\": 14\n\"naughty\": 14\n\"starts\": 14\n\"farthest\": 14\n\"losses\": 14\n\"proofs\": 14\n\"TYRREL\": 14\n\"forced\": 14\n\"riot\": 14\n\"Mus\": 14\n\"stead\": 14\n\"Pisa\": 14\n\"TAILOR\": 14\n\"hunger\": 14\n\"ANDREW\": 14\n\"Cressida\": 14\n\"DORCAS\": 14\n\"PRIAM\": 14\n\"lame\": 14\n\"FOOL\": 14\n\"ATHENIAN\": 14\n\"excess\": 14\n\"Falls\": 14\n\"churlish\": 14\n\"turning\": 14\n\"array\": 14\n\"fantasy\": 14\n\"devour\": 14\n\"Wear\": 14\n\"philosophy\": 14\n\"damnation\": 14\n\"Dumain\": 14\n\"admitted\": 14\n\"beginning\": 14\n\"knavery\": 14\n\"couple\": 14\n\"fawn\": 14\n\"insinuating\": 4\n\"adverse\": 12\n\"Kneeling\": 12\n\"especially\": 12\n\"shroud\": 12\n\"file\": 13\n\"engag\": 13\n\"BANDIT\": 12\n\"fully\": 12\n\"project\": 12\n\"SERVILIUS\": 13\n\"caitiff\": 12\n\"relief\": 13\n\"Parolles\": 12\n\"Prospero\": 13\n\"prompt\": 13\n\"charges\": 13\n\"plants\": 12\n\"Biondello\": 12\n\"curious\": 12\n\"saints\": 12\n\"wilful\": 12\n\"CURIO\": 12\n\"worthiest\": 13\n\"bloods\": 13\n\"size\": 12\n\"relieve\": 12\n\"earn\": 13\n\"frighted\": 12\n\"Illyria\": 13\n\"triumphant\": 13\n\"CARLISLE\": 12\n\"WILLOUGHBY\": 12\n\"BAGOT\": 13\n\"Approach\": 13\n\"personal\": 13\n\"directed\": 13\n\"Gracious\": 13\n\"schoolmaster\": 12\n\"jump\": 13\n\"Friends\": 12\n\"Perhaps\": 13\n\"Borachio\": 12\n\"abundance\": 13\n\"Bottom\": 13\n\"troubles\": 13\n\"counsellor\": 13\n\"summon\": 12\n\"son-in-law\": 12\n\"Theseus\": 13\n\"PHILOSTRATE\": 12\n\"pattern\": 13\n\"meantime\": 12\n\"appearance\": 13\n\"Sits\": 12\n\"bate\": 13\n\"chat\": 12\n\"sith\": 12\n\"nail\": 12\n\"lasting\": 13\n\"digest\": 12\n\"complaint\": 13\n\"smother\": 12\n\"tables\": 13\n\"commends\": 13\n\"drunkard\": 13\n\"reckon\": 13\n\"suffice\": 13\n\"earl\": 13\n\"Been\": 13\n\"tenderness\": 13\n\"mast\": 12\n\"clapp\": 13\n\"mounted\": 13\n\"winged\": 12\n\"jade\": 13\n\"JULIET\": 13\n\"mangled\": 13\n\"Towards\": 12\n\"ache\": 12\n\"lik\": 12\n\"Thither\": 12\n\"gild\": 13\n\"twould\": 13\n\"Fleance\": 13\n\"Lennox\": 12\n\"Donalbain\": 12\n\"deem\": 12\n\"Parson\": 13\n\"victorious\": 12\n\"Boyet\": 12\n\"Costard\": 13\n\"Gave\": 13\n\"Teach\": 13\n\"Shame\": 13\n\"Off\": 12\n\"gloss\": 12\n\"blushes\": 12\n\"motions\": 13\n\"squire\": 13\n\"Navarre\": 12\n\"questions\": 12\n\"broils\": 12\n\"plainness\": 12\n\"cheese\": 13\n\"male\": 12\n\"lowly\": 13\n\"levied\": 12\n\"Spain\": 12\n\"feats\": 13\n\"attire\": 13\n\"renew\": 13\n\"discontented\": 13\n\"plight\": 12\n\"meets\": 12\n\"banks\": 13\n\"Again\": 12\n\"shrew\": 13\n\"Consider\": 13\n\"Trebonius\": 12\n\"hound\": 12\n\"Metellus\": 13\n\"blast\": 12\n\"inheritance\": 12\n\"beest\": 12\n\"immediately\": 13\n\"distraction\": 12\n\"lunatic\": 12\n\"Decius\": 13\n\"Cold\": 12\n\"Looking\": 12\n\"fitted\": 13\n\"suffers\": 12\n\"eyelids\": 13\n\"deeper\": 12\n\"DECIUS\": 13\n\"finish\": 12\n\"casket\": 13\n\"Marcellus\": 12\n\"scroll\": 13\n\"meaner\": 13\n\"Looks\": 12\n\"BLANCH\": 13\n\"VENTIDIUS\": 13\n\"tired\": 13\n\"mended\": 12\n\"Faulconbridge\": 12\n\"liar\": 12\n\"ecstasy\": 12\n\"frenzy\": 12\n\"flames\": 12\n\"frantic\": 13\n\"copy\": 13\n\"sanctuary\": 13\n\"permit\": 13\n\"continent\": 12\n\"approved\": 12\n\"contend\": 13\n\"outrage\": 12\n\"stray\": 12\n\"provok\": 12\n\"WATCHMAN\": 13\n\"Dido\": 13\n\"Bona\": 13\n\"Ventidius\": 12\n\"pestilence\": 13\n\"Menelaus\": 13\n\"rabble\": 12\n\"cords\": 12\n\"During\": 12\n\"Turning\": 12\n\"Stabs\": 13\n\"Thrice\": 12\n\"gaoler\": 12\n\"frost\": 12\n\"parties\": 13\n\"whereupon\": 12\n\"events\": 13\n\"decrees\": 12\n\"imperious\": 12\n\"fence\": 12\n\"immediate\": 13\n\"discharg\": 13\n\"succeed\": 12\n\"commendations\": 13\n\"Eleanor\": 12\n\"mate\": 12\n\"future\": 13\n\"whatsoever\": 13\n\"IDEN\": 12\n\"fights\": 12\n\"HUME\": 13\n\"patricians\": 13\n\"tire\": 12\n\"champion\": 13\n\"regal\": 12\n\"crime\": 12\n\"monsters\": 12\n\"ling\": 13\n\"notorious\": 13\n\"mortality\": 13\n\"Touching\": 12\n\"chains\": 12\n\"adore\": 13\n\"gazing\": 13\n\"resolved\": 13\n\"element\": 12\n\"square\": 13\n\"moody\": 12\n\"Hecuba\": 13\n\"weighty\": 13\n\"Beaufort\": 13\n\"pot\": 13\n\"kneels\": 12\n\"Bastard\": 13\n\"sham\": 13\n\"so-\": 13\n\"father-\": 12\n\"mouse\": 13\n\"reserv\": 12\n\"simplicity\": 13\n\"captive\": 13\n\"inquire\": 12\n\"asking\": 12\n\"achieve\": 13\n\"entreaty\": 12\n\"Frenchman\": 13\n\"adder\": 13\n\"bankrupt\": 12\n\"lively\": 12\n\"trod\": 12\n\"studies\": 12\n\"lustre\": 12\n\"peradventure\": 12\n\"numb\": 12\n\"practices\": 13\n\"Wert\": 13\n\"necessities\": 12\n\"approbation\": 13\n\"surgeon\": 13\n\"ALEXANDER\": 13\n\"receives\": 12\n\"afflict\": 12\n\"leek\": 13\n\"rehearse\": 13\n\"West\": 13\n\"jades\": 12\n\"secrecy\": 13\n\"disgrac\": 12\n\"Florentine\": 13\n\"alms\": 12\n\"endur\": 12\n\"Dieu\": 12\n\"handsome\": 13\n\"Fluellen\": 12\n\"Calais\": 12\n\"ordinary\": 12\n\"cull\": 12\n\"vilely\": 13\n\"Half\": 13\n\"nourish\": 13\n\"beguil\": 13\n\"sow\": 13\n\"Dukes\": 13\n\"upward\": 12\n\"peremptory\": 12\n\"warrior\": 13\n\"tenour\": 13\n\"privy\": 12\n\"Grant\": 12\n\"Cambridge\": 12\n\"drives\": 12\n\"rightful\": 13\n\"Third\": 12\n\"tween\": 12\n\"diadem\": 13\n\"Any\": 13\n\"accusation\": 13\n\"dower\": 12\n\"omit\": 13\n\"nearest\": 12\n\"den\": 13\n\"TWO\": 12\n\"bars\": 13\n\"presented\": 13\n\"contains\": 12\n\"follower\": 12\n\"Rowland\": 12\n\"offense\": 12\n\"Audrey\": 13\n\"Past\": 12\n\"carrion\": 12\n\"badge\": 13\n\"admiration\": 12\n\"temples\": 13\n\"stiff\": 13\n\"bath\": 12\n\"miscarry\": 13\n\"Coming\": 13\n\"churchyard\": 12\n\"fancies\": 12\n\"wrathful\": 13\n\"awak\": 12\n\"Holy\": 13\n\"Name\": 13\n\"Inn\": 12\n\"fold\": 12\n\"voluntary\": 12\n\"prophecy\": 12\n\"capital\": 13\n\"Surrey\": 13\n\"produce\": 13\n\"handle\": 12\n\"hurl\": 12\n\"loins\": 12\n\"dial\": 12\n\"Corporal\": 12\n\"Singing\": 13\n\"Gower\": 12\n\"chances\": 13\n\"secretly\": 12\n\"MARSHAL\": 13\n\"SOLDIERS\": 12\n\"lechery\": 13\n\"infamy\": 12\n\"notable\": 13\n\"progress\": 13\n\"resolute\": 12\n\"deriv\": 12\n\"payment\": 12\n\"vast\": 13\n\"changing\": 12\n\"whate\": 12\n\"feathers\": 12\n\"arts\": 13\n\"shop\": 13\n\"wrinkles\": 12\n\"beards\": 13\n\"sayest\": 12\n\"stabs\": 12\n\"foolery\": 12\n\"plots\": 13\n\"fiends\": 13\n\"follies\": 13\n\"epitaph\": 12\n\"thumb\": 12\n\"devis\": 12\n\"pigeons\": 13\n\"tardy\": 13\n\"peer\": 13\n\"rages\": 12\n\"Marshal\": 13\n\"marr\": 12\n\"longs\": 12\n\"Coventry\": 12\n\"scale\": 13\n\"enforced\": 13\n\"stool\": 13\n\"confin\": 13\n\"wi\": 12\n\"dismay\": 13\n\"all-\": 12\n\"calling\": 13\n\"advanc\": 12\n\"nativity\": 13\n\"habits\": 12\n\"fram\": 12\n\"blank\": 13\n\"Sometimes\": 13\n\"musician\": 12\n\"exceed\": 12\n\"applause\": 12\n\"Confess\": 12\n\"humorous\": 12\n\"basest\": 13\n\"feeds\": 12\n\"lime\": 12\n\"holiday\": 13\n\"recreant\": 13\n\"Kind\": 12\n\"Rich\": 12\n\"mute\": 13\n\"threaten\": 12\n\"speechless\": 12\n\"songs\": 12\n\"ensue\": 13\n\"returns\": 13\n\"mistrust\": 12\n\"swim\": 12\n\"likelihood\": 13\n\"richly\": 13\n\"Yourself\": 12\n\"turned\": 12\n\"parcel\": 12\n\"Best\": 13\n\"publish\": 12\n\"abominable\": 12\n\"dissembling\": 12\n\"requires\": 12\n\"praised\": 13\n\"protection\": 13\n\"Puts\": 12\n\"penalty\": 12\n\"greatly\": 12\n\"Gadshill\": 13\n\"daring\": 12\n\"butt\": 13\n\"Scroop\": 12\n\"Foul\": 12\n\"ages\": 13\n\"lamentable\": 13\n\"fasting\": 13\n\"crooked\": 12\n\"centre\": 12\n\"debate\": 13\n\"faster\": 13\n\"model\": 13\n\"contemplation\": 12\n\"repeal\": 12\n\"somewhat\": 13\n\"hop\": 12\n\"merriment\": 13\n\"brag\": 13\n\"sheet\": 12\n\"judgments\": 13\n\"Base\": 13\n\"Cries\": 12\n\"linger\": 12\n\"neglected\": 12\n\"purchas\": 12\n\"coffers\": 12\n\"instead\": 13\n\"Pole\": 12\n\"Capt\": 12\n\"betters\": 12\n\"succour\": 13\n\"Gallia\": 13\n\"OTHERS\": 12\n\"talks\": 13\n\"plucks\": 13\n\"wring\": 12\n\"rests\": 12\n\"daggers\": 13\n\"quake\": 12\n\"taper\": 12\n\"amazement\": 12\n\"coil\": 12\n\"hurts\": 13\n\"Rise\": 13\n\"crimson\": 12\n\"musicians\": 13\n\"steeds\": 13\n\"arrows\": 13\n\"guts\": 13\n\"CLEOMENES\": 13\n\"dishes\": 13\n\"cue\": 12\n\"Head\": 12\n\"restraint\": 13\n\"tyrannous\": 12\n\"shelter\": 13\n\"throughly\": 12\n\"waist\": 13\n\"compact\": 13\n\"fact\": 12\n\"sorts\": 13\n\"depend\": 13\n\"opinions\": 13\n\"girls\": 13\n\"Spare\": 12\n\"noses\": 12\n\"subscribe\": 12\n\"hedge\": 13\n\"Rey\": 13\n\"executioner\": 12\n\"manifest\": 12\n\"Himself\": 12\n\"bells\": 12\n\"this-\": 13\n\"Health\": 12\n\"rode\": 13\n\"sepulchre\": 12\n\"err\": 12\n\"afore\": 12\n\"sixth\": 12\n\"purple\": 12\n\"lily\": 13\n\"yesternight\": 12\n\"plagues\": 13\n\"Seem\": 13\n\"Eve\": 12\n\"Dare\": 13\n\"actor\": 12\n\"affair\": 12\n\"wisest\": 13\n\"curb\": 13\n\"clap\": 12\n\"twelvemonth\": 13\n\"different\": 12\n\"despis\": 12\n\"gav\": 13\n\"philosopher\": 12\n\"wrinkled\": 12\n\"briefly\": 13\n\"toy\": 13\n\"raw\": 12\n\"tiger\": 13\n\"Chamberlain\": 12\n\"mansion\": 13\n\"understood\": 12\n\"vices\": 12\n\"East\": 12\n\"seasons\": 12\n\"receipt\": 12\n\"resort\": 12\n\"quantity\": 13\n\"enforc\": 13\n\"perilous\": 13\n\"yields\": 12\n\"Sent\": 12\n\"posts\": 12\n\"leaving\": 13\n\"lambs\": 13\n\"tavern\": 13\n\"discovery\": 12\n\"testimony\": 13\n\"monsieur\": 12\n\"Latin\": 12\n\"assist\": 13\n\"spacious\": 12\n\"wretches\": 12\n\"taint\": 13\n\"Deny\": 13\n\"descry\": 4\n\"Fell\": 11\n\"Fight\": 11\n\"debtor\": 11\n\"beauties\": 11\n\"recount\": 11\n\"rushes\": 11\n\"disorder\": 11\n\"madmen\": 11\n\"thrift\": 11\n\"Messina\": 11\n\"boon\": 11\n\"Back\": 11\n\"weaker\": 11\n\"mingle\": 11\n\"feign\": 11\n\"Rosalinde\": 11\n\"usage\": 11\n\"veil\": 11\n\"usurer\": 11\n\"unlike\": 11\n\"jaws\": 11\n\"spot\": 11\n\"avouch\": 11\n\"plenty\": 11\n\"malady\": 11\n\"treble\": 11\n\"chambers\": 11\n\"gap\": 11\n\"horsemen\": 11\n\"assume\": 11\n\"downright\": 11\n\"gape\": 11\n\"tapster\": 11\n\"opposed\": 11\n\"shining\": 11\n\"Agrippa\": 11\n\"stare\": 11\n\"doting\": 11\n\"slipp\": 11\n\"Stoop\": 11\n\"decree\": 11\n\"rumour\": 11\n\"wary\": 11\n\"proudly\": 11\n\"sweep\": 11\n\"pasture\": 11\n\"antic\": 11\n\"sans\": 11\n\"beshrew\": 11\n\"depends\": 11\n\"circumstances\": 11\n\"Words\": 11\n\"Sblood\": 11\n\"merits\": 11\n\"laying\": 11\n\"preferr\": 11\n\"Pyrrhus\": 11\n\"bawdy\": 11\n\"scarlet\": 11\n\"ornaments\": 11\n\"villanous\": 11\n\"Vienna\": 11\n\"Hecate\": 11\n\"particulars\": 11\n\"ports\": 11\n\"unmannerly\": 11\n\"crafty\": 11\n\"seated\": 11\n\"Proclaim\": 11\n\"exquisite\": 11\n\"importune\": 11\n\"wages\": 11\n\"mew\": 11\n\"trow\": 11\n\"agent\": 11\n\"tak\": 11\n\"spoils\": 11\n\"needless\": 11\n\"villany\": 11\n\"lends\": 11\n\"frank\": 11\n\"eloquence\": 11\n\"shrink\": 11\n\"protect\": 11\n\"plenteous\": 11\n\"Spoke\": 11\n\"outside\": 11\n\"Jerusalem\": 11\n\"shakes\": 11\n\"Hearing\": 11\n\"purses\": 11\n\"jealousies\": 11\n\"jerkin\": 11\n\"Musicians\": 11\n\"sinful\": 11\n\"appoint\": 11\n\"springs\": 11\n\"affects\": 11\n\"pronounc\": 11\n\"Troyans\": 11\n\"restrain\": 11\n\"sixpence\": 11\n\"amazed\": 11\n\"inches\": 11\n\"Albeit\": 11\n\"overthrown\": 11\n\"lewd\": 11\n\"entreaties\": 11\n\"cloudy\": 11\n\"Gloucestershire\": 11\n\"son-\": 11\n\"greets\": 11\n\"frailty\": 11\n\"beef\": 11\n\"beam\": 11\n\"adversaries\": 11\n\"breathes\": 11\n\"necks\": 11\n\"chivalry\": 11\n\"pricks\": 11\n\"territories\": 11\n\"broach\": 11\n\"Stafford\": 11\n\"Banish\": 11\n\"pleaseth\": 11\n\"clamorous\": 11\n\"disperse\": 11\n\"dealing\": 11\n\"Worthies\": 11\n\"Egyptian\": 11\n\"Stood\": 11\n\"Begin\": 11\n\"text\": 11\n\"ox\": 11\n\"watchful\": 11\n\"rein\": 11\n\"solemnity\": 11\n\"sixteen\": 11\n\"respected\": 11\n\"leather\": 11\n\"impart\": 11\n\"balls\": 11\n\"Church\": 11\n\"fills\": 11\n\"Thyself\": 11\n\"surly\": 11\n\"Britaine\": 11\n\"glories\": 11\n\"rub\": 11\n\"Harfleur\": 11\n\"entreated\": 11\n\"devilish\": 11\n\"mockery\": 11\n\"SIXTH\": 11\n\"motley\": 11\n\"void\": 11\n\"trusted\": 11\n\"faithfully\": 11\n\"entrails\": 11\n\"snake\": 11\n\"defect\": 11\n\"Bedford\": 11\n\"Become\": 11\n\"Seeing\": 11\n\"dishonest\": 11\n\"generally\": 11\n\"detain\": 11\n\"folks\": 11\n\"member\": 11\n\"signal\": 11\n\"mingled\": 11\n\"doubts\": 11\n\"flatterers\": 11\n\"map\": 11\n\"web\": 11\n\"floods\": 11\n\"ambassadors\": 11\n\"stirr\": 11\n\"imitate\": 11\n\"BASSET\": 11\n\"valued\": 11\n\"fickle\": 11\n\"Leaving\": 11\n\"Cato\": 11\n\"SERVING-MAN\": 11\n\"apes\": 11\n\"armies\": 11\n\"Parliament\": 11\n\"bolt\": 11\n\"objects\": 11\n\"pupil\": 11\n\"grac\": 11\n\"crutch\": 11\n\"traveller\": 11\n\"quaint\": 11\n\"fourth\": 11\n\"Trumpet\": 11\n\"paltry\": 11\n\"balance\": 11\n\"sever\": 11\n\"rivers\": 11\n\"malicious\": 11\n\"support\": 11\n\"infancy\": 11\n\"ruthless\": 11\n\"suffering\": 11\n\"Friend\": 11\n\"WHITMORE\": 11\n\"Ephesus\": 11\n\"SMITH\": 11\n\"vanquish\": 11\n\"goldsmith\": 11\n\"mates\": 11\n\"formal\": 11\n\"hiss\": 11\n\"pearls\": 11\n\"gossip\": 11\n\"midwife\": 11\n\"lightly\": 11\n\"comfortable\": 11\n\"unlawful\": 11\n\"-and\": 11\n\"Free\": 11\n\"arguments\": 11\n\"EUPHRONIUS\": 11\n\"ghosts\": 11\n\"Katharine\": 11\n\"dishonoured\": 11\n\"SURVEYOR\": 11\n\"Graces\": 11\n\"wildly\": 11\n\"impeach\": 11\n\"controversy\": 11\n\"tower\": 11\n\"plebeians\": 11\n\"speedily\": 11\n\"belief\": 11\n\"abject\": 11\n\"exclaim\": 11\n\"Mercy\": 11\n\"vigour\": 11\n\"enrag\": 11\n\"labouring\": 11\n\"M\": 11\n\"TITINIUS\": 11\n\"repeat\": 11\n\"unfortunate\": 11\n\"Cicero\": 11\n\"EPILOGUE\": 11\n\"denies\": 11\n\"favor\": 11\n\"stealing\": 11\n\"inclination\": 11\n\"Cimber\": 11\n\"arrested\": 11\n\"brazen\": 11\n\"statutes\": 11\n\"abhorr\": 11\n\"bitterness\": 11\n\"capacity\": 11\n\"interim\": 11\n\"indignation\": 11\n\"inconstant\": 11\n\"revolted\": 11\n\"compliment\": 11\n\"daylight\": 11\n\"Ill\": 11\n\"midst\": 11\n\"magic\": 11\n\"Armado\": 11\n\"Longaville\": 11\n\"fowl\": 11\n\"spies\": 11\n\"continual\": 11\n\"altar\": 11\n\"Birnam\": 11\n\"FROTH\": 11\n\"FRIAR\": 11\n\"Froth\": 11\n\"Venetian\": 11\n\"chooseth\": 11\n\"truest\": 11\n\"desp\": 11\n\"Stop\": 11\n\"sap\": 11\n\"Doubt\": 11\n\"Nan\": 11\n\"FAIRY\": 11\n\"EGEUS\": 11\n\"crystal\": 11\n\"concern\": 11\n\"prating\": 11\n\"famine\": 11\n\"contracted\": 11\n\"heavily\": 11\n\"designs\": 11\n\"subdu\": 11\n\"Eglamour\": 11\n\"strings\": 11\n\"entreats\": 11\n\"retires\": 11\n\"EXTON\": 11\n\"Leontes\": 11\n\"ague\": 11\n\"sending\": 11\n\"salve\": 11\n\"Muse\": 11\n\"streams\": 11\n\"WIFE\": 11\n\"knell\": 11\n\"ANDRONICUS\": 11\n\"Wast\": 11\n\"despised\": 11\n\"EGLAMOUR\": 11\n\"Haven\": 11\n\"med\": 11\n\"baser\": 11\n\"images\": 11\n\"Shake\": 11\n\"reigns\": 11\n\"offenders\": 11\n\"Antenor\": 11\n\"sinners\": 4\n\"calamity\": 10\n\"examine\": 10\n\"geese\": 10\n\"deformed\": 10\n\"Seems\": 10\n\"tabor\": 10\n\"wave\": 10\n\"sports\": 10\n\"dice\": 10\n\"Worse\": 10\n\"incens\": 10\n\"heave\": 10\n\"impression\": 10\n\"sweetheart\": 10\n\"brand\": 10\n\"bout\": 10\n\"CAPTAINS\": 10\n\"worships\": 10\n\"stairs\": 10\n\"overcame\": 10\n\"Tears\": 10\n\"stinking\": 10\n\"ingrateful\": 10\n\"oppress\": 10\n\"wickedness\": 10\n\"breathless\": 10\n\"channel\": 10\n\"perfume\": 10\n\"litter\": 10\n\"allowance\": 10\n\"mould\": 10\n\"volume\": 10\n\"tribe\": 10\n\"Barbary\": 10\n\"swallowed\": 10\n\"VOLSCE\": 10\n\"Join\": 10\n\"worthily\": 10\n\"Mad\": 10\n\"Twould\": 10\n\"saving\": 10\n\"Mount\": 10\n\"emulation\": 10\n\"imprison\": 10\n\"breasts\": 10\n\"ashore\": 10\n\"rashness\": 10\n\"tickle\": 10\n\"disloyal\": 10\n\"admittance\": 10\n\"winking\": 10\n\"murderers\": 10\n\"Europe\": 10\n\"Britons\": 10\n\"pageant\": 10\n\"girdle\": 10\n\"pious\": 10\n\"Kings\": 10\n\"Bearing\": 10\n\"smells\": 10\n\"falcon\": 10\n\"Amongst\": 10\n\"throwing\": 10\n\"duteous\": 10\n\"chapel\": 10\n\"path\": 10\n\"dirt\": 10\n\"Courage\": 10\n\"Fidele\": 10\n\"probable\": 10\n\"spider\": 10\n\"traffic\": 10\n\"harder\": 10\n\"death-\": 10\n\"cabin\": 10\n\"lane\": 10\n\"slaught\": 10\n\"Silvius\": 10\n\"dwelling\": 10\n\"knives\": 10\n\"trot\": 10\n\"lazy\": 10\n\"minded\": 10\n\"cloth\": 10\n\"ominous\": 10\n\"grand\": 10\n\"fist\": 10\n\"gets\": 10\n\"Whoever\": 10\n\"cedar\": 10\n\"sympathy\": 10\n\"rat\": 10\n\"Irish\": 10\n\"accurs\": 10\n\"errors\": 10\n\"slender\": 10\n\"market\": 10\n\"forfend\": 10\n\"wonted\": 10\n\"lascivious\": 10\n\"mutton\": 10\n\"ewes\": 10\n\"Kneel\": 10\n\"Players\": 10\n\"accordingly\": 10\n\"Sister\": 10\n\"parle\": 10\n\"crew\": 10\n\"apple\": 10\n\"infants\": 10\n\"capon\": 10\n\"generous\": 10\n\"creation\": 10\n\"observation\": 10\n\"bias\": 10\n\"pleased\": 10\n\"syllable\": 10\n\"actors\": 10\n\"tragedy\": 10\n\"frankly\": 10\n\"Goes\": 10\n\"waits\": 10\n\"whet\": 10\n\"yard\": 10\n\"hearers\": 10\n\"Dull\": 10\n\"applaud\": 10\n\"obscure\": 10\n\"coronet\": 10\n\"muddy\": 10\n\"argues\": 10\n\"cases\": 10\n\"boist\": 10\n\"purity\": 10\n\"yeoman\": 10\n\"Left\": 10\n\"mess\": 10\n\"extremest\": 10\n\"commended\": 10\n\"confines\": 10\n\"dearth\": 10\n\"New\": 10\n\"mistaking\": 10\n\"bites\": 10\n\"chiding\": 10\n\"plains\": 10\n\"teaching\": 10\n\"will-\": 10\n\"shillings\": 10\n\"griev\": 10\n\"smil\": 10\n\"murdered\": 10\n\"Nicholas\": 10\n\"Thieves\": 10\n\"cleave\": 10\n\"goodman\": 10\n\"cousins\": 10\n\"modern\": 10\n\"say-\": 10\n\"Paul\": 10\n\"stratagem\": 10\n\"painter\": 10\n\"compulsion\": 10\n\"Desire\": 10\n\"submission\": 10\n\"defiance\": 10\n\"degenerate\": 10\n\"withered\": 10\n\"descended\": 10\n\"Quick\": 10\n\"publicly\": 10\n\"challeng\": 10\n\"gorgeous\": 10\n\"link\": 10\n\"repute\": 10\n\"advantages\": 10\n\"Le\": 10\n\"Gregory\": 10\n\"boat\": 10\n\"members\": 10\n\"FRANCIS\": 10\n\"Commit\": 10\n\"listen\": 10\n\"stealth\": 10\n\"ingenious\": 10\n\"ad\": 10\n\"wrestling\": 10\n\"Holla\": 10\n\"glance\": 10\n\"Prick\": 10\n\"substitute\": 10\n\"generation\": 10\n\"dispers\": 10\n\"Forest\": 10\n\"rascally\": 10\n\"canopy\": 10\n\"chiefly\": 10\n\"Bertram\": 10\n\"dunghill\": 10\n\"STEWARD\": 10\n\"boughs\": 10\n\"shrewdly\": 10\n\"puissant\": 10\n\"Took\": 10\n\"bedfellow\": 10\n\"conspiracy\": 10\n\"charged\": 10\n\"expressly\": 10\n\"bridge\": 10\n\"assembled\": 10\n\"hanged\": 10\n\"biting\": 10\n\"doomsday\": 10\n\"scald\": 10\n\"ceremonies\": 10\n\"greasy\": 10\n\"Rest\": 10\n\"merchants\": 10\n\"gallants\": 10\n\"peaceful\": 10\n\"Tarry\": 10\n\"tongue-tied\": 10\n\"arch\": 10\n\"plate\": 10\n\"barr\": 10\n\"Bordeaux\": 10\n\"remainder\": 10\n\"Escalus\": 10\n\"slack\": 10\n\"pursu\": 10\n\"commonweal\": 10\n\"grudge\": 10\n\"orb\": 10\n\"lighted\": 10\n\"factious\": 10\n\"beggary\": 10\n\"caus\": 10\n\"transform\": 10\n\"desolation\": 10\n\"ungentle\": 10\n\"sleepy\": 10\n\"wealthy\": 10\n\"its\": 10\n\"mirror\": 10\n\"lamentation\": 10\n\"dotage\": 10\n\"gear\": 10\n\"trash\": 10\n\"belie\": 10\n\"drugs\": 10\n\"strangeness\": 10\n\"POST\": 10\n\"frozen\": 10\n\"elsewhere\": 10\n\"HUNTSMAN\": 10\n\"blade\": 10\n\"sphere\": 10\n\"Cast\": 10\n\"froward\": 10\n\"shriek\": 10\n\"BRANDON\": 10\n\"incense\": 10\n\"prepared\": 10\n\"Found\": 10\n\"blemish\": 10\n\"Griffith\": 10\n\"CHILD\": 10\n\"Avaunt\": 10\n\"spell\": 10\n\"Geffrey\": 10\n\"Blanch\": 10\n\"appointment\": 10\n\"AEMILIUS\": 10\n\"hills\": 10\n\"drooping\": 10\n\"powder\": 10\n\"Calpurnia\": 10\n\"honors\": 10\n\"poisonous\": 10\n\"humor\": 10\n\"PUBLIUS\": 10\n\"forever\": 10\n\"nightingale\": 10\n\"ending\": 10\n\"getting\": 10\n\"submit\": 10\n\"swifter\": 10\n\"heath\": 10\n\"Fairies\": 10\n\"loathed\": 10\n\"occupation\": 10\n\"evidence\": 10\n\"dig\": 10\n\"besiege\": 10\n\"cow\": 10\n\"Walk\": 10\n\"winters\": 10\n\"companies\": 10\n\"orator\": 10\n\"Heard\": 10\n\"Nathaniel\": 10\n\"BARNARDINE\": 10\n\"fooling\": 10\n\"meal\": 10\n\"TUBAL\": 10\n\"Brought\": 10\n\"commander\": 10\n\"quest\": 10\n\"Led\": 10\n\"Balth\": 10\n\"reputed\": 10\n\"Lodovico\": 10\n\"peck\": 10\n\"Ratcliff\": 10\n\"stings\": 10\n\"Mon\": 10\n\"Urge\": 10\n\"bondman\": 10\n\"Pet\": 10\n\"labours\": 10\n\"rewards\": 10\n\"Caliban\": 10\n\"JEWELLER\": 10\n\"pilgrim\": 10\n\"madonna\": 10\n\"6\": 10\n\"Lucetta\": 10\n\"influence\": 10\n\"Strange\": 10\n\"sonnet\": 10\n\"wins\": 10\n\"excus\": 10\n\"headstrong\": 10\n\"abuses\": 10\n\"fret\": 10\n\"Beats\": 10\n\"dally\": 10\n\"embrac\": 10\n\"beads\": 10\n\"consort\": 10\n\"Small\": 10\n\"leagues\": 10\n\"sailors\": 10\n\"shrift\": 10\n\"fifth\": 10\n\"buck\": 10\n\"rout\": 10\n\"Far\": 10\n\"damnable\": 10\n\"globe\": 10\n\"scarf\": 10\n\"whe\": 10\n\"simply\": 10\n\"wayward\": 10\n\"served\": 10\n\"vexation\": 10\n\"restor\": 10\n\"happen\": 10\n\"Renowned\": 10\n\"verity\": 10\n\"Antium\": 10\n\"palate\": 10\n\"TUTOR\": 4\n\"braggart\": 9\n\"effected\": 9\n\"delivers\": 9\n\"incensed\": 9\n\"thorn\": 9\n\"RUTLAND\": 9\n\"impress\": 9\n\"bows\": 9\n\"Tullus\": 9\n\"Fourth\": 9\n\"Perdita\": 9\n\"ARCHIDAMUS\": 9\n\"odious\": 9\n\"tapers\": 9\n\"desired\": 9\n\"halt\": 9\n\"hopeful\": 9\n\"budge\": 9\n\"hook\": 9\n\"stumble\": 9\n\"conflict\": 9\n\"fishes\": 9\n\"Officer\": 9\n\"DION\": 9\n\"Haste\": 9\n\"fortnight\": 9\n\"shouts\": 9\n\"tow\": 9\n\"blaze\": 9\n\"SHERIFF\": 9\n\"draught\": 9\n\"compel\": 9\n\"Senators\": 9\n\"widows\": 9\n\"tyrants\": 9\n\"Volscian\": 9\n\"crab\": 9\n\"visited\": 9\n\"alteration\": 9\n\"commendation\": 9\n\"puff\": 9\n\"Marquis\": 9\n\"dames\": 9\n\"cuts\": 9\n\"Owen\": 9\n\"comment\": 9\n\"tops\": 9\n\"Pembroke\": 9\n\"gnaw\": 9\n\"thunders\": 9\n\"hay\": 9\n\"mum\": 9\n\"flinty\": 9\n\"CHANCELLOR\": 9\n\"mire\": 9\n\"vale\": 9\n\"guides\": 9\n\"whelp\": 9\n\"mildly\": 9\n\"sequent\": 9\n\"solicit\": 9\n\"wedding-day\": 9\n\"Palace\": 9\n\"eager\": 9\n\"pilot\": 9\n\"tawny\": 9\n\"retir\": 9\n\"Beside\": 9\n\"forswore\": 9\n\"HORNER\": 9\n\"ills\": 9\n\"Pass\": 9\n\"bitterly\": 9\n\"trencher\": 9\n\"gratis\": 9\n\"gentler\": 9\n\"corpse\": 9\n\"SPIRIT\": 9\n\"lesson\": 9\n\"lamp\": 9\n\"Therein\": 9\n\"Lovell\": 9\n\"brat\": 9\n\"Cried\": 9\n\"spheres\": 9\n\"bench\": 9\n\"witnesses\": 9\n\"Fife\": 9\n\"eagles\": 9\n\"sparks\": 9\n\"distract\": 9\n\"lick\": 9\n\"piercing\": 9\n\"therewithal\": 9\n\"redemption\": 9\n\"passages\": 9\n\"Dane\": 9\n\"butter\": 9\n\"Greekish\": 9\n\"Fit\": 9\n\"Mary\": 9\n\"Turkish\": 9\n\"Killing\": 9\n\"transgression\": 9\n\"pile\": 9\n\"German\": 9\n\"bequeath\": 9\n\"ANDROMACHE\": 9\n\"ordinance\": 9\n\"confederates\": 9\n\"dissemble\": 9\n\"batt\": 9\n\"glasses\": 9\n\"hits\": 9\n\"mole\": 9\n\"However\": 9\n\"Park\": 9\n\"propose\": 9\n\"CALCHAS\": 9\n\"courtiers\": 9\n\"dragon\": 9\n\"hag\": 9\n\"ignoble\": 9\n\"perdition\": 9\n\"FAULCONBRIDGE\": 9\n\"navy\": 9\n\"DERCETAS\": 9\n\"smack\": 9\n\"enow\": 9\n\"chides\": 9\n\"dissension\": 9\n\"idiot\": 9\n\"lease\": 9\n\"issues\": 9\n\"CHATILLON\": 9\n\"kites\": 9\n\"pranks\": 9\n\"sprites\": 9\n\"Toward\": 9\n\"Burn\": 9\n\"rape\": 9\n\"dances\": 9\n\"hew\": 9\n\"gulf\": 9\n\"incorporate\": 9\n\"buckram\": 9\n\"cups\": 9\n\"sped\": 9\n\"Reason\": 9\n\"choleric\": 9\n\"contagious\": 9\n\"pulse\": 9\n\"Weigh\": 9\n\"plea\": 9\n\"observ\": 9\n\"commanding\": 9\n\"cardinal\": 9\n\"Holds\": 9\n\"urging\": 9\n\"utt\": 9\n\"rance\": 9\n\"commendable\": 9\n\"chronicle\": 9\n\"chaff\": 9\n\"display\": 9\n\"faintly\": 9\n\"accomplish\": 9\n\"apprehended\": 9\n\"rite\": 9\n\"compassion\": 9\n\"charter\": 9\n\"AND\": 9\n\"CLITUS\": 9\n\"fails\": 9\n\"sequel\": 9\n\"construction\": 9\n\"inhabit\": 9\n\"BEAUFORT\": 9\n\"Sixth\": 9\n\"Sennet\": 9\n\"more-\": 9\n\"casement\": 9\n\"guiltiness\": 9\n\"TRAGEDY\": 9\n\"gay\": 9\n\"audit\": 9\n\"LUCE\": 9\n\"Philomel\": 9\n\"carve\": 9\n\"Beauty\": 9\n\"Syracuse\": 9\n\"Ligarius\": 9\n\"deceas\": 9\n\"prelate\": 9\n\"trace\": 9\n\"rent\": 9\n\"Hymen\": 9\n\"Direct\": 9\n\"lodg\": 9\n\"peruse\": 9\n\"marrying\": 9\n\"Varro\": 9\n\"crop\": 9\n\"labor\": 9\n\"curtains\": 9\n\"sennet\": 9\n\"roundly\": 9\n\"riotous\": 9\n\"howling\": 9\n\"cordial\": 9\n\"counted\": 9\n\"preferment\": 9\n\"swells\": 9\n\"Alexas\": 9\n\"man-\": 9\n\"Twice\": 9\n\"moonshine\": 9\n\"aweary\": 9\n\"boil\": 9\n\"offered\": 9\n\"adversary\": 9\n\"wooer\": 9\n\"interpreter\": 9\n\"climate\": 9\n\"Whispers\": 9\n\"votre\": 9\n\"wrote\": 9\n\"liquid\": 9\n\"warn\": 9\n\"De\": 9\n\"expected\": 9\n\"jolly\": 9\n\"Je\": 9\n\"blowing\": 9\n\"madame\": 9\n\"parcels\": 9\n\"practis\": 9\n\"wheels\": 9\n\"justices\": 9\n\"alehouse\": 9\n\"whistle\": 9\n\"barber\": 9\n\"Possess\": 9\n\"bees\": 9\n\"parentage\": 9\n\"Yond\": 9\n\"earnestly\": 9\n\"phoenix\": 9\n\"jet\": 9\n\"Jaquenetta\": 9\n\"livers\": 9\n\"hand-\": 9\n\"condemned\": 9\n\"wedlock\": 9\n\"eyne\": 9\n\"shin\": 9\n\"remuneration\": 9\n\"wildness\": 9\n\"poetry\": 9\n\"pander\": 9\n\"queens\": 9\n\"LUCULLUS\": 9\n\"Iras\": 9\n\"duck\": 9\n\"Tunis\": 9\n\"wretchedness\": 9\n\"heart-\": 9\n\"wasteful\": 9\n\"ability\": 9\n\"Gonzalo\": 9\n\"Maria\": 9\n\"haunts\": 9\n\"Desires\": 9\n\"solus\": 9\n\"Convey\": 9\n\"proffer\": 9\n\"British\": 9\n\"complaints\": 9\n\"Close\": 9\n\"Salique\": 9\n\"concerning\": 9\n\"sheriff\": 9\n\"survive\": 9\n\"groaning\": 9\n\"sighing\": 9\n\"tides\": 9\n\"covetous\": 9\n\"denial\": 9\n\"ATTENDANT\": 9\n\"levy\": 9\n\"bag\": 9\n\"tenth\": 9\n\"affright\": 9\n\"cleft\": 9\n\"Glamis\": 9\n\"roots\": 9\n\"characters\": 9\n\"RAMBURES\": 9\n\"Witches\": 9\n\"endeavours\": 9\n\"western\": 9\n\"BATES\": 9\n\"reck\": 9\n\"Dame\": 9\n\"guards\": 9\n\"placed\": 9\n\"ERPINGHAM\": 9\n\"nightgown\": 9\n\"scap\": 9\n\"perceiv\": 9\n\"grounds\": 9\n\"vainly\": 9\n\"consecrate\": 9\n\"solely\": 9\n\"prettiest\": 9\n\"diligence\": 9\n\"autumn\": 9\n\"foils\": 9\n\"Wood\": 9\n\"Sons\": 9\n\"Lays\": 9\n\"dole\": 9\n\"strait\": 9\n\"smart\": 9\n\"spots\": 9\n\"slightly\": 9\n\"swan\": 9\n\"neigh\": 9\n\"cars\": 9\n\"enjoin\": 9\n\"testament\": 9\n\"showers\": 9\n\"beggarly\": 9\n\"Already\": 9\n\"stately\": 9\n\"Katherina\": 9\n\"revive\": 9\n\"paragon\": 9\n\"Colville\": 9\n\"fourscore\": 9\n\"blossom\": 9\n\"miscarried\": 9\n\"Withdraw\": 9\n\"torments\": 9\n\"MOROCCO\": 9\n\"starv\": 9\n\"cope\": 9\n\"Beware\": 9\n\"Green\": 9\n\"snuff\": 9\n\"spectacle\": 9\n\"ow\": 9\n\"advised\": 9\n\"comest\": 9\n\"Mouldy\": 9\n\"shaft\": 9\n\"costly\": 9\n\"Bal\": 9\n\"Note\": 9\n\"easier\": 9\n\"Tubal\": 9\n\"Heart\": 9\n\"greetings\": 9\n\"martial\": 9\n\"drowning\": 9\n\"surge\": 9\n\"scatter\": 9\n\"Bellario\": 9\n\"chest\": 9\n\"aright\": 9\n\"courtesies\": 9\n\"Thoughts\": 9\n\"Sunday\": 9\n\"oman\": 9\n\"presents\": 9\n\"summons\": 9\n\"Attendant\": 9\n\"humbled\": 9\n\"mustard\": 9\n\"unarm\": 9\n\"hitherto\": 9\n\"misled\": 9\n\"puissance\": 9\n\"pence\": 9\n\"deliverance\": 9\n\"imports\": 9\n\"knighthood\": 9\n\"concord\": 9\n\"befits\": 9\n\"CITIZENS\": 9\n\"accord\": 9\n\"STARVELING\": 9\n\"il\": 9\n\"nations\": 9\n\"quietly\": 9\n\"Hautboys\": 9\n\"Certain\": 9\n\"eternity\": 9\n\"mines\": 9\n\"opens\": 9\n\"cheerfully\": 9\n\"P\": 9\n\"FEEBLE\": 9\n\"planted\": 9\n\"spotted\": 9\n\"carrying\": 9\n\"temperate\": 9\n\"know-\": 9\n\"FANG\": 9\n\"advancement\": 9\n\"Titania\": 9\n\"posterity\": 9\n\"Countess\": 9\n\"usurper\": 9\n\"travail\": 9\n\"Christians\": 9\n\"annoy\": 9\n\"Conrade\": 9\n\"Verges\": 9\n\"Widow\": 9\n\"moist\": 9\n\"building\": 9\n\"planet\": 9\n\"mistaken\": 9\n\"fruits\": 9\n\"abode\": 9\n\"roll\": 9\n\"gull\": 9\n\"residence\": 9\n\"abandon\": 9\n\"continuance\": 9\n\"derive\": 9\n\"(as\": 9\n\"limits\": 9\n\"corporal\": 9\n\"buzz\": 9\n\"comedy\": 9\n\"passionate\": 9\n\"eating\": 9\n\"Montano\": 9\n\"compos\": 9\n\"fac\": 9\n\"Blow\": 9\n\"fitness\": 9\n\"FITZWATER\": 9\n\"conjunction\": 9\n\"proceeded\": 9\n\"braver\": 9\n\"Derby\": 9\n\"Menas\": 9\n\"humanity\": 9\n\"spark\": 9\n\"Throwing\": 4\n\"Setting\": 6\n\"prouder\": 7\n\"ashamed\": 7\n\"Hum\": 8\n\"devised\": 6\n\"yare\": 8\n\"drab\": 8\n\"GARDENER\": 7\n\"method\": 7\n\"declining\": 7\n\"unprovided\": 6\n\"mariners\": 6\n\"brine\": 7\n\"friends-\": 6\n\"Bloody\": 6\n\"thanked\": 6\n\"Bagot\": 6\n\"Hall\": 7\n\"Bushy\": 8\n\"LOVEL\": 7\n\"restored\": 6\n\"Maid\": 6\n\"wage\": 7\n\"fresher\": 8\n\"Confound\": 6\n\"droop\": 6\n\"womanhood\": 6\n\"dug\": 6\n\"dispositions\": 6\n\"education\": 8\n\"flows\": 7\n\"Dolabella\": 8\n\"maim\": 8\n\"chronicles\": 6\n\"ascend\": 8\n\"briers\": 8\n\"clout\": 7\n\"Guard\": 7\n\"maidenhead\": 8\n\"jig\": 6\n\"BERKELEY\": 6\n\"Shore\": 8\n\"languish\": 7\n\"acted\": 7\n\"appeared\": 6\n\"nun\": 7\n\"nearly\": 6\n\"darkly\": 8\n\"anew\": 8\n\"lodges\": 6\n\"timorous\": 6\n\"skilful\": 6\n\"cloister\": 7\n\"Finding\": 8\n\"frosty\": 7\n\"bestrid\": 6\n\"writers\": 7\n\"gore\": 8\n\"whips\": 7\n\"copper\": 7\n\"shipp\": 8\n\"professes\": 6\n\"realms\": 7\n\"letting\": 6\n\"anywhere\": 6\n\"Sink\": 6\n\"nunnery\": 6\n\"Rhodes\": 6\n\"inside\": 6\n\"rhetoric\": 8\n\"answering\": 6\n\"convert\": 6\n\"erlook\": 8\n\"imperfect\": 6\n\"spar\": 6\n\"dungeon\": 8\n\"Monday\": 7\n\"grievances\": 7\n\"pole\": 7\n\"hawk\": 7\n\"Injurious\": 7\n\"scour\": 8\n\"remote\": 7\n\"soldiership\": 8\n\"slippery\": 8\n\"Feed\": 8\n\"suggestion\": 8\n\"attaint\": 7\n\"player\": 6\n\"across\": 6\n\"barons\": 6\n\"Youth\": 8\n\"rusty\": 6\n\"fardel\": 7\n\"fort\": 7\n\"wounding\": 6\n\"helmet\": 6\n\"meek\": 7\n\"babbling\": 6\n\"firmament\": 6\n\"halfpenny\": 6\n\"dead-\": 7\n\"forgo\": 6\n\"basely\": 8\n\"crosses\": 8\n\"Christ\": 8\n\"consuls\": 6\n\"Sex\": 7\n\"grapes\": 7\n\"wanted\": 8\n\"bestride\": 6\n\"negligent\": 6\n\"amber\": 6\n\"oxen\": 8\n\"puppet\": 8\n\"leapt\": 6\n\"hoodwink\": 6\n\"strangle\": 6\n\"rules\": 8\n\"farm\": 8\n\"breaths\": 8\n\"offends\": 7\n\"Turns\": 8\n\"Receiv\": 6\n\"unlook\": 8\n\"Excursions\": 6\n\"regards\": 7\n\"insulting\": 7\n\"vanities\": 6\n\"GUARDSMAN\": 6\n\"think-\": 6\n\"manifold\": 7\n\"terrors\": 6\n\"devoted\": 6\n\"changed\": 6\n\"COUNT\": 8\n\"captives\": 8\n\"petticoat\": 7\n\"eyesight\": 7\n\"Sith\": 8\n\"transformation\": 6\n\"avoided\": 8\n\"Ravenspurgh\": 8\n\"juice\": 7\n\"here-\": 6\n\"grind\": 6\n\"instructions\": 8\n\"LANCASTER\": 6\n\"Going\": 7\n\"Assist\": 7\n\"b\": 7\n\"Dogberry\": 8\n\"Vaughan\": 7\n\"directions\": 7\n\"untie\": 6\n\"deign\": 6\n\"canary\": 6\n\"PRIEST\": 6\n\"wilfully\": 6\n\"Despite\": 8\n\"surprise\": 6\n\"Lion\": 6\n\"awry\": 7\n\"sunder\": 8\n\"mounsieur\": 7\n\"quarrelling\": 6\n\"release\": 6\n\"fitting\": 7\n\"COLVILLE\": 7\n\"slips\": 7\n\"usual\": 6\n\"MORTON\": 8\n\"Mustardseed\": 6\n\"Cobweb\": 6\n\"Poison\": 6\n\"Tyrrel\": 7\n\"constrain\": 8\n\"Wall\": 7\n\"Deserves\": 6\n\"trail\": 6\n\"caves\": 6\n\"conclusions\": 7\n\"BLUNT\": 7\n\"(As\": 8\n\"lullaby\": 7\n\"Hic\": 7\n\"pagan\": 6\n\"dominions\": 7\n\"Calls\": 6\n\"whale\": 6\n\"reform\": 7\n\"ostentation\": 8\n\"erthrown\": 6\n\"Frederick\": 8\n\"nymph\": 6\n\"wrestler\": 8\n\"hard-hearted\": 6\n\"flag\": 7\n\"Boys\": 7\n\"tailors\": 7\n\"ROBERT\": 8\n\"Oliver\": 8\n\"howsoever\": 7\n\"self-love\": 6\n\"jester\": 8\n\"Oberon\": 8\n\"luxury\": 8\n\"blossoms\": 6\n\"Vulcan\": 6\n\"MOULDY\": 7\n\"barks\": 6\n\"Danish\": 6\n\"Quince\": 8\n\"Given\": 8\n\"purg\": 8\n\"Durst\": 6\n\"cools\": 6\n\"BULLCALF\": 7\n\"Hippolyta\": 7\n\"LION\": 7\n\"MOONSHINE\": 7\n\"Arden\": 7\n\"thrall\": 6\n\"WALL\": 6\n\"Rumour\": 7\n\"covert\": 8\n\"hardy\": 6\n\"Advise\": 8\n\"Said\": 8\n\"swiftest\": 6\n\"MUSTARDSEED\": 8\n\"hinds\": 8\n\"loses\": 8\n\"COBWEB\": 7\n\"forg\": 8\n\"PEASEBLOSSOM\": 7\n\"tripping\": 6\n\"hobby-horse\": 6\n\"returned\": 7\n\"chanced\": 8\n\"learnt\": 8\n\"portion\": 7\n\"nymphs\": 8\n\"protestation\": 6\n\"sprung\": 8\n\"Egeus\": 6\n\"blasts\": 7\n\"Laid\": 7\n\"buckle\": 7\n\"magnanimous\": 7\n\"pith\": 7\n\"levity\": 6\n\"Capulets\": 6\n\"obsequious\": 8\n\"darling\": 6\n\"swagg\": 6\n\"Keeps\": 7\n\"evident\": 7\n\"juvenal\": 7\n\"blood-\": 8\n\"lanthorn\": 8\n\"India\": 7\n\"SNUG\": 7\n\"Smithfield\": 6\n\"louder\": 8\n\"Clock\": 6\n\"misuse\": 7\n\"unwilling\": 6\n\"wrangling\": 8\n\"unquiet\": 6\n\"framed\": 6\n\"drudge\": 8\n\"scornful\": 6\n\"ungracious\": 7\n\"accusations\": 6\n\"darts\": 7\n\"lousy\": 8\n\"imminent\": 7\n\"disclos\": 6\n\"acquit\": 8\n\"scolding\": 6\n\"catching\": 8\n\"galls\": 7\n\"raised\": 7\n\"robbery\": 8\n\"appearing\": 7\n\"lowest\": 7\n\"sweetness\": 7\n\"necessaries\": 6\n\"Directly\": 6\n\"exceeds\": 7\n\"constraint\": 6\n\"indirect\": 8\n\"devices\": 6\n\"Fairy\": 6\n\"moderate\": 7\n\"Pale\": 8\n\"Heme\": 7\n\"kindle\": 7\n\"beaver\": 6\n\"trimm\": 8\n\"mightiest\": 7\n\"merrier\": 7\n\"Snare\": 6\n\"truncheon\": 6\n\"mare\": 6\n\"Rose\": 7\n\"bak\": 6\n\"whereby\": 7\n\"benefits\": 7\n\"Hyperion\": 6\n\"lineaments\": 6\n\"seed\": 7\n\"unfit\": 6\n\"jocund\": 8\n\"Pay\": 7\n\"Tearsheet\": 7\n\"thinkest\": 6\n\"replete\": 8\n\"bleeds\": 7\n\"niggard\": 7\n\"assign\": 6\n\"Became\": 6\n\"precise\": 8\n\"partake\": 7\n\"suppress\": 8\n\"DRAWER\": 6\n\"bated\": 7\n\"knavish\": 7\n\"bier\": 6\n\"interpret\": 6\n\"planets\": 7\n\"Ancient\": 7\n\"verdict\": 7\n\"vacant\": 6\n\"paradise\": 8\n\"comforted\": 6\n\"vill\": 8\n\"amaze\": 8\n\"inter\": 7\n\"swagger\": 6\n\"majestical\": 8\n\"Shut\": 7\n\"threefold\": 8\n\"trains\": 7\n\"watching\": 8\n\"bullets\": 8\n\"mote\": 6\n\"chaps\": 6\n\"dotes\": 8\n\"foresaid\": 6\n\"lawless\": 7\n\"murtherer\": 8\n\"Dar\": 8\n\"mated\": 6\n\"Simple\": 6\n\"Seal\": 7\n\"supplied\": 8\n\"desirous\": 6\n\"chairs\": 6\n\"bodes\": 6\n\"stalk\": 6\n\"Nile\": 6\n\"bubble\": 8\n\"Question\": 8\n\"adopted\": 6\n\"rivals\": 8\n\"carefully\": 8\n\"goot\": 6\n\"Thrust\": 7\n\"lass\": 7\n\"unrest\": 7\n\"poll\": 6\n\"humble-bee\": 6\n\"morsel\": 8\n\"Reynaldo\": 6\n\"enlarge\": 7\n\"Tuesday\": 8\n\"wards\": 6\n\"Tucket\": 6\n\"Antigonus\": 7\n\"Bernardo\": 8\n\"uncertain\": 7\n\"fulfill\": 7\n\"anchor\": 8\n\"beset\": 6\n\"gaping\": 8\n\"Voltemand\": 6\n\"dispraise\": 8\n\"equally\": 8\n\"moonlight\": 8\n\"oyster\": 7\n\"tumult\": 7\n\"Carthage\": 7\n\"trodden\": 6\n\"frights\": 6\n\"Daniel\": 6\n\"ensign\": 6\n\"Nine\": 7\n\"hem\": 7\n\"Turks\": 7\n\"played\": 7\n\"safest\": 7\n\"unborn\": 8\n\"purgation\": 6\n\"soonest\": 6\n\"intolerable\": 8\n\"bragging\": 8\n\"Tewksbury\": 8\n\"Treason\": 8\n\"defects\": 6\n\"hiding\": 7\n\"fade\": 7\n\"Showing\": 8\n\"consum\": 7\n\"commotion\": 7\n\"declare\": 6\n\"compounds\": 6\n\"Pronounce\": 6\n\"grossness\": 6\n\"wantonness\": 8\n\"melody\": 8\n\"Joy\": 6\n\"Weep\": 7\n\"sacrifices\": 6\n\"speaker\": 8\n\"thigh\": 8\n\"spear\": 8\n\"starting\": 6\n\"staying\": 7\n\"discontents\": 7\n\"Husband\": 6\n\"Gobbo\": 6\n\"outface\": 6\n\"probation\": 7\n\"Ganymede\": 8\n\"Aliena\": 6\n\"forfeiture\": 8\n\"pockets\": 7\n\"benediction\": 6\n\"Obey\": 8\n\"moneys\": 7\n\"echo\": 8\n\"taunt\": 6\n\"Court\": 7\n\"icy\": 6\n\"merited\": 6\n\"Demand\": 7\n\"hint\": 8\n\"mature\": 7\n\"by-and-by\": 8\n\"smock\": 8\n\"counsellors\": 6\n\"feigned\": 6\n\"adversity\": 6\n\"con\": 6\n\"Double\": 7\n\"exempt\": 8\n\"range\": 8\n\"out-\": 7\n\"Cornelius\": 6\n\"caskets\": 7\n\"venison\": 6\n\"starved\": 7\n\"county\": 6\n\"abhorred\": 7\n\"Judge\": 8\n\"esteemed\": 7\n\"owed\": 6\n\"rival\": 6\n\"brawls\": 6\n\"horribly\": 6\n\"hunter\": 7\n\"Wart\": 7\n\"flown\": 7\n\"Feeble\": 7\n\"Straight\": 8\n\"repentance\": 7\n\"Syria\": 6\n\"gamester\": 7\n\"that-\": 8\n\"verge\": 8\n\"feasting\": 8\n\"promontory\": 6\n\"rooted\": 6\n\"Bullcalf\": 7\n\"praying\": 7\n\"hammer\": 6\n\"parallel\": 7\n\"forked\": 6\n\"Lucifer\": 6\n\"rider\": 8\n\"shrine\": 6\n\"citadel\": 6\n\"precepts\": 8\n\"missing\": 7\n\"whereto\": 6\n\"Met\": 6\n\"ARRAGON\": 6\n\"vapour\": 6\n\"overcome\": 8\n\"bonny\": 7\n\"courtly\": 7\n\"swiftly\": 7\n\"comely\": 6\n\"Yorkshire\": 6\n\"overheard\": 8\n\"sand\": 7\n\"privately\": 6\n\"reviv\": 6\n\"gaudy\": 6\n\"truths\": 6\n\"true-\": 7\n\"concludes\": 6\n\"corners\": 8\n\"feat\": 6\n\"sparrow\": 7\n\"claims\": 8\n\"peculiar\": 7\n\"chok\": 8\n\"vicious\": 8\n\"lump\": 6\n\"awful\": 7\n\"faiths\": 6\n\"fortify\": 7\n\"lieu\": 8\n\"station\": 7\n\"Jacob\": 8\n\"gasp\": 8\n\"praising\": 8\n\"Care\": 8\n\"chastisement\": 8\n\"conquering\": 6\n\"translate\": 8\n\"mischiefs\": 8\n\"Mariana\": 8\n\"huswife\": 8\n\"cord\": 8\n\"sacrament\": 8\n\"club\": 8\n\"Hanging\": 6\n\"heaviest\": 6\n\"hearer\": 6\n\"ducat\": 6\n\"lopp\": 8\n\"doctrine\": 8\n\"pursues\": 7\n\"Troth\": 8\n\"fashions\": 8\n\"domestic\": 6\n\"ware\": 6\n\"Beg\": 7\n\"detest\": 7\n\"hive\": 6\n\"Elbow\": 7\n\"graze\": 6\n\"bearer\": 7\n\"Retreat\": 7\n\"Elysium\": 6\n\"Chamber\": 7\n\"sale\": 8\n\"GHOSTS\": 6\n\"Alcides\": 7\n\"cottage\": 6\n\"revenues\": 7\n\"melting\": 8\n\"sealed\": 7\n\"fam\": 6\n\"imposition\": 7\n\"wrestle\": 7\n\"weasel\": 6\n\"eggs\": 7\n\"fealty\": 6\n\"lovest\": 8\n\"t-\": 8\n\"SICILIUS\": 8\n\"hypocrite\": 7\n\"Softly\": 6\n\"attendance\": 8\n\"temporal\": 7\n\"invited\": 8\n\"plough\": 7\n\"lineal\": 8\n\"cheerly\": 7\n\"invest\": 7\n\"bane\": 6\n\"hidden\": 8\n\"resist\": 8\n\"stony\": 7\n\"yet-\": 6\n\"jars\": 8\n\"musical\": 7\n\"chas\": 7\n\"Forthwith\": 6\n\"chariot\": 8\n\"grin\": 6\n\"blister\": 6\n\"Part\": 7\n\"Pointing\": 7\n\"riots\": 6\n\"wilderness\": 8\n\"preservation\": 6\n\"cramm\": 8\n\"Hostess\": 8\n\"December\": 6\n\"upbraid\": 7\n\"roars\": 6\n\"Withal\": 6\n\"galled\": 6\n\"parish\": 7\n\"dregs\": 7\n\"enforcement\": 6\n\"sheath\": 7\n\"Sly\": 6\n\"attorney\": 7\n\"boarded\": 7\n\"churl\": 8\n\"physicians\": 8\n\"commanders\": 8\n\"soften\": 6\n\"brutish\": 6\n\"angle\": 7\n\"sores\": 7\n\"enjoys\": 6\n\"license\": 7\n\"Despair\": 8\n\"bravery\": 6\n\"Thinking\": 6\n\"Seyton\": 6\n\"conceited\": 6\n\"scattered\": 7\n\"skirmish\": 6\n\"Taurus\": 6\n\"thorny\": 6\n\"serving-man\": 6\n\"conversation\": 8\n\"reserve\": 6\n\"Sorrow\": 8\n\"creeping\": 8\n\"lightness\": 8\n\"Speaking\": 6\n\"wip\": 8\n\"arbour\": 6\n\"minist\": 6\n\"doe\": 7\n\"whores\": 8\n\"end-\": 6\n\"bit\": 7\n\"spaniel\": 6\n\"testy\": 6\n\"Minola\": 6\n\"CAMBIO\": 6\n\"fig\": 6\n\"Spaniard\": 6\n\"snail\": 7\n\"motives\": 6\n\"BEADLE\": 8\n\"demanded\": 7\n\"somebody\": 7\n\"dart\": 7\n\"calendar\": 8\n\"swing\": 8\n\"severe\": 7\n\"Abbey\": 6\n\"instances\": 7\n\"distrust\": 6\n\"GROOM\": 8\n\"liveries\": 6\n\"spectacles\": 8\n\"elves\": 7\n\"shrunk\": 6\n\"childish\": 8\n\"yew\": 6\n\"pipes\": 6\n\"Licio\": 6\n\"Damn\": 6\n\"Heigh-ho\": 6\n\"charmed\": 6\n\"cauldron\": 8\n\"imagin\": 7\n\"freeze\": 8\n\"brood\": 8\n\"Siward\": 8\n\"mortals\": 7\n\"wren\": 7\n\"malignant\": 7\n\"herbs\": 8\n\"justify\": 8\n\"obsequies\": 7\n\"Night\": 6\n\"sparkling\": 8\n\"men-\": 7\n\"clothe\": 7\n\"creditors\": 7\n\"Fate\": 7\n\"orphans\": 7\n\"colors\": 6\n\"martyr\": 7\n\"Cambio\": 8\n\"Seven\": 8\n\"shepherds\": 8\n\"favourites\": 7\n\"beetle\": 6\n\"betrayed\": 7\n\"sweeten\": 7\n\"haunted\": 7\n\"grease\": 6\n\"weird\": 6\n\"sailor\": 6\n\"rudeness\": 6\n\"direful\": 7\n\"spied\": 6\n\"inferior\": 8\n\"Next\": 6\n\"lamenting\": 6\n\"Learn\": 7\n\"conspirator\": 7\n\"Mend\": 7\n\"incision\": 6\n\"death-bed\": 6\n\"weaver\": 6\n\"Lucrece\": 6\n\"VIII\": 8\n\"MACMORRIS\": 6\n\"JAMY\": 6\n\"galleys\": 6\n\"seals\": 8\n\"to-\": 8\n\"Murtherers\": 6\n\"important\": 8\n\"pictures\": 7\n\"untrue\": 7\n\"BRITAINE\": 6\n\"excepted\": 6\n\"drawer\": 7\n\"hart\": 8\n\"Isis\": 8\n\"Curtis\": 6\n\"SEYTON\": 6\n\"cart\": 6\n\"Grow\": 6\n\"pennyworth\": 7\n\"GOVERNOR\": 8\n\"trophies\": 6\n\"IX\": 6\n\"medlar\": 6\n\"MENTEITH\": 6\n\"Blessed\": 6\n\"afflicted\": 8\n\"Lethe\": 7\n\"sociable\": 6\n\"Runs\": 7\n\"ISABEL\": 7\n\"cram\": 6\n\"poorly\": 7\n\"tinker\": 8\n\"wooden\": 8\n\"distill\": 8\n\"tires\": 6\n\"Sad\": 8\n\"salvation\": 6\n\"Agincourt\": 6\n\"Suppose\": 8\n\"mightier\": 7\n\"baggage\": 7\n\"logs\": 7\n\"FRANCISCO\": 6\n\"mannerly\": 7\n\"Cuckoo\": 6\n\"banners\": 8\n\"wooers\": 7\n\"Smile\": 8\n\"supp\": 6\n\"multitudes\": 7\n\"Ilion\": 6\n\"external\": 7\n\"deservings\": 6\n\"devout\": 8\n\"acceptance\": 8\n\"achiev\": 7\n\"cine\": 7\n\"expedient\": 7\n\"dirty\": 7\n\"freshly\": 7\n\"Gold\": 6\n\"earls\": 7\n\"finding\": 8\n\"sloth\": 6\n\"prevention\": 6\n\"Howe\": 8\n\"industry\": 7\n\"cog\": 6\n\"visor\": 8\n\"sentences\": 6\n\"berries\": 6\n\"ken\": 6\n\"toss\": 8\n\"obscur\": 7\n\"spiritual\": 6\n\"hardness\": 6\n\"requital\": 7\n\"forester\": 6\n\"trusting\": 6\n\"aptly\": 7\n\"dukedoms\": 8\n\"diligent\": 6\n\"constantly\": 6\n\"bat\": 6\n\"marshal\": 7\n\"halting\": 6\n\"compounded\": 8\n\"reliev\": 6\n\"straightway\": 7\n\"CENTURION\": 6\n\"gout\": 6\n\"packing\": 8\n\"sincerity\": 6\n\"Germany\": 6\n\"skirts\": 6\n\"swallowing\": 6\n\"invent\": 7\n\"IRIS\": 7\n\"strongest\": 6\n\"courtship\": 8\n\"painful\": 8\n\"gaol\": 6\n\"Severn\": 6\n\"CERES\": 7\n\"JUNO\": 6\n\"nut\": 6\n\"net\": 6\n\"Descend\": 7\n\"rigour\": 8\n\"cage\": 7\n\"Sycorax\": 7\n\"Present\": 7\n\"bonnet\": 6\n\"Whoe\": 6\n\"abed\": 7\n\"Titan\": 6\n\"greedy\": 6\n\"fun\": 8\n\"marches\": 6\n\"rhymes\": 8\n\"Herself\": 7\n\"Drawn\": 6\n\"castles\": 8\n\"effeminate\": 7\n\"singular\": 7\n\"pricket\": 6\n\"worshipp\": 8\n\"waxen\": 8\n\"Nilus\": 6\n\"heresy\": 6\n\"Parthia\": 7\n\"quietness\": 7\n\"goats\": 8\n\"Villains\": 6\n\"Army\": 6\n\"Confirm\": 7\n\"SEMPRONIUS\": 7\n\"humbleness\": 7\n\"violet\": 8\n\"nance\": 6\n\"warp\": 7\n\"Strong\": 6\n\"conveyance\": 7\n\"pedant\": 8\n\"haviour\": 6\n\"credulous\": 8\n\"wight\": 7\n\"Ride\": 6\n\"Cadwal\": 7\n\"sheathe\": 7\n\"Polydore\": 8\n\"palaces\": 7\n\"graver\": 6\n\"threatens\": 6\n\"harness\": 8\n\"beseem\": 6\n\"Horns\": 7\n\"PHILOTUS\": 8\n\"pent\": 8\n\"faculties\": 7\n\"quondam\": 6\n\"sland\": 6\n\"brotherhood\": 6\n\"vine\": 7\n\"profits\": 8\n\"inhuman\": 6\n\"conspire\": 8\n\"sharper\": 6\n\"Englishman\": 8\n\"family\": 8\n\"HORTENSIUS\": 8\n\"Bar\": 6\n\"Wash\": 6\n\"impious\": 6\n\"proceeds\": 7\n\"military\": 8\n\"monarchs\": 6\n\"blasted\": 8\n\"clip\": 6\n\"finely\": 6\n\"Aquitaine\": 8\n\"Touch\": 8\n\"flea\": 6\n\"inclining\": 6\n\"st-\": 6\n\"battery\": 7\n\"doctors\": 6\n\"collected\": 6\n\"attempts\": 6\n\"sucking\": 6\n\"Lovers\": 6\n\"spill\": 7\n\"puny\": 7\n\"persever\": 7\n\"bauble\": 8\n\"FORESTER\": 6\n\"virgins\": 8\n\"turf\": 6\n\"fouler\": 7\n\"adultery\": 6\n\"victor\": 7\n\"dialogue\": 7\n\"utterance\": 8\n\"Satan\": 8\n\"belied\": 7\n\"monuments\": 6\n\"butchers\": 6\n\"maidens\": 8\n\"counts\": 6\n\"world-\": 8\n\"gripe\": 8\n\"Jewry\": 7\n\"unsure\": 6\n\"skip\": 6\n\"Advancing\": 8\n\"woful\": 8\n\"rejoicing\": 6\n\"bountiful\": 7\n\"costard\": 6\n\"climbing\": 6\n\"Od\": 7\n\"Herod\": 8\n\"rails\": 6\n\"treads\": 8\n\"fearfully\": 7\n\"abound\": 7\n\"importunate\": 6\n\"Abate\": 6\n\"precisely\": 6\n\"tumble\": 7\n\"ill-favour\": 7\n\"dissolve\": 6\n\"opposition\": 8\n\"Doct\": 8\n\"disciplines\": 7\n\"bewitch\": 6\n\"raiment\": 7\n\"Macmorris\": 6\n\"Room\": 6\n\"gud\": 6\n\"James\": 7\n\"Chrish\": 6\n\"Wish\": 6\n\"overtake\": 7\n\"Fill\": 7\n\"glean\": 6\n\"ish\": 6\n\"quicken\": 7\n\"PHRYNIA\": 6\n\"mix\": 7\n\"sall\": 6\n\"quittance\": 6\n\"Hard\": 6\n\"Repent\": 7\n\"Shows\": 8\n\"drunkards\": 6\n\"relation\": 8\n\"Governor\": 6\n\"lawyer\": 6\n\"career\": 6\n\"tasted\": 7\n\"Steps\": 6\n\"posted\": 6\n\"TIMANDRA\": 8\n\"te\": 6\n\"Gods\": 8\n\"Augustus\": 6\n\"hog\": 6\n\"convoy\": 7\n\"Search\": 7\n\"La\": 8\n\"brawling\": 6\n\"Et\": 6\n\"organs\": 7\n\"forbearance\": 6\n\"ambush\": 8\n\"pense\": 6\n\"true-love\": 7\n\"buys\": 7\n\"Knocks\": 6\n\"orderly\": 8\n\"C\": 6\n\"too-\": 8\n\"hovel\": 7\n\"D\": 6\n\"penury\": 7\n\"camps\": 7\n\"Cham\": 7\n\"dawning\": 6\n\"hunted\": 6\n\"codpiece\": 7\n\"taunts\": 7\n\"Taking\": 7\n\"testify\": 6\n\"parrot\": 6\n\"ditch\": 7\n\"monkey\": 8\n\"Albion\": 6\n\"abstract\": 6\n\"chimney\": 8\n\"coach\": 6\n\"Saying\": 6\n\"defil\": 6\n\"CUPID\": 6\n\"wooed\": 6\n\"Storm\": 7\n\"Chatillon\": 7\n\"conceiv\": 6\n\"waken\": 6\n\"killed\": 7\n\"dukes\": 7\n\"Sleeps\": 8\n\"scythe\": 7\n\"showing\": 8\n\"Knows\": 8\n\"barefoot\": 6\n\"childhood\": 6\n\"whispers\": 8\n\"uttermost\": 7\n\"foresee\": 6\n\"verily\": 8\n\"ginger\": 7\n\"bedchamber\": 8\n\"Soothsayer\": 6\n\"dedicate\": 8\n\"railing\": 8\n\"soar\": 7\n\"suns\": 8\n\"strains\": 7\n\"ventures\": 6\n\"operation\": 6\n\"incline\": 8\n\"her-\": 8\n\"requir\": 8\n\"exhibition\": 6\n\"pelting\": 6\n\"empery\": 6\n\"dissuade\": 6\n\"knots\": 7\n\"garlands\": 8\n\"becoming\": 7\n\"unusual\": 6\n\"Englishmen\": 6\n\"opening\": 8\n\"venge\": 7\n\"radiant\": 8\n\"lioness\": 7\n\"Lucullus\": 7\n\"Persuade\": 6\n\"discern\": 7\n\"Fire\": 8\n\"ISIDORE\": 6\n\"olive\": 6\n\"Exceeding\": 6\n\"contrive\": 8\n\"Monster\": 7\n\"unsatisfied\": 6\n\"Work\": 6\n\"Humbly\": 8\n\"Flaminius\": 7\n\"fainting\": 7\n\"Brief\": 7\n\"ceremonious\": 7\n\"swoons\": 6\n\"suited\": 8\n\"distinguish\": 8\n\"MICHAEL\": 6\n\"checks\": 8\n\"thankfully\": 7\n\"Thames\": 7\n\"priz\": 8\n\"trenches\": 8\n\"soe\": 6\n\"filling\": 6\n\"robbers\": 6\n\"myself-\": 6\n\"woman-\": 7\n\"liars\": 7\n\"bandy\": 7\n\"tenderly\": 6\n\"bower\": 8\n\"spotless\": 7\n\"trip\": 6\n\"violets\": 7\n\"prerogative\": 7\n\"outrun\": 7\n\"feels\": 8\n\"Servilius\": 8\n\"shak\": 6\n\"sly\": 8\n\"incontinent\": 6\n\"STRANGER\": 8\n\"saddle\": 6\n\"chests\": 6\n\"beadle\": 6\n\"gesture\": 8\n\"penitence\": 6\n\"scales\": 6\n\"riddle\": 8\n\"admired\": 8\n\"poisons\": 8\n\"Presenting\": 7\n\"pages\": 6\n\"lantern\": 8\n\"Iachimo\": 7\n\"active\": 6\n\"recorded\": 7\n\"Scarce\": 6\n\"atone\": 6\n\"sunshine\": 7\n\"exceptions\": 6\n\"basis\": 6\n\"divinity\": 8\n\"Saturninus\": 6\n\"Yours\": 8\n\"holes\": 7\n\"Volumnius\": 8\n\"Strato\": 8\n\"assail\": 7\n\"Clitus\": 6\n\"wrangle\": 7\n\"accents\": 7\n\"clime\": 7\n\"Tribune\": 8\n\"abate\": 8\n\"qualified\": 7\n\"seventh\": 7\n\"mistresses\": 7\n\"contention\": 8\n\"arbitrement\": 6\n\"seconds\": 6\n\"Briton\": 6\n\"consorted\": 6\n\"sojourn\": 8\n\"then-\": 8\n\"disobedience\": 8\n\"murders\": 8\n\"plotted\": 8\n\"Herald\": 7\n\"Valiant\": 7\n\"FRENCHMAN\": 8\n\"Excuse\": 6\n\"sanctified\": 7\n\"Shout\": 7\n\"measur\": 8\n\"reflection\": 6\n\"needle\": 7\n\"slanderous\": 6\n\"Welshmen\": 6\n\"provinces\": 6\n\"revenged\": 8\n\"hats\": 8\n\"fraught\": 7\n\"unkindly\": 6\n\"bracelet\": 6\n\"heralds\": 7\n\"exil\": 6\n\"Want\": 8\n\"sear\": 6\n\"hen\": 8\n\"savour\": 8\n\"oration\": 7\n\"riding\": 7\n\"MUTIUS\": 7\n\"incur\": 6\n\"Fled\": 6\n\"hoop\": 6\n\"allies\": 6\n\"paying\": 6\n\"epilogue\": 6\n\"recovery\": 8\n\"Lose\": 7\n\"pulpit\": 7\n\"non\": 6\n\"skies\": 7\n\"thaw\": 6\n\"judges\": 7\n\"complexions\": 6\n\"do-\": 7\n\"Fates\": 8\n\"proclaimed\": 8\n\"rarest\": 8\n\"clog\": 6\n\"blots\": 8\n\"robs\": 6\n\"Stir\": 6\n\"plume\": 6\n\"To-night\": 8\n\"rosemary\": 6\n\"purposed\": 7\n\"BALTHAZAR\": 8\n\"failing\": 6\n\"suspected\": 6\n\"valor\": 7\n\"Berkeley\": 8\n\"Presents\": 6\n\"PINCH\": 8\n\"Wait\": 6\n\"imaginary\": 8\n\"rarely\": 8\n\"Greater\": 6\n\"heretic\": 7\n\"GAOLERS\": 6\n\"Tongue\": 7\n\"Tomorrow\": 6\n\"Briefly\": 6\n\"petitions\": 6\n\"partial\": 7\n\"mournful\": 7\n\"prattle\": 8\n\"perils\": 8\n\"unity\": 7\n\"striving\": 6\n\"summers\": 7\n\"Choose\": 6\n\"construe\": 8\n\"ides\": 7\n\"decreed\": 7\n\"solemnly\": 7\n\"gathered\": 6\n\"Syracusian\": 7\n\"fleece\": 8\n\"treaty\": 6\n\"Dream\": 6\n\"Seest\": 7\n\"amount\": 7\n\"perfumes\": 6\n\"departed\": 7\n\"canon\": 6\n\"COMMONER\": 7\n\"Steal\": 6\n\"regarded\": 6\n\"Epidamnum\": 7\n\"idolatry\": 6\n\"hereditary\": 6\n\"vat\": 7\n\"Tear\": 7\n\"provision\": 7\n\"arrived\": 7\n\"inn\": 8\n\"scold\": 8\n\"idol\": 8\n\"empress\": 6\n\"dive\": 6\n\"tragic\": 8\n\"retain\": 7\n\"PINDARUS\": 6\n\"pirate\": 7\n\"principal\": 7\n\"chuck\": 7\n\"Further\": 6\n\"delays\": 7\n\"hellish\": 8\n\"Grecians\": 7\n\"gains\": 7\n\"exchequer\": 7\n\"Fast\": 7\n\"grapple\": 7\n\"Corinth\": 7\n\"vapours\": 7\n\"discovered\": 8\n\"admits\": 6\n\"shifts\": 6\n\"merciless\": 6\n\"miracles\": 7\n\"Happily\": 6\n\"dealt\": 6\n\"sticks\": 8\n\"CONSPIRATOR\": 8\n\"discarded\": 6\n\"FASTOLFE\": 7\n\"lurk\": 6\n\"indirectly\": 8\n\"hale\": 8\n\"prolong\": 6\n\"engine\": 8\n\"converted\": 6\n\"perfections\": 7\n\"eighteen\": 6\n\"peerless\": 7\n\"importun\": 7\n\"MARULLUS\": 7\n\"breadth\": 8\n\"LONDON\": 6\n\"List\": 7\n\"lace\": 6\n\"CALPURNIA\": 7\n\"Daughter\": 6\n\"METELLUS\": 6\n\"impiety\": 6\n\"fates\": 6\n\"ensuing\": 8\n\"LIGARIUS\": 6\n\"reconcile\": 8\n\"cutting\": 6\n\"Tiber\": 8\n\"zealous\": 6\n\"behaviours\": 6\n\"bewray\": 6\n\"colder\": 6\n\"admire\": 7\n\"murtherous\": 6\n\"arrival\": 6\n\"Centaur\": 7\n\"SERGEANT\": 8\n\"wrongfully\": 8\n\"rudely\": 6\n\"churchmen\": 6\n\"wive\": 6\n\"throughout\": 7\n\"Prosper\": 8\n\"Olympus\": 6\n\"doves\": 8\n\"increasing\": 6\n\"eyeless\": 6\n\"refuge\": 6\n\"pig\": 7\n\"strucken\": 8\n\"laments\": 6\n\"massacre\": 6\n\"swine\": 8\n\"headlong\": 6\n\"quell\": 6\n\"maw\": 6\n\"Home\": 8\n\"sconce\": 6\n\"ordain\": 8\n\"intercession\": 6\n\"confused\": 6\n\"repetition\": 7\n\"governor\": 8\n\"uttered\": 6\n\"verified\": 6\n\"grievously\": 6\n\"soul-\": 6\n\"savours\": 8\n\"waited\": 6\n\"liberties\": 6\n\"differences\": 7\n\"Normandy\": 7\n\"parson\": 6\n\"hum\": 8\n\"grooms\": 7\n\"smelt\": 7\n\"asses\": 6\n\"Told\": 8\n\"purest\": 6\n\"Austria\": 6\n\"varnish\": 6\n\"coals\": 8\n\"strengths\": 7\n\"jollity\": 6\n\"portly\": 6\n\"irons\": 7\n\"giv\": 7\n\"Mutius\": 7\n\"Life\": 7\n\"brooch\": 6\n\"Eight\": 7\n\"consideration\": 7\n\"spices\": 6\n\"forgetfulness\": 6\n\"reformation\": 6\n\"stark\": 8\n\"needy\": 6\n\"pretence\": 8\n\"pie\": 8\n\"detestable\": 6\n\"drag\": 8\n\"indignity\": 6\n\"Carry\": 8\n\"amiable\": 7\n\"changeling\": 7\n\"hearty\": 8\n\"Grandam\": 6\n\"consented\": 8\n\"unwholesome\": 7\n\"slaughtered\": 6\n\"overture\": 6\n\"consume\": 7\n\"Deserve\": 6\n\"wheat\": 8\n\"Safe\": 6\n\"heart-blood\": 7\n\"mellow\": 7\n\"meditation\": 7\n\"displeas\": 8\n\"fathom\": 7\n\"deity\": 6\n\"Married\": 6\n\"s-skin\": 6\n\"trump\": 6\n\"festival\": 6\n\"excels\": 6\n\"lightens\": 6\n\"Blood\": 7\n\"coffer\": 7\n\"eyes-\": 6\n\"baleful\": 7\n\"examples\": 6\n\"insolent\": 8\n\"functions\": 8\n\"blazon\": 7\n\"liable\": 6\n\"alarums\": 6\n\"Tend\": 7\n\"porridge\": 8\n\"deceitful\": 6\n\"Drown\": 6\n\"Chiron\": 6\n\"securely\": 6\n\"dusky\": 6\n\"rust\": 8\n\"contagion\": 6\n\"prophecies\": 7\n\"Plead\": 7\n\"upper\": 7\n\"desolate\": 6\n\"ungrateful\": 6\n\"prophetic\": 6\n\"dreaming\": 7\n\"encounters\": 6\n\"royalties\": 6\n\"hoar\": 6\n\"rapt\": 8\n\"brier\": 6\n\"formerly\": 7\n\"drawing\": 6\n\"stains\": 6\n\"see-\": 8\n\"overborne\": 6\n\"embassage\": 6\n\"Longer\": 6\n\"bathe\": 6\n\"fantastic\": 6\n\"revengeful\": 8\n\"Mistake\": 6\n\"forsook\": 7\n\"sot\": 6\n\"transformed\": 6\n\"rides\": 7\n\"laughs\": 8\n\"dastard\": 6\n\"nettles\": 6\n\"hermit\": 6\n\"audacious\": 6\n\"Sleeping\": 6\n\"daws\": 6\n\"dulcet\": 6\n\"bits\": 6\n\"us-\": 6\n\"parchment\": 8\n\"lordly\": 6\n\"jar\": 7\n\"troublesome\": 8\n\"Constance\": 8\n\"cargo\": 6\n\"presage\": 7\n\"well-\": 6\n\"MELUN\": 7\n\"Marian\": 6\n\"tunes\": 8\n\"vizards\": 7\n\"Seeking\": 8\n\"GOTH\": 7\n\"erst\": 6\n\"whipping\": 8\n\"earthquake\": 6\n\"accompany\": 6\n\"DEIPHOBUS\": 7\n\"Place\": 7\n\"windy\": 6\n\"certainty\": 8\n\"fin\": 8\n\"distinction\": 8\n\"conquered\": 7\n\"arrogance\": 6\n\"drench\": 8\n\"admiring\": 6\n\"rung\": 6\n\"Pretty\": 8\n\"Elizabeth\": 6\n\"oftentimes\": 7\n\"advocate\": 8\n\"what-\": 6\n\"Coeur-de-lion\": 6\n\"ruinous\": 6\n\"helping\": 6\n\"Dismiss\": 7\n\"pestilent\": 7\n\"ANTENOR\": 6\n\"brags\": 6\n\"sauciness\": 6\n\"solace\": 7\n\"Six\": 7\n\"Samson\": 7\n\"mine-\": 8\n\"Less\": 6\n\"folded\": 6\n\"lackey\": 7\n\"decline\": 6\n\"discovers\": 6\n\"candles\": 7\n\"drowned\": 6\n\"reverent\": 8\n\"boats\": 6\n\"exclaims\": 6\n\"gossips\": 7\n\"reek\": 6\n\"cherry\": 7\n\"honoured\": 7\n\"sentenc\": 6\n\"quarters\": 6\n\"righteous\": 6\n\"hip\": 8\n\"News\": 8\n\"entirely\": 7\n\"countries\": 7\n\"salutation\": 6\n\"lucky\": 6\n\"Rome-\": 7\n\"hasten\": 7\n\"wheresoe\": 6\n\"proclaims\": 6\n\"pavilion\": 7\n\"ostler\": 6\n\"Sicily\": 6\n\"gentlewomen\": 8\n\"accompanied\": 8\n\"legate\": 7\n\"endless\": 8\n\"housewife\": 7\n\"wart\": 7\n\"richest\": 7\n\"sandy\": 6\n\"Bade\": 6\n\"kennel\": 6\n\"supper-time\": 7\n\"considered\": 7\n\"poets\": 6\n\"partners\": 6\n\"Plains\": 6\n\"spade\": 8\n\"digg\": 8\n\"one-\": 8\n\"preserv\": 8\n\"succeeding\": 7\n\"deepest\": 6\n\"unsettled\": 6\n\"yawn\": 6\n\"astonish\": 6\n\"captivity\": 6\n\"suffered\": 8\n\"nerves\": 7\n\"dalliance\": 7\n\"humane\": 6\n\"Calchas\": 8\n\"fitter\": 8\n\"carpenter\": 7\n\"denying\": 6\n\"perus\": 6\n\"Consent\": 6\n\"Pursue\": 7\n\"flatteries\": 6\n\"Mass\": 6\n\"O-\": 6\n\"Cassandra\": 6\n\"Holiness\": 7\n\"Pandar\": 7\n\"bourn\": 6\n\"Cranmer\": 8\n\"havoc\": 8\n\"boundless\": 6\n\"meteors\": 6\n\"servile\": 7\n\"legitimate\": 7\n\"Helenus\": 8\n\"cooling\": 6\n\"arithmetic\": 6\n\"source\": 6\n\"auspicious\": 6\n\"timeless\": 8\n\"heaps\": 7\n\"Throws\": 8\n\"foundation\": 6\n\"establish\": 6\n\"ravenous\": 6\n\"session\": 7\n\"rested\": 6\n\"Cain\": 6\n\"sergeant\": 7\n\"fondly\": 8\n\"Report\": 6\n\"Seize\": 6\n\"goat\": 6\n\"traitorous\": 8\n\"Ferdinand\": 8\n\"aspiring\": 6\n\"Angus\": 7\n\"BISHOPS\": 6\n\"depending\": 7\n\"reveal\": 6\n\"Myrmidons\": 6\n\"eminence\": 6\n\"durance\": 7\n\"exploits\": 6\n\"mace\": 8\n\"qualify\": 8\n\"sexton\": 8\n\"travels\": 6\n\"discreet\": 7\n\"bespeak\": 6\n\"comparison\": 7\n\"quillets\": 6\n\"betake\": 6\n\"betroth\": 7\n\"ruler\": 6\n\"womanish\": 7\n\"determination\": 6\n\"first-born\": 7\n\"estates\": 7\n\"merchandise\": 7\n\"supreme\": 7\n\"disdainful\": 8\n\"fasten\": 6\n\"peasants\": 6\n\"Scots\": 8\n\"afterward\": 8\n\"daughter-\": 7\n\"lenity\": 8\n\"card\": 6\n\"ruminate\": 8\n\"Pinch\": 8\n\"conjurer\": 6\n\"confounded\": 7\n\"trembles\": 8\n\"reckless\": 6\n\"interchange\": 6\n\"digestion\": 6\n\"distressed\": 8\n\"watery\": 6\n\"travell\": 7\n\"Merely\": 7\n\"VAUX\": 7\n\"mounting\": 7\n\"Bound\": 7\n\"conception\": 7\n\"MASTER\": 6\n\"halter\": 8\n\"uneven\": 6\n\"serpents\": 6\n\"suborn\": 8\n\"Money\": 6\n\"rag\": 6\n\"Went\": 7\n\"SOUTHWELL\": 6\n\"harlot\": 8\n\"pardons\": 6\n\"gorge\": 8\n\"playfellow\": 6\n\"temperance\": 8\n\"Colours\": 6\n\"tribune\": 8\n\"creditor\": 6\n\"healthful\": 8\n\"Welshman\": 6\n\"broil\": 8\n\"cornets\": 8\n\"moulded\": 6\n\"filth\": 6\n\"grievance\": 6\n\"shock\": 6\n\"CLERK\": 6\n\"Second\": 7\n\"beer\": 6\n\"sicken\": 8\n\"openly\": 8\n\"Little\": 7\n\"mud\": 8\n\"confessor\": 8\n\"replied\": 8\n\"Bind\": 7\n\"safeguard\": 7\n\"kinds\": 6\n\"Retires\": 6\n\"duly\": 8\n\"thirsty\": 6\n\"brake\": 8\n\"seventeen\": 6\n\"masque\": 7\n\"towers\": 6\n\"GALLUS\": 6\n\"MURDERERS\": 6\n\"Sheriff\": 7\n\"Spirits\": 7\n\"d-for\": 8\n\"clamours\": 6\n\"Boar\": 8\n\"stained\": 6\n\"meals\": 6\n\"Whip\": 7\n\"potency\": 6\n\"Royal\": 8\n\"recreation\": 8\n\"weighs\": 8\n\"tun\": 6\n\"waving\": 8\n\"of-\": 7\n\"Fabian\": 7\n\"cross-garter\": 6\n\"Certainly\": 6\n\"Repair\": 8\n\"stew\": 7\n\"BUTTS\": 7\n\"cropp\": 6\n\"forgiveness\": 8\n\"prostrate\": 6\n\"Done\": 6\n\"affable\": 6\n\"surmise\": 6\n\"Behind\": 6\n\"VARRIUS\": 6\n\"shaking\": 8\n\"unluckily\": 7\n\"recovered\": 8\n\"Wolsey\": 7\n\"outrageous\": 6\n\"DENNY\": 8\n\"paces\": 7\n\"new-made\": 8\n\"glow\": 7\n\"Dick\": 8\n\"War\": 8\n\"customary\": 6\n\"brands\": 8\n\"ABERGAVENNY\": 8\n\"again-\": 8\n\"victors\": 6\n\"utterly\": 8\n\"begging\": 8\n\"Acquaint\": 6\n\"estimate\": 6\n\"Plague\": 6\n\"Ceres\": 6\n\"mow\": 8\n\"shameless\": 6\n\"dews\": 6\n\"CAPUCIUS\": 7\n\"fog\": 7\n\"burdens\": 8\n\"bode\": 7\n\"digested\": 6\n\"Hume\": 8\n\"stable\": 7\n\"regions\": 7\n\"regiment\": 7\n\"exeunt\": 7\n\"acting\": 6\n\"newer\": 6\n\"agony\": 6\n\"depth\": 7\n\"kite\": 7\n\"broker\": 6\n\"Forsooth\": 6\n\"drove\": 6\n\"PETITIONER\": 7\n\"woodcock\": 7\n\"muffled\": 7\n\"churchman\": 7\n\"thereupon\": 8\n\"grieved\": 7\n\"unjustly\": 7\n\"widower\": 6\n\"kinder\": 6\n\"gratify\": 8\n\"king-\": 7\n\"PATRICIANS\": 6\n\"cloy\": 8\n\"supple\": 6\n\"bags\": 8\n\"offspring\": 6\n\"cushions\": 6\n\"treasury\": 6\n\"patron\": 8\n\"Pour\": 6\n\"breeches\": 7\n\"genius\": 6\n\"misfortune\": 8\n\"weeks\": 7\n\"danc\": 6\n\"depose\": 8\n\"impose\": 8\n\"sounding\": 6\n\"doubted\": 8\n\"himself-\": 6\n\"Bestow\": 6\n\"relate\": 8\n\"embark\": 6\n\"Embrace\": 7\n\"harmful\": 8\n\"pry\": 8\n\"Thence\": 6\n\"exact\": 7\n\"confounds\": 8\n\"slily\": 6\n\"nicely\": 8\n\"Volscians\": 6\n\"Kissing\": 6\n\"packet\": 8\n\"proportions\": 6\n\"Launce\": 7\n\"throngs\": 6\n\"impediments\": 7\n\"popular\": 6\n\"excel\": 6\n\"betide\": 8\n\"subdue\": 7\n\"Admit\": 6\n\"variable\": 6\n\"injurious\": 8\n\"unhallowed\": 6\n\"Divide\": 6\n\"alt\": 6\n\"pins\": 8\n\"begs\": 7\n\"sweating\": 6\n\"garter\": 7\n\"cures\": 8\n\"misprision\": 6\n\"welcomes\": 7\n\"life-\": 8\n\"sleeves\": 7\n\"courageous\": 8\n\"poise\": 7\n\"subdued\": 6\n\"Tartar\": 8\n\"Tarquin\": 8\n\"Disdain\": 6\n\"cushion\": 7\n\"neighbourhood\": 7\n\"Remain\": 7\n\"mutinous\": 8\n\"staves\": 8\n\"clubs\": 6\n\"poisoned\": 7\n\"honestly\": 7\n\"gust\": 6\n\"adding\": 7\n\"accounted\": 6\n\"gusts\": 7\n\"trivial\": 7\n\"remedies\": 8\n\"Immediately\": 7\n\"seemeth\": 8\n\"inventory\": 6\n\"pikes\": 8\n\"thirst\": 8\n\"honourably\": 6\n\"supplant\": 6\n\"ghostly\": 7\n\"downfall\": 7\n\"firmly\": 8\n\"correct\": 8\n\"brav\": 7\n\"teaches\": 6\n\"string\": 6\n\"Indian\": 8\n\"slaughter-house\": 6\n\"am-\": 7\n\"Crying\": 7\n\"resemble\": 8\n\"I-\": 8\n\"Cornets\": 6\n\"tir\": 6\n\"measures\": 8\n\"Ourselves\": 7\n\"transported\": 8\n\"Measure\": 6\n\"steeled\": 6\n\"erwhelm\": 6\n\"uncivil\": 8\n\"stride\": 6\n\"kerns\": 7\n\"strives\": 8\n\"tough\": 8\n\"antiquity\": 6\n\"courts\": 8\n\"lances\": 8\n\"bribe\": 6\n\"speak-\": 8\n\"murderous\": 7\n\"selfsame\": 7\n\"sways\": 8\n\"Herein\": 7\n\"triumphs\": 8\n\"judg\": 7\n\"refus\": 6\n\"hatches\": 7\n\"done-\": 7\n\"bloodless\": 6\n\"accusers\": 6\n\"comparisons\": 7\n\"ninth\": 7\n\"brew\": 6\n\"bastardy\": 8\n\"bran\": 7\n\"bridal\": 8\n\"tam\": 6\n\"misdoubt\": 6\n\"Ambassador\": 8\n\"toads\": 8\n\"poorest\": 8\n\"injustice\": 8\n\"rats\": 8\n\"Doing\": 8\n\"faints\": 6\n\"prospect\": 6\n\"Change\": 8\n\"mounts\": 6\n\"ertake\": 8\n\"coal\": 7\n\"shunn\": 7\n\"enrolled\": 6\n\"thorough\": 8\n\"greyhound\": 8\n\"saith\": 6\n\"Holding\": 8\n\"mildness\": 7\n\"factions\": 7\n\"impudent\": 8\n\"anguish\": 6\n\"waft\": 6\n\"nick\": 7\n\"flay\": 6\n\"Drink\": 8\n\"skins\": 6\n\"itch\": 8\n\"wisdoms\": 8\n\"pedlar\": 8\n\"tigers\": 6\n\"Win\": 6\n\"Bury\": 8\n\"provokes\": 6\n\"doit\": 7\n\"obdurate\": 7\n\"saves\": 6\n\"musty\": 8\n\"Iden\": 6\n\"entire\": 8\n\"bended\": 7\n\"flaw\": 8\n\"Observe\": 7\n\"doubtless\": 7\n\"continues\": 6\n\"Lartius\": 8\n\"Shalt\": 7\n\"edict\": 7\n\"Pluto\": 8\n\"cursing\": 6\n\"Neapolitan\": 6\n\"Advance\": 7\n\"cloven\": 6\n\"chop\": 8\n\"dispense\": 7\n\"SELEUCUS\": 7\n\"generals\": 7\n\"uncles\": 8\n\"strengthen\": 7\n\"northern\": 8\n\"sinister\": 6\n\"Try\": 6\n\"MONTGOMERY\": 7\n\"peal\": 7\n\"shorter\": 6\n\"Wiltshire\": 7\n\"organ\": 6\n\"BONA\": 7\n\"sew\": 8\n\"FATHER\": 7\n\"escap\": 6\n\"margent\": 6\n\"ordnance\": 6\n\"battlements\": 8\n\"arrow\": 8\n\"scant\": 8\n\"hilts\": 6\n\"herb\": 8\n\"closely\": 8\n\"royally\": 8\n\"viands\": 6\n\"carriages\": 7\n\"Drinks\": 8\n\"moons\": 7\n\"burthen\": 6\n\"potion\": 6\n\"7\": 7\n\"carved\": 6\n\"lamented\": 6\n\"suburbs\": 8\n\"abides\": 7\n\"imputation\": 7\n\"considering\": 4\n\"yours-\": 5\n\"Summon\": 5\n\"undertook\": 5\n\"uphold\": 5\n\"SOMERVILLE\": 5\n\"stamps\": 5\n\"graciously\": 5\n\"disdains\": 5\n\"reconcil\": 5\n\"carelessly\": 5\n\"fry\": 5\n\"forgiven\": 5\n\"Trouble\": 5\n\"union\": 5\n\"cannons\": 5\n\"palpable\": 5\n\"Peruse\": 5\n\"enfranchisement\": 5\n\"DAUGHTER\": 5\n\"hitherward\": 5\n\"sheep-shearing\": 5\n\"beck\": 5\n\"impossibility\": 5\n\"hic\": 5\n\"wrap\": 5\n\"remembrances\": 5\n\"sues\": 5\n\"whatsoe\": 5\n\"Stealing\": 5\n\"scaped\": 5\n\"slowly\": 5\n\"pleading\": 5\n\"PART\": 5\n\"masked\": 5\n\"Antipodes\": 5\n\"insurrection\": 5\n\"Mounsieur\": 5\n\"MARINER\": 5\n\"gotten\": 5\n\"raising\": 5\n\"Bold\": 5\n\"conjuration\": 5\n\"declin\": 5\n\"Breathe\": 5\n\"Destroy\": 5\n\"deputation\": 5\n\"issued\": 5\n\"Held\": 5\n\"lamps\": 5\n\"consents\": 5\n\"determinate\": 5\n\"thoroughly\": 5\n\"legacy\": 5\n\"predominant\": 5\n\"Antony-\": 5\n\"daub\": 5\n\"fawning\": 5\n\"oaks\": 5\n\"loam\": 5\n\"loaden\": 5\n\"sea-side\": 5\n\"Land\": 5\n\"heraldry\": 5\n\"unwelcome\": 5\n\"vaward\": 5\n\"shoots\": 5\n\"Holmedon\": 5\n\"artillery\": 5\n\"eclipses\": 5\n\"speeds\": 5\n\"smear\": 5\n\"apothecary\": 5\n\"chafe\": 5\n\"Viola\": 5\n\"orbs\": 5\n\"wishing\": 5\n\"gun\": 5\n\"target\": 5\n\"scout\": 5\n\"clocks\": 5\n\"rearward\": 5\n\"braving\": 5\n\"contradict\": 5\n\"foremost\": 5\n\"Unworthy\": 5\n\"gnats\": 5\n\"progeny\": 5\n\"repaid\": 5\n\"deliberate\": 5\n\"hymn\": 5\n\"MARGARELON\": 5\n\"HELENUS\": 5\n\"footman\": 5\n\"clos\": 5\n\"instructed\": 5\n\"disaster\": 5\n\"madcap\": 5\n\"grosser\": 5\n\"stumps\": 5\n\"fitly\": 5\n\"thus-\": 5\n\"hawthorn\": 5\n\"Woo\": 5\n\"pear\": 5\n\"sinks\": 5\n\"Meg\": 5\n\"chafed\": 5\n\"violate\": 5\n\"discomfort\": 5\n\"Rape\": 5\n\"leaning\": 5\n\"enjoying\": 5\n\"usurers\": 5\n\"remiss\": 5\n\"argosy\": 5\n\"orders\": 5\n\"Suffer\": 5\n\"Emperess\": 5\n\"slime\": 5\n\"cracking\": 5\n\"surveyor\": 5\n\"bruise\": 5\n\"EMPEROR\": 5\n\"sorely\": 5\n\"smoky\": 5\n\"cypress\": 5\n\"Letters\": 5\n\"seeds\": 5\n\"caution\": 5\n\"sorrowful\": 5\n\"rancour\": 5\n\"commence\": 5\n\"boasting\": 5\n\"armourer\": 5\n\"Sooth\": 5\n\"buckled\": 5\n\"Carrier\": 5\n\"infallible\": 5\n\"abilities\": 5\n\"SILIUS\": 5\n\"selves\": 5\n\"forfeited\": 5\n\"Verily\": 5\n\"synod\": 5\n\"BANDITTI\": 5\n\"are-\": 5\n\"dank\": 5\n\"deformity\": 5\n\"arraign\": 5\n\"oats\": 5\n\"Drums\": 5\n\"hawks\": 5\n\"duchess\": 5\n\"Lean\": 5\n\"White\": 5\n\"thump\": 5\n\"(Sings)\": 5\n\"Retire\": 5\n\"appellant\": 5\n\"God-den\": 5\n\"nods\": 5\n\"furniture\": 5\n\"straws\": 5\n\"iniquity\": 5\n\"yards\": 5\n\"sprightly\": 5\n\"colt\": 5\n\"repulse\": 5\n\"artificial\": 5\n\"picking\": 5\n\"gash\": 5\n\"craven\": 5\n\"Compare\": 5\n\"gashes\": 5\n\"Leap\": 5\n\"deceased\": 5\n\"Creep\": 5\n\"caterpillars\": 5\n\"CONSPIRATORS\": 5\n\"nettle\": 5\n\"snakes\": 5\n\"gowns\": 5\n\"Hide\": 5\n\"coal-black\": 5\n\"rattling\": 5\n\"murmur\": 5\n\"meditating\": 5\n\"descends\": 5\n\"doubting\": 5\n\"bring\": 374\n\"Galen\": 5\n\"flew\": 5\n\"lastly\": 5\n\"night-\": 5\n\"raught\": 5\n\"People\": 5\n\"sleepers\": 5\n\"during\": 5\n\"despiteful\": 5\n\"bleak\": 5\n\"conjoin\": 5\n\"showed\": 5\n\"temp\": 5\n\"herring\": 5\n\"vesture\": 5\n\"bestowing\": 5\n\"patches\": 5\n\"authorities\": 5\n\"dejected\": 5\n\"tithe\": 5\n\"sea-\": 5\n\"unmeet\": 5\n\"lath\": 5\n\"fretted\": 5\n\"flung\": 5\n\"buckler\": 5\n\"scanted\": 5\n\"pepper\": 5\n\"Began\": 5\n\"smelling\": 5\n\"indifferently\": 5\n\"basin\": 5\n\"separation\": 5\n\"extempore\": 5\n\"teachest\": 5\n\"slumbers\": 5\n\"ancestor\": 5\n\"grasp\": 5\n\"Inform\": 5\n\"lim\": 5\n\"usest\": 5\n\"rood\": 5\n\"Ran\": 5\n\"rive\": 5\n\"extant\": 5\n\"pat\": 5\n\"outrages\": 5\n\"new-born\": 5\n\"pageants\": 5\n\"repay\": 5\n\"bed-\": 5\n\"currish\": 5\n\"visible\": 5\n\"nether\": 5\n\"gan\": 5\n\"reeking\": 5\n\"Queen-\": 5\n\"Roger\": 5\n\"massy\": 5\n\"lost-\": 5\n\"preposterous\": 5\n\"contemn\": 5\n\"rook\": 5\n\"Margery\": 5\n\"heigh\": 5\n\"discords\": 5\n\"musters\": 5\n\"strangled\": 5\n\"Weary\": 5\n\"camel\": 5\n\"Unarm\": 5\n\"Manent\": 5\n\"Deep\": 5\n\"Sher\": 5\n\"OFEPHESUS\": 5\n\"halberds\": 5\n\"retirement\": 5\n\"ban\": 5\n\"vasty\": 5\n\"scapes\": 5\n\"transport\": 5\n\"milk-white\": 5\n\"wherewith\": 5\n\"nursery\": 5\n\"FIFTH\": 5\n\"Nevils\": 5\n\"remnant\": 5\n\"sued\": 5\n\"thou-\": 5\n\"cape\": 5\n\"hurried\": 5\n\"Abbess\": 5\n\"harp\": 5\n\"pillars\": 5\n\"dimm\": 5\n\"grate\": 5\n\"Especially\": 5\n\"cavil\": 5\n\"stooping\": 5\n\"GARTER\": 5\n\"bolder\": 5\n\"comfortless\": 5\n\"Gardiner\": 5\n\"Prologue\": 5\n\"Lascivious\": 5\n\"Servingman\": 5\n\"temptation\": 5\n\"Pride\": 5\n\"Abr\": 5\n\"BULLEN\": 5\n\"Bullen\": 5\n\"Montagues\": 5\n\"churches\": 5\n\"PATIENCE\": 5\n\"penn\": 5\n\"roughly\": 5\n\"woos\": 5\n\"Enforce\": 5\n\"Maskers\": 5\n\"convenience\": 5\n\"understands\": 5\n\"guided\": 5\n\"brach\": 5\n\"lacking\": 5\n\"allied\": 5\n\"lavish\": 5\n\"buffets\": 5\n\"skipping\": 5\n\"twofold\": 5\n\"cop\": 5\n\"Sitting\": 5\n\"additions\": 5\n\"hopeless\": 5\n\"(for\": 5\n\"welfare\": 5\n\"monk\": 5\n\"Proculeius\": 5\n\"Due\": 5\n\"Richer\": 5\n\"queen-\": 5\n\"CHRISTOPHER\": 5\n\"wailing\": 5\n\"thunderbolt\": 5\n\"virtuously\": 5\n\"bearest\": 5\n\"confederate\": 5\n\"besmear\": 5\n\"calumny\": 5\n\"examination\": 5\n\"WALTER\": 5\n\"breeder\": 5\n\"visiting\": 5\n\"currents\": 5\n\"ball\": 5\n\"Striking\": 5\n\"shirts\": 5\n\"fife\": 5\n\"maskers\": 5\n\"habited\": 5\n\"rounds\": 5\n\"frustrate\": 5\n\"conquerors\": 5\n\"vail\": 5\n\"VAUGHAN\": 5\n\"simpleness\": 5\n\"Charge\": 5\n\"taints\": 5\n\"aches\": 5\n\"blench\": 5\n\"innocency\": 5\n\"mutinies\": 5\n\"revolts\": 5\n\"demean\": 5\n\"steer\": 5\n\"foh\": 5\n\"tractable\": 5\n\"seats\": 5\n\"gaunt\": 5\n\"arrive\": 5\n\"Ely\": 5\n\"Temple\": 5\n\"unclean\": 5\n\"Keeper\": 5\n\"secretary\": 5\n\"hypocrisy\": 5\n\"Delay\": 5\n\"ABBOT\": 5\n\"Sick\": 5\n\"adds\": 5\n\"pirates\": 5\n\"juggling\": 5\n\"up-\": 5\n\"Drawing\": 5\n\"threshold\": 5\n\"implore\": 5\n\"thighs\": 5\n\"Grows\": 5\n\"Canidius\": 5\n\"MUSICIAN\": 5\n\"flaming\": 5\n\"Ilium\": 5\n\"magistrates\": 5\n\"Wretched\": 5\n\"distinctly\": 5\n\"Lack\": 5\n\"avaunt\": 5\n\"couched\": 5\n\"nephews\": 5\n\"Tarpeian\": 5\n\"rugged\": 5\n\"napkins\": 5\n\"tut\": 5\n\"register\": 5\n\"tackle\": 5\n\"encamp\": 5\n\"clearer\": 5\n\"decease\": 5\n\"resisted\": 5\n\"Envy\": 5\n\"Entreat\": 5\n\"spells\": 5\n\"vanished\": 5\n\"thereon\": 5\n\"Needs\": 5\n\"tapestry\": 5\n\"exactly\": 5\n\"paramour\": 5\n\"lady-\": 5\n\"reprieve\": 5\n\"Arch\": 5\n\"confederacy\": 5\n\"sterile\": 5\n\"doff\": 5\n\"swarm\": 5\n\"Alone\": 5\n\"smote\": 5\n\"Falconbridge\": 5\n\"Anything\": 5\n\"befriend\": 5\n\"Hell\": 5\n\"Maintain\": 5\n\"subjection\": 5\n\"withhold\": 5\n\"Surely\": 5\n\"aprons\": 5\n\"stepp\": 5\n\"modestly\": 5\n\"wholly\": 5\n\"life-blood\": 5\n\"Mean\": 5\n\"extremities\": 5\n\"sceptres\": 5\n\"posture\": 5\n\"Born\": 5\n\"expostulate\": 5\n\"prompts\": 5\n\"Arabia\": 5\n\"earthy\": 5\n\"Thracian\": 5\n\"riseth\": 5\n\"stratagems\": 5\n\"Marseilles\": 5\n\"strangest\": 5\n\"Moreover\": 5\n\"Pleaseth\": 5\n\"luggage\": 5\n\"mermaid\": 5\n\"trophy\": 5\n\"scouts\": 5\n\"fuel\": 5\n\"officious\": 5\n\"warmth\": 5\n\"affrighted\": 5\n\"trudge\": 5\n\"leave-taking\": 5\n\"lecture\": 5\n\"suppliant\": 5\n\"snares\": 5\n\"venomous\": 5\n\"slide\": 5\n\"Fine\": 5\n\"brothel\": 5\n\"chaf\": 5\n\"Indies\": 5\n\"sucks\": 5\n\"importing\": 5\n\"respite\": 5\n\"moans\": 5\n\"Ourself\": 5\n\"Allow\": 5\n\"suspicious\": 5\n\"citizen\": 5\n\"rushing\": 5\n\"contriv\": 5\n\"quaintly\": 5\n\"lords-\": 5\n\"clutch\": 5\n\"toucheth\": 5\n\"whiteness\": 5\n\"celebration\": 5\n\"adulterate\": 5\n\"groves\": 5\n\"Blessing\": 5\n\"dreaded\": 5\n\"derision\": 5\n\"possessed\": 5\n\"Peaseblossom\": 5\n\"chink\": 5\n\"unwillingly\": 5\n\"Moonshine\": 5\n\"stag\": 5\n\"Poland\": 5\n\"moods\": 5\n\"graced\": 5\n\"plumes\": 5\n\"FAIRIES\": 5\n\"populous\": 5\n\"vial\": 5\n\"(within)\": 5\n\"Puck\": 5\n\"DENNIS\": 5\n\"MARTEXT\": 5\n\"vicar\": 5\n\"FLORENCE\": 5\n\"stung\": 5\n\"combined\": 5\n\"poesy\": 5\n\"blanks\": 5\n\"usher\": 5\n\"Pepin\": 5\n\"seriously\": 5\n\"sweeting\": 5\n\"animals\": 5\n\"beckons\": 5\n\"Morton\": 5\n\"vanquished\": 5\n\"Provide\": 5\n\"husks\": 5\n\"vowed\": 5\n\"Porpentine\": 5\n\"Grief\": 5\n\"unawares\": 5\n\"albeit\": 5\n\"thrusting\": 5\n\"airs\": 5\n\"baited\": 5\n\"Weak\": 5\n\"Rough\": 5\n\"highway\": 5\n\"dressed\": 5\n\"hapless\": 5\n\"complices\": 5\n\"exercises\": 5\n\"cake\": 5\n\"debating\": 5\n\"tending\": 5\n\"bawds\": 5\n\"par\": 5\n\"spits\": 5\n\"mickle\": 5\n\"frets\": 5\n\"tragical\": 5\n\"JAMES\": 5\n\"joiner\": 5\n\"blindness\": 5\n\"rful\": 5\n\"unaccustom\": 5\n\"Affection\": 5\n\"builds\": 5\n\"celerity\": 5\n\"arbitrate\": 5\n\"fling\": 5\n\"defendant\": 5\n\"engenders\": 5\n\"much-\": 5\n\"caper\": 5\n\"dispossess\": 5\n\"brandish\": 5\n\"Bears\": 5\n\"escapes\": 5\n\"dieted\": 5\n\"eclipse\": 5\n\"Wisdom\": 5\n\"cheater\": 5\n\"beheaded\": 5\n\"requited\": 5\n\"knightly\": 5\n\"vehement\": 5\n\"trifling\": 5\n\"unworthiness\": 5\n\"orient\": 5\n\"Hunter\": 5\n\"cank\": 5\n\"Cuts\": 5\n\"goblins\": 5\n\"Commanded\": 5\n\"worshipful\": 5\n\"incestuous\": 5\n\"(O\": 5\n\"Visit\": 5\n\"keepers\": 5\n\"workman\": 5\n\"obligation\": 5\n\"counties\": 5\n\"singly\": 5\n\"bashful\": 5\n\"wrung\": 5\n\"freer\": 5\n\"Lionel\": 5\n\"apparell\": 5\n\"foolishly\": 5\n\"Fain\": 5\n\"purblind\": 5\n\"eminent\": 5\n\"surrender\": 5\n\"Taste\": 5\n\"tenants\": 5\n\"clad\": 5\n\"hallow\": 5\n\"barge\": 5\n\"clears\": 5\n\"started\": 5\n\"Vat\": 5\n\"spout\": 5\n\"Ev\": 5\n\"larger\": 5\n\"demonstrate\": 5\n\"beholders\": 5\n\"mouldy\": 5\n\"lethargy\": 5\n\"denote\": 5\n\"forwardness\": 5\n\"prunes\": 5\n\"cashier\": 5\n\"sorted\": 5\n\"venturous\": 5\n\"challenger\": 5\n\"enchanting\": 5\n\"lake\": 5\n\"fortified\": 5\n\"owners\": 5\n\"Others\": 5\n\"ventur\": 5\n\"standard\": 5\n\"Traitors\": 5\n\"sinn\": 5\n\"fortitude\": 5\n\"tickling\": 5\n\"platform\": 5\n\"largess\": 5\n\"shilling\": 5\n\"Sailors\": 5\n\"chastise\": 5\n\"fragrant\": 5\n\"prophetess\": 5\n\"Ambassadors\": 5\n\"glittering\": 5\n\"Stephen\": 5\n\"thirteen\": 5\n\"pinches\": 5\n\"Add\": 5\n\"doleful\": 5\n\"Priest\": 5\n\"Beating\": 5\n\"Lodowick\": 5\n\"MUSICIANS\": 5\n\"dross\": 5\n\"tempts\": 5\n\"greed\": 5\n\"doubled\": 5\n\"Sisters\": 5\n\"driving\": 5\n\"thievish\": 5\n\"paths\": 5\n\"habitation\": 5\n\"Lafeu\": 5\n\"ruins\": 5\n\"unite\": 5\n\"using\": 5\n\"Buy\": 5\n\"Perform\": 5\n\"expel\": 5\n\"hearken\": 5\n\"aggravate\": 5\n\"Lent\": 5\n\"fulsome\": 5\n\"coupled\": 5\n\"garb\": 5\n\"cuff\": 5\n\"tore\": 5\n\"Salerio\": 5\n\"buzzing\": 5\n\"billows\": 5\n\"hips\": 5\n\"grafted\": 5\n\"Clement\": 5\n\"mince\": 5\n\"Whatever\": 5\n\"coy\": 5\n\"feelingly\": 5\n\"annoyance\": 5\n\"Sampson\": 5\n\"noisome\": 5\n\"lash\": 5\n\"Rialto\": 5\n\"bridle\": 5\n\"brooks\": 5\n\"esquire\": 5\n\"phrases\": 5\n\"Presently\": 5\n\"semblable\": 5\n\"Touraine\": 5\n\"gor\": 5\n\"Resolve\": 5\n\"rays\": 5\n\"Shadow\": 5\n\"hairy\": 5\n\"duller\": 5\n\"validity\": 5\n\"such-like\": 5\n\"Post\": 5\n\"jumps\": 5\n\"thrusts\": 5\n\"fork\": 5\n\"witches\": 5\n\"possessions\": 5\n\"attention\": 5\n\"thrifty\": 5\n\"translated\": 5\n\"ravens\": 5\n\"rebellious\": 5\n\"Sufficeth\": 5\n\"fellow-\": 5\n\"vineyard\": 5\n\"schedule\": 5\n\"hug\": 5\n\"rocky\": 5\n\"suggest\": 5\n\"united\": 5\n\"shent\": 5\n\"Lov\": 5\n\"travellers\": 5\n\"toothache\": 5\n\"stolen\": 5\n\"matron\": 5\n\"nurs\": 5\n\"Poictiers\": 5\n\"dwarfish\": 5\n\"searching\": 5\n\"obstinate\": 5\n\"longest\": 5\n\"immaculate\": 5\n\"Soon\": 5\n\"supplication\": 5\n\"Cease\": 5\n\"Isabella\": 5\n\"closes\": 5\n\"rents\": 5\n\"beach\": 5\n\"Heralds\": 5\n\"shamefully\": 5\n\"JOAN\": 5\n\"feeder\": 5\n\"striking\": 5\n\"in-\": 5\n\"immodest\": 5\n\"thing-\": 5\n\"bee\": 5\n\"Says\": 5\n\"births\": 5\n\"TREBONIUS\": 5\n\"Hate\": 5\n\"recall\": 5\n\"apparition\": 5\n\"dogg\": 5\n\"gem\": 5\n\"Aegeon\": 5\n\"Rain\": 5\n\"gyves\": 5\n\"fetter\": 5\n\"Putting\": 5\n\"reference\": 5\n\"CICERO\": 5\n\"prone\": 5\n\"Cheerly\": 5\n\"properties\": 5\n\"stories\": 5\n\"GARGRAVE\": 5\n\"delighted\": 5\n\"homeward\": 5\n\"sallet\": 5\n\"FRANCISCA\": 5\n\"thankfulness\": 5\n\"threescore\": 5\n\"masks\": 5\n\"believed\": 5\n\"violently\": 5\n\"Grew\": 5\n\"prophesied\": 5\n\"Overdone\": 5\n\"Thanes\": 5\n\"STRATO\": 5\n\"heedful\": 5\n\"admir\": 5\n\"observing\": 5\n\"Forc\": 5\n\"carbonado\": 5\n\"lout\": 5\n\"fines\": 5\n\"incessant\": 5\n\"civility\": 5\n\"Enjoy\": 5\n\"guise\": 5\n\"conspirators\": 5\n\"mon\": 5\n\"oh\": 5\n\"inland\": 5\n\"Brothers\": 5\n\"walked\": 5\n\"raze\": 5\n\"Stain\": 5\n\"curl\": 5\n\"teeming\": 5\n\"embracements\": 5\n\"cited\": 5\n\"Drew\": 5\n\"theatre\": 5\n\"meads\": 5\n\"outright\": 5\n\"factor\": 5\n\"Flavius\": 5\n\"perceived\": 5\n\"unspeakable\": 5\n\"interr\": 5\n\"hedges\": 5\n\"burned\": 5\n\"libertine\": 5\n\"confiscate\": 5\n\"interview\": 5\n\"LEONATUS\": 5\n\"fairs\": 5\n\"school-boy\": 5\n\"cudgell\": 5\n\"curtsies\": 5\n\"groat\": 5\n\"rancorous\": 5\n\"Belarius\": 5\n\"bough\": 5\n\"and-\": 5\n\"infringe\": 5\n\"marketplace\": 5\n\"complaining\": 5\n\"tortures\": 5\n\"lin\": 5\n\"inviting\": 5\n\"Gaoler\": 5\n\"spongy\": 5\n\"undoubted\": 5\n\"Sans\": 5\n\"ruled\": 5\n\"headless\": 5\n\"feigning\": 5\n\"murthers\": 5\n\"momentary\": 5\n\"rubs\": 5\n\"extent\": 5\n\"lodged\": 5\n\"forge\": 5\n\"twin\": 5\n\"ram\": 5\n\"forbids\": 5\n\"seemed\": 5\n\"counterpoise\": 5\n\"Golden\": 5\n\"incertain\": 5\n\"Lechery\": 5\n\"mayest\": 5\n\"furr\": 5\n\"court-\": 5\n\"primrose\": 5\n\"cherubin\": 5\n\"ENGLISH\": 5\n\"insinuate\": 5\n\"lasts\": 5\n\"surgery\": 5\n\"perfum\": 5\n\"lowliness\": 5\n\"DE\": 5\n\"nothing-\": 5\n\"groats\": 5\n\"Thorough\": 5\n\"nonpareil\": 5\n\"rams\": 5\n\"untaught\": 5\n\"cattle\": 5\n\"forged\": 5\n\"combine\": 5\n\"leeks\": 5\n\"Forres\": 5\n\"ruffle\": 5\n\"Macedon\": 5\n\"weakest\": 5\n\"Listen\": 5\n\"haven\": 5\n\"carcass\": 5\n\"snatches\": 5\n\"clearly\": 5\n\"esteems\": 5\n\"fear-\": 5\n\"fulfil\": 5\n\"slavish\": 5\n\"wardrobe\": 5\n\"BOURBON\": 5\n\"gallop\": 5\n\"ANGUS\": 5\n\"pointed\": 5\n\"similes\": 5\n\"tributary\": 5\n\"millions\": 5\n\"orisons\": 5\n\"charming\": 5\n\"sayings\": 5\n\"erring\": 5\n\"gentles\": 5\n\"sightless\": 5\n\"Saturn\": 5\n\"Reply\": 5\n\"sprite\": 5\n\"wished\": 5\n\"foison\": 5\n\"dignified\": 5\n\"importance\": 5\n\"doubly\": 5\n\"word-\": 5\n\"twigs\": 5\n\"receiving\": 5\n\"downward\": 5\n\"Chorus\": 5\n\"couples\": 5\n\"a-\": 5\n\"flowing\": 5\n\"waning\": 5\n\"Crispian\": 5\n\"convince\": 5\n\"provender\": 5\n\"replies\": 5\n\"disgraces\": 5\n\"team\": 5\n\"caparison\": 5\n\"strip\": 5\n\"jesting\": 5\n\"ghastly\": 5\n\"utters\": 5\n\"Twenty\": 5\n\"conceits\": 5\n\"fulness\": 5\n\"mortified\": 5\n\"offending\": 5\n\"hoarse\": 5\n\"vizard\": 5\n\"unloose\": 5\n\"Via\": 5\n\"wrinkle\": 5\n\"plunge\": 5\n\"drug\": 5\n\"kick\": 5\n\"afflictions\": 5\n\"conn\": 5\n\"Humh\": 5\n\"leans\": 5\n\"prop\": 5\n\"magician\": 5\n\"wrest\": 5\n\"Satisfy\": 5\n\"Maccabaeus\": 5\n\"successive\": 5\n\"se\": 5\n\"confirmation\": 5\n\"oppressed\": 5\n\"contrived\": 5\n\"Bur\": 5\n\"authors\": 5\n\"forestall\": 5\n\"Trip\": 5\n\"lawyers\": 5\n\"vilest\": 5\n\"heathen\": 5\n\"suspects\": 5\n\"kindled\": 5\n\"infinitely\": 5\n\"turtles\": 5\n\"finer\": 5\n\"mongrel\": 5\n\"counterfeited\": 5\n\"teen\": 5\n\"monkeys\": 5\n\"Crown\": 5\n\"brawn\": 5\n\"great-uncle\": 5\n\"slough\": 5\n\"Forget\": 5\n\"gibes\": 5\n\"consciences\": 5\n\"lunacy\": 5\n\"Praise\": 5\n\"rescu\": 5\n\"defended\": 5\n\"Playing\": 5\n\"victories\": 5\n\"believing\": 5\n\"pillage\": 5\n\"choughs\": 5\n\"watches\": 5\n\"apish\": 5\n\"pang\": 5\n\"ooze\": 5\n\"apology\": 5\n\"loathe\": 5\n\"Russian\": 5\n\"forsaken\": 5\n\"illustrious\": 5\n\"bestows\": 5\n\"she-\": 5\n\"buttock\": 5\n\"diseas\": 5\n\"paste\": 5\n\"sola\": 5\n\"Sola\": 5\n\"Meaning\": 5\n\"thatch\": 5\n\"shooting\": 5\n\"jacks\": 5\n\"Southampton\": 5\n\"material\": 5\n\"Ethiope\": 5\n\"foulness\": 5\n\"village\": 5\n\"robbing\": 5\n\"plantain\": 5\n\"pless\": 5\n\"slavery\": 5\n\"foaming\": 5\n\"Crete\": 5\n\"enchanted\": 5\n\"values\": 5\n\"quote\": 5\n\"pauca\": 5\n\"pridge\": 5\n\"Moth\": 5\n\"fading\": 5\n\"refresh\": 5\n\"Wonder\": 5\n\"piety\": 5\n\"pitying\": 5\n\"Aunchient\": 5\n\"scarfs\": 5\n\"Phoenix\": 5\n\"dues\": 5\n\"crocodile\": 5\n\"flats\": 5\n\"soever\": 5\n\"feasted\": 5\n\"sanctity\": 5\n\"sisterhood\": 5\n\"religiously\": 5\n\"covered\": 5\n\"five-and-twenty\": 5\n\"well-favour\": 5\n\"perjured\": 5\n\"unlock\": 5\n\"Study\": 5\n\"celebrate\": 5\n\"contradiction\": 5\n\"Montjoy\": 5\n\"lac\": 5\n\"reservation\": 5\n\"reckonings\": 5\n\"Brabant\": 5\n\"dye\": 5\n\"shap\": 5\n\"ma\": 5\n\"outwardly\": 5\n\"pities\": 5\n\"cowslip\": 5\n\"athwart\": 5\n\"redoubted\": 5\n\"dragons\": 5\n\"was-\": 5\n\"serviceable\": 5\n\"honneur\": 5\n\"monarchy\": 5\n\"Day\": 5\n\"curate\": 5\n\"penetrate\": 5\n\"MARCADE\": 5\n\"Oui\": 5\n\"gins\": 5\n\"extort\": 5\n\"grieving\": 5\n\"blanket\": 5\n\"passed\": 5\n\"brim\": 5\n\"forgetful\": 5\n\"hotter\": 5\n\"vantages\": 5\n\"mots\": 5\n\"raineth\": 5\n\"bon\": 5\n\"ounce\": 5\n\"inspir\": 5\n\"stillness\": 5\n\"greyhounds\": 5\n\"tutors\": 5\n\"eyeballs\": 5\n\"cream\": 5\n\"leer\": 5\n\"acold\": 5\n\"Caesar-\": 5\n\"attentive\": 5\n\"pretend\": 5\n\"dumbness\": 5\n\"graceful\": 5\n\"ply\": 5\n\"Les\": 5\n\"doigts\": 5\n\"enlargement\": 5\n\"hilding\": 5\n\"honester\": 5\n\"Fellows\": 5\n\"jointure\": 5\n\"scatt\": 5\n\"damask\": 5\n\"loo\": 5\n\"sa\": 5\n\"competitors\": 5\n\"Anglais\": 5\n\"simples\": 5\n\"Child\": 5\n\"devouring\": 4\n\"sieve\": 4\n\"distil\": 4\n\"j\": 4\n\"lecher\": 4\n\"curfew\": 4\n\"Traveller\": 4\n\"greediness\": 4\n\"shortness\": 4\n\"Angleterre\": 4\n\"winner\": 4\n\"tu\": 4\n\"sundry\": 4\n\"Alice\": 4\n\"appelez-vous\": 4\n\"Rises\": 4\n\"ang\": 4\n\"cable\": 4\n\"proposed\": 4\n\"vary\": 4\n\"basilisk\": 4\n\"steads\": 4\n\"head-\": 4\n\"clipp\": 4\n\"tish\": 4\n\"covetousness\": 4\n\"excuses\": 4\n\"Wherever\": 4\n\"scraps\": 4\n\"Untimely\": 4\n\"stumbled\": 4\n\"Bad\": 4\n\"discuss\": 4\n\"oublie\": 4\n\"Obedience\": 4\n\"ungovern\": 4\n\"affirm\": 4\n\"deceiving\": 4\n\"chafes\": 4\n\"bawcock\": 4\n\"Affliction\": 4\n\"Fools\": 4\n\"orators\": 4\n\"ford\": 4\n\"fingres\": 4\n\"Caesars\": 4\n\"Disguise\": 4\n\"tends\": 4\n\"suis\": 4\n\"tangle\": 4\n\"pitiless\": 4\n\"shame-\": 4\n\"returning\": 4\n\"surges\": 4\n\"footed\": 4\n\"Lud\": 4\n\"Town\": 4\n\"fire-new\": 4\n\"Furies\": 4\n\"crook\": 4\n\"sluttish\": 4\n\"Leander\": 4\n\"Seigneur\": 4\n\"Tremble\": 4\n\"betrothed\": 4\n\"Sauf\": 4\n\"knighted\": 4\n\"Opens\": 4\n\"brightest\": 4\n\"rake\": 4\n\"accustom\": 4\n\"pedigree\": 4\n\"Willing\": 4\n\"vessels\": 4\n\"Hellespont\": 4\n\"mightiness\": 4\n\"heroical\": 4\n\"memorable\": 4\n\"figs\": 4\n\"Non\": 4\n\"pied\": 4\n\"cinable\": 4\n\"perfumed\": 4\n\"Blest\": 4\n\"Tereus\": 4\n\"Few\": 4\n\"day-\": 4\n\"Wise\": 4\n\"Wit\": 4\n\"apiece\": 4\n\"enclosed\": 4\n\"lids\": 4\n\"DUKES\": 4\n\"Bourbon\": 4\n\"abjure\": 4\n\"barbarism\": 4\n\"lurking\": 4\n\"crickets\": 4\n\"tickled\": 4\n\"Sorry\": 4\n\"mint\": 4\n\"Deserv\": 4\n\"damsel\": 4\n\"endow\": 4\n\"revolve\": 4\n\"varied\": 4\n\"timber\": 4\n\"comb\": 4\n\"neighbouring\": 4\n\"eel\": 4\n\"restless\": 4\n\"ruth\": 4\n\"dolphin\": 4\n\"muffler\": 4\n\"volley\": 4\n\"prave\": 4\n\"odour\": 4\n\"Sword\": 4\n\"rote\": 4\n\"boisterous\": 4\n\"espouse\": 4\n\"perfectly\": 4\n\"Strength\": 4\n\"hunters\": 4\n\"Unlike\": 4\n\"roofs\": 4\n\"societies\": 4\n\"languages\": 4\n\"Soldier\": 4\n\"effusion\": 4\n\"kneeling\": 4\n\"retort\": 4\n\"Euriphile\": 4\n\"Pish\": 4\n\"d-up\": 4\n\"perplex\": 4\n\"blacker\": 4\n\"hard-favour\": 4\n\"poetical\": 4\n\"adultress\": 4\n\"surmises\": 4\n\"almighty\": 4\n\"paved\": 4\n\"anybody\": 4\n\"jay\": 4\n\"Finely\": 4\n\"expert\": 4\n\"infirmities\": 4\n\"Masham\": 4\n\"presages\": 4\n\"grounded\": 4\n\"Vengeance\": 4\n\"moss\": 4\n\"scabbard\": 4\n\"haud\": 4\n\"wreath\": 4\n\"galliard\": 4\n\"conjecture\": 4\n\"credo\": 4\n\"Parts\": 4\n\"sentinels\": 4\n\"tongueless\": 4\n\"Cur\": 4\n\"changeable\": 4\n\"cripple\": 4\n\"inly\": 4\n\"intellect\": 4\n\"Bids\": 4\n\"pool\": 4\n\"knaveries\": 4\n\"Dark\": 4\n\"unfurnish\": 4\n\"tastes\": 4\n\"oily\": 4\n\"Dry\": 4\n\"vomit\": 4\n\"pierc\": 4\n\"qui\": 4\n\"hogshead\": 4\n\"commits\": 4\n\"imitation\": 4\n\"place-\": 4\n\"fa\": 4\n\"ben\": 4\n\"Hoo\": 4\n\"lubber\": 4\n\"reprove\": 4\n\"grandmother\": 4\n\"minstrels\": 4\n\"grateful\": 4\n\"counterfeiting\": 4\n\"nakedness\": 4\n\"distaste\": 4\n\"mi\": 4\n\"shepherdess\": 4\n\"evasion\": 4\n\"divisions\": 4\n\"unspotted\": 4\n\"glib\": 4\n\"founder\": 4\n\"Perforce\": 4\n\"delightful\": 4\n\"Unhappy\": 4\n\"solemniz\": 4\n\"forges\": 4\n\"Clubs\": 4\n\"convers\": 4\n\"gallops\": 4\n\"distressful\": 4\n\"exit\": 4\n\"ambles\": 4\n\"interrupt\": 4\n\"time-\": 4\n\"belch\": 4\n\"detect\": 4\n\"Russians\": 4\n\"cipher\": 4\n\"clergy\": 4\n\"France-\": 4\n\"Pays\": 4\n\"visages\": 4\n\"possesses\": 4\n\"Antonius\": 4\n\"stature\": 4\n\"cruelly\": 4\n\"christen\": 4\n\"curiosity\": 4\n\"laughed\": 4\n\"satire\": 4\n\"statute\": 4\n\"nonino\": 4\n\"spin\": 4\n\"acorn\": 4\n\"Uncertain\": 4\n\"acres\": 4\n\"covenants\": 4\n\"floor\": 4\n\"approv\": 4\n\"ordered\": 4\n\"tripp\": 4\n\"ditty\": 4\n\"wrings\": 4\n\"Alisander\": 4\n\"tarrying\": 4\n\"flatt\": 4\n\"Forbid\": 4\n\"Pythagoras\": 4\n\"Dardanius\": 4\n\"incite\": 4\n\"lamely\": 4\n\"breathed\": 4\n\"binds\": 4\n\"accompt\": 4\n\"rather-\": 4\n\"shall-\": 4\n\"bodily\": 4\n\"wearied\": 4\n\"makest\": 4\n\"span\": 4\n\"defense\": 4\n\"allowed\": 4\n\"observed\": 4\n\"Shakes\": 4\n\"Signieur\": 4\n\"AMBASSADORS\": 4\n\"Truth\": 4\n\"DONALBAIN\": 4\n\"gnat\": 4\n\"luxurious\": 4\n\"CAITHNESS\": 4\n\"Morgan\": 4\n\"Offer\": 4\n\"imprisoned\": 4\n\"Winter\": 4\n\"dit-il\": 4\n\"un\": 4\n\"Wrong\": 4\n\"tres\": 4\n\"Gentlewoman\": 4\n\"shamed\": 4\n\"seigneur\": 4\n\"sunset\": 4\n\"contaminated\": 4\n\"Spake\": 4\n\"cuckoldly\": 4\n\"unkindest\": 4\n\"Address\": 4\n\"purposely\": 4\n\"glowing\": 4\n\"withholds\": 4\n\"withheld\": 4\n\"permission\": 4\n\"Always\": 4\n\"civet\": 4\n\"unhandsome\": 4\n\"undoing\": 4\n\"sparrows\": 4\n\"expire\": 4\n\"Cousins\": 4\n\"prabbles\": 4\n\"Popilius\": 4\n\"defied\": 4\n\"handling\": 4\n\"professions\": 4\n\"dubb\": 4\n\"uncleanly\": 4\n\"disclose\": 4\n\"fruitless\": 4\n\"conjured\": 4\n\"bareness\": 4\n\"flattered\": 4\n\"Blackheath\": 4\n\"flash\": 4\n\"naming\": 4\n\"Quiet\": 4\n\"Cassibelan\": 4\n\"drowns\": 4\n\"mayor\": 4\n\"imp\": 4\n\"whatever\": 4\n\"avail\": 4\n\"howe\": 4\n\"petter\": 4\n\"Rouse\": 4\n\"mechanical\": 4\n\"inflame\": 4\n\"abundant\": 4\n\"venerable\": 4\n\"bedlam\": 4\n\"infer\": 4\n\"APPARITION\": 4\n\"slipper\": 4\n\"Adriana\": 4\n\"saws\": 4\n\"mule\": 4\n\"Success\": 4\n\"arming\": 4\n\"Descends\": 4\n\"bearded\": 4\n\"unused\": 4\n\"chidden\": 4\n\"color\": 4\n\"Puff\": 4\n\"blew\": 4\n\"blocks\": 4\n\"whining\": 4\n\"partisans\": 4\n\"leas\": 4\n\"Wanting\": 4\n\"whereat\": 4\n\"amazedly\": 4\n\"uplifted\": 4\n\"And-\": 4\n\"spouse\": 4\n\"reconciled\": 4\n\"shares\": 4\n\"Denis\": 4\n\"approves\": 4\n\"Safer\": 4\n\"Sardis\": 4\n\"meanly\": 4\n\"-why\": 4\n\"tears-\": 4\n\"impartial\": 4\n\"Counsel\": 4\n\"customs\": 4\n\"DARDANIUS\": 4\n\"Weeping\": 4\n\"wan\": 4\n\"meanings\": 4\n\"authentic\": 4\n\"counter\": 4\n\"supplies\": 4\n\"tiny\": 4\n\"tended\": 4\n\"dissolute\": 4\n\"Provided\": 4\n\"justified\": 4\n\"helpful\": 4\n\"perfidious\": 4\n\"fishermen\": 4\n\"records\": 4\n\"Accept\": 4\n\"intermission\": 4\n\"newest\": 4\n\"quoted\": 4\n\"scum\": 4\n\"ARTEMIDORUS\": 4\n\"VOLUMNIUS\": 4\n\"sage\": 4\n\"triple\": 4\n\"hearse\": 4\n\"CATO\": 4\n\"nowhere\": 4\n\"punk\": 4\n\"POPILIUS\": 4\n\"tract\": 4\n\"Depart\": 4\n\"WOODVILLE\": 4\n\"schools\": 4\n\"veriest\": 4\n\"pil\": 4\n\"mocker\": 4\n\"coldest\": 4\n\"LAWYER\": 4\n\"divorc\": 4\n\"serving\": 4\n\"appease\": 4\n\"timely\": 4\n\"sulphur\": 4\n\"favourable\": 4\n\"invocation\": 4\n\"untainted\": 4\n\"posting\": 4\n\"MASTER-GUNNER\": 4\n\"Rising\": 4\n\"rely\": 4\n\"beguiled\": 4\n\"drave\": 4\n\"everlastingly\": 4\n\"ancestry\": 4\n\"BROTHER\": 4\n\"consummate\": 4\n\"crescent\": 4\n\"dates\": 4\n\"dinner-time\": 4\n\"flaws\": 4\n\"renders\": 4\n\"traders\": 4\n\"miser\": 4\n\"dolours\": 4\n\"erewhile\": 4\n\"borrowing\": 4\n\"substitutes\": 4\n\"revolting\": 4\n\"successful\": 4\n\"monastery\": 4\n\"naturally\": 4\n\"flocks\": 4\n\"hoard\": 4\n\"warranted\": 4\n\"vital\": 4\n\"beacon\": 4\n\"sherris\": 4\n\"buildings\": 4\n\"fantasies\": 4\n\"fleeting\": 4\n\"shins\": 4\n\"Wake\": 4\n\"swerve\": 4\n\"lot\": 4\n\"shuns\": 4\n\"destin\": 4\n\"Commends\": 4\n\"unpeople\": 4\n\"confined\": 4\n\"Dale\": 4\n\"Wounds\": 4\n\"eld\": 4\n\"obstruction\": 4\n\"spectators\": 4\n\"unhappily\": 4\n\"discharged\": 4\n\"Wherewith\": 4\n\"trice\": 4\n\"Parthian\": 4\n\"counters\": 4\n\"Asia\": 4\n\"stumbling\": 4\n\"grange\": 4\n\"Swinstead\": 4\n\"resides\": 4\n\"exposition\": 4\n\"remission\": 4\n\"crotchets\": 4\n\"plucking\": 4\n\"tell-tale\": 4\n\"varying\": 4\n\"aery\": 4\n\"spiders\": 4\n\"tendance\": 4\n\"besieg\": 4\n\"trunks\": 4\n\"staggers\": 4\n\"neighing\": 4\n\"seduced\": 4\n\"raz\": 4\n\"appeas\": 4\n\"austere\": 4\n\"limited\": 4\n\"inundation\": 4\n\"ill-beseeming\": 4\n\"surfeiting\": 4\n\"manifested\": 4\n\"mice\": 4\n\"mad-brain\": 4\n\"ey\": 4\n\"fretting\": 4\n\"consecrated\": 4\n\"forfeits\": 4\n\"Dogs\": 4\n\"gratulate\": 4\n\"banner\": 4\n\"remember-\": 4\n\"define\": 4\n\"Strive\": 4\n\"believes\": 4\n\"spurring\": 4\n\"tumbled\": 4\n\"engines\": 4\n\"quiver\": 4\n\"Loves\": 4\n\"brush\": 4\n\"eye-\": 4\n\"scab\": 4\n\"LEONARDO\": 4\n\"begotten\": 4\n\"deform\": 4\n\"Il\": 4\n\"Red\": 4\n\"staring\": 4\n\"leathern\": 4\n\"Wishing\": 4\n\"fasts\": 4\n\"thereabouts\": 4\n\"renounce\": 4\n\"Amazon\": 4\n\"wildest\": 4\n\"accommodated\": 4\n\"lott\": 4\n\"stripp\": 4\n\"throned\": 4\n\"oddly\": 4\n\"Melun\": 4\n\"Finds\": 4\n\"Ascension-day\": 4\n\"shears\": 4\n\"foam\": 4\n\"wrack\": 4\n\"Cursed\": 4\n\"undertaking\": 4\n\"Abram\": 4\n\"scruples\": 4\n\"businesses\": 4\n\"catastrophe\": 4\n\"int\": 4\n\"licence\": 4\n\"pill\": 4\n\"fittest\": 4\n\"covering\": 4\n\"ascends\": 4\n\"viewing\": 4\n\"Devise\": 4\n\"unthrifty\": 4\n\"sanguine\": 4\n\"EXECUTIONERS\": 4\n\"prodigies\": 4\n\"hood\": 4\n\"abridgment\": 4\n\"morrows\": 4\n\"hurly\": 4\n\"anchors\": 4\n\"Tearing\": 4\n\"Arragon\": 4\n\"Silver\": 4\n\"beseeming\": 4\n\"crossing\": 4\n\"thwarted\": 4\n\"Genoa\": 4\n\"bruis\": 4\n\"containing\": 4\n\"last-\": 4\n\"doubtfully\": 4\n\"Eat\": 4\n\"Camp\": 4\n\"Quoth\": 4\n\"minions\": 4\n\"indictment\": 4\n\"disposing\": 4\n\"discourses\": 4\n\"wastes\": 4\n\"gawds\": 4\n\"baboon\": 4\n\"roasted\": 4\n\"SO\": 4\n\"coxcombs\": 4\n\"ewe\": 4\n\"valorous\": 4\n\"pines\": 4\n\"ratify\": 4\n\"HAMLET\": 4\n\"whirl\": 4\n\"Nought\": 4\n\"burs\": 4\n\"tumultuous\": 4\n\"incapable\": 4\n\"henceforward\": 4\n\"regreet\": 4\n\"intercept\": 4\n\"Sovereign\": 4\n\"curiously\": 4\n\"shone\": 4\n\"retention\": 4\n\"smaller\": 4\n\"butterflies\": 4\n\"resting\": 4\n\"Francisco\": 4\n\"hymns\": 4\n\"lifeless\": 4\n\"handled\": 4\n\"random\": 4\n\"Accursed\": 4\n\"prodigious\": 4\n\"unpleasing\": 4\n\"bonfires\": 4\n\"plentiful\": 4\n\"Sergeant\": 4\n\"excrement\": 4\n\"sourest\": 4\n\"Merry\": 4\n\"plainer\": 4\n\"tiring\": 4\n\"spurns\": 4\n\"rounded\": 4\n\"bulwarks\": 4\n\"fustian\": 4\n\"substantial\": 4\n\"westward\": 4\n\"fery\": 4\n\"Laying\": 4\n\"Abraham\": 4\n\"approof\": 4\n\"hoa\": 4\n\"censures\": 4\n\"emboss\": 4\n\"Cerberus\": 4\n\"Ascend\": 4\n\"aspects\": 4\n\"Blush\": 4\n\"congeal\": 4\n\"cakes\": 4\n\"cuckolds\": 4\n\"(For\": 4\n\"ratified\": 4\n\"Rescue\": 4\n\"-Come\": 4\n\"enfranchise\": 4\n\"Discharge\": 4\n\"saffron\": 4\n\"apoplexy\": 4\n\"froth\": 4\n\"fangs\": 4\n\"puppy\": 4\n\"Phrygian\": 4\n\"Neighbour\": 4\n\"oratory\": 4\n\"dwarf\": 4\n\"sons-\": 4\n\"murmuring\": 4\n\"gallery\": 4\n\"determined\": 4\n\"Sport\": 4\n\"faded\": 4\n\"thwack\": 4\n\"doers\": 4\n\"recourse\": 4\n\"painfully\": 4\n\"rheumatic\": 4\n\"SERVINGMEN\": 4\n\"Walks\": 4\n\"conveniently\": 4\n\"burgonet\": 4\n\"looked\": 4\n\"ransack\": 4\n\"dropping\": 4\n\"weighing\": 4\n\"reverse\": 4\n\"pike\": 4\n\"sect\": 4\n\"carp\": 4\n\"down-\": 4\n\"decays\": 4\n\"impotent\": 4\n\"refused\": 4\n\"badness\": 4\n\"taxation\": 4\n\"bearers\": 4\n\"Frogmore\": 4\n\"Threw\": 4\n\"sups\": 4\n\"advanced\": 4\n\"Mardian\": 4\n\"agrees\": 4\n\"chins\": 4\n\"JACK\": 4\n\"ripened\": 4\n\"slanderer\": 4\n\"Datchet\": 4\n\"mandate\": 4\n\"hateth\": 4\n\"ivy\": 4\n\"unmanly\": 4\n\"guardian\": 4\n\"presses\": 4\n\"Wittenberg\": 4\n\"whetstone\": 4\n\"bruit\": 4\n\"solid\": 4\n\"unprofitable\": 4\n\"a-birding\": 4\n\"alacrity\": 4\n\"provoked\": 4\n\"buck-basket\": 4\n\"hotly\": 4\n\"intrusion\": 4\n\"dexterity\": 4\n\"sequence\": 4\n\"friend-\": 4\n\"student\": 4\n\"lour\": 4\n\"washing\": 4\n\"exclamation\": 4\n\"sinner\": 4\n\"varlets\": 4\n\"habiliments\": 4\n\"declines\": 4\n\"Street\": 4\n\"extraordinary\": 4\n\"ignobly\": 4\n\"dishonesty\": 4\n\"prat\": 4\n\"Eton\": 4\n\"wreak\": 4\n\"budget\": 4\n\"entrap\": 4\n\"contriver\": 4\n\"assistant\": 4\n\"unadvis\": 4\n\"Whoop\": 4\n\"unfirm\": 4\n\"frosts\": 4\n\"Hope\": 4\n\"laboured\": 4\n\"Eating\": 4\n\"credent\": 4\n\"stink\": 4\n\"foully\": 4\n\"Shed\": 4\n\"Raise\": 4\n\"respective\": 4\n\"defective\": 4\n\"lingers\": 4\n\"beseems\": 4\n\"quean\": 4\n\"twins\": 4\n\"Hood\": 4\n\"land-\": 4\n\"trap\": 4\n\"Balthazar\": 4\n\"pebble\": 4\n\"Drive\": 4\n\"perturbation\": 4\n\"lied\": 4\n\"invites\": 4\n\"bethought\": 4\n\"tenders\": 4\n\"niggardly\": 4\n\"toll\": 4\n\"shipping\": 4\n\"instructs\": 4\n\"GURNEY\": 4\n\"tucket\": 4\n\"agate\": 4\n\"overwhelm\": 4\n\"preach\": 4\n\"exhibit\": 4\n\"sincere\": 4\n\"revolution\": 4\n\"metaphor\": 4\n\"gentleman-like\": 4\n\"pond\": 4\n\"Rhenish\": 4\n\"propos\": 4\n\"Knew\": 4\n\"engaged\": 4\n\"flourishes\": 4\n\"attribute\": 4\n\"origin\": 4\n\"sportive\": 4\n\"else-\": 4\n\"gauntlet\": 4\n\"puling\": 4\n\"hous\": 4\n\"distempered\": 4\n\"mysteries\": 4\n\"unknit\": 4\n\"upbraided\": 4\n\"departing\": 4\n\"Moe\": 4\n\"op\": 4\n\"lustful\": 4\n\"PHILO\": 4\n\"votary\": 4\n\"youths\": 4\n\"braves\": 4\n\"sug\": 4\n\"cliff\": 4\n\"Staying\": 4\n\"brother-\": 4\n\"warmed\": 4\n\"earldom\": 4\n\"lag\": 4\n\"differs\": 4\n\"properly\": 4\n\"enchant\": 4\n\"Porter\": 4\n\"christening\": 4\n\"prosecute\": 4\n\"handmaid\": 4\n\"fretful\": 4\n\"distilled\": 4\n\"Alps\": 4\n\"HYMEN\": 4\n\"advertisement\": 4\n\"fornication\": 4\n\"spritely\": 4\n\"WART\": 4\n\"SHADOW\": 4\n\"hazards\": 4\n\"SNARE\": 4\n\"Flute\": 4\n\"deities\": 4\n\"minority\": 4\n\"imperfections\": 4\n\"invincible\": 4\n\"deface\": 4\n\"Spread\": 4\n\"defac\": 4\n\"PETO\": 4\n\"Writes\": 4\n\"conceived\": 4\n\"were-\": 4\n\"tallow\": 4\n\"wandering\": 4\n\"Patrick\": 4\n\"whoso\": 4\n\"decayed\": 4\n\"palter\": 4\n\"miscreant\": 4\n\"prettily\": 4\n\"elect\": 4\n\"sweats\": 4\n\"Grace-\": 4\n\"ceases\": 4\n\"hostile\": 4\n\"distant\": 4\n\"Writ\": 4\n\"impregnable\": 4\n\"cunningly\": 4\n\"eastern\": 4\n\"comforting\": 4\n\"unpitied\": 4\n\"combatants\": 4\n\"wavering\": 4\n\"spends\": 4\n\"Throng\": 4\n\"mention\": 4\n\"howsoe\": 4\n\"confus\": 4\n\"Hop\": 4\n\"rubies\": 4\n\"trades\": 4\n\"Chide\": 4\n\"Produce\": 4\n\"badges\": 4\n\"bespoke\": 4\n\"remembered\": 4\n\"nothings\": 4\n\"stirrup\": 4\n\"Nobody\": 4\n\"hostages\": 4\n\"Spur\": 4\n\"cough\": 4\n\"happiest\": 4\n\"Lucy\": 4\n\"vulture\": 4\n\"dateless\": 4\n\"enfranchis\": 4\n\"fraud\": 4\n\"sharply\": 4\n\"busines\": 4\n\"los\": 4\n\"whispering\": 4\n\"Majesties\": 4\n\"unable\": 4\n\"Avoid\": 4\n\"brittle\": 4\n\"Assure\": 4\n\"afresh\": 4\n\"Polack\": 4\n\"unavoided\": 4\n\"crutches\": 4\n\"annual\": 4\n\"absurd\": 4\n\"bounties\": 4\n\"brevity\": 4\n\"tediousness\": 4\n\"whoe\": 4\n\"tush\": 4\n\"Hides\": 4\n\"Power\": 4\n\"sobs\": 4\n\"Pause\": 4\n\"milder\": 4\n\"trusts\": 4\n\"gratitude\": 4\n\"Deformed\": 4\n\"Saving\": 4\n\"vassals\": 4\n\"perceives\": 4\n\"filled\": 4\n\"Defy\": 4\n\"excellently\": 4\n\"NOBLES\": 4\n\"gum\": 4\n\"Imagine\": 4\n\"default\": 4\n\"prisons\": 4\n\"amendment\": 4\n\"pell-mell\": 4\n\"comforter\": 4\n\"violation\": 4\n\"waggon\": 4\n\"expedience\": 4\n\"Excellence\": 4\n\"cinders\": 4\n\"unfolded\": 4\n\"unlucky\": 4\n\"Rebellion\": 4\n\"Beggar\": 4\n\"borrows\": 4\n\"prodigy\": 4\n\"meteor\": 4\n\"godly\": 4\n\"crests\": 4\n\"catches\": 4\n\"losers\": 4\n\"southern\": 4\n\"swiftness\": 4\n\"together-\": 4\n\"sinew\": 4\n\"father-in-law\": 4\n\"Slave\": 4\n\"hir\": 4\n\"superstitious\": 4\n\"depriv\": 4\n\"villages\": 4\n\"Seleucus\": 4\n\"trull\": 4\n\"performed\": 4\n\"desk\": 4\n\"noises\": 4\n\"tombs\": 4\n\"severity\": 4\n\"extenuate\": 4\n\"Sole\": 4\n\"Meanwhile\": 4\n\"dowager\": 4\n\"say)\": 4\n\"meekness\": 4\n\"honour-\": 4\n\"Taken\": 4\n\"shapeless\": 4\n\"fighter\": 4\n\"lapwing\": 4\n\"prudent\": 4\n\"Com\": 4\n\"Warwickshire\": 4\n\"vie\": 4\n\"Alban\": 4\n\"Bethink\": 4\n\"Remove\": 4\n\"elected\": 4\n\"itself-\": 4\n\"button\": 4\n\"buff\": 4\n\"dishonourable\": 4\n\"cankers\": 4\n\"yeomen\": 4\n\"clink\": 4\n\"Refuse\": 4\n\"Rebellious\": 4\n\"go-\": 4\n\"hallowed\": 4\n\"Confusion\": 4\n\"bustle\": 4\n\"Low\": 4\n\"bulls\": 4\n\"matches\": 4\n\"haggard\": 4\n\"courser\": 4\n\"hereabout\": 4\n\"wrapp\": 4\n\"Conceit\": 4\n\"husbanded\": 4\n\"alarm\": 4\n\"kindnesses\": 4\n\"reversion\": 4\n\"becom\": 4\n\"Gonzago\": 4\n\"curls\": 4\n\"palates\": 4\n\"bolts\": 4\n\"silks\": 4\n\"Prodigal\": 4\n\"boiling\": 4\n\"pudding\": 4\n\"Purpose\": 4\n\"spoon\": 4\n\"Provokes\": 4\n\"meditations\": 4\n\"insatiate\": 4\n\"mann\": 4\n\"lecherous\": 4\n\"lordships\": 4\n\"Evermore\": 4\n\"mind-\": 4\n\"faithless\": 4\n\"attainder\": 4\n\"donation\": 4\n\"extremely\": 4\n\"unequal\": 4\n\"rarer\": 4\n\"healths\": 4\n\"dow\": 4\n\"s-end\": 4\n\"feared\": 4\n\"hired\": 4\n\"Devil\": 4\n\"owest\": 4\n\"skulls\": 4\n\"die-\": 4\n\"looking-glass\": 4\n\"Dance\": 4\n\"confirms\": 4\n\"forbidden\": 4\n\"SCALES\": 4\n\"consist\": 4\n\"State\": 4\n\"Sandys\": 4\n\"fable\": 4\n\"commerce\": 4\n\"s-head\": 4\n\"flax\": 4\n\"cockle\": 4\n\"MARQUIS\": 4\n\"contraries\": 4\n\"potions\": 4\n\"stint\": 4\n\"frailties\": 4\n\"Beneath\": 4\n\"purpose-\": 4\n\"innocents\": 4\n\"engross\": 4\n\"cured\": 4\n\"closing\": 4\n\"sty\": 4\n\"Unfit\": 4\n\"disclaim\": 4\n\"G\": 4\n\"delivery\": 4\n\"readiest\": 4\n\"hereof\": 4\n\"restitution\": 4\n\"birthright\": 4\n\"unchaste\": 4\n\"Lovel\": 4\n\"loathes\": 4\n\"surfeited\": 4\n\"Heat\": 4\n\"tempting\": 4\n\"SECRETARY\": 4\n\"(all\": 4\n\"Harp\": 4\n\"sumptuous\": 4\n\"named\": 4\n\"core\": 4\n\"Kinsmen\": 4\n\"imaginations\": 4\n\"approaching\": 4\n\"Seeming\": 4\n\"preposterously\": 4\n\"bides\": 4\n\"chameleon\": 4\n\"straying\": 4\n\"continued\": 4\n\"inveterate\": 4\n\"ord\": 4\n\"embracement\": 4\n\"confounding\": 4\n\"MARGERY\": 4\n\"bruising\": 4\n\"descried\": 4\n\"JOURDAIN\": 4\n\"Aldermen\": 4\n\"assailed\": 4\n\"Kills\": 4\n\"Standing\": 4\n\"gems\": 4\n\"garlic\": 4\n\"lackeys\": 4\n\"wooes\": 4\n\"hoping\": 4\n\"angers\": 4\n\"CRIER\": 4\n\"bishops\": 4\n\"flouted\": 4\n\"rebukes\": 4\n\"invested\": 4\n\"MENECRATES\": 4\n\"Forswear\": 4\n\"Book\": 4\n\"equals\": 4\n\"ireful\": 4\n\"accurst\": 4\n\"wormwood\": 4\n\"Calling\": 4\n\"interchangeably\": 4\n\"conjur\": 4\n\"inevitable\": 4\n\"Dutchman\": 4\n\"skilless\": 4\n\"abhors\": 4\n\"shuts\": 4\n\"Trent\": 4\n\"rarity\": 4\n\"disobedient\": 4\n\"Sees\": 4\n\"LINCOLN\": 4\n\"Feeds\": 4\n\"Thetis\": 4\n\"distemp\": 4\n\"Itself\": 4\n\"come-\": 4\n\"disfigure\": 4\n\"Apoth\": 4\n\"hawking\": 4\n\"Crack\": 4\n\"Laur\": 4\n\"perdy\": 4\n\"divines\": 4\n\"Remains\": 4\n\"mattock\": 4\n\"threes\": 4\n\"Discover\": 4\n\"eloquent\": 4\n\"Praising\": 4\n\"troublous\": 4\n\"tearing\": 4\n\"Age\": 4\n\"ire\": 4\n\"Along\": 4\n\"Nero\": 4\n\"whoremaster\": 4\n\"sanctify\": 4\n\"cleanly\": 4\n\"surfeits\": 4\n\"Offers\": 4\n\"panting\": 4\n\"stem\": 4\n\"harlotry\": 4\n\"anatomy\": 4\n\"gainsay\": 4\n\"files\": 4\n\"maidenheads\": 4\n\"unconstant\": 4\n\"pursuivant\": 4\n\"relics\": 4\n\"sportful\": 4\n\"PLAYERS\": 4\n\"blamed\": 4\n\"talent\": 4\n\"champions\": 4\n\"indignities\": 4\n\"portend\": 4\n\"mars\": 4\n\"Resign\": 4\n\"wield\": 4\n\"wringing\": 4\n\"quill\": 4\n\"bondmen\": 4\n\"grained\": 4\n\"bulwark\": 4\n\"fees\": 4\n\"Hung\": 4\n\"vacancy\": 4\n\"shouting\": 4\n\"hoist\": 4\n\"index\": 4\n\"huntsmen\": 4\n\"throes\": 4\n\"expose\": 4\n\"Contempt\": 4\n\"begets\": 4\n\"thicket\": 4\n\"misbegotten\": 4\n\"Eleven\": 4\n\"wean\": 4\n\"turtle\": 4\n\"older\": 4\n\"appetites\": 4\n\"Accuse\": 4\n\"fume\": 4\n\"terribly\": 4\n\"mutter\": 4\n\"forcibly\": 4\n\"kitchen\": 4\n\"wasp\": 4\n\"bass\": 4\n\"guerdon\": 4\n\"tortur\": 4\n\"gamut\": 4\n\"fewer\": 4\n\"choosing\": 4\n\"sinewy\": 4\n\"rolling\": 4\n\"gavest\": 4\n\"shaken\": 4\n\"test\": 4\n\"fee-simple\": 4\n\"shrill\": 4\n\"s-\": 4\n\"upholds\": 4\n\"alters\": 4\n\"flatly\": 4\n\"earnestness\": 4\n\"Tavern\": 4\n\"MARINERS\": 4\n\"X\": 4\n\"roan\": 4\n\"abstinence\": 4\n\"multiplying\": 4\n\"ravel\": 4\n\"portents\": 4\n\"Vere\": 4\n\"basilisks\": 4\n\"despairing\": 4\n\"TULLUS\": 4\n\"frontiers\": 4\n\"eas\": 4\n\"creeps\": 4\n\"ner\": 4\n\"providence\": 4\n\"sea-fight\": 4\n\"Miranda\": 4\n\"Warkworth\": 4\n\"tinct\": 4\n\"sponge\": 4\n\"replication\": 4\n\"cloaks\": 4\n\"Claribel\": 4\n\"service-\": 4\n\"Unfold\": 4\n\"equity\": 4\n\"haps\": 4\n\"moon-calf\": 4\n\"Fury\": 4\n\"marrow\": 4\n\"rendezvous\": 4\n\"buffet\": 4\n\"Jesus\": 4\n\"undeserved\": 4\n\"dauntless\": 4\n\"unmatchable\": 4\n\"GENERAL\": 4\n\"prevails\": 4\n\"amended\": 4\n\"Painting\": 4\n\"Cobham\": 4\n\"adjunct\": 4\n\"sainted\": 4\n\"medicines\": 4\n\"prescription\": 4\n\"hares\": 4\n\"botch\": 4\n\"Virginity\": 4\n\"pulls\": 4\n\"Sets\": 4\n\"conjectures\": 4\n\"plod\": 4\n\"spilt\": 4\n\"(sings)\": 4\n\"desperately\": 4\n\"immured\": 4\n\"predecessors\": 4\n\"controlling\": 4\n\"clerks\": 4\n\"wagging\": 4\n\"assemble\": 4\n\"superfluity\": 4\n\"Field\": 4\n\"goddesses\": 4\n\"Athenians\": 4\n\"Mock\": 4\n\"scathe\": 4\n\"shifted\": 4\n\"leanness\": 4\n\"mules\": 4\n\"expos\": 4\n\"knits\": 4\n\"pricking\": 4\n\"subscrib\": 4\n\"chooses\": 4\n\"Followers\": 4\n\"reins\": 4\n\"effectual\": 4\n\"comments\": 4\n\"sunk\": 4\n\"onset\": 4\n\"loser\": 4\n\"Bristow\": 4\n\"Early\": 4\n\"betime\": 4\n\"Ambitious\": 4\n\"Scorn\": 4\n\"Scottish\": 4\n\"leprosy\": 4\n\"daff\": 4\n\"Thought\": 4\n\"incomparable\": 4\n\"defences\": 4\n\"jointly\": 4\n\"likelihoods\": 4\n\"half-fac\": 4\n\"Andronici\": 4\n\"pale-fac\": 4\n\"overlook\": 4\n\"passengers\": 4\n\"argue\": 4\n\"Ad\": 4\n\"complot\": 4\n\"usury\": 4\n\"mainly\": 4\n\"unclasp\": 4\n\"gender\": 4\n\"SONS\": 4\n\"risen\": 4\n\"repossess\": 4\n\"clerkly\": 4\n\"diamonds\": 4\n\"hautboys\": 4\n\"intercepted\": 4\n\"Brittany\": 4\n\"ingrate\": 4\n\"Train\": 4\n\"separate\": 4\n\"displease\": 4\n\"agreement\": 4\n\"valiantly\": 4\n\"brother-in-law\": 4\n\"unsay\": 4\n\"cherubins\": 4\n\"brisk\": 4\n\"curbs\": 4\n\"Fresh\": 4\n\"helms\": 4\n\"madam-\": 4\n\"Oppose\": 4\n\"Experience\": 4\n\"manacles\": 4\n\"Collected\": 4\n\"established\": 4\n\"villainies\": 4\n\"mutually\": 4\n\"catalogue\": 4\n\"rainy\": 4\n\"Goth\": 4\n\"unseal\": 4\n\"cheers\": 4\n\"jarring\": 4\n\"booty\": 4\n\"senator\": 4\n\"speakest\": 4\n\"concealment\": 4\n\"Aemilius\": 4\n\"GOTHS\": 4\n\"fabric\": 4\n\"cormorant\": 4\n\"melodious\": 4\n\"clouded\": 4\n\"extol\": 4\n\"drain\": 4\n\"cozening\": 4\n\"proverbs\": 4\n\"hies\": 4\n\"Goodman\": 4\n\"filed\": 4\n\"vocation\": 4\n\"meagre\": 4\n\"folk\": 4\n\"he-\": 4\n\"Scripture\": 4\n\"sensual\": 4\n\"Whereby\": 4\n\"bagpipe\": 4\n\"required\": 4\n\"Afric\": 4\n\"fubb\": 4\n\"supposition\": 4\n\"quips\": 4\n\"squires\": 4\n\"privileg\": 4\n\"tarried\": 4\n\"Force\": 4\n\"none-\": 4\n\"refrain\": 4\n\"emulous\": 4\n\"stripes\": 4\n\"affrights\": 4\n\"bristle\": 4\n\"expressed\": 4\n\"embraces\": 4\n\"recoil\": 4\n\"Alive\": 4\n\"poorer\": 4\n\"thousand-fold\": 4\n\"Mordake\": 4\n\"blinded\": 4\n\"traitorously\": 4\n\"indentures\": 4\n\"inheritor\": 4\n\"applied\": 4\n\"meddling\": 4\n\"misty\": 4\n\"Courteous\": 4\n\"Antiates\": 4\n\"abortive\": 4\n\"Returns\": 4\n\"Worth\": 4\n\"horned\": 4\n\"Offering\": 4\n\"rates\": 4\n\"hags\": 4\n\"strut\": 4\n\"sea-coast\": 4\n\"helmets\": 4\n\"promising\": 4\n\"hoofs\": 4\n\"stor\": 4\n\"procession\": 4\n\"fountains\": 4\n\"sparkle\": 4\n\"busied\": 4\n\"love-song\": 4\n\"Puritan\": 4\n\"heated\": 4\n\"Leaps\": 4\n\"melts\": 4\n\"part-\": 4\n\"Authority\": 4\n\"looker-on\": 4\n\"islanders\": 4\n\"nap\": 4\n\"dissolv\": 4\n\"fronts\": 4\n\"patent\": 4\n\"OUTLAWS\": 4\n\"sinking\": 4\n\"separated\": 4\n\"encompass\": 4\n\"surnamed\": 4\n\"disposed\": 4\n\"concealed\": 4\n\"fated\": 4\n\"thickest\": 4\n\"attainted\": 4\n\"supremacy\": 4\n\"graceless\": 4\n\"sender\": 4\n\"conduit\": 4\n\"competitor\": 4\n\"injur\": 4\n\"vestal\": 4\n\"fragments\": 4\n\"hastily\": 4\n\"remorseful\": 4\n\"consult\": 4\n\"ravin\": 4\n\"elders\": 4\n\"bloodily\": 4\n\"Fort\": 4\n\"matter-\": 4\n\"feverous\": 4\n\"grape\": 4\n\"cracks\": 4\n\"gin\": 4\n\"Camillo-\": 4\n\"Ring\": 4\n\"Requires\": 4\n\"Cleomenes\": 4\n\"compt\": 4\n\"sensibly\": 4\n\"Florizel\": 4\n\"pledges\": 4\n\"Doricles\": 4\n\"Following\": 4\n\"noontide\": 4\n\"stormy\": 4\n\"fliers\": 4\n\"shell\": 4\n\"falchion\": 4\n\"people-\": 4\n\"gird\": 4\n\"Bedlam\": 4\n\"exception\": 4\n\"Dalmatians\": 2\n\"steterat\": 3\n\"firstlings\": 3\n\"outlaw\": 3\n\"8\": 3\n\"winnowed\": 3\n\"splendour\": 3\n\"bubbles\": 3\n\"marring\": 3\n\"trib\": 3\n\"fest\": 3\n\"princess-\": 3\n\"pinion\": 3\n\"Promise\": 3\n\"edified\": 3\n\"hangers\": 3\n\"TIME\": 3\n\"ranges\": 3\n\"Hiding\": 3\n\"emptiness\": 3\n\"unthankfulness\": 3\n\"nomination\": 3\n\"constrained\": 3\n\"Silvia-\": 3\n\"alchemy\": 3\n\"Crab\": 3\n\"noddy\": 3\n\"meadows\": 3\n\"combating\": 3\n\"carnal\": 3\n\"accidental\": 3\n\"slaughters\": 3\n\"Flatter\": 3\n\"sheds\": 3\n\"Proper\": 3\n\"Elephant\": 3\n\"opposites\": 3\n\"cicatrice\": 3\n\"strove\": 3\n\"signet\": 3\n\"M-\": 3\n\"item\": 3\n\"Accost\": 3\n\"laurel\": 3\n\"feeders\": 3\n\"seel\": 3\n\"fragment\": 3\n\"Devis\": 3\n\"guiding\": 3\n\"9\": 3\n\"10\": 3\n\"loathness\": 3\n\"swerving\": 3\n\"-Why\": 3\n\"mislike\": 3\n\"disposer\": 3\n\"portends\": 3\n\"granting\": 3\n\"Millions\": 3\n\"engender\": 3\n\"Deiphobus\": 3\n\"Forty\": 3\n\"Drop\": 3\n\"enfeebled\": 3\n\"Andromache\": 3\n\"determines\": 3\n\"skittish\": 3\n\"Phrygia\": 3\n\"pity-\": 3\n\"Diomedes\": 3\n\"Ptolemy\": 3\n\"Vintner\": 3\n\"cramp\": 3\n\"hearted\": 3\n\"1595\": 3\n\"bowls\": 3\n\"unsanctified\": 3\n\"pant\": 3\n\"Trojan\": 3\n\"preys\": 3\n\"warranty\": 3\n\"Rapine\": 3\n\"rods\": 3\n\"Laugh\": 3\n\"Pallas\": 3\n\"XI\": 3\n\"espied\": 3\n\"servitors\": 3\n\"grinning\": 3\n\"pagans\": 3\n\"womanly\": 3\n\"Transform\": 3\n\"Prodigious\": 3\n\"flashes\": 3\n\"butchered\": 3\n\"gambols\": 3\n\"panther\": 3\n\"loan\": 3\n\"emperess\": 3\n\"Endure\": 3\n\"accessary\": 3\n\"tight\": 3\n\"sourly\": 3\n\"picked\": 3\n\"ALARBUS\": 3\n\"discomfited\": 3\n\"Good-morrow\": 3\n\"two-and-twenty\": 3\n\"1599\": 3\n\"riveted\": 3\n\"Reserve\": 3\n\"gallantly\": 3\n\"thievery\": 3\n\"Menteith\": 3\n\"Followed\": 3\n\"spok\": 3\n\"Timandra\": 3\n\"gouty\": 3\n\"Worm\": 3\n\"ador\": 3\n\"incident\": 3\n\"Secure\": 3\n\"refined\": 3\n\"Isidore\": 3\n\"there-\": 3\n\"giver\": 3\n\"taffeta\": 3\n\"Borne\": 3\n\"behove\": 3\n\"for-\": 3\n\"stoup\": 3\n\"bringer\": 3\n\"resolutely\": 3\n\"dissolutely\": 3\n\"lad-\": 3\n\"mental\": 3\n\"Belong\": 3\n\"dedication\": 3\n\"Exceeds\": 3\n\"clouts\": 3\n\"obtaining\": 3\n\"ceas\": 3\n\"undermine\": 3\n\"blam\": 3\n\"pants\": 3\n\"triumphing\": 3\n\"resistance\": 3\n\"Plutus\": 3\n\"snare\": 3\n\"shortens\": 3\n\"unlettered\": 3\n\"handsomely\": 3\n\"Inhabits\": 3\n\"omnipotent\": 3\n\"fathoms\": 3\n\"admiral\": 3\n\"fervour\": 3\n\"Friday\": 3\n\"tang\": 3\n\"wittingly\": 3\n\"crowner\": 3\n\"pilgrims\": 3\n\"Pull\": 3\n\"goal\": 3\n\"indued\": 3\n\"Burden\": 3\n\"cramps\": 3\n\"darest\": 3\n\"sliver\": 3\n\"darken\": 3\n\"Kiss\": 3\n\"Imprison\": 3\n\"library\": 3\n\"Naught\": 3\n\"achieved\": 3\n\"boatswain\": 3\n\"glassy\": 3\n\"NYMPHS\": 3\n\"nonce\": 3\n\"carouses\": 3\n\"entail\": 3\n\"marcheth\": 3\n\"dip\": 3\n\"squadrons\": 3\n\"butler\": 3\n\"Swoons\": 3\n\"Feast\": 3\n\"HABERDASHER\": 3\n\"Order\": 3\n\"soud\": 3\n\"armoury\": 3\n\"senis\": 3\n\"celsa\": 3\n\"regia\": 3\n\"Priami\": 3\n\"envenom\": 3\n\"masterly\": 3\n\"Norman\": 3\n\"Mamillius\": 3\n\"tellus\": 3\n\"Sigeia\": 3\n\"Simois\": 3\n\"reeds\": 3\n\"crisp\": 3\n\"recompens\": 3\n\"ibat\": 3\n\"unworthiest\": 3\n\"augurers\": 3\n\"errule\": 3\n\"warms\": 3\n\"Quarrel\": 3\n\"buzzard\": 3\n\"Asses\": 3\n\"novice\": 3\n\"appointments\": 3\n\"predicament\": 3\n\"liberality\": 3\n\"Convert\": 3\n\"maze\": 3\n\"rap\": 3\n\"blackness\": 3\n\"invocate\": 3\n\"Gramercies\": 3\n\"Sailor\": 3\n\"fadom\": 3\n\"mathematics\": 3\n\"apprehends\": 3\n\"commune\": 3\n\"deathbed\": 3\n\"Beguil\": 3\n\"politician\": 3\n\"York-\": 3\n\"conserves\": 3\n\"PLAYER\": 3\n\"ewer\": 3\n\"cozeners\": 3\n\"bestrew\": 3\n\"pitchy\": 3\n\"Subdue\": 3\n\"pelican\": 3\n\"Conscience\": 3\n\"exceedingly\": 3\n\"credence\": 3\n\"pendent\": 3\n\"redeems\": 3\n\"Egyptians\": 3\n\"receptacle\": 3\n\"new-fangled\": 3\n\"exigent\": 3\n\"lain\": 3\n\"addle\": 3\n\"aching\": 3\n\"roe\": 3\n\"leak\": 3\n\"Blind\": 3\n\"Disgrace\": 3\n\"bewitched\": 3\n\"dignifies\": 3\n\"manes\": 3\n\"gelding\": 3\n\"Mab\": 3\n\"chamberlain\": 3\n\"radiance\": 3\n\"as-\": 3\n\"branded\": 3\n\"Jule\": 3\n\"bewept\": 3\n\"(God\": 3\n\"vials\": 3\n\"Susan\": 3\n\"spites\": 3\n\"pois\": 3\n\"swor\": 3\n\"sable\": 3\n\"nineteen\": 3\n\"Beauteous\": 3\n\"continually\": 3\n\"impossible-\": 3\n\"Servingmen\": 3\n\"Falling\": 3\n\"gardens\": 3\n\"Franciscan\": 3\n\"doer\": 3\n\"Ravish\": 3\n\"All-Souls\": 3\n\"Christopher\": 3\n\"garters\": 3\n\"godlike\": 3\n\"lengthens\": 3\n\"Earth\": 3\n\"sixty\": 3\n\"reel\": 3\n\"Forrest\": 3\n\"childishness\": 3\n\"Dighton\": 3\n\"lolling\": 3\n\"especial\": 3\n\"inferr\": 3\n\"sharing\": 3\n\"Baynard\": 3\n\"PURSUIVANT\": 3\n\"councils\": 3\n\"women-\": 3\n\"Ludlow\": 3\n\"CHILDREN\": 3\n\"infidel\": 3\n\"tumbling\": 3\n\"millstones\": 3\n\"treasures\": 3\n\"musing\": 3\n\"endeared\": 3\n\"gentleman-\": 3\n\"Crosby\": 3\n\"heady\": 3\n\"Chertsey\": 3\n\"hest\": 3\n\"essentially\": 3\n\"impudence\": 3\n\"mourner\": 3\n\"easiness\": 3\n\"esperance\": 3\n\"Brakenbury\": 3\n\"tilt\": 3\n\"Lament\": 3\n\"well-spoken\": 3\n\"descant\": 3\n\"I-that\": 3\n\"drawers\": 3\n\"HERBERT\": 3\n\"Infects\": 3\n\"ulcerous\": 3\n\"have-\": 3\n\"dilated\": 3\n\"Exton\": 3\n\"gambol\": 3\n\"Step\": 3\n\"derives\": 3\n\"Fitzwater\": 3\n\"rapes\": 3\n\"Carlisle\": 3\n\"vipers\": 3\n\"stinging\": 3\n\"signories\": 3\n\"impair\": 3\n\"sully\": 3\n\"forerun\": 3\n\"Start\": 3\n\"wearisome\": 3\n\"Forth\": 3\n\"washes\": 3\n\"Willoughby\": 3\n\"nameless\": 3\n\"Persuades\": 3\n\"Breed\": 3\n\"laps\": 3\n\"stall\": 3\n\"EGYPTIAN\": 3\n\"cutpurse\": 3\n\"Confin\": 3\n\"Awak\": 3\n\"dolour\": 3\n\"backing\": 3\n\"unwillingness\": 3\n\"speediest\": 3\n\"impute\": 3\n\"diverted\": 3\n\"Plashy\": 3\n\"flourishing\": 3\n\"WESTMINSTER\": 3\n\"sift\": 3\n\"composure\": 3\n\"dependency\": 3\n\"(dear\": 3\n\"Eyes\": 3\n\"obscene\": 3\n\"foregone\": 3\n\"Desdemon\": 3\n\"combination\": 3\n\"unsafe\": 3\n\"counterfeits\": 3\n\"bobb\": 3\n\"nimbly\": 3\n\"brimstone\": 3\n\"chastis\": 3\n\"gibbet\": 3\n\"hungerly\": 3\n\"minx\": 3\n\"deed-\": 3\n\"no-\": 3\n\"handkerchief-\": 3\n\"before-\": 3\n\"strawberries\": 3\n\"livest\": 3\n\"ns\": 3\n\"Procure\": 3\n\"propertied\": 3\n\"mistress-\": 3\n\"hent\": 3\n\"splinter\": 3\n\"drunkenness\": 3\n\"pistol\": 3\n\"rel\": 3\n\"Prizes\": 3\n\"satiety\": 3\n\"kissed\": 3\n\"thinkings\": 3\n\"shuffling\": 3\n\"thrill\": 3\n\"Mayst\": 3\n\"Destruction\": 3\n\"Rude\": 3\n\"thicker\": 3\n\"defile\": 3\n\"keepest\": 3\n\"Ottomites\": 3\n\"deceives\": 3\n\"Attends\": 3\n\"bolting\": 3\n\"Sagittary\": 3\n\"islands\": 3\n\"ruffians\": 3\n\"Narbon\": 3\n\"riper\": 3\n\"Gerard\": 3\n\"(I\": 3\n\"honourable-\": 3\n\"inducement\": 3\n\"By-and-by\": 3\n\"removes\": 3\n\"Govern\": 3\n\"answerable\": 3\n\"Pawn\": 3\n\"gentle-\": 3\n\"fetches\": 3\n\"recorders\": 3\n\"Bliss\": 3\n\"Lights\": 3\n\"ii\": 3\n\"bereave\": 3\n\"Actium\": 3\n\"tip\": 3\n\"Graves\": 3\n\"--a\": 3\n\"eruptions\": 3\n\"induce\": 3\n\"mixture\": 3\n\"Confederate\": 3\n\"rature\": 3\n\"dotard\": 3\n\"sufficiency\": 3\n\"Wye\": 3\n\"Bootless\": 3\n\"Pox\": 3\n\"agues\": 3\n\"acknowledg\": 3\n\"Cheer\": 3\n\"accused\": 3\n\"northward\": 3\n\"attir\": 3\n\"Neighbours\": 3\n\"benedictus\": 3\n\"stables\": 3\n\"Intends\": 3\n\"smug\": 3\n\"evenly\": 3\n\"Discomfort\": 3\n\"ernight\": 3\n\"hammers\": 3\n\"orbed\": 3\n\"mincing\": 3\n\"well-deserving\": 3\n\"posy\": 3\n\"Seacoal\": 3\n\"consenting\": 3\n\"Saucy\": 3\n\"sadder\": 3\n\"dreamer\": 3\n\"Gentlewomen\": 3\n\"advances\": 3\n\"ramping\": 3\n\"condole\": 3\n\"dumps\": 3\n\"Hey\": 3\n\"delivering\": 3\n\"attires\": 3\n\"pours\": 3\n\"embracing\": 3\n\"harpy\": 3\n\"sedges\": 3\n\"self-will\": 3\n\"Libya\": 3\n\"cursy\": 3\n\"aspic\": 3\n\"overflow\": 3\n\"(his\": 3\n\"purging\": 3\n\"Sexton\": 3\n\"enact\": 3\n\"curled\": 3\n\"asp\": 3\n\"givest\": 3\n\"bravest\": 3\n\"broom\": 3\n\"deflower\": 3\n\"Curs\": 3\n\"unparallel\": 3\n\"Quit\": 3\n\"faulty\": 3\n\"Gentles\": 3\n\"singer\": 3\n\"comet\": 3\n\"Loud\": 3\n\"salutations\": 3\n\"Seldom\": 3\n\"ribbons\": 3\n\"Spartan\": 3\n\"Sparta\": 3\n\"valley\": 3\n\"winding\": 3\n\"visions\": 3\n\"awaking\": 3\n\"unskilful\": 3\n\"squirrel\": 3\n\"honey-bag\": 3\n\"thistle\": 3\n\"lighter\": 3\n\"sent-\": 3\n\"personage\": 3\n\"chronicled\": 3\n\"Descended\": 3\n\"whirlwind\": 3\n\"torrent\": 3\n\"levell\": 3\n\"Ninny\": 3\n\"rough-cast\": 3\n\"touched\": 3\n\"redoubled\": 3\n\"augmented\": 3\n\"protected\": 3\n\"Despised\": 3\n\"deject\": 3\n\"lulla\": 3\n\"woodbine\": 3\n\"Daphne\": 3\n\"odorous\": 3\n\"ploughman\": 3\n\"glimmering\": 3\n\"scorned\": 3\n\"Company\": 3\n\"nickname\": 3\n\"Crowns\": 3\n\"Swifter\": 3\n\"paradox\": 3\n\"enterprises\": 3\n\"dale\": 3\n\"Snug\": 3\n\"Snout\": 3\n\"Starveling\": 3\n\"metre\": 3\n\"undiscover\": 3\n\"verbal\": 3\n\"denier\": 3\n\"younker\": 3\n\"treats\": 3\n\"errs\": 3\n\"bodkin\": 3\n\"unfolds\": 3\n\"shocks\": 3\n\"Relent\": 3\n\"Pages\": 3\n\"otter\": 3\n\"plentifully\": 3\n\"Darest\": 3\n\"servitude\": 3\n\"forcing\": 3\n\"allows\": 3\n\"miraculous\": 3\n\"sessions\": 3\n\"sharpness\": 3\n\"rankness\": 3\n\"bellows-mender\": 3\n\"Lastly\": 3\n\"unwash\": 3\n\"(A\": 3\n\"importunes\": 3\n\"offal\": 3\n\"laud\": 3\n\"vowing\": 3\n\"irreligious\": 3\n\"misgives\": 3\n\"plummet\": 3\n\"putter\": 3\n\"fiction\": 3\n\"Player\": 3\n\"expressure\": 3\n\"intendment\": 3\n\"shades\": 3\n\"Hobgoblin\": 3\n\"Europa\": 3\n\"loop\": 3\n\"nave\": 3\n\"brightness\": 3\n\"spokes\": 3\n\"brotherly\": 3\n\"anatomize\": 3\n\"cozened\": 3\n\"plum\": 3\n\"privacy\": 3\n\"queasy\": 3\n\"urchins\": 3\n\"Herne\": 3\n\"neutral\": 3\n\"Pegasus\": 3\n\"scrape\": 3\n\"Celia\": 3\n\"milky\": 3\n\"protests\": 3\n\"costs\": 3\n\"fil\": 3\n\"parching\": 3\n\"lunes\": 3\n\"caliver\": 3\n\"horum\": 3\n\"consists\": 3\n\"serving-men\": 3\n\"Younger\": 3\n\"tapsters\": 3\n\"gules\": 3\n\"declined\": 3\n\"prentice\": 3\n\"rooms\": 3\n\"flush\": 3\n\"ill-favouredly\": 3\n\"botcher\": 3\n\"scenes\": 3\n\"uncurrent\": 3\n\"puppies\": 3\n\"Jephthah\": 3\n\"dedicated\": 3\n\"Peradventure\": 3\n\"dullness\": 3\n\"never-\": 3\n\"farthingale\": 3\n\"comply\": 3\n\"hostility\": 3\n\"fixture\": 3\n\"posterns\": 3\n\"sneaking\": 3\n\"Mead\": 3\n\"tarre\": 3\n\"cogging\": 3\n\"rapiers\": 3\n\"knog\": 3\n\"Pless\": 3\n\"Proceeded\": 3\n\"Scurvy\": 3\n\"curer\": 3\n\"Broke\": 3\n\"innovation\": 3\n\"impawn\": 3\n\"ambling\": 3\n\"Pompeius\": 3\n\"Sextus\": 3\n\"aqua-vitae\": 3\n\"overrul\": 3\n\"lenten\": 3\n\"congregation\": 3\n\"contriving\": 3\n\"appeareth\": 3\n\"Beau\": 3\n\"excellency\": 3\n\"sip\": 3\n\"Absolute\": 3\n\"pottle\": 3\n\"Cavaleiro\": 3\n\"Actaeon\": 3\n\"jour\": 3\n\"Destinies\": 3\n\"Pulling\": 3\n\"Villainy\": 3\n\"fay\": 3\n\"losest\": 3\n\"outstretch\": 3\n\"fe\": 3\n\"bounded\": 3\n\"unthrift\": 3\n\"wrestled\": 3\n\"successfully\": 3\n\"er-read\": 3\n\"rigg\": 3\n\"soles\": 3\n\"withal-\": 3\n\"signifies\": 3\n\"Star\": 3\n\"Wives\": 3\n\"amounts\": 3\n\"accepted\": 3\n\"marries\": 3\n\"Awakes\": 3\n\"prescriptions\": 3\n\"Quicken\": 3\n\"closure\": 3\n\"Air\": 3\n\"Suspicion\": 3\n\"plausive\": 3\n\"unreasonable\": 3\n\"defending\": 3\n\"Hereafter\": 3\n\"colts\": 3\n\"carters\": 3\n\"rift\": 3\n\"Inquire\": 3\n\"rehears\": 3\n\"selling\": 3\n\"bleat\": 3\n\"Hem\": 3\n\"Check\": 3\n\"Plain\": 3\n\"beautified\": 3\n\"broached\": 3\n\"molten\": 3\n\"vaunting\": 3\n\"back-\": 3\n\"mong\": 3\n\"inherited\": 3\n\"blotted\": 3\n\"irrevocable\": 3\n\"requested\": 3\n\"maintenance\": 3\n\"thought-\": 3\n\"promiseth\": 3\n\"shedding\": 3\n\"ivory\": 3\n\"Clifton\": 3\n\"high-day\": 3\n\"alighted\": 3\n\"distinct\": 3\n\"smirch\": 3\n\"runaway\": 3\n\"joyfully\": 3\n\"savages\": 3\n\"encourage\": 3\n\"liveth\": 3\n\"gunpowder\": 3\n\"embraced\": 3\n\"expend\": 3\n\"adheres\": 3\n\"exterior\": 3\n\"cum\": 3\n\"enjoyed\": 3\n\"undertakings\": 3\n\"casements\": 3\n\"masques\": 3\n\"RUMOUR\": 3\n\"torch-bearer\": 3\n\"Gramercy\": 3\n\"who-\": 3\n\"mannish\": 3\n\"Sophy\": 3\n\"scimitar\": 3\n\"dealings\": 3\n\"tennis\": 3\n\"whisp\": 3\n\"gaberdine\": 3\n\"cite\": 3\n\"streak\": 3\n\"savageness\": 3\n\"perspective\": 3\n\"fencing\": 3\n\"gaming\": 3\n\"TRAVERS\": 3\n\"fang\": 3\n\"retainers\": 3\n\"Lifts\": 3\n\"Methoughts\": 3\n\"Hebrew\": 3\n\"glazed\": 3\n\"HARCOURT\": 3\n\"creating\": 3\n\"Wears\": 3\n\"Tripolis\": 3\n\"bound-\": 3\n\"End\": 3\n\"ducats-\": 3\n\"Morocco\": 3\n\"copied\": 3\n\"stubbornness\": 3\n\"irks\": 3\n\"crust\": 3\n\"Desiring\": 3\n\"posset\": 3\n\"scent\": 3\n\"peeps\": 3\n\"school-days\": 3\n\"seduce\": 3\n\"Antonio-\": 3\n\"porpentine\": 3\n\"Bravely\": 3\n\"alabaster\": 3\n\"leisures\": 3\n\"sequest\": 3\n\"alien\": 3\n\"animal\": 3\n\"TEARSHEET\": 3\n\"marked\": 3\n\"signiors\": 3\n\"argosies\": 3\n\"INDUCTION\": 3\n\"moralize\": 3\n\"BALTHASAR\": 3\n\"ensconce\": 3\n\"uprear\": 3\n\"(my\": 3\n\"measured\": 3\n\"desperation\": 3\n\"dully\": 3\n\"hulk\": 3\n\"Suspect\": 3\n\"beweep\": 3\n\"Travers\": 3\n\"muddied\": 3\n\"retail\": 3\n\"Round\": 3\n\"beetles\": 3\n\"summit\": 3\n\"apprehensive\": 3\n\"reaches\": 3\n\"erheard\": 3\n\"usurpation\": 3\n\"tremblest\": 3\n\"runaways\": 3\n\"onward\": 3\n\"ponderous\": 3\n\"quits\": 3\n\"Rememb\": 3\n\"tolling\": 3\n\"lank\": 3\n\"squar\": 3\n\"dullest\": 3\n\"bruited\": 3\n\"Labouring\": 3\n\"Slander\": 3\n\"Impatient\": 3\n\"butchery\": 3\n\"dout\": 3\n\"veiled\": 3\n\"Intended\": 3\n\"blasting\": 3\n\"achievements\": 3\n\"Valentinus\": 3\n\"bray\": 3\n\"Guess\": 3\n\"well-appointed\": 3\n\"draughts\": 3\n\"wassail\": 3\n\"Ragozine\": 3\n\"scrap\": 3\n\"breather\": 3\n\"resemblance\": 3\n\"beguiles\": 3\n\"extended\": 3\n\"countermand\": 3\n\"postern\": 3\n\"brokers\": 3\n\"mandrake\": 3\n\"discredit\": 3\n\"Abhorson\": 3\n\"promotion\": 3\n\"satin\": 3\n\"dissolution\": 3\n\"Mere\": 3\n\"crabbed\": 3\n\"girdles\": 3\n\"ratsbane\": 3\n\"Touchstone\": 3\n\"Luke\": 3\n\"refer\": 3\n\"Corin\": 3\n\"sterling\": 3\n\"lender\": 3\n\"finest\": 3\n\"theoric\": 3\n\"borrower\": 3\n\"reside\": 3\n\"marking\": 3\n\"slightest\": 3\n\"dugs\": 3\n\"avis\": 3\n\"Plays\": 3\n\"Assemble\": 3\n\"essence\": 3\n\"geld\": 3\n\"peascod\": 3\n\"capers\": 3\n\"Russia\": 3\n\"Hallowmas\": 3\n\"profanation\": 3\n\"benefactors\": 3\n\"nuns\": 3\n\"Supply\": 3\n\"workings\": 3\n\"consumption\": 3\n\"witless\": 3\n\"incurable\": 3\n\"preceding\": 3\n\"pension\": 3\n\"familiarity\": 3\n\"sallets\": 3\n\"ducdame\": 3\n\"largely\": 3\n\"importunity\": 3\n\"standeth\": 3\n\"provost\": 3\n\"Tapster\": 3\n\"war-\": 3\n\"awards\": 3\n\"outlaws\": 3\n\"waxes\": 3\n\"thews\": 3\n\"erection\": 3\n\"Angelo-\": 3\n\"Using\": 3\n\"wags\": 3\n\"Forward\": 3\n\"Need\": 3\n\"partaker\": 3\n\"contemplative\": 3\n\"buildeth\": 3\n\"lifted\": 3\n\"enamour\": 3\n\"Fang\": 3\n\"Form\": 3\n\"paws\": 3\n\"bob\": 3\n\"glances\": 3\n\"jelly\": 3\n\"embossed\": 3\n\"Foh\": 3\n\"disgorge\": 3\n\"Armed\": 3\n\"horrors\": 3\n\"armor\": 3\n\"Seward\": 3\n\"arn\": 3\n\"Dolphin\": 3\n\"Oh\": 3\n\"meats\": 3\n\"vinegar\": 3\n\"satyr\": 3\n\"wrenching\": 3\n\"Physic\": 3\n\"chickens\": 3\n\"shrieks\": 3\n\"decision\": 3\n\"filial\": 3\n\"knoll\": 3\n\"tap\": 3\n\"lighten\": 3\n\"engend\": 3\n\"Delphos\": 3\n\"pantaloon\": 3\n\"Apparition\": 3\n\"inwardly\": 3\n\"Passing\": 3\n\"fortress\": 3\n\"mummy\": 3\n\"exasperate\": 3\n\"rabbit\": 3\n\"Althaea\": 3\n\"firebrand\": 3\n\"Wound\": 3\n\"Hush\": 3\n\"Acheron\": 3\n\"kinswoman\": 3\n\"shady\": 3\n\"gory\": 3\n\"streaks\": 3\n\"Cancel\": 3\n\"shrinks\": 3\n\"lave\": 3\n\"discoveries\": 3\n\"seizure\": 3\n\"confessing\": 3\n\"Scone\": 3\n\"unfelt\": 3\n\"Sneak\": 3\n\"supposes\": 3\n\"Importing\": 3\n\"Steep\": 3\n\"pillows\": 3\n\"parlous\": 3\n\"urine\": 3\n\"Instance\": 3\n\"equivocator\": 3\n\"good-year\": 3\n\"-the\": 3\n\"snores\": 3\n\"Merciful\": 3\n\"extravagant\": 3\n\"invulnerable\": 3\n\"swaggerers\": 3\n\"illusion\": 3\n\"rer\": 3\n\"frieze\": 3\n\"ldst\": 3\n\"Inverness\": 3\n\"Feel\": 3\n\"infold\": 3\n\"Arabian\": 3\n\"portentous\": 3\n\"mounch\": 3\n\"thinly\": 3\n\"Doubly\": 3\n\"preparations\": 3\n\"hooks\": 3\n\"Norweyan\": 3\n\"sounder\": 3\n\"perpend\": 3\n\"Hover\": 3\n\"HECATE\": 3\n\"unfolding\": 3\n\"infernal\": 3\n\"Erebus\": 3\n\"earliest\": 3\n\"love-suit\": 3\n\"limed\": 3\n\"FLEANCE\": 3\n\"delicious\": 3\n\"lacked\": 3\n\"Adonis\": 3\n\"keel\": 3\n\"Tu-who\": 3\n\"jaded\": 3\n\"fester\": 3\n\"both-\": 3\n\"Snatching\": 3\n\"sakes\": 3\n\"South\": 3\n\"budding\": 3\n\"Ergo\": 3\n\"war-like\": 3\n\"Anointed\": 3\n\"remit\": 3\n\"altars\": 3\n\"kersey\": 3\n\"nostrils\": 3\n\"smokes\": 3\n\"meetings\": 3\n\"wares\": 3\n\"atomies\": 3\n\"perplexity\": 3\n\"Silius\": 3\n\"chariots\": 3\n\"fugitive\": 3\n\"fleer\": 3\n\"Crassus\": 3\n\"claw\": 3\n\"lisping\": 3\n\"sycamore\": 3\n\"Ware\": 3\n\"&\": 3\n\"continents\": 3\n\"contempts\": 3\n\"B\": 3\n\"majestic\": 3\n\"roast\": 3\n\"boy-\": 3\n\"trots\": 3\n\"Pleas\": 3\n\"U\": 3\n\"epithet\": 3\n\"spruce\": 3\n\"taverns\": 3\n\"nominated\": 3\n\"quod\": 3\n\"standards\": 3\n\"Promethean\": 3\n\"ebony\": 3\n\"collection\": 3\n\"uneasy\": 3\n\"Expecting\": 3\n\"Dun\": 3\n\"glutton\": 3\n\"gig\": 3\n\"thankings\": 3\n\"lectures\": 3\n\"halfpence\": 3\n\"shrouded\": 3\n\"mill\": 3\n\"heedfully\": 3\n\"worlds\": 3\n\"pap\": 3\n\"Nevil\": 3\n\"sonnets\": 3\n\"venuto\": 3\n\"Horace\": 3\n\"Mantuan\": 3\n\"commenting\": 3\n\"princes-\": 3\n\"begetting\": 3\n\"mater\": 3\n\"pia\": 3\n\"apprehensions\": 3\n\"Mighty\": 3\n\"Inns\": 3\n\"nursing\": 3\n\"sorel\": 3\n\"yell\": 3\n\"variation\": 3\n\"du\": 3\n\"facility\": 3\n\"Phoebe\": 3\n\"Dictynna\": 3\n\"Embracing\": 3\n\"forehand\": 3\n\"Prison\": 3\n\"features\": 3\n\"Dangerous\": 3\n\"Spit\": 3\n\"Ovid\": 3\n\"lie-\": 3\n\"shooter\": 3\n\"weathercock\": 3\n\"justicer\": 3\n\"vane\": 3\n\"commiseration\": 3\n\"seconded\": 3\n\"Argus\": 3\n\"Means\": 3\n\"Remuneration\": 3\n\"Martext\": 3\n\"restrained\": 3\n\"forcible\": 3\n\"stagger\": 3\n\"stakes\": 3\n\"Nightwork\": 3\n\"Isbel\": 3\n\"JUSTICES\": 3\n\"snip\": 3\n\"bucket\": 3\n\"gazes\": 3\n\"pink\": 3\n\"entitle\": 3\n\"ravished\": 3\n\"volumes\": 3\n\"loveth\": 3\n\"passado\": 3\n\"appertaining\": 3\n\"fantastically\": 3\n\"dimensions\": 3\n\"bawdry\": 3\n\"aforesaid\": 3\n\"with-\": 3\n\"snow-white\": 3\n\"Wind\": 3\n\"snap\": 3\n\"Creatures\": 3\n\"browner\": 3\n\"shuffle\": 3\n\"countenanc\": 3\n\"bettered\": 3\n\"reprehend\": 3\n\"pens\": 3\n\"hight\": 3\n\"possibly\": 3\n\"concave\": 3\n\"Christmas\": 3\n\"Construe\": 3\n\"mistrusted\": 3\n\"coursers\": 3\n\"warder\": 3\n\"worm-eaten\": 3\n\"tasks\": 3\n\"filching\": 3\n\"regist\": 3\n\"odours\": 3\n\"adoption\": 3\n\"mineral\": 3\n\"quirks\": 3\n\"softest\": 3\n\"ripens\": 3\n\"unswept\": 3\n\"partition\": 3\n\"Limbo\": 3\n\"ADRIANO\": 3\n\"DON\": 3\n\"impressure\": 3\n\"statues\": 3\n\"Bow\": 3\n\"darted\": 3\n\"ever-\": 3\n\"Touches\": 3\n\"gibbets\": 3\n\"insult\": 3\n\"abroach\": 3\n\"interlude\": 3\n\"Dispose\": 3\n\"Employ\": 3\n\"acquittance\": 3\n\"Bore\": 3\n\"tamely\": 3\n\"Wipe\": 3\n\"news-\": 3\n\"sects\": 3\n\"reeling\": 3\n\"Fourscore\": 3\n\"jail\": 3\n\"opportunities\": 3\n\"Chill\": 3\n\"repast\": 3\n\"farmer\": 3\n\"inky\": 3\n\"sulphurous\": 3\n\"bullet\": 3\n\"Centaurs\": 3\n\"possibility\": 3\n\"covers\": 3\n\"Waking\": 3\n\"demure\": 3\n\"fitchew\": 3\n\"environ\": 3\n\"Often\": 3\n\"foggy\": 3\n\"properer\": 3\n\"reels\": 3\n\"beak\": 3\n\"Express\": 3\n\"acre\": 3\n\"trials\": 3\n\"furrow\": 3\n\"thereat\": 3\n\"Oppos\": 3\n\"batters\": 3\n\"Offend\": 3\n\"Decline\": 3\n\"markets\": 3\n\"difficulty\": 3\n\"Peep\": 3\n\"tuft\": 3\n\"hardiment\": 3\n\"Embowell\": 3\n\"congealed\": 3\n\"reverently\": 3\n\"irksome\": 3\n\"Cunning\": 3\n\"Slight\": 3\n\"youth-\": 3\n\"find-\": 3\n\"MOTHER\": 3\n\"pall\": 3\n\"repeals\": 3\n\"portable\": 3\n\"palmers\": 3\n\"foulest\": 3\n\"loathly\": 3\n\"attired\": 3\n\"intelligent\": 3\n\"Tween\": 3\n\"abatement\": 3\n\"pales\": 3\n\"injunction\": 3\n\"Serving\": 3\n\"downy\": 3\n\"swallows\": 3\n\"shanks\": 3\n\"perpetuity\": 3\n\"lisp\": 3\n\"Err\": 3\n\"nonny\": 3\n\"Yields\": 3\n\"quaff\": 3\n\"flatters\": 3\n\"bugs\": 3\n\"prologues\": 3\n\"placket\": 3\n\"prevents\": 3\n\"bedew\": 3\n\"unguarded\": 3\n\"form-\": 3\n\"ranker\": 3\n\"strides\": 3\n\"taker\": 3\n\"distaff\": 3\n\"muzzle\": 3\n\"Accommodated\": 3\n\"videlicet\": 3\n\"wit-\": 3\n\"patterns\": 3\n\"concealing\": 3\n\"midsummer\": 3\n\"Athwart\": 3\n\"Forsake\": 3\n\"pathetical\": 3\n\"things-\": 3\n\"Necessity\": 3\n\"expiration\": 3\n\"frames\": 3\n\"waspish\": 3\n\"smith\": 3\n\"harshness\": 3\n\"Cam\": 3\n\"re-enter\": 3\n\"Visor\": 3\n\"hermits\": 3\n\"godhead\": 3\n\"wantons\": 3\n\"persuades\": 3\n\"sorrow-\": 3\n\"fallen\": 3\n\"scatters\": 3\n\"befell\": 3\n\"ergrown\": 3\n\"remaining\": 3\n\"shrinking\": 3\n\"profan\": 3\n\"slighted\": 3\n\"Tie\": 3\n\"fortunately\": 3\n\"rubb\": 3\n\"shorten\": 3\n\"dialect\": 3\n\"couching\": 3\n\"leman\": 3\n\"R\": 3\n\"quart\": 3\n\"dub\": 3\n\"sop\": 3\n\"pursued\": 3\n\"potential\": 3\n\"gentlemen-\": 3\n\"Cophetua\": 3\n\"mourners\": 3\n\"decorum\": 3\n\"fogs\": 3\n\"cooks\": 3\n\"ebbs\": 3\n\"Saddle\": 3\n\"Mum\": 3\n\"bled\": 3\n\"pined\": 3\n\"divination\": 3\n\"dependants\": 3\n\"Dinner\": 3\n\"garrison\": 3\n\"paler\": 3\n\"wombs\": 3\n\"profaned\": 3\n\"upbraids\": 3\n\"Struck\": 3\n\"madded\": 3\n\"(though\": 3\n\"flouting\": 3\n\"slower\": 3\n\"Awaking\": 3\n\"wider\": 3\n\"Parted\": 3\n\"Cover\": 3\n\"sol\": 3\n\"mercies\": 3\n\"leave-\": 3\n\"memorial\": 3\n\"Resolv\": 3\n\"bastinado\": 3\n\"disasters\": 3\n\"foppery\": 3\n\"disorders\": 3\n\"prediction\": 3\n\"er-run\": 3\n\"Unnatural\": 3\n\"needed\": 3\n\"professed\": 3\n\"leaping\": 3\n\"Solemn\": 3\n\"benison\": 3\n\"claws\": 3\n\"piec\": 3\n\"slandered\": 3\n\"hollowness\": 3\n\"rav\": 3\n\"COURT\": 3\n\"arrogant\": 3\n\"Beloved\": 3\n\"messes\": 3\n\"lustier\": 3\n\"lowness\": 3\n\"robber\": 3\n\"mountaineers\": 3\n\"vines\": 3\n\"ding\": 3\n\"tenant\": 3\n\"GRANDPRE\": 3\n\"Curan\": 3\n\"pitifully\": 3\n\"tattered\": 3\n\"withering\": 3\n\"reed\": 3\n\"love)\": 3\n\"settle\": 3\n\"funerals\": 3\n\"Mistrust\": 3\n\"Stick\": 3\n\"sententious\": 3\n\"Varrius\": 3\n\"Forever\": 3\n\"perch\": 3\n\"Modest\": 3\n\"everyone\": 3\n\"yoked\": 3\n\"TRIBUNE\": 3\n\"nominate\": 3\n\"loads\": 3\n\"alias\": 3\n\"proscription\": 3\n\"bang\": 3\n\"BOYS\": 3\n\"engage\": 3\n\"victuals\": 3\n\"rustic\": 3\n\"elbows\": 3\n\"snore\": 3\n\"bushes\": 3\n\"weariness\": 3\n\"Freedom\": 3\n\"scouring\": 3\n\"woodman\": 3\n\"rumor\": 3\n\"Artemidorus\": 3\n\"ERRORS\": 3\n\"variance\": 3\n\"erthrow\": 3\n\"kerchief\": 3\n\"trespasses\": 3\n\"ripen\": 3\n\"ungently\": 3\n\"lattice\": 3\n\"perfected\": 3\n\"Conspiracy\": 3\n\"foul-mouth\": 3\n\"Commons\": 3\n\"handkercher\": 3\n\"menace\": 3\n\"jack-an-apes\": 3\n\"Flow\": 3\n\"Clean\": 3\n\"shrieking\": 3\n\"warr\": 3\n\"entertained\": 3\n\"great-grandfather\": 3\n\"Presence\": 3\n\"calumnious\": 3\n\"learns\": 3\n\"condemnation\": 3\n\"baptism\": 3\n\"Merchant\": 3\n\"Pharamond\": 3\n\"rigorous\": 3\n\"cement\": 3\n\"Disdaining\": 3\n\"banqueting\": 3\n\"Sala\": 3\n\"crowd\": 3\n\"Ours\": 3\n\"omnes\": 3\n\"deposed\": 3\n\"(being\": 3\n\"Capet\": 3\n\"builded\": 3\n\"exalted\": 3\n\"unpaid\": 3\n\"wearer\": 3\n\"livelong\": 3\n\"Commoners\": 3\n\"Poet\": 3\n\"envied\": 3\n\"amply\": 3\n\"splitted\": 3\n\"progenitors\": 3\n\"abroad-\": 3\n\"reft\": 3\n\"misfortunes\": 3\n\"name-\": 3\n\"unsought\": 3\n\"harbours\": 3\n\"bedded\": 3\n\"self-\": 3\n\"beneficial\": 3\n\"Woman\": 3\n\"custody\": 3\n\"helpless\": 3\n\"statesman\": 3\n\"residing\": 3\n\"clod\": 3\n\"tyrannize\": 3\n\"peopled\": 3\n\"Bringing\": 3\n\"chants\": 3\n\"Fierce\": 3\n\"executors\": 3\n\"yawning\": 3\n\"Washes\": 3\n\"Unseen\": 3\n\"retired\": 3\n\"rareness\": 3\n\"AMBASSADOR\": 3\n\"Freely\": 3\n\"casts\": 3\n\"Amazons\": 3\n\"presageth\": 3\n\"sanctimony\": 3\n\"temporize\": 3\n\"measuring\": 3\n\"merriest\": 3\n\"Fond\": 3\n\"Outside\": 3\n\"enkindled\": 3\n\"Lift\": 3\n\"plaster\": 3\n\"cozenage\": 3\n\"sorcerers\": 3\n\"appliance\": 3\n\"leaven\": 3\n\"Sinon\": 3\n\"ripp\": 3\n\"Maecenas\": 3\n\"twisted\": 3\n\"sighed\": 3\n\"toast\": 3\n\"troth-plight\": 3\n\"somewhere\": 3\n\"needles\": 3\n\"Edmundsbury\": 3\n\"consequently\": 3\n\"Apt\": 3\n\"rumours\": 3\n\"clergymen\": 3\n\"unseasonable\": 3\n\"urged\": 3\n\"rainbow\": 3\n\"fowls\": 3\n\"red-hot\": 3\n\"valleys\": 3\n\"females\": 3\n\"Plainly\": 3\n\"demesnes\": 3\n\"hangings\": 3\n\"edges\": 3\n\"erswell\": 3\n\"marriage-bed\": 3\n\"worse-\": 3\n\"horn-mad\": 3\n\"vaulty\": 3\n\"Barren\": 3\n\"voluble\": 3\n\"Shaking\": 3\n\"inconstancy\": 3\n\"sunny\": 3\n\"later\": 3\n\"blaspheme\": 3\n\"choir\": 3\n\"familiarly\": 3\n\"chew\": 3\n\"Belonging\": 3\n\"conspir\": 3\n\"bargains\": 3\n\"Ingrateful\": 3\n\"travelling\": 3\n\"demeanour\": 3\n\"dyed\": 3\n\"glist\": 3\n\"Stays\": 3\n\"unfledg\": 3\n\"smooth-fac\": 3\n\"namely\": 3\n\"unprepared\": 3\n\"complement\": 3\n\"purged\": 3\n\"ensues\": 3\n\"espy\": 3\n\"Beseeching\": 3\n\"promotions\": 3\n\"carv\": 3\n\"honey-sweet\": 3\n\"blithe\": 3\n\"fair-fac\": 3\n\"pare\": 3\n\"licentious\": 3\n\"confronted\": 3\n\"Acknowledge\": 3\n\"circumference\": 3\n\"marjoram\": 3\n\"scann\": 3\n\"Denied\": 3\n\"sense-\": 3\n\"inspiration\": 3\n\"thwart\": 3\n\"elm\": 3\n\"brib\": 3\n\"Eke\": 3\n\"clasp\": 3\n\"Infect\": 3\n\"uncertainty\": 3\n\"owls\": 3\n\"gardeners\": 3\n\"assaults\": 3\n\"interruption\": 3\n\"premises\": 3\n\"Ate\": 3\n\"drone\": 3\n\"forerunner\": 3\n\"Intend\": 3\n\"Almighty\": 3\n\"handiwork\": 3\n\"college\": 3\n\"confess-\": 3\n\"unreverend\": 3\n\"awkward\": 3\n\"catechize\": 3\n\"however\": 3\n\"Known\": 3\n\"adventures\": 3\n\"examined\": 3\n\"requiring\": 3\n\"liege-\": 3\n\"dainties\": 3\n\"mouth-\": 3\n\"truly-\": 3\n\"sparing\": 3\n\"cates\": 3\n\"Bridget\": 3\n\"hempen\": 3\n\"propagate\": 3\n\"foams\": 3\n\"lottery\": 3\n\"ESSEX\": 3\n\"Tiger\": 3\n\"desert-\": 3\n\"wife-\": 3\n\"Clap\": 3\n\"harbinger\": 3\n\"conquers\": 3\n\"godfather\": 3\n\"chastely\": 3\n\"memories\": 3\n\"nostril\": 3\n\"councillor\": 3\n\"Fathers\": 3\n\"Butts\": 3\n\"attest\": 3\n\"vehemency\": 3\n\"untender\": 3\n\"personally\": 3\n\"plain-song\": 3\n\"weightier\": 3\n\"erflows\": 3\n\"ell\": 3\n\"blessedness\": 3\n\"persuading\": 3\n\"untruths\": 3\n\"Abbot\": 3\n\"Lust\": 3\n\"Leicester\": 3\n\"tools\": 3\n\"pervert\": 3\n\"Cheshu\": 3\n\"spherical\": 3\n\"bogs\": 3\n\"Jamy\": 3\n\"aunchient\": 3\n\"woven\": 3\n\"breast-\": 3\n\"satisfying\": 3\n\"goodliest\": 3\n\"incontinency\": 3\n\"cognizance\": 3\n\"stifled\": 3\n\"chalky\": 3\n\"Serve\": 3\n\"bladders\": 3\n\"affability\": 3\n\"larks\": 3\n\"believe-\": 3\n\"unfinish\": 3\n\"sleek\": 3\n\"enraged\": 3\n\"eagerly\": 3\n\"Pentecost\": 3\n\"succours\": 3\n\"huntsman\": 3\n\"prescience\": 3\n\"Fairly\": 3\n\"wronger\": 3\n\"Profess\": 3\n\"bien\": 3\n\"crawl\": 3\n\"wasps\": 3\n\"fineness\": 3\n\"Arrest\": 3\n\"Blows\": 3\n\"Forgetting\": 3\n\"Religious\": 3\n\"Orpheus\": 3\n\"tilting\": 3\n\"Dorothy\": 3\n\"pleaded\": 3\n\"ordering\": 3\n\"sere\": 3\n\"rectify\": 3\n\"communicate\": 3\n\"commodities\": 3\n\"foi\": 3\n\"foster\": 3\n\"vengeful\": 3\n\"CARDINALS\": 3\n\"Paradise\": 3\n\"Marchioness\": 3\n\"sont\": 3\n\"spice\": 3\n\"friended\": 3\n\"Kept\": 3\n\"ai\": 3\n\"madding\": 3\n\"law-\": 3\n\"committing\": 3\n\"sorceress\": 3\n\"fatherly\": 3\n\"insupportable\": 3\n\"Fears\": 3\n\"bin\": 3\n\"unstained\": 3\n\"avez\": 3\n\"des\": 3\n\"fingre\": 3\n\"disquiet\": 3\n\"Vex\": 3\n\"holily\": 3\n\"Campeius\": 3\n\"fingering\": 3\n\"parings\": 3\n\"ace\": 3\n\"undertakes\": 3\n\"whoever\": 3\n\"cheat\": 3\n\"ce\": 3\n\"peacock\": 3\n\"disprais\": 3\n\"learnedly\": 3\n\"harshly\": 3\n\"afear\": 3\n\"tout\": 3\n\"wizard\": 3\n\"une\": 3\n\"customers\": 3\n\"damage\": 3\n\"chaplain\": 3\n\"sprays\": 3\n\"Concerning\": 3\n\"Normans\": 3\n\"movables\": 3\n\"sally\": 3\n\"icicles\": 3\n\"exaction\": 3\n\"exactions\": 3\n\"commissions\": 3\n\"diseased\": 3\n\"priory\": 3\n\"Gilbert\": 3\n\"nous\": 3\n\"whiter\": 3\n\"Cytherea\": 3\n\"treasonous\": 3\n\"July\": 3\n\"province\": 3\n\"Grandpre\": 3\n\"maladies\": 3\n\"Pierce\": 3\n\"monumental\": 3\n\"Buried\": 3\n\"certes\": 3\n\"prevailing\": 3\n\"sweeps\": 3\n\"thron\": 3\n\"Namely\": 3\n\"reprehended\": 3\n\"Picardy\": 3\n\"Kimbolton\": 3\n\"appeach\": 3\n\"derogate\": 3\n\"sauc\": 3\n\"asked\": 3\n\"rolls\": 3\n\"Thereof\": 3\n\"standers-by\": 3\n\"SERGEANT-AT-ARMS\": 3\n\"suffocate\": 3\n\"intimate\": 3\n\"jack\": 3\n\"Supposing\": 3\n\"Attended\": 3\n\"dissever\": 3\n\"oath-\": 3\n\"resty\": 3\n\"pickle\": 3\n\"hales\": 3\n\"bareheaded\": 3\n\"NICHOLAS\": 3\n\"affiance\": 3\n\"Country\": 3\n\"expound\": 3\n\"rately\": 3\n\"lessen\": 3\n\"runagate\": 3\n\"GUILDFORD\": 3\n\"parallels\": 3\n\"scorch\": 3\n\"harlots\": 3\n\"frequent\": 3\n\"Perseus\": 3\n\"EIGHTH\": 3\n\"armours\": 3\n\"spurr\": 3\n\"signified\": 3\n\"Horrible\": 3\n\"pies\": 3\n\"TAURUS\": 3\n\"Forgot\": 3\n\"Stars\": 3\n\"mountebank\": 3\n\"activity\": 3\n\"malapert\": 3\n\"breech\": 3\n\"juggler\": 3\n\"shrouds\": 3\n\"mastiffs\": 3\n\"gale\": 3\n\"manors\": 3\n\"apples\": 3\n\"sympathise\": 3\n\"gripes\": 3\n\"born-\": 3\n\"Barnet\": 3\n\"unfeignedly\": 3\n\"fount\": 3\n\"paly\": 3\n\"Northampton\": 3\n\"ton\": 3\n\"true-hearted\": 3\n\"Germans\": 3\n\"fearless\": 3\n\"limp\": 3\n\"Montgomery\": 3\n\"gamesome\": 3\n\"ALDERMEN\": 3\n\"lurks\": 3\n\"visits\": 3\n\"tub\": 3\n\"foretold\": 3\n\"unbound\": 3\n\"soothsayer\": 3\n\"Erpingham\": 3\n\"gabble\": 3\n\"untun\": 3\n\"advertis\": 3\n\"froze\": 3\n\"wasting\": 3\n\"Aemilia\": 3\n\"mows\": 3\n\"fierceness\": 3\n\"chatter\": 3\n\"accidentally\": 3\n\"twinn\": 3\n\"arose\": 3\n\"Reflect\": 3\n\"rosy\": 3\n\"malcontent\": 3\n\"Matter\": 3\n\"servitor\": 3\n\"disobey\": 3\n\"tempests\": 3\n\"Sends\": 3\n\"step-dame\": 3\n\"bends\": 3\n\"years-\": 3\n\"unfeigned\": 3\n\"premeditated\": 3\n\"shower\": 3\n\"Virgilia\": 3\n\"Seats\": 3\n\"tenure\": 3\n\"outstrip\": 3\n\"Patricians\": 3\n\"chaos\": 3\n\"lustily\": 3\n\"disproportion\": 3\n\"altitude\": 3\n\"Shouts\": 3\n\"aims\": 3\n\"plies\": 3\n\"Continue\": 3\n\"kernel\": 3\n\"Weeps\": 3\n\"bats\": 3\n\"brinish\": 3\n\"interred\": 3\n\"yearly\": 3\n\"cats\": 3\n\"scare\": 3\n\"amplify\": 3\n\"L\": 3\n\"trembled\": 3\n\"issuing\": 3\n\"covenant\": 3\n\"Speaks\": 3\n\"positive\": 3\n\"profitable\": 3\n\"unnecessary\": 3\n\"screech-owl\": 3\n\"tott\": 3\n\"tainting\": 3\n\"plaints\": 3\n\"indigest\": 3\n\"stoutly\": 3\n\"razed\": 3\n\"curds\": 3\n\"vigilant\": 3\n\"trumpeter\": 3\n\"winning\": 3\n\"agents\": 3\n\"storehouse\": 3\n\"Crispin\": 3\n\"deniest\": 3\n\"angling\": 3\n\"vagabond\": 3\n\"Dying\": 3\n\"misshapen\": 3\n\"dissentious\": 3\n\"surer\": 3\n\"Safely\": 3\n\"Withhold\": 3\n\"swims\": 3\n\"haught\": 3\n\"thrives\": 3\n\"marriages\": 3\n\"Dew\": 3\n\"Short\": 3\n\"closed\": 3\n\"quarry\": 3\n\"pencil\": 3\n\"foretell\": 3\n\"Fer\": 3\n\"inviolable\": 3\n\"maketh\": 3\n\"ferret\": 3\n\"singled\": 3\n\"Stabbing\": 3\n\"Peasant\": 3\n\"Sicinius\": 3\n\"arguing\": 3\n\"rave\": 3\n\"Senseless\": 3\n\"dad\": 3\n\"revell\": 3\n\"wav\": 3\n\"questioned\": 3\n\"obloquy\": 3\n\"Phaethon\": 3\n\"diable\": 3\n\"perdu\": 3\n\"hilt\": 3\n\"Opinion\": 3\n\"demerits\": 3\n\"john\": 3\n\"singularity\": 3\n\"watchman\": 3\n\"resteth\": 3\n\"abreast\": 3\n\"privily\": 3\n\"espous\": 3\n\"porn\": 3\n\"Subdues\": 3\n\"Wakefield\": 3\n\"Sandal\": 3\n\"orld\": 3\n\"prains\": 3\n\"disinherited\": 3\n\"Accurs\": 3\n\"disinherit\": 3\n\"finished\": 3\n\"latch\": 3\n\"disprove\": 3\n\"words-\": 3\n\"usurps\": 3\n\"diff\": 3\n\"certainties\": 3\n\"manacle\": 3\n\"Belzebub\": 3\n\"Whereat\": 3\n\"Watchmen\": 3\n\"stools\": 3\n\"sincerely\": 3\n\"Proclaims\": 3\n\"NOBLEMAN\": 3\n\"Admiral\": 3\n\"Valeria\": 3\n\"mail\": 3\n\"Sin\": 3\n\"Points\": 3\n\"Big\": 3\n\"claps\": 3\n\"deep-mouth\": 3\n\"Died\": 3\n\"bruised\": 3\n\"recovers\": 3\n\"butterfly\": 3\n\"blasphemy\": 3\n\"Anchises\": 3\n\"prowess\": 3\n\"Agreed\": 3\n\"orphan\": 3\n\"paw\": 3\n\"Glad\": 3\n\"mistakes\": 3\n\"Clapp\": 3\n\"carbuncle\": 3\n\"Fields\": 3\n\"brick\": 3\n\"advertised\": 3\n\"Philario\": 3\n\"halters\": 3\n\"peat\": 3\n\"murrain\": 3\n\"spoons\": 3\n\"doublets\": 3\n\"caudle\": 3\n\"forests\": 3\n\"forefathers\": 3\n\"Piercing\": 3\n\"toasted\": 3\n\"Southwark\": 3\n\"gelded\": 3\n\"plain-dealing\": 3\n\"fallow\": 3\n\"workmen\": 3\n\"hemlock\": 3\n\"Stabb\": 3\n\"forgot-\": 3\n\"uncover\": 3\n\"cannot-\": 3\n\"Flower\": 3\n\"crafts\": 3\n\"leash\": 3\n\"cocks\": 3\n\"foot-cloth\": 3\n\"Whitmore\": 3\n\"pinnace\": 3\n\"conducted\": 3\n\"reduce\": 3\n\"judicious\": 3\n\"consign\": 3\n\"lots\": 3\n\"whereso\": 3\n\"overcharged\": 3\n\"Traduc\": 3\n\"critic\": 3\n\"unholy\": 3\n\"Gall\": 3\n\"new-married\": 3\n\"chopt\": 3\n\"tinkers\": 3\n\"Dread\": 3\n\"abysm\": 3\n\"Wrench\": 3\n\"bucklers\": 3\n\"Traitor\": 3\n\"Dat\": 3\n\"graft\": 3\n\"Kate-\": 3\n\"blameful\": 3\n\"heifer\": 3\n\"beautify\": 3\n\"shrug\": 3\n\"fusty\": 3\n\"thoughts-\": 3\n\"contending\": 3\n\"Christian-like\": 3\n\"Noise\": 3\n\"splitting\": 3\n\"loos\": 3\n\"parasite\": 3\n\"seduc\": 3\n\"transparent\": 3\n\"sepulchres\": 3\n\"tresses\": 3\n\"levies\": 3\n\"spring-time\": 3\n\"marvell\": 3\n\"Faster\": 3\n\"mercenary\": 3\n\"freshest\": 3\n\"Presented\": 3\n\"Undone\": 3\n\"EDMUND\": 3\n\"fairness\": 3\n\"skills\": 3\n\"meritorious\": 3\n\"stamped\": 3\n\"GLANSDALE\": 3\n\"dries\": 3\n\"Condition\": 3\n\"grub\": 3\n\"strays\": 3\n\"dangerously\": 3\n\"afire\": 3\n\"hospitable\": 3\n\"augment\": 3\n\"ail\": 3\n\"overweening\": 3\n\"dogged\": 3\n\"rang\": 3\n\"disabled\": 3\n\"Sharp\": 3\n\"limping\": 3\n\"fike\": 3\n\"censured\": 3\n\"AN\": 3\n\"studying\": 3\n\"Misenum\": 3\n\"bribes\": 3\n\"Hangs\": 3\n\"censur\": 3\n\"ruff\": 3\n\"interior\": 3\n\"Respecting\": 3\n\"Meeting\": 3\n\"major\": 3\n\"far-off\": 3\n\"threepence\": 3\n\"colic\": 3\n\"pebbles\": 3\n\"instigation\": 3\n\"entomb\": 3\n\"glorify\": 3\n\"Thump\": 3\n\"parent\": 3\n\"NEIGHBOUR\": 3\n\"Isle\": 3\n\"adjudg\": 3\n\"Instead\": 3\n\"Woodstock\": 3\n\"molehill\": 3\n\"Rheims\": 3\n\"gladness\": 3\n\"wanteth\": 3\n\"craving\": 3\n\"purchasing\": 3\n\"barely\": 3\n\"faultless\": 3\n\"Privy\": 3\n\"Resembling\": 3\n\"expressing\": 3\n\"Spanish\": 3\n\"leaps\": 3\n\"blemishes\": 3\n\"archers\": 3\n\"reechy\": 3\n\"Berwick\": 3\n\"undaunted\": 3\n\"Fastolfe\": 3\n\"Simpcox\": 3\n\"TOWNSMAN\": 3\n\"foemen\": 3\n\"Scales\": 3\n\"hors\": 3\n\"oracles\": 3\n\"agreeing\": 3\n\"forthcoming\": 3\n\"commoners\": 3\n\"Eltham\": 3\n\"pint\": 3\n\"Attending\": 3\n\"silenc\": 3\n\"suggested\": 3\n\"infirm\": 3\n\"expects\": 3\n\"accuser\": 3\n\"overblown\": 3\n\"matrons\": 3\n\"Consul\": 3\n\"kindest\": 3\n\"Dispute\": 3\n\"convented\": 3\n\"callet\": 3\n\"Speed\": 3\n\"whereas\": 3\n\"base-born\": 3\n\"aveng\": 3\n\"grumbling\": 3\n\"Otherwise\": 3\n\"prophets\": 3\n\"resembled\": 3\n\"counterpois\": 3\n\"petitioner\": 3\n\"supplications\": 3\n\"Armourer\": 3\n\"Forum\": 3\n\"Ingratitude\": 3\n\"hammering\": 3\n\"lengthen\": 3\n\"circled\": 3\n\"sunken\": 3\n\"spreading\": 3\n\"inspired\": 3\n\"bookish\": 3\n\"revelling\": 3\n\"vigilance\": 3\n\"WARDER\": 3\n\"Imprimis\": 3\n\"scornfully\": 3\n\"grains\": 3\n\"charters\": 3\n\"Guards\": 3\n\"Woodville\": 3\n\"interpretation\": 3\n\"Tying\": 3\n\"poniards\": 3\n\"BEVIS\": 3\n\"Kentish\": 3\n\"SAINT\": 3\n\"Iris\": 3\n\"controll\": 3\n\"austerity\": 3\n\"casque\": 3\n\"thriftless\": 3\n\"buckles\": 3\n\"Hardly\": 3\n\"MATE\": 3\n\"obeys\": 3\n\"sedition\": 3\n\"bachelors\": 3\n\"SHIPMASTER\": 3\n\"tetter\": 3\n\"Choler\": 3\n\"unwise\": 3\n\"informed\": 3\n\"overpeer\": 3\n\"Hydra\": 3\n\"apron\": 3\n\"brats\": 3\n\"releas\": 3\n\"Agree\": 3\n\"scoffs\": 3\n\"contumelious\": 3\n\"commonly\": 3\n\"magistrate\": 3\n\"multiplied\": 3\n\"adamant\": 3\n\"debase\": 3\n\"tempestuous\": 3\n\"Swell\": 3\n\"fondness\": 3\n\"compromise\": 3\n\"fanning\": 3\n\"pates\": 3\n\"aediles\": 3\n\"cometh\": 3\n\"noting\": 3\n\"Environ\": 3\n\"Machiavel\": 3\n\"Dutch\": 3\n\"unrelenting\": 3\n\"daughter-in-law\": 3\n\"pillar\": 3\n\"Hannibal\": 3\n\"stench\": 3\n\"AEDILES\": 3\n\"leopard\": 3\n\"bloom\": 3\n\"Virtuous\": 3\n\"plighted\": 3\n\"oldest\": 3\n\"enthrall\": 3\n\"interrupted\": 3\n\"Cydnus\": 3\n\"Confounds\": 3\n\"daunted\": 3\n\"erbear\": 3\n\"lop\": 3\n\"viper\": 3\n\"affecting\": 3\n\"masculine\": 3\n\"viperous\": 3\n\"shops\": 3\n\"SCOUT\": 3\n\"debated\": 3\n\"pest\": 3\n\"hurry\": 3\n\"LEGATE\": 3\n\"professors\": 3\n\"tribes\": 3\n\"insensible\": 3\n\"fro\": 3\n\"weakly\": 3\n\"Armagnac\": 3\n\"erect\": 3\n\"obedience-\": 3\n\"bolted\": 3\n\"Unknown\": 3\n\"clust\": 3\n\"Icarus\": 3\n\"woollen\": 3\n\"rescued\": 3\n\"balmy\": 3\n\"adopt\": 3\n\"Action\": 3\n\"rashly\": 3\n\"Tours\": 3\n\"hemm\": 3\n\"babies\": 3\n\"Victorious\": 3\n\"experienc\": 3\n\"surcease\": 3\n\"divining\": 3\n\"blades\": 3\n\"approacheth\": 3\n\"decipher\": 3\n\"discretions\": 3\n\"grudging\": 3\n\"objections\": 3\n\"dimpled\": 3\n\"Spring\": 3\n\"Condemn\": 3\n\"Twelve\": 3\n\"blood-drinking\": 3\n\"Bestride\": 3\n\"criminal\": 3\n\"frivolous\": 3\n\"brainsick\": 3\n\"impostor\": 3\n\"scarr\": 3\n\"droops\": 3\n\"ignominious\": 3\n\"represent\": 3\n\"carping\": 3\n\"umpire\": 3\n\"desiring\": 3\n\"guile\": 3\n\"Mov\": 3\n\"bluntly\": 3\n\"superscription\": 3\n\"Langley\": 3\n\"Knights\": 3\n\"Plucking\": 3\n\"install\": 3\n\"thankless\": 3\n\"Esteem\": 3\n\"removing\": 3\n\"submissive\": 3\n\"prejudice\": 3\n\"extemporal\": 3\n\"Presumptuous\": 3\n\"abated\": 3\n\"endured\": 3\n\"mastership\": 3\n\"Bridge\": 3\n\"perverse\": 3\n\"ARMY\": 3\n\"fen\": 3\n\"useth\": 3\n\"baits\": 3\n\"bishop\": 3\n\"fitteth\": 3\n\"unbruis\": 3\n\"humbler\": 3\n\"hearth\": 3\n\"potentates\": 3\n\"Cats\": 3\n\"sacks\": 3\n\"Stones\": 3\n\"oars\": 3\n\"Dion\": 3\n\"mitigate\": 3\n\"aptness\": 3\n\"girt\": 3\n\"inkhorn\": 3\n\"Opening\": 3\n\"enacted\": 3\n\"irregular\": 3\n\"salt-water\": 2\n\"mulberry\": 2\n\"llous\": 2\n\"Bright\": 2\n\"yarely\": 2\n\"twos\": 2\n\"illusions\": 2\n\"love-sick\": 2\n\"Cotus\": 2\n\"Burns\": 2\n\"pelt\": 2\n\"Adrian\": 2\n\"stand-\": 2\n\"Begun\": 2\n\"market-men\": 2\n\"gens\": 2\n\"Anger\": 2\n\"specify\": 2\n\"uproar\": 2\n\"Bastards\": 2\n\"flutes\": 2\n\"hear-\": 2\n\"twit\": 2\n\"Damsel\": 2\n\"Vow\": 2\n\"Requite\": 2\n\"Courageous\": 2\n\"hoarded\": 2\n\"Talbots\": 2\n\"a-doing\": 2\n\"amort\": 2\n\"gnaws\": 2\n\"Dismay\": 2\n\"corrosive\": 2\n\"diffidence\": 2\n\"reverenc\": 2\n\"persuasions\": 2\n\"marv\": 2\n\"entice\": 2\n\"unhallow\": 2\n\"patronage\": 2\n\"cautelous\": 2\n\"Wine\": 2\n\"batten\": 2\n\"lonely\": 2\n\"Pushes\": 2\n\"Despising\": 2\n\"particularly\": 2\n\"surname\": 2\n\"reclaim\": 2\n\"Lets\": 2\n\"ridden\": 2\n\"resident\": 2\n\"experiment\": 2\n\"spak\": 2\n\"nodding\": 2\n\"unburied\": 2\n\"carcasses\": 2\n\"fens\": 2\n\"studious\": 2\n\"distribute\": 2\n\"lies-\": 2\n\"has-\": 2\n\"weening\": 2\n\"unworthily\": 2\n\"Marrying\": 2\n\"degraded\": 2\n\"derived\": 2\n\"Endeavour\": 2\n\"Depos\": 2\n\"tuns\": 2\n\"expir\": 2\n\"arbitrator\": 2\n\"twine\": 2\n\"sapless\": 2\n\"anvil\": 2\n\"paleness\": 2\n\"flaying\": 2\n\"pursuivants\": 2\n\"Sigh\": 2\n\"blindfold\": 2\n\"Grown\": 2\n\"Confounded\": 2\n\"seventy\": 2\n\"consuming\": 2\n\"temperately\": 2\n\"rougher\": 2\n\"fewest\": 2\n\"certified\": 2\n\"Cupids\": 2\n\"pouring\": 2\n\"institute\": 2\n\"fans\": 2\n\"undid\": 2\n\"burnish\": 2\n\"Calmly\": 2\n\"bandying\": 2\n\"corrected\": 2\n\"daw\": 2\n\"olives\": 2\n\"stoutness\": 2\n\"fables\": 2\n\"heedless\": 2\n\"EARLS\": 2\n\"stags\": 2\n\"schoolboys\": 2\n\"Gascony\": 2\n\"lulls\": 2\n\"youngly\": 2\n\"riddling\": 2\n\"forfeiting\": 2\n\"reguerdon\": 2\n\"ripest\": 2\n\"captivate\": 2\n\"ears-\": 2\n\"neglection\": 2\n\"general-\": 2\n\"er-match\": 2\n\"assailing\": 2\n\"Drops\": 2\n\"Swearing\": 2\n\"shrimp\": 2\n\"stones-\": 2\n\"dishonours\": 2\n\"ill-boding\": 2\n\"steers\": 2\n\"companionship\": 2\n\"scotch\": 2\n\"rescues\": 2\n\"strong-knit\": 2\n\"fabulous\": 2\n\"interchanging\": 2\n\"subscribes\": 2\n\"counsell\": 2\n\"Scythian\": 2\n\"ballad-makers\": 2\n\"precipitation\": 2\n\"Suddenly\": 2\n\"comic\": 2\n\"Coupled\": 2\n\"Boskos\": 2\n\"audible\": 2\n\"Created\": 2\n\"Duty\": 2\n\"Arc\": 2\n\"upstart\": 2\n\"engrav\": 2\n\"endamage\": 2\n\"ravisher\": 2\n\"parties-\": 2\n\"defensive\": 2\n\"Marriage\": 2\n\"Mortal\": 2\n\"Tends\": 2\n\"maker\": 2\n\"unready\": 2\n\"ersways\": 2\n\"enroll\": 2\n\"tradesmen\": 2\n\"Somewhat\": 2\n\"ercome\": 2\n\"information\": 2\n\"damp\": 2\n\"Coward\": 2\n\"condescend\": 2\n\"a-bed\": 2\n\"Curse\": 2\n\"trident\": 2\n\"Keeping\": 2\n\"sorcery\": 2\n\"slave-\": 2\n\"carous\": 2\n\"SENTINEL\": 2\n\"dispensation\": 2\n\"Transported\": 2\n\"my-\": 2\n\"porch\": 2\n\"unlikely\": 2\n\"labyrinth\": 2\n\"Solicit\": 2\n\"hems\": 2\n\"Repeat\": 2\n\"Counting\": 2\n\"obstacle\": 2\n\"collop\": 2\n\"piles\": 2\n\"afield\": 2\n\"Weapons\": 2\n\"Recover\": 2\n\"polluted\": 2\n\"whelps\": 2\n\"victual\": 2\n\"straining\": 2\n\"erborne\": 2\n\"driveth\": 2\n\"Strumpet\": 2\n\"reflex\": 2\n\"gloomy\": 2\n\"quagmire\": 2\n\"wights\": 2\n\"multitudinous\": 2\n\"viceroy\": 2\n\"&C\": 2\n\"Retain\": 2\n\"reasonless\": 2\n\"Insulting\": 2\n\"Us\": 2\n\"manor\": 2\n\"Gate\": 2\n\"Moist\": 2\n\"ensigns\": 2\n\"Gargrave\": 2\n\"ignorance-\": 2\n\"shipwreck\": 2\n\"fellest\": 2\n\"superficial\": 2\n\"enticing\": 2\n\"sufficiently\": 2\n\"Nicanor\": 2\n\"scarecrow\": 2\n\"blended\": 2\n\"bringeth\": 2\n\"produc\": 2\n\"adjacent\": 2\n\"inflaming\": 2\n\"turret\": 2\n\"expenses\": 2\n\"reigned\": 2\n\"smilingly\": 2\n\"espials\": 2\n\"Tired\": 2\n\"Abominable\": 2\n\"mingling\": 2\n\"Rare\": 2\n\"MATTHEW\": 2\n\"GOFFE\": 2\n\"resists\": 2\n\"clusters\": 2\n\"distrain\": 2\n\"Invited\": 2\n\"Regard\": 2\n\"restful\": 2\n\"meiny\": 2\n\"burly\": 2\n\"tug\": 2\n\"prank\": 2\n\"vanquisher\": 2\n\"CHATHAM\": 2\n\"tawny-coats\": 2\n\"ALBANS\": 2\n\"still-\": 2\n\"Hostilius\": 2\n\"privileged\": 2\n\"portance\": 2\n\"Advantage\": 2\n\"bearing-cloth\": 2\n\"HOLLAND\": 2\n\"revoke\": 2\n\"BUTCHER\": 2\n\"plated\": 2\n\"WEAVER\": 2\n\"outworn\": 2\n\"Abel\": 2\n\"ELEANOR\": 2\n\"barking\": 2\n\"su\": 2\n\"these-\": 2\n\"Petitioners\": 2\n\"universe\": 2\n\"Falconers\": 2\n\"Faint-hearted\": 2\n\"falter\": 2\n\"Upbraid\": 2\n\"ruder\": 2\n\"dismission\": 2\n\"Marquess\": 2\n\"speech-\": 2\n\"duchy\": 2\n\"released\": 2\n\"qualm\": 2\n\"official\": 2\n\"steepy\": 2\n\"limitation\": 2\n\"unload\": 2\n\"warders\": 2\n\"Fatal\": 2\n\"mountainous\": 2\n\"Large\": 2\n\"Custom\": 2\n\"smoothing\": 2\n\"circumspect\": 2\n\"vouches\": 2\n\"housekeeping\": 2\n\"Excepting\": 2\n\"pennyworths\": 2\n\"courtezans\": 2\n\"unfill\": 2\n\"shar\": 2\n\"wolvish\": 2\n\"enigma\": 2\n\"billeted\": 2\n\"Glory\": 2\n\"grisly\": 2\n\"grovel\": 2\n\"entered\": 2\n\"halcyon\": 2\n\"abase\": 2\n\"southward\": 2\n\"rehearsal\": 2\n\"wedg\": 2\n\"curd\": 2\n\"Expect\": 2\n\"assuredly\": 2\n\"conferr\": 2\n\"recreants\": 2\n\"Jourdain\": 2\n\"erleap\": 2\n\"couplement\": 2\n\"lurch\": 2\n\"asketh\": 2\n\"waxed\": 2\n\"bristled\": 2\n\"Doubtless\": 2\n\"Amazonian\": 2\n\"chased\": 2\n\"pout\": 2\n\"Horner\": 2\n\"unapt\": 2\n\"Deck\": 2\n\"Ave-Maries\": 2\n\"spawn\": 2\n\"conveyances\": 2\n\"Cardinals\": 2\n\"pertinent\": 2\n\"suppler\": 2\n\"priest-like\": 2\n\"swart\": 2\n\"passable\": 2\n\"contemptible\": 2\n\"quire\": 2\n\"denay\": 2\n\"loneliness\": 2\n\"leasing\": 2\n\"dastards\": 2\n\"PEOPLE\": 2\n\"manifests\": 2\n\"handkerchers\": 2\n\"Frenchwoman\": 2\n\"dandle\": 2\n\"Howsoever\": 2\n\"stubble\": 2\n\"flee\": 2\n\"spiteful\": 2\n\"sheep-\": 2\n\"soaring\": 2\n\"defender\": 2\n\"virginal\": 2\n\"Remaineth\": 2\n\"screech-owls\": 2\n\"palms\": 2\n\"Late\": 2\n\"palsied\": 2\n\"indebted\": 2\n\"munition\": 2\n\"trinkets\": 2\n\"guardant\": 2\n\"drained\": 2\n\"preparing\": 2\n\"assuage\": 2\n\"Invite\": 2\n\"halloing\": 2\n\"Hungerford\": 2\n\"Pernicious\": 2\n\"priesthood\": 2\n\"ridges\": 2\n\"themes\": 2\n\"Clamb\": 2\n\"Cowardly\": 2\n\"townsmen\": 2\n\"spying\": 2\n\"pitched\": 2\n\"rapture\": 2\n\"prattling\": 2\n\"Retiring\": 2\n\"bleared\": 2\n\"Saunder\": 2\n\"beadles\": 2\n\"August\": 2\n\"embassies\": 2\n\"shrill-tongu\": 2\n\"wane\": 2\n\"flower-de-luces\": 2\n\"guileful\": 2\n\"Hatfield\": 2\n\"await\": 2\n\"Philippe\": 2\n\"renewed\": 2\n\"Wink\": 2\n\"snar\": 2\n\"disciplin\": 2\n\"harrow\": 2\n\"oaken\": 2\n\"softer\": 2\n\"condemns\": 2\n\"herdsmen\": 2\n\"once-\": 2\n\"erpow\": 2\n\"fastened\": 2\n\"holdeth\": 2\n\"PRENTICE\": 2\n\"Deucalion\": 2\n\"judgment-day\": 2\n\"mid-day\": 2\n\"dazzled\": 2\n\"mockers\": 2\n\"Brandish\": 2\n\"cedars\": 2\n\"bisson\": 2\n\"St\": 2\n\"Edmunds\": 2\n\"hindmost\": 2\n\"syllables\": 2\n\"Commonly\": 2\n\"Murd\": 2\n\"misplaced\": 2\n\"fools-\": 2\n\"icicle\": 2\n\"collect\": 2\n\"AUVERGNE\": 2\n\"sea-mark\": 2\n\"subornation\": 2\n\"descent-\": 2\n\"vaunts\": 2\n\"protectorship\": 2\n\"right-hand\": 2\n\"scolds\": 2\n\"city-\": 2\n\"strumpeted\": 2\n\"disgraced\": 2\n\"wrested\": 2\n\"denials\": 2\n\"condign\": 2\n\"felon\": 2\n\"hearsay\": 2\n\"baes\": 2\n\"willingness\": 2\n\"all-hail\": 2\n\"Kingdoms\": 2\n\"dungy\": 2\n\"Causeless\": 2\n\"Loaden\": 2\n\"Proffers\": 2\n\"winners\": 2\n\"gnarling\": 2\n\"engirt\": 2\n\"louring\": 2\n\"coign\": 2\n\"attributes\": 2\n\"remorseless\": 2\n\"lowing\": 2\n\"remembers\": 2\n\"chicken\": 2\n\"treading\": 2\n\"expulsion\": 2\n\"Thrice-noble\": 2\n\"patroness\": 2\n\"articulate\": 2\n\"MARCH\": 2\n\"divulged\": 2\n\"uncurable\": 2\n\"wishest\": 2\n\"empoison\": 2\n\"Howbeit\": 2\n\"Bristol\": 2\n\"survivor\": 2\n\"vassalage\": 2\n\"perused\": 2\n\"politicly\": 2\n\"circuit\": 2\n\"managing\": 2\n\"prosperously\": 2\n\"Ashford\": 2\n\"belonging\": 2\n\"hyperbolical\": 2\n\"confining\": 2\n\"soothing\": 2\n\"eye-balls\": 2\n\"distribution\": 2\n\"overta\": 2\n\"boded\": 2\n\"attempted\": 2\n\"been-\": 2\n\"spousal\": 2\n\"induc\": 2\n\"neck-\": 2\n\"Combine\": 2\n\"spleenful\": 2\n\"He-\": 2\n\"beheld-\": 2\n\"Bed\": 2\n\"Rex\": 2\n\"quak\": 2\n\"girdled\": 2\n\"Subscrib\": 2\n\"tugg\": 2\n\"sticking\": 2\n\"noblemen\": 2\n\"serviteur\": 2\n\"partridge\": 2\n\"talons\": 2\n\"controller\": 2\n\"laissez\": 2\n\"roi\": 2\n\"crab-tree\": 2\n\"Majestee\": 2\n\"deathsman\": 2\n\"bragg\": 2\n\"cher\": 2\n\"twist\": 2\n\"flower-de-luce\": 2\n\"Fix\": 2\n\"envenomed\": 2\n\"COMMONS\": 2\n\"unpolish\": 2\n\"grave-\": 2\n\"Mischance\": 2\n\"playfellows\": 2\n\"execrations\": 2\n\"soft-hearted\": 2\n\"quand\": 2\n\"thickens\": 2\n\"moon-\": 2\n\"daintiest\": 2\n\"mans\": 2\n\"lizards\": 2\n\"frightful\": 2\n\"shorn\": 2\n\"deceits\": 2\n\"select\": 2\n\"Able\": 2\n\"printed\": 2\n\"Vaux\": 2\n\"Omitting\": 2\n\"vraiment\": 2\n\"woefull\": 2\n\"folds\": 2\n\"outweighs\": 2\n\"Lesser\": 2\n\"diffus\": 2\n\"peaceably\": 2\n\"Filling\": 2\n\"meditate\": 2\n\"discoloured\": 2\n\"sciences\": 2\n\"calculate\": 2\n\"bloody-minded\": 2\n\"Gualtier\": 2\n\"Bareheaded\": 2\n\"Tread\": 2\n\"Fed\": 2\n\"crestfall\": 2\n\"disadvantage\": 2\n\"Poole\": 2\n\"Losing\": 2\n\"affy\": 2\n\"gobbets\": 2\n\"docks\": 2\n\"hating\": 2\n\"revenging\": 2\n\"teems\": 2\n\"Conceives\": 2\n\"mead\": 2\n\"savagery\": 2\n\"Tully\": 2\n\"deracinate\": 2\n\"mantled\": 2\n\"clothier\": 2\n\"quails\": 2\n\"Trail\": 2\n\"successes\": 2\n\"bricklayer\": 2\n\"placeth\": 2\n\"Prosperity\": 2\n\"felony\": 2\n\"Cheapside\": 2\n\"copies\": 2\n\"bewail\": 2\n\"cottages\": 2\n\"fertility\": 2\n\"STAFFORDS\": 2\n\"executor\": 2\n\"opposers\": 2\n\"Killingworth\": 2\n\"physical\": 2\n\"withstand\": 2\n\"Stone\": 2\n\"pissing\": 2\n\"Convenient\": 2\n\"murdering\": 2\n\"jurisdiction\": 2\n\"joyous\": 2\n\"grammar\": 2\n\"ruminated\": 2\n\"terra\": 2\n\"Knowledge\": 2\n\"behoof\": 2\n\"cudgels\": 2\n\"palsy\": 2\n\"hangmen\": 2\n\"obstinacy\": 2\n\"swear-\": 2\n\"movers\": 2\n\"Bite\": 2\n\"rabblement\": 2\n\"surmount\": 2\n\"knave-\": 2\n\"BRITISH\": 2\n\"gallowglasses\": 2\n\"assaulted\": 2\n\"expiate\": 2\n\"entering\": 2\n\"singleness\": 2\n\"compared\": 2\n\"heaved\": 2\n\"Wither\": 2\n\"burying\": 2\n\"turkey-cock\": 2\n\"prings\": 2\n\"Captains\": 2\n\"palmer\": 2\n\"worths\": 2\n\"Slain\": 2\n\"Volsce\": 2\n\"chanc\": 2\n\"shields\": 2\n\"stopped\": 2\n\"berard\": 2\n\"Invites\": 2\n\"may-\": 2\n\"larum\": 2\n\"protects\": 2\n\"stigmatic\": 2\n\"scowl\": 2\n\"Ithaca\": 2\n\"delve\": 2\n\"erbears\": 2\n\"governs\": 2\n\"spun\": 2\n\"Medea\": 2\n\"ostent\": 2\n\"Priests\": 2\n\"Sicilius\": 2\n\"forgets\": 2\n\"vainness\": 2\n\"sewing\": 2\n\"Tenantius\": 2\n\"contemning\": 2\n\"lovelier\": 2\n\"Deum\": 2\n\"possesseth\": 2\n\"Te\": 2\n\"ropes\": 2\n\"suckle\": 2\n\"Bequeathed\": 2\n\"bed-chamber\": 2\n\"shunning\": 2\n\"cross-bows\": 2\n\"TOWER\": 2\n\"Admir\": 2\n\"KEEPERS\": 2\n\"slackly\": 2\n\"sprang\": 2\n\"Howsoe\": 2\n\"stanch\": 2\n\"strengthened\": 2\n\"pody\": 2\n\"effectually\": 2\n\"Harm\": 2\n\"Dares\": 2\n\"Praised\": 2\n\"shambles\": 2\n\"Fret\": 2\n\"winding-sheet\": 2\n\"circumvention\": 2\n\"skirr\": 2\n\"Cleitus\": 2\n\"ales\": 2\n\"YORKISTS\": 2\n\"wraths\": 2\n\"Enforc\": 2\n\"Chancellor\": 2\n\"maps\": 2\n\"(the\": 2\n\"lukewarm\": 2\n\"grip\": 2\n\"puttock\": 2\n\"Uttering\": 2\n\"thrice-valiant\": 2\n\"Disorder\": 2\n\"music-\": 2\n\"pent-up\": 2\n\"oceans\": 2\n\"coffins\": 2\n\"perdurable\": 2\n\"cleaving\": 2\n\"homes\": 2\n\"priority\": 2\n\"Reproach\": 2\n\"thrice-worthy\": 2\n\"rud\": 2\n\"envying\": 2\n\"errun\": 2\n\"considerate\": 2\n\"struggle\": 2\n\"plus\": 2\n\"crook-back\": 2\n\"chevalier\": 2\n\"parch\": 2\n\"Stamp\": 2\n\"ecus\": 2\n\"Incapable\": 2\n\"type\": 2\n\"Sicils\": 2\n\"adage\": 2\n\"pardonner\": 2\n\"flexible\": 2\n\"cannibals\": 2\n\"supplie\": 2\n\"weeping-ripe\": 2\n\"seemly\": 2\n\"Que\": 2\n\"Junius\": 2\n\"firk\": 2\n\"opes\": 2\n\"resembles\": 2\n\"shreds\": 2\n\"fer\": 2\n\"overshine\": 2\n\"daughters-\": 2\n\"Distinguish\": 2\n\"rim\": 2\n\"Environed\": 2\n\"saddest\": 2\n\"moys\": 2\n\"moisture\": 2\n\"kindling\": 2\n\"attempting\": 2\n\"Stab\": 2\n\"Below\": 2\n\"Muster\": 2\n\"moi\": 2\n\"coldness\": 2\n\"shes\": 2\n\"night-owl\": 2\n\"bonne\": 2\n\"fins\": 2\n\"gentilhomme\": 2\n\"etes\": 2\n\"borough\": 2\n\"endowments\": 2\n\"argued\": 2\n\"subdues\": 2\n\"Successful\": 2\n\"fly-\": 2\n\"hoarding\": 2\n\"foxes\": 2\n\"Unsheathe\": 2\n\"long-tongu\": 2\n\"rubbing\": 2\n\"big-swol\": 2\n\"grazing\": 2\n\"good-\": 2\n\"unparagon\": 2\n\"Iron\": 2\n\"Sham\": 2\n\"pomegranate\": 2\n\"slimy\": 2\n\"englutted\": 2\n\"competency\": 2\n\"hewn\": 2\n\"Perish\": 2\n\"unprizable\": 2\n\"casual\": 2\n\"withdrawn\": 2\n\"body-\": 2\n\"Olympian\": 2\n\"games\": 2\n\"stabbed\": 2\n\"Brings\": 2\n\"covet\": 2\n\"yearns\": 2\n\"answer-\": 2\n\"Thereby\": 2\n\"times-\": 2\n\"participate\": 2\n\"Princely\": 2\n\"bereaved\": 2\n\"ercharg\": 2\n\"bye\": 2\n\"Erroneous\": 2\n\"ruthful\": 2\n\"outwear\": 2\n\"Ram\": 2\n\"commixture\": 2\n\"luckless\": 2\n\"foolhardy\": 2\n\"cureless\": 2\n\"edicts\": 2\n\"Revoke\": 2\n\"carrions\": 2\n\"Worthily\": 2\n\"ershades\": 2\n\"embattl\": 2\n\"unstanched\": 2\n\"kiss-\": 2\n\"wagers\": 2\n\"Culling\": 2\n\"Varlet\": 2\n\"prayer-book\": 2\n\"compassing\": 2\n\"inkling\": 2\n\"Creating\": 2\n\"wots\": 2\n\"Obeying\": 2\n\"dawn\": 2\n\"Gets\": 2\n\"grants\": 2\n\"subtly\": 2\n\"flexure\": 2\n\"surplus\": 2\n\"worshippers\": 2\n\"famously\": 2\n\"commonalty\": 2\n\"afflicts\": 2\n\"Flattering\": 2\n\"impossibilities\": 2\n\"shrub\": 2\n\"relieved\": 2\n\"Ceremony\": 2\n\"blessedly\": 2\n\"tart\": 2\n\"Torment\": 2\n\"ye-\": 2\n\"remembrancer\": 2\n\"Deceive\": 2\n\"churls\": 2\n\"beguiling\": 2\n\"Divert\": 2\n\"possessor\": 2\n\"hand-fast\": 2\n\"ariseth\": 2\n\"cowslips\": 2\n\"Gilding\": 2\n\"Springs\": 2\n\"JUNIUS\": 2\n\"primroses\": 2\n\"obeyed\": 2\n\"VELUTUS\": 2\n\"endings\": 2\n\"Thereon\": 2\n\"ever-fixed\": 2\n\"transporting\": 2\n\"proveth\": 2\n\"imposed\": 2\n\"Boldness\": 2\n\"masquers\": 2\n\"willow-garland\": 2\n\"uncrown\": 2\n\"chopp\": 2\n\"pensive\": 2\n\"ransomed\": 2\n\"home-bred\": 2\n\"gossiping\": 2\n\"sweet-fac\": 2\n\"dislikes\": 2\n\"shipboard\": 2\n\"rejoices\": 2\n\"coverture\": 2\n\"discoursed\": 2\n\"Offence\": 2\n\"precedence\": 2\n\"audacity\": 2\n\"vaulted\": 2\n\"sobriety\": 2\n\"solicits\": 2\n\"Cornish\": 2\n\"glimmer\": 2\n\"Roy\": 2\n\"faith-\": 2\n\"idiots\": 2\n\"disport\": 2\n\"Discuss\": 2\n\"conduits\": 2\n\"Flanders\": 2\n\"Huntsman\": 2\n\"drizzled\": 2\n\"sov\": 2\n\"incaged\": 2\n\"Conceive\": 2\n\"thwarting\": 2\n\"Creator\": 2\n\"Qui\": 2\n\"Suggest\": 2\n\"ill-dispos\": 2\n\"escaped\": 2\n\"pining\": 2\n\"garbage\": 2\n\"Presenteth\": 2\n\"tediously\": 2\n\"Gallian\": 2\n\"Lieutenant-General\": 2\n\"over-lusty\": 2\n\"mean-\": 2\n\"rivets\": 2\n\"fawns\": 2\n\"Assured\": 2\n\"sithence\": 2\n\"Circe\": 2\n\"Southam\": 2\n\"gnawing\": 2\n\"Lamentable\": 2\n\"Sail\": 2\n\"trowest\": 2\n\"sacrific\": 2\n\"outfacing\": 2\n\"Fills\": 2\n\"bug\": 2\n\"shrubs\": 2\n\"parks\": 2\n\"falsehood-\": 2\n\"wreaths\": 2\n\"Foolish\": 2\n\"overboard\": 2\n\"Neglected\": 2\n\"shelves\": 2\n\"rottenness\": 2\n\"cancell\": 2\n\"hooded\": 2\n\"threadbare\": 2\n\"Recoil\": 2\n\"Reveng\": 2\n\"lean-fac\": 2\n\"abuse-\": 2\n\"executing\": 2\n\"to-night-\": 2\n\"Promising\": 2\n\"au\": 2\n\"warily\": 2\n\"thither-\": 2\n\"kern\": 2\n\"greybeards\": 2\n\"Isbels\": 2\n\"palfrey\": 2\n\"swept\": 2\n\"enforces\": 2\n\"scalding\": 2\n\"palfreys\": 2\n\"disturbed\": 2\n\"nutmeg\": 2\n\"hoof\": 2\n\"unhair\": 2\n\"rarities\": 2\n\"hoisted\": 2\n\"vaulting\": 2\n\"puddled\": 2\n\"blaz\": 2\n\"feu\": 2\n\"cheval\": 2\n\"Beaten\": 2\n\"ANTHONY\": 2\n\"impeachment\": 2\n\"athversary\": 2\n\"SECRETARIES\": 2\n\"shifting\": 2\n\"maturity\": 2\n\"enchants\": 2\n\"ditches\": 2\n\"THREE\": 2\n\"syrups\": 2\n\"marvellously\": 2\n\"bottles\": 2\n\"highmost\": 2\n\"figo\": 2\n\"windpipe\": 2\n\"Kinsman\": 2\n\"accumulate\": 2\n\"pax\": 2\n\"curtail\": 2\n\"divorced\": 2\n\"digestions\": 2\n\"upbraidings\": 2\n\"bellyful\": 2\n\"wakened\": 2\n\"Dumb\": 2\n\"glanced\": 2\n\"Fold\": 2\n\"Richly\": 2\n\"assemblies\": 2\n\"tempters\": 2\n\"Beheld\": 2\n\"Wrinkles\": 2\n\"Rush\": 2\n\"Repairs\": 2\n\"Equal\": 2\n\"Distinctly\": 2\n\"Bouciqualt\": 2\n\"Lestrake\": 2\n\"freed\": 2\n\"successors\": 2\n\"Foix\": 2\n\"assistants\": 2\n\"him-let\": 2\n\"Fauconbridge\": 2\n\"Roussi\": 2\n\"checked\": 2\n\"Ipswich\": 2\n\"Beaumont\": 2\n\"Vaudemont\": 2\n\"Rambures\": 2\n\"Bows\": 2\n\"suggests\": 2\n\"menac\": 2\n\"Aberga\": 2\n\"ny\": 2\n\"Rogue\": 2\n\"Delabreth\": 2\n\"Peck\": 2\n\"edged\": 2\n\"Chartreux\": 2\n\"Hopkins\": 2\n\"confessions\": 2\n\"unconsidered\": 2\n\"canopied\": 2\n\"adornment\": 2\n\"reproaches\": 2\n\"ring-\": 2\n\"putter-on\": 2\n\"madams\": 2\n\"taxations\": 2\n\"spinsters\": 2\n\"villian\": 2\n\"Daring\": 2\n\"Pertains\": 2\n\"Sweat\": 2\n\"Melt\": 2\n\"interpreters\": 2\n\"contribution\": 2\n\"tot\": 2\n\"nois\": 2\n\"Dissembling\": 2\n\"unthrifts\": 2\n\"stretches\": 2\n\"Henton\": 2\n\"Lawrence\": 2\n\"emptying\": 2\n\"vineyards\": 2\n\"Gordian\": 2\n\"Certes\": 2\n\"revil\": 2\n\"Revel\": 2\n\"remnants\": 2\n\"privilegio\": 2\n\"speeding\": 2\n\"fiddle\": 2\n\"converting\": 2\n\"fois\": 2\n\"wherewithal\": 2\n\"Guildford\": 2\n\"Salutes\": 2\n\"dedicates\": 2\n\"monde\": 2\n\"devant\": 2\n\"Establish\": 2\n\"welcom\": 2\n\"Applying\": 2\n\"gros\": 2\n\"alleged\": 2\n\"cistern\": 2\n\"Confessor\": 2\n\"Swift\": 2\n\"reciterai\": 2\n\"ante-chamber\": 2\n\"pas\": 2\n\"aussi\": 2\n\"courtesy-\": 2\n\"numberless\": 2\n\"apartments\": 2\n\"Flying\": 2\n\"Seventh\": 2\n\"mornings\": 2\n\"menton\": 2\n\"bitterest\": 2\n\"flinch\": 2\n\"col\": 2\n\"bras\": 2\n\"calves\": 2\n\"Ecoutez\": 2\n\"Malice\": 2\n\"talker\": 2\n\"ongles\": 2\n\"Prefer\": 2\n\"deux\": 2\n\"Pace\": 2\n\"soliciting\": 2\n\"Blackfriars\": 2\n\"enthroned\": 2\n\"severing\": 2\n\"forespent\": 2\n\"giveth\": 2\n\"sob\": 2\n\"cheveril\": 2\n\"ils\": 2\n\"qu\": 2\n\"wands\": 2\n\"SCRIBES\": 2\n\"wiles\": 2\n\"USHER\": 2\n\"stealer\": 2\n\"consistory\": 2\n\"SCRIBE\": 2\n\"Ma\": 2\n\"souls-\": 2\n\"beggary-\": 2\n\"Judgment\": 2\n\"alleys\": 2\n\"Consistory\": 2\n\"rebuked\": 2\n\"presumptuous\": 2\n\"saint-like\": 2\n\"Carried\": 2\n\"humblest\": 2\n\"befriends\": 2\n\"advertise\": 2\n\"devil-\": 2\n\"Discredit\": 2\n\"Lincoln\": 2\n\"austerely\": 2\n\"cardinals\": 2\n\"dilatory\": 2\n\"well-beloved\": 2\n\"Gorgon\": 2\n\"warmer\": 2\n\"absolv\": 2\n\"Smil\": 2\n\"far-\": 2\n\"pleasure-\": 2\n\"honest-\": 2\n\"waftage\": 2\n\"habits-\": 2\n\"goodlier\": 2\n\"rewarded\": 2\n\"fraughtage\": 2\n\"eaves\": 2\n\"Strangely\": 2\n\"lawfully\": 2\n\"tangled\": 2\n\"harts\": 2\n\"Digest\": 2\n\"allure\": 2\n\"unhandled\": 2\n\"carat\": 2\n\"Shortly\": 2\n\"Bullens\": 2\n\"peu\": 2\n\"unwittingly\": 2\n\"stuffs\": 2\n\"havings\": 2\n\"locking\": 2\n\"masterless\": 2\n\"contrives\": 2\n\"addrest\": 2\n\"exhalation\": 2\n\"slaughtermen\": 2\n\"Defile\": 2\n\"cites\": 2\n\"mowing\": 2\n\"Tied\": 2\n\"curtal\": 2\n\"jury\": 2\n\"resolves\": 2\n\"packets\": 2\n\"Belgia\": 2\n\"assent\": 2\n\"carbuncles\": 2\n\"Press\": 2\n\"Chaste\": 2\n\"Vain\": 2\n\"Neglect\": 2\n\"ransoms\": 2\n\"Maker\": 2\n\"Corruption\": 2\n\"Sir-\": 2\n\"minds-\": 2\n\"cliffs\": 2\n\"Render\": 2\n\"Dowager\": 2\n\"JUDGES\": 2\n\"reverted\": 2\n\"Collars\": 2\n\"Esses\": 2\n\"adorned\": 2\n\"examin\": 2\n\"communication\": 2\n\"colted\": 2\n\"pristine\": 2\n\"pac\": 2\n\"verify\": 2\n\"musics\": 2\n\"Reach\": 2\n\"roads\": 2\n\"hour-\": 2\n\"covent\": 2\n\"antics\": 2\n\"Pursu\": 2\n\"Nice\": 2\n\"mutability\": 2\n\"Driving\": 2\n\"Cause\": 2\n\"bays\": 2\n\"cullions\": 2\n\"Famous\": 2\n\"primero\": 2\n\"Yearly\": 2\n\"Jewel\": 2\n\"preferments\": 2\n\"Incens\": 2\n\"Straining\": 2\n\"Noah\": 2\n\"Tow\": 2\n\"holidame\": 2\n\"Fail\": 2\n\"breeding-\": 2\n\"Acquainted\": 2\n\"grime\": 2\n\"Dishonour\": 2\n\"fet\": 2\n\"sight-\": 2\n\"em-\": 2\n\"d-with\": 2\n\"Divers\": 2\n\"heresies\": 2\n\"uproars\": 2\n\"jutty\": 2\n\"detests\": 2\n\"nourishment\": 2\n\"sectary\": 2\n\"siren\": 2\n\"title-\": 2\n\"footboy\": 2\n\"resume\": 2\n\"scaling-ladders\": 2\n\"Colbrand\": 2\n\"cuckold-maker\": 2\n\"chine\": 2\n\"tool\": 2\n\"managed\": 2\n\"Effect\": 2\n\"porringer\": 2\n\"combustion\": 2\n\"disloyalty\": 2\n\"Muffle\": 2\n\"linstock\": 2\n\"Noblemen\": 2\n\"godmother\": 2\n\"gunner\": 2\n\"forenoon\": 2\n\"star-like\": 2\n\"ungalled\": 2\n\"grandsires\": 2\n\"erflow\": 2\n\"reserved\": 2\n\"bottoms\": 2\n\"rig\": 2\n\"threaden\": 2\n\"Luce\": 2\n\"malt-horse\": 2\n\"Cicely\": 2\n\"POMFRET\": 2\n\"top-mast\": 2\n\"giglot\": 2\n\"Louvre\": 2\n\"composed\": 2\n\"repeated\": 2\n\"matching\": 2\n\"Mulmutius\": 2\n\"er-count\": 2\n\"preserver\": 2\n\"known-\": 2\n\"Behoves\": 2\n\"Pannonians\": 2\n\"ercast\": 2\n\"mist\": 2\n\"conspired\": 2\n\"Bequeath\": 2\n\"Chiefly\": 2\n\"dines\": 2\n\"shrive\": 2\n\"Pick\": 2\n\"accoutrement\": 2\n\"pertain\": 2\n\"heirs-\": 2\n\"divest\": 2\n\"auger\": 2\n\"untoward\": 2\n\"slug\": 2\n\"unmatched\": 2\n\"aweless\": 2\n\"Disloyal\": 2\n\"undergoes\": 2\n\"Palestine\": 2\n\"hedg\": 2\n\"goddess-like\": 2\n\"sun-\": 2\n\"sire-\": 2\n\"Rash\": 2\n\"inconsiderate\": 2\n\"float\": 2\n\"wife-like\": 2\n\"Whitsun\": 2\n\"unexpected\": 2\n\"present-\": 2\n\"fedary\": 2\n\"provident\": 2\n\"pruning\": 2\n\"Cambria\": 2\n\"congregated\": 2\n\"Berri\": 2\n\"Pisanio-\": 2\n\"plagued\": 2\n\"unadvised\": 2\n\"bores\": 2\n\"housewifery\": 2\n\"Religiously\": 2\n\"moveables\": 2\n\"Babylon\": 2\n\"Whore\": 2\n\"those-\": 2\n\"triumphantly\": 2\n\"Hither\": 2\n\"purpled\": 2\n\"carnation\": 2\n\"overlooks\": 2\n\"incarnate\": 2\n\"mousing\": 2\n\"unmingled\": 2\n\"industrious\": 2\n\"conjointly\": 2\n\"sharpest\": 2\n\"estranged\": 2\n\"fumble\": 2\n\"smoothed\": 2\n\"Lions\": 2\n\"Cool\": 2\n\"unurg\": 2\n\"wafts\": 2\n\"franklin\": 2\n\"full-fraught\": 2\n\"ly\": 2\n\"Garnish\": 2\n\"rustling\": 2\n\"dutiful\": 2\n\"Rid\": 2\n\"frighting\": 2\n\"peering\": 2\n\"periwig\": 2\n\"faculty\": 2\n\"Patch\": 2\n\"moles\": 2\n\"eye-offending\": 2\n\"lilies\": 2\n\"supporter\": 2\n\"battering\": 2\n\"solemnize\": 2\n\"Instruct\": 2\n\"alchemist\": 2\n\"use-\": 2\n\"Hampton\": 2\n\"anatomiz\": 2\n\"Pandulph\": 2\n\"amis\": 2\n\"Innocent\": 2\n\"Measures\": 2\n\"pinching\": 2\n\"Sooner\": 2\n\"Purchase\": 2\n\"excommunicate\": 2\n\"computation\": 2\n\"otherwhere\": 2\n\"formless\": 2\n\"curse-\": 2\n\"disjoin\": 2\n\"indirection\": 2\n\"Crowned\": 2\n\"careers\": 2\n\"fracted\": 2\n\"gauntlets\": 2\n\"defeatures\": 2\n\"dismember\": 2\n\"vestments\": 2\n\"Unkindness\": 2\n\"Bell\": 2\n\"becks\": 2\n\"Sheathing\": 2\n\"erbearing\": 2\n\"usuries\": 2\n\"odoriferous\": 2\n\"football\": 2\n\"healing\": 2\n\"unhack\": 2\n\"buss\": 2\n\"Misery\": 2\n\"Sheathes\": 2\n\"Remembers\": 2\n\"pyramids\": 2\n\"betting\": 2\n\"accounts\": 2\n\"misplac\": 2\n\"evilly\": 2\n\"Shook\": 2\n\"lazar\": 2\n\"unacquainted\": 2\n\"accords\": 2\n\"spital\": 2\n\"EXECUTIONER\": 2\n\"intellectual\": 2\n\"Couple\": 2\n\"males\": 2\n\"three-foot\": 2\n\"repentant\": 2\n\"exhale\": 2\n\"garnish\": 2\n\"Arviragus\": 2\n\"Barbason\": 2\n\"disfigured\": 2\n\"Startles\": 2\n\"overbear\": 2\n\"Bend\": 2\n\"situate\": 2\n\"conceiving\": 2\n\"shog\": 2\n\"targes\": 2\n\"Bigot\": 2\n\"beldams\": 2\n\"slippers\": 2\n\"bridled\": 2\n\"urgest\": 2\n\"Iceland\": 2\n\"combin\": 2\n\"braved\": 2\n\"well-a-day\": 2\n\"blazing\": 2\n\"lodgers\": 2\n\"wall-ey\": 2\n\"Luciana\": 2\n\"traded\": 2\n\"mountebanks\": 2\n\"interpreted\": 2\n\"testimonies\": 2\n\"stifle\": 2\n\"cheaters\": 2\n\"Reports\": 2\n\"inflam\": 2\n\"Goodly\": 2\n\"coronets\": 2\n\"Threaten\": 2\n\"self-slaughter\": 2\n\"erraught\": 2\n\"armourers\": 2\n\"fostered\": 2\n\"high-born\": 2\n\"secondary\": 2\n\"stomachers\": 2\n\"underprop\": 2\n\"dazzle\": 2\n\"plodded\": 2\n\"wilder\": 2\n\"boyish\": 2\n\"buckets\": 2\n\"wells\": 2\n\"crouch\": 2\n\"gained\": 2\n\"crupper\": 2\n\"saddler\": 2\n\"vaults\": 2\n\"Englishman-\": 2\n\"teachers\": 2\n\"fett\": 2\n\"reverberate\": 2\n\"need-\": 2\n\"sparingly\": 2\n\"Goodwin\": 2\n\"Sands\": 2\n\"untread\": 2\n\"whereunto\": 2\n\"newness\": 2\n\"almanac\": 2\n\"Plantagenets\": 2\n\"Unkind\": 2\n\"compose\": 2\n\"tide-\": 2\n\"urn\": 2\n\"porters\": 2\n\"dressings\": 2\n\"cygnet\": 2\n\"kneading\": 2\n\"organ-pipe\": 2\n\"defends\": 2\n\"traps\": 2\n\"inclusive\": 2\n\"wend\": 2\n\"JULIUS\": 2\n\"courtezan\": 2\n\"Triumvir\": 2\n\"Serves\": 2\n\"gleaned\": 2\n\"coursing\": 2\n\"disparagement\": 2\n\"mishap\": 2\n\"MARK\": 2\n\"Hapless\": 2\n\"invade\": 2\n\"waggish\": 2\n\"Forage\": 2\n\"Hopeless\": 2\n\"coasting\": 2\n\"cookery\": 2\n\"Exposing\": 2\n\"inquisitive\": 2\n\"dilate\": 2\n\"mishaps\": 2\n\"accusing\": 2\n\"laboursome\": 2\n\"unwind\": 2\n\"teacher\": 2\n\"egregious\": 2\n\"Usurp\": 2\n\"floating\": 2\n\"Fixing\": 2\n\"Beginning\": 2\n\"obscured\": 2\n\"shave\": 2\n\"Happiness\": 2\n\"Unwilling\": 2\n\"Aboard\": 2\n\"voyages\": 2\n\"Marullus\": 2\n\"laboring\": 2\n\"impos\": 2\n\"cobbler\": 2\n\"awl\": 2\n\"Weeds\": 2\n\"Also\": 2\n\"truth-\": 2\n\"galley\": 2\n\"Lupercal\": 2\n\"Lorraine\": 2\n\"repented\": 2\n\"twenty-six\": 2\n\"Saxons\": 2\n\"unbridled\": 2\n\"Elbe\": 2\n\"intestine\": 2\n\"grieved-\": 2\n\"chill\": 2\n\"mirrors\": 2\n\"laugher\": 2\n\"placing\": 2\n\"gloze\": 2\n\"guilders\": 2\n\"(Though\": 2\n\"Sweets\": 2\n\"Sprung\": 2\n\"observer\": 2\n\"shouted\": 2\n\"hooted\": 2\n\"choked\": 2\n\"swounded\": 2\n\"confirmations\": 2\n\"plucked\": 2\n\"forgave\": 2\n\"smiled\": 2\n\"rip\": 2\n\"leases\": 2\n\"employments\": 2\n\"rived\": 2\n\"knotty\": 2\n\"threatening\": 2\n\"Transformed\": 2\n\"Howling\": 2\n\"severals\": 2\n\"pursuest\": 2\n\"Labour\": 2\n\"unbraced\": 2\n\"infused\": 2\n\"retentive\": 2\n\"rubbish\": 2\n\"Porch\": 2\n\"hugely\": 2\n\"cherishing\": 2\n\"onions\": 2\n\"Urg\": 2\n\"scorning\": 2\n\"Fashion\": 2\n\"burneth\": 2\n\"mitigation\": 2\n\"cavern\": 2\n\"interpose\": 2\n\"fastest\": 2\n\"particle\": 2\n\"Darkness\": 2\n\"distillation\": 2\n\"ersway\": 2\n\"unicorns\": 2\n\"eighth\": 2\n\"extern\": 2\n\"mountain-top\": 2\n\"stared\": 2\n\"impatiently\": 2\n\"Hoping\": 2\n\"humors\": 2\n\"appertain\": 2\n\"charactery\": 2\n\"sequestration\": 2\n\"discard\": 2\n\"banquets\": 2\n\"sufficeth\": 2\n\"Horses\": 2\n\"spouts\": 2\n\"bathed\": 2\n\"addiction\": 2\n\"hardiness\": 2\n\"Security\": 2\n\"COMEDY\": 2\n\"acquir\": 2\n\"Familiar\": 2\n\"jowl\": 2\n\"Lena\": 2\n\"simp\": 2\n\"melteth\": 2\n\"bases\": 2\n\"Liberty\": 2\n\"savoury\": 2\n\"prognostication\": 2\n\"pompous\": 2\n\"lazars\": 2\n\"boldest\": 2\n\"brides\": 2\n\"Sign\": 2\n\"esquires\": 2\n\"(Which\": 2\n\"ruby\": 2\n\"Domestic\": 2\n\"cumber\": 2\n\"ranging\": 2\n\"Passion\": 2\n\"new-fall\": 2\n\"rendered\": 2\n\"clamors\": 2\n\"countrymen-\": 2\n\"rest-\": 2\n\"Ambition\": 2\n\"valu\": 2\n\"ershot\": 2\n\"murtherers\": 2\n\"Mongst\": 2\n\"Pitiful\": 2\n\"diminish\": 2\n\"presentation\": 2\n\"drachmas\": 2\n\"orchards\": 2\n\"differing\": 2\n\"errands\": 2\n\"scambling\": 2\n\"Gently\": 2\n\"Discourse\": 2\n\"howsome\": 2\n\"disclosed\": 2\n\"surest\": 2\n\"hour-glass\": 2\n\"Circumstantial\": 2\n\"Powers\": 2\n\"Quarrelsome\": 2\n\"itching\": 2\n\"stares\": 2\n\"thunderbolts\": 2\n\"Dash\": 2\n\"Countercheck\": 2\n\"Dearer\": 2\n\"lovedst\": 2\n\"Sheathe\": 2\n\"Remaining\": 2\n\"ill-temper\": 2\n\"Reproof\": 2\n\"world-without-end\": 2\n\"strong-\": 2\n\"absent)\": 2\n\"Churlish\": 2\n\"fuller\": 2\n\"increaseth\": 2\n\"shallows\": 2\n\"mapp\": 2\n\"erwatch\": 2\n\"vain-glory\": 2\n\"Quip\": 2\n\"Retort\": 2\n\"criedst\": 2\n\"avenged\": 2\n\"Defiance\": 2\n\"billow\": 2\n\"donn\": 2\n\"puritan\": 2\n\"conversant\": 2\n\"scaffold\": 2\n\"suborned\": 2\n\"avails\": 2\n\"Mrs\": 2\n\"reconciles\": 2\n\"rudiments\": 2\n\"marigold\": 2\n\"journal\": 2\n\"yarn\": 2\n\"untuneable\": 2\n\"carol\": 2\n\"Cowards\": 2\n\"real\": 2\n\"angel-like\": 2\n\"rye\": 2\n\"Nobly\": 2\n\"yokes\": 2\n\"dulness\": 2\n\"perishing\": 2\n\"Beguiles\": 2\n\"exorcist\": 2\n\"misprizing\": 2\n\"spares\": 2\n\"saucily\": 2\n\"adoration\": 2\n\"darker\": 2\n\"dowers\": 2\n\"eased\": 2\n\"shadowy\": 2\n\"quietus\": 2\n\"runagates\": 2\n\"prorogue\": 2\n\"ruined\": 2\n\"monthly\": 2\n\"mountaineer\": 2\n\"dreading\": 2\n\"thrasonical\": 2\n\"goaded\": 2\n\"vow-\": 2\n\"Wounded\": 2\n\"unlearn\": 2\n\"clotpoll\": 2\n\"hostage\": 2\n\"clouted\": 2\n\"Prescribe\": 2\n\"soundest\": 2\n\"gad\": 2\n\"unfathered\": 2\n\"(reads)\": 2\n\"Abhorred\": 2\n\"nourished\": 2\n\"viewest\": 2\n\"azur\": 2\n\"eglantine\": 2\n\"protract\": 2\n\"LIFE\": 2\n\"reverence-\": 2\n\"planetary\": 2\n\"Bate\": 2\n\"chimney-sweepers\": 2\n\"ipse\": 2\n\"fortuna\": 2\n\"breaches\": 2\n\"consummation\": 2\n\"fumes\": 2\n\"Jovial\": 2\n\"face-\": 2\n\"hoc\": 2\n\"affection-\": 2\n\"lucre\": 2\n\"strewing\": 2\n\"Counterfeit\": 2\n\"Dy\": 2\n\"widowed\": 2\n\"censer\": 2\n\"defunct\": 2\n\"destroys\": 2\n\"showest\": 2\n\"bor\": 2\n\"occident\": 2\n\"darkling\": 2\n\"notion\": 2\n\"debosh\": 2\n\"besort\": 2\n\"dragging\": 2\n\"repents\": 2\n\"sea-monster\": 2\n\"wrench\": 2\n\"vultures\": 2\n\"teem\": 2\n\"channels\": 2\n\"Epicurean\": 2\n\"Striving\": 2\n\"kibes\": 2\n\"conversion\": 2\n\"Food\": 2\n\"Scarlet\": 2\n\"Assyrian\": 2\n\"Slandering\": 2\n\"pight\": 2\n\"foutra\": 2\n\"Loyal\": 2\n\"childlike\": 2\n\"pickaxes\": 2\n\"eater\": 2\n\"lily-liver\": 2\n\"bitch\": 2\n\"century\": 2\n\"affront\": 2\n\"glides\": 2\n\"atwain\": 2\n\"cackling\": 2\n\"constrains\": 2\n\"corrupter\": 2\n\"betid\": 2\n\"conjunct\": 2\n\"Perplex\": 2\n\"Rotten\": 2\n\"course-\": 2\n\"succeeds\": 2\n\"elf\": 2\n\"Amurath\": 2\n\"Pins\": 2\n\"osiers\": 2\n\"bans\": 2\n\"valuation\": 2\n\"Highness-\": 2\n\"sheep-cote\": 2\n\"Fiery\": 2\n\"Infirmity\": 2\n\"disrobe\": 2\n\"Leonati\": 2\n\"remotion\": 2\n\"cockney\": 2\n\"wiry\": 2\n\"knapp\": 2\n\"conversing\": 2\n\"routs\": 2\n\"quality-\": 2\n\"blinding\": 2\n\"excused\": 2\n\"sizes\": 2\n\"startle\": 2\n\"Effects\": 2\n\"tartness\": 2\n\"unlearned\": 2\n\"forth-\": 2\n\"damm\": 2\n\"Ptolemies\": 2\n\"displac\": 2\n\"hot-blooded\": 2\n\"situation\": 2\n\"bottomless\": 2\n\"successively\": 2\n\"misus\": 2\n\"schoolmasters\": 2\n\"Acting\": 2\n\"Contending\": 2\n\"bove\": 2\n\"Catch\": 2\n\"Strives\": 2\n\"fur\": 2\n\"unbonneted\": 2\n\"bloodshed\": 2\n\"anon-\": 2\n\"but-\": 2\n\"head-piece\": 2\n\"Fridays\": 2\n\"louse\": 2\n\"achievement\": 2\n\"undivulged\": 2\n\"Pleading\": 2\n\"incredulous\": 2\n\"Repose\": 2\n\"inhabitants\": 2\n\"cas\": 2\n\"beginners\": 2\n\"heretics\": 2\n\"contentious\": 2\n\"houseless\": 2\n\"grumble\": 2\n\"back-door\": 2\n\"bog\": 2\n\"trotting\": 2\n\"slaughterman\": 2\n\"whirlwinds\": 2\n\"Judicious\": 2\n\"Pillicock\": 2\n\"Hill\": 2\n\"nourisheth\": 2\n\"servingman\": 2\n\"gondola\": 2\n\"swam\": 2\n\"whetted\": 2\n\"favourer\": 2\n\"wool\": 2\n\"lendings\": 2\n\"disable\": 2\n\"Flibbertigibbet\": 2\n\"Groan\": 2\n\"aroint\": 2\n\"swimming\": 2\n\"frog\": 2\n\"suspire\": 2\n\"tithing\": 2\n\"Modo\": 2\n\"Mahu\": 2\n\"Desir\": 2\n\"Importune\": 2\n\"craz\": 2\n\"masonry\": 2\n\"debtors\": 2\n\"provoking\": 2\n\"cancel\": 2\n\"tameness\": 2\n\"gray\": 2\n\"Arms\": 2\n\"Tooth\": 2\n\"Sessa\": 2\n\"lifting\": 2\n\"Persian\": 2\n\"haunch\": 2\n\"defiles\": 2\n\"Added\": 2\n\"sy\": 2\n\"shielded\": 2\n\"mete\": 2\n\"perfectness\": 2\n\"fattest\": 2\n\"buoy\": 2\n\"geck\": 2\n\"neighbourly\": 2\n\"enkindle\": 2\n\"adjourn\": 2\n\"whites\": 2\n\"unsubstantial\": 2\n\"falser\": 2\n\"Madman\": 2\n\"Doubting\": 2\n\"stile\": 2\n\"footpath\": 2\n\"BROTHERS\": 2\n\"chambermaids\": 2\n\"(If\": 2\n\"JUPITER\": 2\n\"Tigers\": 2\n\"plumed\": 2\n\"Esquire\": 2\n\"manured\": 2\n\"demonstration\": 2\n\"Lending\": 2\n\"coasts\": 2\n\"sustaining\": 2\n\"retinue\": 2\n\"Sell\": 2\n\"inwards\": 2\n\"dun\": 2\n\"ag\": 2\n\"arrives\": 2\n\"Preferment\": 2\n\"dizzy\": 2\n\"midway\": 2\n\"anchoring\": 2\n\"infects\": 2\n\"deficient\": 2\n\"wires\": 2\n\"jeweller\": 2\n\"gossamer\": 2\n\"shiver\": 2\n\"pavement\": 2\n\"delectable\": 2\n\"green-sickness\": 2\n\"speeded\": 2\n\"undoes\": 2\n\"pah\": 2\n\"bugle\": 2\n\"indifferency\": 2\n\"jointed\": 2\n\"jovial\": 2\n\"biding\": 2\n\"emphasis\": 2\n\"zir\": 2\n\"beauty-\": 2\n\"vor\": 2\n\"hurries\": 2\n\"new-appearing\": 2\n\"Cure\": 2\n\"tolerable\": 2\n\"leaders\": 2\n\"man)\": 2\n\"incurr\": 2\n\"redresses\": 2\n\"debitor\": 2\n\"Crowd\": 2\n\"holla\": 2\n\"intelligencer\": 2\n\"opposer\": 2\n\"protest-\": 2\n\"exult\": 2\n\"gazers\": 2\n\"verier\": 2\n\"Alexandrian\": 2\n\"fordone\": 2\n\"customer\": 2\n\"Stepp\": 2\n\"atonement\": 2\n\"overturn\": 2\n\"offensive\": 2\n\"unfix\": 2\n\"Scratch\": 2\n\"Greet\": 2\n\"misdoubts\": 2\n\"Affected\": 2\n\"scorpion\": 2\n\"Ta\": 2\n\"Grand\": 2\n\"decide\": 2\n\"sterner\": 2\n\"rence\": 2\n\"Service\": 2\n\"enquired\": 2\n\"absolutely\": 2\n\"user\": 2\n\"tilter\": 2\n\"digression\": 2\n\"traverse\": 2\n\"equivocal\": 2\n\"Fat\": 2\n\"observances\": 2\n\"Bacchanals\": 2\n\"Despairing\": 2\n\"dint\": 2\n\"pore\": 2\n\"godfathers\": 2\n\"sneaping\": 2\n\"Ink\": 2\n\"goblet\": 2\n\"summary\": 2\n\"Troop\": 2\n\"majesty-\": 2\n\"pick-purse\": 2\n\"chestnut\": 2\n\"complements\": 2\n\"deemed\": 2\n\"minstrelsy\": 2\n\"off-\": 2\n\"peace-\": 2\n\"Arme-\": 2\n\"magnificent\": 2\n\"Gaultree\": 2\n\"moderately\": 2\n\"beeves\": 2\n\"dominator\": 2\n\"oppressing\": 2\n\"prepost\": 2\n\"draweth\": 2\n\"crowding\": 2\n\"Vice\": 2\n\"Quail\": 2\n\"compliments\": 2\n\"Not-\": 2\n\"sware\": 2\n\"congruent\": 2\n\"Renew\": 2\n\"nibbling\": 2\n\"reprobate\": 2\n\"Bacchus\": 2\n\"hereby\": 2\n\"pardoned\": 2\n\"punished\": 2\n\"transgressing\": 2\n\"forsworn-\": 2\n\"Solomon\": 2\n\"butt-shaft\": 2\n\"feast-\": 2\n\"duello\": 2\n\"manager\": 2\n\"ones-\": 2\n\"tah\": 2\n\"blames\": 2\n\"chapmen\": 2\n\"solicitor\": 2\n\"votaries\": 2\n\"solemnized\": 2\n\"short-liv\": 2\n\"Minerva\": 2\n\"thanksgiving\": 2\n\"Discovering\": 2\n\"mad-cap\": 2\n\"jangling\": 2\n\"book-men\": 2\n\"wiving\": 2\n\"dispraising\": 2\n\"ushers\": 2\n\"foeman\": 2\n\"virtue-\": 2\n\"purchased\": 2\n\"fir\": 2\n\"reputes\": 2\n\"acute\": 2\n\"Cup\": 2\n\"fifty-five\": 2\n\"Gan\": 2\n\"heaving\": 2\n\"tofore\": 2\n\"operate\": 2\n\"simular\": 2\n\"incony\": 2\n\"Egregious\": 2\n\"ribbon\": 2\n\"farthing\": 2\n\"slut\": 2\n\"gardon\": 2\n\"module\": 2\n\"malcontents\": 2\n\"plackets\": 2\n\"Simon\": 2\n\"Splits\": 2\n\"John-\": 2\n\"tallest\": 2\n\"Spent\": 2\n\"illustrate\": 2\n\"witnesseth\": 2\n\"expecting\": 2\n\"Lydia\": 2\n\"soldier-like\": 2\n\"TRAIN\": 2\n\"villain-like\": 2\n\"engrossed\": 2\n\"good-night\": 2\n\"smoothly\": 2\n\"obscenely\": 2\n\"handful\": 2\n\"nit\": 2\n\"sacrilegious\": 2\n\"Falstaffs\": 2\n\"hangeth\": 2\n\"Holofernes\": 2\n\"epithets\": 2\n\"nook\": 2\n\"three-fold\": 2\n\"pretending\": 2\n\"house-\": 2\n\"via\": 2\n\"curing\": 2\n\"replenished\": 2\n\"indiscreet\": 2\n\"omne\": 2\n\"bene\": 2\n\"bullocks\": 2\n\"dullard\": 2\n\"five-score\": 2\n\"allusion\": 2\n\"scurrility\": 2\n\"pursuing\": 2\n\"apter\": 2\n\"Rail\": 2\n\"tasting\": 2\n\"ousel\": 2\n\"bed-fellow\": 2\n\"new-found\": 2\n\"accoutrements\": 2\n\"saluteth\": 2\n\"Person\": 2\n\"likest\": 2\n\"falseness\": 2\n\"unbutton\": 2\n\"Figuring\": 2\n\"ungarter\": 2\n\"Venetia\": 2\n\"ti\": 2\n\"quotidian\": 2\n\"gathering\": 2\n\"domine\": 2\n\"bowed\": 2\n\"comprehend\": 2\n\"caret\": 2\n\"Naso\": 2\n\"Marvellous\": 2\n\"elegies\": 2\n\"Guiderius\": 2\n\"verba\": 2\n\"Sicyon\": 2\n\"Climbs\": 2\n\"Shot\": 2\n\"lapp\": 2\n\"carving\": 2\n\"prose\": 2\n\"slop\": 2\n\"Vows\": 2\n\"demigod\": 2\n\"firmness\": 2\n\"Distinction\": 2\n\"napping\": 2\n\"wreathed\": 2\n\"appliances\": 2\n\"interrogatories\": 2\n\"coaches\": 2\n\"bunting\": 2\n\"slowness\": 2\n\"ship-boy\": 2\n\"Presume\": 2\n\"canopies\": 2\n\"Adramadio\": 2\n\"loggerhead\": 2\n\"Guilty\": 2\n\"label\": 2\n\"worthies\": 2\n\"fetters\": 2\n\"Devils\": 2\n\"mourns\": 2\n\"colliers\": 2\n\"Flat\": 2\n\"academes\": 2\n\"Earls\": 2\n\"causer\": 2\n\"Learning\": 2\n\"prompting\": 2\n\"strung\": 2\n\"-well\": 2\n\"omitted\": 2\n\"Allons\": 2\n\"Sow\": 2\n\"whirls\": 2\n\"undeserver\": 2\n\"mollis\": 2\n\"aer\": 2\n\"mulier\": 2\n\"table-book\": 2\n\"insociable\": 2\n\"point-devise\": 2\n\"orthography\": 2\n\"quis\": 2\n\"flap-dragon\": 2\n\"Ba\": 2\n\"Answering\": 2\n\"disputes\": 2\n\"posterior\": 2\n\"nnight\": 2\n\"hardest\": 2\n\"other-\": 2\n\"strangling\": 2\n\"fadge\": 2\n\"wicked-\": 2\n\"Promises\": 2\n\"Vilely\": 2\n\"hests\": 2\n\"note-book\": 2\n\"dissuaded\": 2\n\"nodded\": 2\n\"Muscovites\": 2\n\"confessed\": 2\n\"chipp\": 2\n\"BLACKAMOORS\": 2\n\"views\": 2\n\"Out-\": 2\n\"behold-\": 2\n\"sun-beamed\": 2\n\"slink\": 2\n\"Honey\": 2\n\"Media\": 2\n\"pantler\": 2\n\"Cutting\": 2\n\"foining\": 2\n\"eunuchs\": 2\n\"pert\": 2\n\"Bartholomew\": 2\n\"Disguis\": 2\n\"pease\": 2\n\"Laud\": 2\n\"Spending\": 2\n\"canvass\": 2\n\"pastimes\": 2\n\"Trim\": 2\n\"undeserving\": 2\n\"stayed\": 2\n\"hyperboles\": 2\n\"maggot\": 2\n\"yeas\": 2\n\"shov\": 2\n\"Despise\": 2\n\"Claudius\": 2\n\"Forestall\": 2\n\"squier\": 2\n\"catechism\": 2\n\"whereuntil\": 2\n\"opulent\": 2\n\"surnam\": 2\n\"Alisander-\": 2\n\"cork\": 2\n\"tis-\": 2\n\"blesses\": 2\n\"flask\": 2\n\"half-cheek\": 2\n\"Jude\": 2\n\"Sea\": 2\n\"armipotent\": 2\n\"Stuck\": 2\n\"Clowns\": 2\n\"Ates\": 2\n\"slash\": 2\n\"dishclout\": 2\n\"petitionary\": 2\n\"justle\": 2\n\"abridge\": 2\n\"fashioning\": 2\n\"imbrue\": 2\n\"lining\": 2\n\"hermitage\": 2\n\"Trow\": 2\n\"taller\": 2\n\"Impose\": 2\n\"flouts\": 2\n\"Jill\": 2\n\"Owl\": 2\n\"coranto\": 2\n\"Hiems\": 2\n\"Mocks\": 2\n\"Unpleasing\": 2\n\"rooks\": 2\n\"smocks\": 2\n\"WINTER\": 2\n\"scrip\": 2\n\"pail\": 2\n\"liegemen\": 2\n\"Tu-whit\": 2\n\"neaf\": 2\n\"coughing\": 2\n\"crabs\": 2\n\"purposeth\": 2\n\"parishioners\": 2\n\"Atalanta\": 2\n\"quintessence\": 2\n\"imitated\": 2\n\"Teaching\": 2\n\"stalks\": 2\n\"Tongues\": 2\n\"unpeopled\": 2\n\"Si\": 2\n\"observant\": 2\n\"Cannibals\": 2\n\"pamper\": 2\n\"Hiren\": 2\n\"graff\": 2\n\"clearness\": 2\n\"rind\": 2\n\"sheaf\": 2\n\"toils\": 2\n\"implements\": 2\n\"sealing\": 2\n\"dinners\": 2\n\"adores\": 2\n\"carcanet\": 2\n\"Inde\": 2\n\"sweaty\": 2\n\"bell-wether\": 2\n\"copulation\": 2\n\"occupy\": 2\n\"tar\": 2\n\"cling\": 2\n\"-from\": 2\n\"emulate\": 2\n\"competent\": 2\n\"furbish\": 2\n\"bawdy-house\": 2\n\"bottle-ale\": 2\n\"Golgotha\": 2\n\"post-haste\": 2\n\"camest\": 2\n\"Point\": 2\n\"subtleties\": 2\n\"cut-purse\": 2\n\"ronyon\": 2\n\"Aleppo\": 2\n\"penthouse\": 2\n\"lid\": 2\n\"Wreck\": 2\n\"tenantless\": 2\n\"fells\": 2\n\"aspen\": 2\n\"squeak\": 2\n\"perfectest\": 2\n\"rers\": 2\n\"substances\": 2\n\"recommends\": 2\n\"martlet\": 2\n\"Smells\": 2\n\"harbingers\": 2\n\"Conduct\": 2\n\"ingredients\": 2\n\"hoo\": 2\n\"adhere\": 2\n\"unmake\": 2\n\"nipple\": 2\n\"Subdu\": 2\n\"crowing\": 2\n\"sentinel\": 2\n\"Moves\": 2\n\"celebrated\": 2\n\"awaked\": 2\n\"emptier\": 2\n\"Balm\": 2\n\"watchers\": 2\n\"russet\": 2\n\"conger\": 2\n\"carousing\": 2\n\"disjoint\": 2\n\"pester\": 2\n\"physics\": 2\n\"chimneys\": 2\n\"lees\": 2\n\"Empty\": 2\n\"mouthed\": 2\n\"canaries\": 2\n\"Unmannerly\": 2\n\"exposure\": 2\n\"Lost\": 2\n\"Hours\": 2\n\"strangles\": 2\n\"predominance\": 2\n\"bedrid\": 2\n\"Tonight\": 2\n\"recordation\": 2\n\"So-\": 2\n\"Simply\": 2\n\"solitary\": 2\n\"crazed\": 2\n\"housekeeper\": 2\n\"MURTHERERS\": 2\n\"rib\": 2\n\"Abide\": 2\n\"defensible\": 2\n\"hums\": 2\n\"Volt\": 2\n\"endear\": 2\n\"Murtherer\": 2\n\"founded\": 2\n\"jerkins\": 2\n\"territory\": 2\n\"charnel\": 2\n\"maws\": 2\n\"unmann\": 2\n\"batter\": 2\n\"speculation\": 2\n\"wade\": 2\n\"Returning\": 2\n\"angerly\": 2\n\"riddles\": 2\n\"transgress\": 2\n\"vaporous\": 2\n\"familiars\": 2\n\"Damned\": 2\n\"nighted\": 2\n\"pottle-pot\": 2\n\"clogs\": 2\n\"holly\": 2\n\"Toad\": 2\n\"heigh-ho\": 2\n\"bake\": 2\n\"newt\": 2\n\"man-at-arms\": 2\n\"maidenly\": 2\n\"pouch\": 2\n\"it)\": 2\n\"bladed\": 2\n\"foundations\": 2\n\"passeth\": 2\n\"power-\": 2\n\"show-\": 2\n\"pard\": 2\n\"furnace\": 2\n\"Oppress\": 2\n\"maidenhood\": 2\n\"bodements\": 2\n\"suffic\": 2\n\"Infected\": 2\n\"peach-colour\": 2\n\"diminutive\": 2\n\"fatherless\": 2\n\"Everyone\": 2\n\"swearers\": 2\n\"laudable\": 2\n\"blisters\": 2\n\"transpose\": 2\n\"loosely\": 2\n\"avarice\": 2\n\"trappings\": 2\n\"detraction\": 2\n\"swol\": 2\n\"drollery\": 2\n\"distresses\": 2\n\"tongue-\": 2\n\"surprised\": 2\n\"close-stool\": 2\n\"enrage\": 2\n\"unschool\": 2\n\"Flies\": 2\n\"agitation\": 2\n\"actual\": 2\n\"performances\": 2\n\"accustomed\": 2\n\"pasty\": 2\n\"sea-coal\": 2\n\"mandragora\": 2\n\"whisperings\": 2\n\"Caithness\": 2\n\"Season\": 2\n\"pronounced\": 2\n\"wild-goose\": 2\n\"taxing\": 2\n\"honey-seed\": 2\n\"speculative\": 2\n\"treatise\": 2\n\"honeysuckle\": 2\n\"dusty\": 2\n\"avouches\": 2\n\"leavy\": 2\n\"Tyrant\": 2\n\"cap-a-pe\": 2\n\"fiend-like\": 2\n\"MEASURE\": 2\n\"headed\": 2\n\"Smooth\": 2\n\"blunting\": 2\n\"Cleanse\": 2\n\"indited\": 2\n\"squand\": 2\n\"foin\": 2\n\"sickens\": 2\n\"slanderers\": 2\n\"fundamental\": 2\n\"passport\": 2\n\"vents\": 2\n\"biscuit\": 2\n\"substituted\": 2\n\"chanticleer\": 2\n\"birth-\": 2\n\"enriched\": 2\n\"work-\": 2\n\"besmirch\": 2\n\"Hungary\": 2\n\"sanctimonious\": 2\n\"sciatica\": 2\n\"uncouth\": 2\n\"foot-\": 2\n\"Julietta\": 2\n\"unvalued\": 2\n\"aids\": 2\n\"unmask\": 2\n\"glimpse\": 2\n\"penalties\": 2\n\"milkmaid\": 2\n\"encouragement\": 2\n\"hopes-\": 2\n\"Devouring\": 2\n\"buttons\": 2\n\"Contagious\": 2\n\"Grapple\": 2\n\"formally\": 2\n\"three-man\": 2\n\"cote\": 2\n\"tilth\": 2\n\"recks\": 2\n\"Notice\": 2\n\"shear\": 2\n\"fillip\": 2\n\"malefactors\": 2\n\"scoured\": 2\n\"dissolved\": 2\n\"commoner\": 2\n\"hoops\": 2\n\"extraordinarily\": 2\n\"comrade\": 2\n\"Iniquity\": 2\n\"voice-\": 2\n\"bum\": 2\n\"Pompey-\": 2\n\"appertinent\": 2\n\"kitchens\": 2\n\"gravy\": 2\n\"new-heal\": 2\n\"belt\": 2\n\"preserved\": 2\n\"tempter\": 2\n\"hollowly\": 2\n\"Benedicite\": 2\n\"Falsely\": 2\n\"Costly\": 2\n\"craftily\": 2\n\"redeeming\": 2\n\"Ignominy\": 2\n\"Owe\": 2\n\"warrants\": 2\n\"Jane\": 2\n\"Bidding\": 2\n\"pollution\": 2\n\"influences\": 2\n\"Hourly\": 2\n\"Wearing\": 2\n\"serpigo\": 2\n\"after-dinner\": 2\n\"Job\": 2\n\"Root\": 2\n\"deafness\": 2\n\"original\": 2\n\"unlawfully\": 2\n\"Tender\": 2\n\"well-seeming\": 2\n\"stews\": 2\n\"scaled\": 2\n\"(not\": 2\n\"moated\": 2\n\"woodcocks\": 2\n\"feathered\": 2\n\"prove-\": 2\n\"extracting\": 2\n\"bunches\": 2\n\"sea-maid\": 2\n\"detected\": 2\n\"Expire\": 2\n\"shy\": 2\n\"continency\": 2\n\"admonition\": 2\n\"liked\": 2\n\"slops\": 2\n\"strifes\": 2\n\"Pattern\": 2\n\"lapse\": 2\n\"Seals\": 2\n\"inquir\": 2\n\"face-royal\": 2\n\"liquors\": 2\n\"Lends\": 2\n\"extinct\": 2\n\"look-\": 2\n\"Proof\": 2\n\"invented\": 2\n\"healthy\": 2\n\"promise-breaker\": 2\n\"unwonted\": 2\n\"reprieves\": 2\n\"Tells\": 2\n\"coloured\": 2\n\"delaying\": 2\n\"Derives\": 2\n\"difficulties\": 2\n\"induced\": 2\n\"investments\": 2\n\"gravel\": 2\n\"unprepar\": 2\n\"nipping\": 2\n\"Prefix\": 2\n\"injunctions\": 2\n\"Chok\": 2\n\"gradation\": 2\n\"burr\": 2\n\"swinish\": 2\n\"Reveal\": 2\n\"arch-villain\": 2\n\"brief-\": 2\n\"intemperate\": 2\n\"forts\": 2\n\"scandalous\": 2\n\"meddler\": 2\n\"villainously\": 2\n\"request-\": 2\n\"Reign\": 2\n\"undergo-\": 2\n\"Unveiling\": 2\n\"garden-house\": 2\n\"Partly\": 2\n\"Cucullus\": 2\n\"facit\": 2\n\"monachum\": 2\n\"Abhor\": 2\n\"Boldly\": 2\n\"reposing\": 2\n\"Angels\": 2\n\"Immediate\": 2\n\"strengthless\": 2\n\"Wooing\": 2\n\"canoniz\": 2\n\"Sounds\": 2\n\"prizer\": 2\n\"horridly\": 2\n\"Stopping\": 2\n\"inquisition\": 2\n\"strand\": 2\n\"Who-\": 2\n\"bloodied\": 2\n\"Charlemain\": 2\n\"dignify\": 2\n\"usurpers\": 2\n\"deprive\": 2\n\"Blown\": 2\n\"outcast\": 2\n\"flux\": 2\n\"swoln\": 2\n\"allege\": 2\n\"emnity\": 2\n\"Nemean\": 2\n\"abandoned\": 2\n\"nerve\": 2\n\"suggestions\": 2\n\"worldlings\": 2\n\"solicited\": 2\n\"sulph\": 2\n\"wearies\": 2\n\"tossing\": 2\n\"Epilogue\": 2\n\"Speaker\": 2\n\"Peering\": 2\n\"tormenting\": 2\n\"edifice\": 2\n\"Janus\": 2\n\"parrots\": 2\n\"coragio\": 2\n\"lightest\": 2\n\"discredited\": 2\n\"mortifying\": 2\n\"knotted\": 2\n\"gifts-\": 2\n\"lewdness\": 2\n\"prest\": 2\n\"messages\": 2\n\"Jasons\": 2\n\"sate\": 2\n\"waiting-woman\": 2\n\"confidently\": 2\n\"reasoning\": 2\n\"burghers\": 2\n\"Palatine\": 2\n\"throstle\": 2\n\"incest\": 2\n\"Taint\": 2\n\"obtained\": 2\n\"Fairer\": 2\n\"compile\": 2\n\"neer\": 2\n\"months-\": 2\n\"whirling\": 2\n\"scholars\": 2\n\"Aha\": 2\n\"Mexico\": 2\n\"pork\": 2\n\"usance\": 2\n\"pronouncing\": 2\n\"vented\": 2\n\"altered\": 2\n\"Act\": 2\n\"Laban\": 2\n\"forgeries\": 2\n\"a-foot\": 2\n\"prenominate\": 2\n\"woolly\": 2\n\"breeders\": 2\n\"foresters\": 2\n\"is)\": 2\n\"inheritors\": 2\n\"roughest\": 2\n\"ertook\": 2\n\"notary\": 2\n\"assays\": 2\n\"clownish\": 2\n\"estimable\": 2\n\"muttons\": 2\n\"semblances\": 2\n\"shadowed\": 2\n\"shallowest\": 2\n\"ruinate\": 2\n\"afloat\": 2\n\"Budge\": 2\n\"Fiend\": 2\n\"loosed\": 2\n\"sand-blind\": 2\n\"confusions\": 2\n\"Dobbin\": 2\n\"soundless\": 2\n\"specify-\": 2\n\"impertinent\": 2\n\"leven\": 2\n\"swashing\": 2\n\"twinkling\": 2\n\"curtle-axe\": 2\n\"wrist\": 2\n\"money-bags\": 2\n\"a-bleeding\": 2\n\"busily\": 2\n\"fordoes\": 2\n\"wild-cat\": 2\n\"puddle\": 2\n\"confutes\": 2\n\"killeth\": 2\n\"masquing\": 2\n\"forefinger\": 2\n\"stoops\": 2\n\"grav\": 2\n\"immur\": 2\n\"glisters\": 2\n\"riddance\": 2\n\"fighteth\": 2\n\"arrests\": 2\n\"umber\": 2\n\"moth\": 2\n\"Receives\": 2\n\"Gifts\": 2\n\"heark\": 2\n\"uncheck\": 2\n\"lading\": 2\n\"prolixity\": 2\n\"Maids\": 2\n\"Gawsey\": 2\n\"sund\": 2\n\"cooled\": 2\n\"teacheth\": 2\n\"flieth\": 2\n\"synagogue\": 2\n\"effect-\": 2\n\"torturer\": 2\n\"Ding\": 2\n\"dong\": 2\n\"massacres\": 2\n\"Move\": 2\n\"mesh\": 2\n\"cobwebs\": 2\n\"Exceed\": 2\n\"unpractis\": 2\n\"blent\": 2\n\"pertains\": 2\n\"Perpend\": 2\n\"smoothness\": 2\n\"constitution\": 2\n\"mine)\": 2\n\"inseparable\": 2\n\"onion\": 2\n\"Wars\": 2\n\"accomplished\": 2\n\"died-\": 2\n\"Jacks\": 2\n\"tricksy\": 2\n\"Rend\": 2\n\"MAGNIFICOES\": 2\n\"unreveng\": 2\n\"declension\": 2\n\"Sabbath\": 2\n\"loathing\": 2\n\"unfeeling\": 2\n\"enamoured\": 2\n\"misconstrued\": 2\n\"Trimm\": 2\n\"conveniency\": 2\n\"wether\": 2\n\"infuse\": 2\n\"furnished\": 2\n\"petticoats\": 2\n\"Nearest\": 2\n\"pound-\": 2\n\"hair-\": 2\n\"raves\": 2\n\"acquitted\": 2\n\"scuse\": 2\n\"tasking\": 2\n\"Aloud\": 2\n\"(if\": 2\n\"lobby\": 2\n\"working-day\": 2\n\"lam\": 2\n\"bounden\": 2\n\"fishmonger\": 2\n\"bellowing\": 2\n\"forswearing\": 2\n\"brightly\": 2\n\"tell-tales\": 2\n\"scrubbed\": 2\n\"maggots\": 2\n\"daintily\": 2\n\"away-\": 2\n\"Interpretation\": 2\n\"mending\": 2\n\"issueless\": 2\n\"Strangers\": 2\n\"accuses\": 2\n\"seizes\": 2\n\"Colossus\": 2\n\"weights\": 2\n\"hams\": 2\n\"potently\": 2\n\"advisedly\": 2\n\"Capilet\": 2\n\"exceeded\": 2\n\"Rebuke\": 2\n\"considerations\": 2\n\"Armigero\": 2\n\"Majesty-\": 2\n\"prain\": 2\n\"Sticks\": 2\n\"hurlyburly\": 2\n\"pribbles\": 2\n\"Domitius\": 2\n\"untrimmed\": 2\n\"likings\": 2\n\"worts\": 2\n\"cony-catching\": 2\n\"enthron\": 2\n\"fidelicet\": 2\n\"Fery\": 2\n\"ork\": 2\n\"discreetly\": 2\n\"bilbo\": 2\n\"Word\": 2\n\"Caesarion\": 2\n\"Riddles\": 2\n\"wassails\": 2\n\"ort\": 2\n\"vexed\": 2\n\"thefts\": 2\n\"cony-catch\": 2\n\"legion\": 2\n\"intention\": 2\n\"morris\": 2\n\"tightly\": 2\n\"privates\": 2\n\"dungeons\": 2\n\"abusing\": 2\n\"whey\": 2\n\"Shuts\": 2\n\"expertness\": 2\n\"green-a\": 2\n\"nutshell\": 2\n\"Dere\": 2\n\"urgent\": 2\n\"contrarious\": 2\n\"Doncaster\": 2\n\"dreadfully\": 2\n\"tell-a\": 2\n\"Jarteer\": 2\n\"modesties\": 2\n\"Bon\": 2\n\"well-nigh\": 2\n\"frugal\": 2\n\"puddings\": 2\n\"Greensleeves\": 2\n\"unmeasurable\": 2\n\"gallimaufry\": 2\n\"Prevent\": 2\n\"consonancy\": 2\n\"Cataian\": 2\n\"late-\": 2\n\"sympathize\": 2\n\"marketable\": 2\n\"fire-\": 2\n\"grated\": 2\n\"endanger\": 2\n\"blust\": 2\n\"pensioners\": 2\n\"notify\": 2\n\"attraction\": 2\n\"nay-word\": 2\n\"imperfection\": 2\n\"Pursuing\": 2\n\"erected\": 2\n\"prescribe\": 2\n\"Foretells\": 2\n\"predominate\": 2\n\"whistling\": 2\n\"Cuckold\": 2\n\"welcome-\": 2\n\"adventurous\": 2\n\"punto\": 2\n\"Armenia\": 2\n\"Ethiopian\": 2\n\"Sought\": 2\n\"Guest\": 2\n\"Mockwater\": 2\n\"(so\": 2\n\"gatories\": 2\n\"lanes\": 2\n\"bridges\": 2\n\"urinals\": 2\n\"Melodious\": 2\n\"posies\": 2\n\"terrestrial\": 2\n\"make-a\": 2\n\"maintains\": 2\n\"pancakes\": 2\n\"cuffs\": 2\n\"Jack-a-Lent\": 2\n\"humidity\": 2\n\"warnings\": 2\n\"Roscius\": 2\n\"tattling\": 2\n\"Drag\": 2\n\"laundress\": 2\n\"Buck\": 2\n\"Buzz\": 2\n\"heartly\": 2\n\"poem\": 2\n\"Anne-\": 2\n\"speciously\": 2\n\"row\": 2\n\"affectation\": 2\n\"pills\": 2\n\"draff\": 2\n\"Hyrcanian\": 2\n\"rankest\": 2\n\"-a\": 2\n\"nouns\": 2\n\"lapis\": 2\n\"total\": 2\n\"Accusativo\": 2\n\"focative\": 2\n\"Oman\": 2\n\"plural\": 2\n\"Genitive\": 2\n\"bellies\": 2\n\"lunatics\": 2\n\"quae\": 2\n\"lieve\": 2\n\"deserver\": 2\n\"kiln-hole\": 2\n\"fire-ey\": 2\n\"bleaching\": 2\n\"lawn\": 2\n\"peard\": 2\n\"horsemanship\": 2\n\"misprised\": 2\n\"insufficiency\": 2\n\"milch-kine\": 2\n\"awork\": 2\n\"Wanton\": 2\n\"ouphes\": 2\n\"amazedness\": 2\n\"the-\": 2\n\"truckle-bed\": 2\n\"Bully\": 2\n\"tarries\": 2\n\"Cyclops\": 2\n\"Conceal\": 2\n\"nimble-footed\": 2\n\"larded\": 2\n\"hitherwards\": 2\n\"dean\": 2\n\"eterne\": 2\n\"erturn\": 2\n\"Brooks\": 2\n\"Leda\": 2\n\"provocation\": 2\n\"}\": 2\n\"mobled\": 2\n\"consumed\": 2\n\"revellers\": 2\n\"all)\": 2\n\"underhand\": 2\n\"sluts\": 2\n\"insert\": 2\n\"instalment\": 2\n\"sev\": 2\n\"ral\": 2\n\"quailing\": 2\n\"rald\": 2\n\"sapphire\": 2\n\"Vile\": 2\n\"Seese\": 2\n\"appal\": 2\n\"swearings\": 2\n\"peak\": 2\n\"postmaster\": 2\n\"unpregnant\": 2\n\"Swounds\": 2\n\"NIGHT\": 2\n\"shrieve\": 2\n\"betraying\": 2\n\"Ends\": 2\n\"cradles\": 2\n\"Unlooked\": 2\n\"fatted\": 2\n\"pierced\": 2\n\"Prompted\": 2\n\"Dennis\": 2\n\"procured\": 2\n\"Rob\": 2\n\"(like\": 2\n\"pacified\": 2\n\"scullion\": 2\n\"Tempt\": 2\n\"new-fired\": 2\n\"tradition\": 2\n\"recounting\": 2\n\"turbulent\": 2\n\"hogs\": 2\n\"Excellently\": 2\n\"Affront\": 2\n\"gentility\": 2\n\"slings\": 2\n\"protestations\": 2\n\"dunghills\": 2\n\"quenched\": 2\n\"neighs\": 2\n\"Foresters\": 2\n\"opposing\": 2\n\"Philostrate\": 2\n\"bracelets\": 2\n\"nosegays\": 2\n\"filch\": 2\n\"fellowship-\": 2\n\"sleep-\": 2\n\"boasts\": 2\n\"heats\": 2\n\"Nedar\": 2\n\"WELL\": 2\n\"collied\": 2\n\"Devoutly\": 2\n\"tuneable\": 2\n\"grunt\": 2\n\"unnoted\": 2\n\"seal-ring\": 2\n\"quicker\": 2\n\"Nick\": 2\n\"holland\": 2\n\"Ercles\": 2\n\"shivering\": 2\n\"strained\": 2\n\"Thisne\": 2\n\"Partlet\": 2\n\"heart-burn\": 2\n\"maintained\": 2\n\"orange-tawny\": 2\n\"links\": 2\n\"crawling\": 2\n\"termed\": 2\n\"paintings\": 2\n\"spangled\": 2\n\"starlight\": 2\n\"brewer\": 2\n\"wanderer\": 2\n\"fainted\": 2\n\"already-\": 2\n\"Ariadne\": 2\n\"beached\": 2\n\"ringlets\": 2\n\"piping\": 2\n\"expectancy\": 2\n\"rotted\": 2\n\"undistinguishable\": 2\n\"dwindle\": 2\n\"vot\": 2\n\"ress\": 2\n\"ascended\": 2\n\"plainest\": 2\n\"debile\": 2\n\"Rais\": 2\n\"thyme\": 2\n\"oxlips\": 2\n\"luscious\": 2\n\"Bridgenorth\": 2\n\"musk-roses\": 2\n\"enamell\": 2\n\"espies\": 2\n\"devours\": 2\n\"hedgehogs\": 2\n\"ROUSILLON\": 2\n\"eleventh\": 2\n\"spinners\": 2\n\"Pard\": 2\n\"unlov\": 2\n\"intemperance\": 2\n\"Transparent\": 2\n\"Starting\": 2\n\"lakin\": 2\n\"unmatch\": 2\n\"Northern\": 2\n\"unthought\": 2\n\"commencement\": 2\n\"cranny\": 2\n\"trippingly\": 2\n\"Ninus\": 2\n\"ass-head\": 2\n\"enthralled\": 2\n\"gleek\": 2\n\"trimming\": 2\n\"revives\": 2\n\"crier\": 2\n\"apricocks\": 2\n\"love-juice\": 2\n\"sleeping-\": 2\n\"Pierc\": 2\n\"archery\": 2\n\"augurer\": 2\n\"incursions\": 2\n\"aby\": 2\n\"sampler\": 2\n\"warbling\": 2\n\"Precious\": 2\n\"Bishops\": 2\n\"Leads\": 2\n\"Lower\": 2\n\"mistak\": 2\n\"blameless\": 2\n\"nointed\": 2\n\"astray\": 2\n\"lasted\": 2\n\"Aurora\": 2\n\"black-brow\": 2\n\"Morning\": 2\n\"robustious\": 2\n\"overdone\": 2\n\"Shine\": 2\n\"scores\": 2\n\"thrice-gracious\": 2\n\"participation\": 2\n\"desirest\": 2\n\"standest\": 2\n\"nuts\": 2\n\"scalp\": 2\n\"bellowed\": 2\n\"popularity\": 2\n\"beardless\": 2\n\"Uncouple\": 2\n\"gibing\": 2\n\"Mingled\": 2\n\"candied\": 2\n\"Melted\": 2\n\"hinges\": 2\n\"pumps\": 2\n\"comprehends\": 2\n\"local\": 2\n\"torturing\": 2\n\"unkennel\": 2\n\"critical\": 2\n\"dumbly\": 2\n\"disordered\": 2\n\"rivet\": 2\n\"Accompany\": 2\n\"capons\": 2\n\"stay-\": 2\n\"Shafalus\": 2\n\"Procrus\": 2\n\"thorn-bush\": 2\n\"Roaring\": 2\n\"inordinate\": 2\n\"Bergomask\": 2\n\"displeasing\": 2\n\"glide\": 2\n\"frolic\": 2\n\"sarcenet\": 2\n\"Eastern\": 2\n\"wherever\": 2\n\"applies\": 2\n\"Cleopatra-\": 2\n\"university\": 2\n\"vanishest\": 2\n\"Headborough\": 2\n\"attractive\": 2\n\"Begins\": 2\n\"ravishing\": 2\n\"noiseless\": 2\n\"Sung\": 2\n\"January\": 2\n\"sables\": 2\n\"Yare\": 2\n\"Scratching\": 2\n\"Immortal\": 2\n\"thronging\": 2\n\"broader\": 2\n\"Receiving\": 2\n\"alley\": 2\n\"Musician\": 2\n\"--\": 2\n\"VIOLENTA\": 2\n\"controlment\": 2\n\"levying\": 2\n\"lengths\": 2\n\"unquietness\": 2\n\"Niece\": 2\n\"ditties\": 2\n\"Scotch\": 2\n\"cinque-pace\": 2\n\"ancientry\": 2\n\"Vanquish\": 2\n\"lovingly\": 2\n\"rural\": 2\n\"Unmasks\": 2\n\"Friendship\": 2\n\"negotiate\": 2\n\"sympathized\": 2\n\"overjoyed\": 2\n\"furthest\": 2\n\"haunting\": 2\n\"orange\": 2\n\"sunburnt\": 2\n\"unhappiness\": 2\n\"sleeper\": 2\n\"archer\": 2\n\"profited\": 2\n\"Song\": 2\n\"windmill\": 2\n\"Poisoner\": 2\n\"--I\": 2\n\"Knavery\": 2\n\"linguist\": 2\n\"griffin\": 2\n\"Merlin\": 2\n\"parlour\": 2\n\"Whisper\": 2\n\"ant\": 2\n\"brushes\": 2\n\"accepts\": 2\n\"entangled\": 2\n\"writer\": 2\n\"Constable--\": 2\n\"babble\": 2\n\"earned\": 2\n\"sheen\": 2\n\"giddily\": 2\n\"journeys\": 2\n\"half-moon\": 2\n\"operant\": 2\n\"illegitimate\": 2\n\"sailing\": 2\n\"Burton\": 2\n\"unshaken\": 2\n\"excepting\": 2\n\"unconstrained\": 2\n\"sensuality\": 2\n\"lord--\": 2\n\"favourite\": 2\n\"Finish\": 2\n\"epitaphs\": 2\n\"idea\": 2\n\"withers\": 2\n\"Beatrice--\": 2\n\"cursies\": 2\n\"Constables\": 2\n\"Lucianus\": 2\n\"profitless\": 2\n\"dallying\": 2\n\"lineament\": 2\n\"bellow\": 2\n\"differ\": 2\n\"dissembler\": 2\n\"experiments\": 2\n\"lustihood\": 2\n\"braggarts\": 2\n\"Anthony--\": 2\n\"thirdly\": 2\n\"reformed\": 2\n\"plaintiff\": 2\n\"topples\": 2\n\"Livia\": 2\n\"fencer\": 2\n\"kitten\": 2\n\"Honours\": 2\n\"rhyming\": 2\n\"unkiss\": 2\n\"intermingle\": 2\n\"Epitaph\": 2\n\"Heavily\": 2\n\"primal\": 2\n\"induction\": 2\n\"Bull\": 2\n\"Containing\": 2\n\"double-dealer\": 2\n\"narrowly\": 2\n\"adulterous\": 2\n\"MOOR\": 2\n\"Archdeacon\": 2\n\"Pours\": 2\n\"snorting\": 2\n\"thumbs\": 2\n\"intents-\": 2\n\"mares\": 2\n\"laden\": 2\n\"fiddlestick\": 2\n\"churchyards\": 2\n\"smites\": 2\n\"Heigh\": 2\n\"Condemning\": 2\n\"unseeing\": 2\n\"Pharaoh\": 2\n\"ours-\": 2\n\"white-bearded\": 2\n\"affined\": 2\n\"misleader\": 2\n\"Hazard\": 2\n\"clasps\": 2\n\"Moor-\": 2\n\"deluding\": 2\n\"bombard\": 2\n\"Depose\": 2\n\"maidhood\": 2\n\"godliness\": 2\n\"unhoused\": 2\n\"weaken\": 2\n\"prompter\": 2\n\"SAILOR\": 2\n\"lewdly\": 2\n\"crownets\": 2\n\"confront\": 2\n\"d-stool\": 2\n\"grise\": 2\n\"housewives\": 2\n\"scion\": 2\n\"usurped\": 2\n\"barbarian\": 2\n\"mane\": 2\n\"halts\": 2\n\"seaside\": 2\n\"Buys\": 2\n\"Guns\": 2\n\"blazoning\": 2\n\"Tempests\": 2\n\"hundreds\": 2\n\"Saints\": 2\n\"harbor\": 2\n\"paradoxes\": 2\n\"hobnails\": 2\n\"disembark\": 2\n\"struggling\": 2\n\"conveniences\": 2\n\"position-\": 2\n\"finder\": 2\n\"quail\": 2\n\"Villainous\": 2\n\"Provoke\": 2\n\"profitably\": 2\n\"canakin\": 2\n\"tuned\": 2\n\"June\": 2\n\"Drunk\": 2\n\"Lieutenant-\": 2\n\"Montano-\": 2\n\"propriety\": 2\n\"Swords\": 2\n\"waked\": 2\n\"Reputation\": 2\n\"bestial\": 2\n\"seasoned\": 2\n\"unblest\": 2\n\"ingredient\": 2\n\"liegeman\": 2\n\"hunts\": 2\n\"alderman\": 2\n\"screen\": 2\n\"sawest\": 2\n\"if-\": 2\n\"echoes\": 2\n\"Utter\": 2\n\"intrude\": 2\n\"Robs\": 2\n\"bombast\": 2\n\"position\": 2\n\"Assuredly\": 2\n\"heartstrings\": 2\n\"hinge\": 2\n\"weakens\": 2\n\"bolster\": 2\n\"Spotted\": 2\n\"exhalations\": 2\n\"inmost\": 2\n\"ever-burning\": 2\n\"voluptuousness\": 2\n\"stabbing\": 2\n\"Toryne\": 2\n\"Entirely\": 2\n\"penetrable\": 2\n\"unhatch\": 2\n\"Begot\": 2\n\"braz\": 2\n\"abhorring\": 2\n\"continuate\": 2\n\"did-\": 2\n\"trance\": 2\n\"Breaks\": 2\n\"Confine\": 2\n\"prizes\": 2\n\"undertaker\": 2\n\"Gallants\": 2\n\"tristful\": 2\n\"Committed\": 2\n\"votarist\": 2\n\"languishes\": 2\n\"unpin\": 2\n\"purgatory\": 2\n\"outfac\": 2\n\"Minion\": 2\n\"tuck\": 2\n\"presentment\": 2\n\"happ\": 2\n\"excelling\": 2\n\"blackberries\": 2\n\"rids\": 2\n\"Filth\": 2\n\"Torments\": 2\n\"medicinal\": 2\n\"racks\": 2\n\"unrespected\": 2\n\"Reliev\": 2\n\"Disarms\": 2\n\"unbar\": 2\n\"Kendal\": 2\n\"bequeathed\": 2\n\"mope\": 2\n\"compulsive\": 2\n\"shackles\": 2\n\"ardour\": 2\n\"PIERCE\": 2\n\"slackness\": 2\n\"inherits\": 2\n\"uglier\": 2\n\"sacrificing\": 2\n\"nearness\": 2\n\"baffl\": 2\n\"Rage\": 2\n\"lieth\": 2\n\"saidst\": 2\n\"panders\": 2\n\"radish\": 2\n\"Stew\": 2\n\"nasty\": 2\n\"compassionate\": 2\n\"Shorten\": 2\n\"ore\": 2\n\"miscall\": 2\n\"Caucasus\": 2\n\"wallow\": 2\n\"rankle\": 2\n\"paunch\": 2\n\"farewells\": 2\n\"Frank\": 2\n\"twentieth\": 2\n\"meeter\": 2\n\"unstaid\": 2\n\"psalms\": 2\n\"Consuming\": 2\n\"scept\": 2\n\"hover\": 2\n\"regent\": 2\n\"Presuming\": 2\n\"unreverent\": 2\n\"drunkenly\": 2\n\"patents\": 2\n\"severely\": 2\n\"Divides\": 2\n\"gaz\": 2\n\"drinketh\": 2\n\"nether-stocks\": 2\n\"blunted\": 2\n\"stewardship\": 2\n\"gasping\": 2\n\"scrupulous\": 2\n\"muleteers\": 2\n\"deceivable\": 2\n\"carver\": 2\n\"glares\": 2\n\"portal\": 2\n\"trample\": 2\n\"Michaelmas\": 2\n\"unwieldy\": 2\n\"indenture\": 2\n\"destroying\": 2\n\"over-blown\": 2\n\"Flint\": 2\n\"Pewter\": 2\n\"carpet\": 2\n\"thund\": 2\n\"barbed\": 2\n\"figur\": 2\n\"Diseases\": 2\n\"supportance\": 2\n\"over-proud\": 2\n\"coinage\": 2\n\"Adding\": 2\n\"Ralph\": 2\n\"Engage\": 2\n\"Stirr\": 2\n\"dens\": 2\n\"unking\": 2\n\"deposing\": 2\n\"Pilate\": 2\n\"Drawer\": 2\n\"Dashes\": 2\n\"shivers\": 2\n\"converts\": 2\n\"after-love\": 2\n\"sheer\": 2\n\"whosoever\": 2\n\"pardoning\": 2\n\"Pleads\": 2\n\"mads\": 2\n\"Rode\": 2\n\"jauncing\": 2\n\"unction\": 2\n\"Bennet\": 2\n\"sprinkle\": 2\n\"BOURCHIER\": 2\n\"Nessus\": 2\n\"pleasest\": 2\n\"livelihood\": 2\n\"film\": 2\n\"refusing\": 2\n\"milks\": 2\n\"pursy\": 2\n\"remarkable\": 2\n\"Contend\": 2\n\"URSWICK\": 2\n\"TRESSEL\": 2\n\"countryman-\": 2\n\"purer\": 2\n\"closer\": 2\n\"whereabout\": 2\n\"a-horseback\": 2\n\"hearkens\": 2\n\"tempers\": 2\n\"volubility\": 2\n\"Assume\": 2\n\"abjects\": 2\n\"Share\": 2\n\"paddling\": 2\n\"Butler\": 2\n\"bestirr\": 2\n\"butcheries\": 2\n\"exhales\": 2\n\"deluge\": 2\n\"concernings\": 2\n\"heroes\": 2\n\"adorn\": 2\n\"includes\": 2\n\"Aiming\": 2\n\"stripling\": 2\n\"Iwis\": 2\n\"Threat\": 2\n\"joyless\": 2\n\"plagu\": 2\n\"standers\": 2\n\"bottled\": 2\n\"bunch-back\": 2\n\"dallies\": 2\n\"lug\": 2\n\"tugging\": 2\n\"heaves\": 2\n\"Inestimable\": 2\n\"methoughts\": 2\n\"requites\": 2\n\"obstacles\": 2\n\"malmsey-butt\": 2\n\"Redeemer\": 2\n\"Dissemble\": 2\n\"Provok\": 2\n\"barn\": 2\n\"dragg\": 2\n\"leisurely\": 2\n\"Pitchers\": 2\n\"slander-\": 2\n\"re-edified\": 2\n\"Buckingham-\": 2\n\"lards\": 2\n\"complots\": 2\n\"stow\": 2\n\"acquire\": 2\n\"sapling\": 2\n\"protector\": 2\n\"Mile-end\": 2\n\"distraught\": 2\n\"unsuspected\": 2\n\"Guildhall\": 2\n\"Infer\": 2\n\"convocation\": 2\n\"SCRIVENER\": 2\n\"stair\": 2\n\"Craves\": 2\n\"disgracious\": 2\n\"Tongue-tied\": 2\n\"Despiteful\": 2\n\"cockatrice\": 2\n\"freezes\": 2\n\"unrespective\": 2\n\"liker\": 2\n\"disturbers\": 2\n\"frontier\": 2\n\"disguises\": 2\n\"Wept\": 2\n\"smothered\": 2\n\"thriving\": 2\n\"snail-pac\": 2\n\"imposthume\": 2\n\"setter\": 2\n\"gapes\": 2\n\"garish\": 2\n\"wails\": 2\n\"succeeders\": 2\n\"unscarr\": 2\n\"after-hours\": 2\n\"Endur\": 2\n\"chastised\": 2\n\"Sweetly\": 2\n\"forward-\": 2\n\"circling\": 2\n\"erpast\": 2\n\"hull\": 2\n\"Reward\": 2\n\"exhort\": 2\n\"Rightly\": 2\n\"Tamworth\": 2\n\"Bosworth\": 2\n\"Brandon\": 2\n\"mista\": 2\n\"mid\": 2\n\"edgeless\": 2\n\"why-\": 2\n\"ORATION\": 2\n\"Britaines\": 2\n\"over-weening\": 2\n\"Excitements\": 2\n\"Inspire\": 2\n\"enacts\": 2\n\"Proportion\": 2\n\"Hers\": 2\n\"overplus\": 2\n\"Rinaldo\": 2\n\"mildest\": 2\n\"Spurns\": 2\n\"found-\": 2\n\"winks\": 2\n\"Apothecary\": 2\n\"prophesying\": 2\n\"Lock\": 2\n\"Torchbearers\": 2\n\"GUARDS\": 2\n\"Chor\": 2\n\"households\": 2\n\"unseason\": 2\n\"gestures\": 2\n\"spills\": 2\n\"fernseed\": 2\n\"doubling\": 2\n\"shoon\": 2\n\"zounds\": 2\n\"mustachio\": 2\n\"Carries\": 2\n\"joined\": 2\n\"steel-\": 2\n\"garboils\": 2\n\"Misshapen\": 2\n\"choking\": 2\n\"Examine\": 2\n\"useful\": 2\n\"nets\": 2\n\"starveling\": 2\n\"talkest\": 2\n\"Lammas\": 2\n\"Larded\": 2\n\"auditor\": 2\n\"dovehouse\": 2\n\"tetchy\": 2\n\"layest\": 2\n\"stinted\": 2\n\"teat\": 2\n\"bedtime\": 2\n\"Cock\": 2\n\"carrier\": 2\n\"wagoner\": 2\n\"carriers\": 2\n\"Potpan\": 2\n\"toes\": 2\n\"corns\": 2\n\"corrigible\": 2\n\"collateral\": 2\n\"bitt\": 2\n\"strik\": 2\n\"Cross\": 2\n\"greenly\": 2\n\"bacon\": 2\n\"medlars\": 2\n\"cetera\": 2\n\"lure\": 2\n\"Echo\": 2\n\"slays\": 2\n\"unbruised\": 2\n\"right-\": 2\n\"duellist\": 2\n\"jordan\": 2\n\"flowed\": 2\n\"pump\": 2\n\"good-den\": 2\n\"shamest\": 2\n\"tench\": 2\n\"Henceforward\": 2\n\"fleas\": 2\n\"Divided\": 2\n\"Consort\": 2\n\"Alla\": 2\n\"dry-beat\": 2\n\"aspir\": 2\n\"Citizen\": 2\n\"tilts\": 2\n\"Retorts\": 2\n\"stainless\": 2\n\"weraday\": 2\n\"vitae\": 2\n\"lips-\": 2\n\"Adversity\": 2\n\"dispute\": 2\n\"railest\": 2\n\"indeed-\": 2\n\"Window\": 2\n\"Nightly\": 2\n\"light-\": 2\n\"Feeling\": 2\n\"bots\": 2\n\"Detest\": 2\n\"Prudence\": 2\n\"unstain\": 2\n\"uncovered\": 2\n\"Eats\": 2\n\"drier\": 2\n\"deflowered\": 2\n\"Tuscan\": 2\n\"planks\": 2\n\"dump\": 2\n\"serving-creature\": 2\n\"misadventure\": 2\n\"tortoise\": 2\n\"arched\": 2\n\"impetuous\": 2\n\"neglecting\": 2\n\"Whistle\": 2\n\"props\": 2\n\"cards\": 2\n\"Warm\": 2\n\"indistinct\": 2\n\"Acts\": 2\n\"blackest\": 2\n\"piteously\": 2\n\"Thessaly\": 2\n\"receivest\": 2\n\"well-belov\": 2\n\"Lichas\": 2\n\"Suitors\": 2\n\"dislik\": 2\n\"1611\": 2\n\"1609\": 2\n\"nony\": 2\n\"Patient\": 2\n\"Publicola\": 2\n\"amplest\": 2\n\"1608\": 2\n\"Tailor\": 2\n\"pheeze\": 2\n\"distractions\": 2\n\"fennel\": 2\n\"candy\": 2\n\"Sundays\": 2\n\"Bolingbroke-\": 2\n\"scourg\": 2\n\"drank\": 2\n\"Hacket\": 2\n\"caged\": 2\n\"nightingales\": 2\n\"Semiramis\": 2\n\"trapp\": 2\n\"roaming\": 2\n\"gypsy\": 2\n\"specially\": 2\n\"abjur\": 2\n\"funeral-\": 2\n\"England-\": 2\n\"blossoming\": 2\n\"Eternal\": 2\n\"Drives\": 2\n\"dough\": 2\n\"coral\": 2\n\"inventions\": 2\n\"rhymers\": 2\n\"speedier\": 2\n\"conjunctive\": 2\n\"Sibyl\": 2\n\"wealthily\": 2\n\"uprise\": 2\n\"begone\": 2\n\"Naked\": 2\n\"larums\": 2\n\"Unbind\": 2\n\"aside-\": 2\n\"wrong-\": 2\n\"steely\": 2\n\"postscript\": 2\n\"lutes\": 2\n\"pillory\": 2\n\"fiddler\": 2\n\"twangling\": 2\n\"banns\": 2\n\"Kates\": 2\n\"moveable\": 2\n\"Heir\": 2\n\"should-\": 2\n\"scandaliz\": 2\n\"cardecue\": 2\n\"grimly\": 2\n\"kernels\": 2\n\"quickens\": 2\n\"twink\": 2\n\"Youngling\": 2\n\"LICIO\": 2\n\"lessons\": 2\n\"riband\": 2\n\"topp\": 2\n\"forgery\": 2\n\"indent\": 2\n\"emptied\": 2\n\"guns\": 2\n\"spendthrift\": 2\n\"easing\": 2\n\"therewith\": 2\n\"nests\": 2\n\"Swallows\": 2\n\"milliner\": 2\n\"digress\": 2\n\"sops\": 2\n\"own-\": 2\n\"ray\": 2\n\"prescript\": 2\n\"miry\": 2\n\"waded\": 2\n\"ulcer\": 2\n\"sermon\": 2\n\"longeth\": 2\n\"taming-school\": 2\n\"wants-\": 2\n\"unbated\": 2\n\"Breathless\": 2\n\"nip\": 2\n\"thimble\": 2\n\"skein\": 2\n\"loose-bodied\": 2\n\"Happier\": 2\n\"Vicentio\": 2\n\"Danger\": 2\n\"TEMPEST\": 2\n\"adjoining\": 2\n\"1606\": 2\n\"1605\": 2\n\"anoint\": 2\n\"infamous\": 2\n\"science\": 2\n\"perusal\": 2\n\"compiled\": 2\n\"Nobler\": 2\n\"Unapt\": 2\n\"chalice\": 2\n\"unyok\": 2\n\"helper\": 2\n\"sullied\": 2\n\"true-bred\": 2\n\"barricado\": 2\n\"wizards\": 2\n\"REAPERS\": 2\n\"bestir\": 2\n\"Muses\": 2\n\"topmast\": 2\n\"a-hold\": 2\n\"cheated\": 2\n\"furlongs\": 2\n\"girded\": 2\n\"verdure\": 2\n\"daisies\": 2\n\"Providence\": 2\n\"targets\": 2\n\"re-survey\": 2\n\"assails\": 2\n\"Argier\": 2\n\"pendant\": 2\n\"profiting\": 2\n\"chops\": 2\n\"Setebos\": 2\n\"featly\": 2\n\"Rochester\": 2\n\"dispersedly\": 2\n\"Bow-wow\": 2\n\"strutting\": 2\n\"Spirit\": 2\n\"Yet-\": 2\n\"advantageous\": 2\n\"freshness\": 2\n\"favouring\": 2\n\"offerings\": 2\n\"Bove\": 2\n\"Hereditary\": 2\n\"undrown\": 2\n\"molest\": 2\n\"swabber\": 2\n\"Mall\": 2\n\"breaker\": 2\n\"Sack\": 2\n\"Remorse\": 2\n\"Ban\": 2\n\"log\": 2\n\"invert\": 2\n\"Servant-monster\": 2\n\"SHAPES\": 2\n\"vanishes\": 2\n\"Expos\": 2\n\"Alonso\": 2\n\"mudded\": 2\n\"opportune\": 2\n\"pertly\": 2\n\"Dis\": 2\n\"SPIRITS\": 2\n\"Advanc\": 2\n\"trumpery\": 2\n\"glistering\": 2\n\"nill\": 2\n\"discase\": 2\n\"Argal\": 2\n\"ship-\": 2\n\"baffle\": 2\n\"indulgence\": 2\n\"1602\": 2\n\"uncaught\": 2\n\"thyself-\": 2\n\"Hal-\": 2\n\"1601\": 2\n\"iteration\": 2\n\"comparative\": 2\n\"unsavoury\": 2\n\"rudder\": 2\n\"mason\": 2\n\"Hectors\": 2\n\"shipwright\": 2\n\"MERCER\": 2\n\"tenfold\": 2\n\"STRANGERS\": 2\n\"maul\": 2\n\"H\": 2\n\"judgest\": 2\n\"outlives\": 2\n\"turpitude\": 2\n\"Masque\": 2\n\"grave-maker\": 2\n\"Hybla\": 2\n\"visitors\": 2\n\"unbolt\": 2\n\"Continues\": 2\n\"courteously\": 2\n\"Dispraise\": 2\n\"governed\": 2\n\"Traffic\": 2\n\"dials\": 2\n\"witb\": 2\n\"Affairs\": 2\n\"benches\": 2\n\"coins\": 2\n\"Caphis\": 2\n\"Plant\": 2\n\"importunacy\": 2\n\"gramercy\": 2\n\"Lacedaemon\": 2\n\"sword-\": 2\n\"prosp\": 2\n\"Corrupted\": 2\n\"Sempronius\": 2\n\"fractions\": 2\n\"scarcity\": 2\n\"Nev\": 2\n\"adieus\": 2\n\"disfurnish\": 2\n\"Religion\": 2\n\"equall\": 2\n\"usuring\": 2\n\"SOME\": 2\n\"Degrees\": 2\n\"Such-a-one\": 2\n\"marrows\": 2\n\"oblique\": 2\n\"Digging\": 2\n\"mends\": 2\n\"prune\": 2\n\"novices\": 2\n\"mindless\": 2\n\"shrilly\": 2\n\"Derive\": 2\n\"chapless\": 2\n\"Common\": 2\n\"wreakful\": 2\n\"rational\": 2\n\"nature-\": 2\n\"swath\": 2\n\"gravestone\": 2\n\"exchang\": 2\n\"Determine\": 2\n\"holier\": 2\n\"mazzard\": 2\n\"advises\": 2\n\"simpler\": 2\n\"fashionable\": 2\n\"patchery\": 2\n\"Timon-\": 2\n\"restraining\": 2\n\"sorrowed\": 2\n\"Surprise\": 2\n\"brink\": 2\n\"Lips\": 2\n\"Taught\": 2\n\"Wrapp\": 2\n\"lustrous\": 2\n\"decrepit\": 2\n\"cantle\": 2\n\"mechanic\": 2\n\"bett\": 2\n\"buyer\": 2\n\"highways\": 2\n\"vouchers\": 2\n\"Balk\": 2\n\"recoveries\": 2\n\"equivocation\": 2\n\"inhibited\": 2\n\"nag\": 2\n\"kibe\": 2\n\"loveliness\": 2\n\"corses\": 2\n\"yok\": 2\n\"remainders\": 2\n\"decrease\": 2\n\"re-salute\": 2\n\"Styx\": 2\n\"perpetually\": 2\n\"watchmen\": 2\n\"Scythia\": 2\n\"Alarbus\": 2\n\"proclamations\": 2\n\"manfully\": 2\n\"now-a-days\": 2\n\"suffrages\": 2\n\"tanner\": 2\n\"Pantheon\": 2\n\"Clear\": 2\n\"Surpris\": 2\n\"wrongful\": 2\n\"Yorick\": 2\n\"reproachful\": 2\n\"vendible\": 2\n\"unsuitable\": 2\n\"bretheren\": 2\n\"toothpick\": 2\n\"dissembled\": 2\n\"retold\": 2\n\"Herefordshire\": 2\n\"fight-\": 2\n\"brabble\": 2\n\"unfrequented\": 2\n\"per\": 2\n\"chant\": 2\n\"unroll\": 2\n\"impressed\": 2\n\"dreads\": 2\n\"Unfurnish\": 2\n\"intruder\": 2\n\"lamentably\": 2\n\"thrash\": 2\n\"heard-\": 2\n\"elder-tree\": 2\n\"well-beseeming\": 2\n\"scribe\": 2\n\"oven\": 2\n\"Grave\": 2\n\"befriended\": 2\n\"handless\": 2\n\"blabb\": 2\n\"Writing\": 2\n\"soaking\": 2\n\"Follows\": 2\n\"Cornelia\": 2\n\"lifts\": 2\n\"describes\": 2\n\"returneth\": 2\n\"lentus\": 2\n\"bundle\": 2\n\"blackamoor\": 2\n\"caterwauling\": 2\n\"Typhon\": 2\n\"maugre\": 2\n\"EMPRESS\": 2\n\"Imperious\": 2\n\"lated\": 2\n\"Bruise\": 2\n\"hottest\": 2\n\"swooned\": 2\n\"dismount\": 2\n\"ACT_4|SC_1\": 2\n\"King-\": 2\n\"brain-sick\": 2\n\"Virginius\": 2\n\"1598\": 2\n\"1597\": 2\n\"commenc\": 2\n\"diminution\": 2\n\"aiding\": 2\n\"blinking\": 2\n\"short-winded\": 2\n\"outstare\": 2\n\"birthday\": 2\n\"compeers\": 2\n\"1596\": 2\n\"maliciously\": 2\n\"Extended\": 2\n\"equipage\": 2\n\"Travellers\": 2\n\"Carriers\": 2\n\"1594\": 2\n\"Theirs\": 2\n\"Drawers\": 2\n\"1593\": 2\n\"scurrilous\": 2\n\"procur\": 2\n\"bride-bed\": 2\n\"corrupting\": 2\n\"pelleted\": 2\n\"Depriv\": 2\n\"Dardan\": 2\n\"gulls\": 2\n\"grinding\": 2\n\"smite\": 2\n\"leavening\": 2\n\"Dissolve\": 2\n\"ertop\": 2\n\"Pelion\": 2\n\"chin-\": 2\n\"Troilus-\": 2\n\"reave\": 2\n\"hacks\": 2\n\"Grapples\": 2\n\"would-\": 2\n\"ungain\": 2\n\"largeness\": 2\n\"(with\": 2\n\"ties\": 2\n\"Archibald\": 2\n\"Valour\": 2\n\"boils\": 2\n\"strikest\": 2\n\"Proserpina\": 2\n\"superficially\": 2\n\"conduce\": 2\n\"Priamus\": 2\n\"elephant\": 2\n\"bone-ache\": 2\n\"knower\": 2\n\"eclips\": 2\n\"appertainings\": 2\n\"pash\": 2\n\"indiscretion\": 2\n\"tickles\": 2\n\"a-field\": 2\n\"nectar\": 2\n\"ducks\": 2\n\"swains\": 2\n\"Pandars\": 2\n\"great-siz\": 2\n\"deeps\": 2\n\"slides\": 2\n\"Reprove\": 2\n\"Fo\": 2\n\"fo\": 2\n\"prompted\": 2\n\"tisick\": 2\n\"Florentines\": 2\n\"Finger\": 2\n\"thrones\": 2\n\"ORSINO\": 2\n\"withdrew\": 2\n\"harping\": 2\n\"Sweep\": 2\n\"1591\": 2\n\"BELCH\": 2\n\"Soundly\": 2\n\"Eye\": 2\n\"forgetting\": 2\n\"supervise\": 2\n\"Clouds\": 2\n\"FESTE\": 2\n\"villanies\": 2\n\"comma\": 2\n\"gainer\": 2\n\"hard-\": 2\n\"suit-\": 2\n\"amities\": 2\n\"Aguecheek\": 2\n\"Belch\": 2\n\"lameness\": 2\n\"accost\": 2\n\"bear-baiting\": 2\n\"pestiferous\": 2\n\"Tug\": 2\n\"Horse\": 2\n\"gagg\": 2\n\"squash\": 2\n\"schedules\": 2\n\"debatement\": 2\n\"dimension\": 2\n\"Messaline\": 2\n\"distractedly\": 2\n\"whine\": 2\n\"tributaries\": 2\n\"epistles\": 2\n\"opal\": 2\n\"headsman\": 2\n\"practising\": 2\n\"shriving\": 2\n\"insinuation\": 2\n\"vouchsafed\": 2\n\"enchantment\": 2\n\"Thrown\": 2\n\"Vent\": 2\n\"retrograde\": 2\n\"another-\": 2\n\"notoriously\": 2\n\"agone\": 2\n\"Roses\": 2\n\"cesse\": 2\n\"performs\": 2\n\"metals\": 2\n\"Favours\": 2\n\"upshot\": 2\n\"chough\": 2\n\"dancer\": 2\n\"landlord\": 2\n\"Unmuffling\": 2\n\"sultry\": 2\n\"presenteth\": 2\n\"lieutenantry\": 2\n\"heart-sore\": 2\n\"metamorphis\": 2\n\"Exceedingly\": 2\n\"fruitfully\": 2\n\"supernatural\": 2\n\"Heavy\": 2\n\"Panthino\": 2\n\"infusion\": 2\n\"squares\": 2\n\"flights\": 2\n\"infallibly\": 2\n\"corded\": 2\n\"Northgate\": 2\n\"Inprimis\": 2\n\"Tune\": 2\n\"leaky\": 2\n\"passenger\": 2\n\"want-\": 2\n\"despiseth\": 2\n\"felicity\": 2\n\"displeasures\": 2\n\"Exchange\": 2\n\"impon\": 2\n\"ascribe\": 2\n\"sworder\": 2\n\"Spurio\": 2\n\"flags\": 2\n\"captainship\": 2\n\"Frighted\": 2\n\"assigns\": 2\n\"disdaineth\": 2\n\"XIII\": 2\n\"springe\": 2\n\"Thyreus\": 2\n\"perjure\": 2\n\"endowed\": 2\n\"(They\": 2\n\"germane\": 2\n\"unheard\": 2\n\"hazarded\": 2\n\"redeliver\": 2\n\"Impossible\": 2\n\"cannoneer\": 2\n\"by-gone\": 2\n\"Twenty-three\": 2\n\"allowing\": 2\n\"rfull\": 2\n\"lessens\": 2\n\"bevy\": 2\n\"eyebrows\": 2\n\"yesty\": 2\n\"salutes\": 2\n\"fann\": 2\n\"Conceiving\": 2\n\"casting\": 2\n\"myrtle\": 2\n\"barne\": 2\n\"roared\": 2\n\"darkest\": 2\n\"daffodils\": 2\n\"Autolycus\": 2\n\"XII\": 2\n\"horseman\": 2\n\"prig\": 2\n\"gillyvors\": 2\n\"repays\": 2\n\"Mopsa\": 2\n\"tape\": 2\n\"augury\": 2\n\"asks\": 2\n\"horseback\": 2\n\"pheasant\": 2\n\"ston\": 2\n\"assisted\": 2\n\"remained\": 2\n\"levelled\": 2\n````",
    "timestamp": "2025-05-23T16:33:31.111841",
    "tags": [],
    "severity": "high",
    "services_affected": [
      "api",
      "web",
      "database"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "kubernetes",
      "aws",
      "azure",
      "elasticsearch",
      "kafka",
      "rabbitmq",
      "jenkins"
    ],
    "failure_pattern": "resource_exhaustion",
    "timeline_events": [],
    "blast_radius": "global",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 0.96
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/chaconnewu/awesome-augmented/blob/627464897f6e6e5f64d677e977b27872d4620c54/original_awesomes/awesome-malware-analysis.md",
    "title": "awesome-malware-analysis.md",
    "content": "# Awesome Malware Analysis\n\n[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)\n[![Link Status](https://travis-ci.org/rshipp/awesome-malware-analysis.svg?branch=master)](https://travis-ci.org/rshipp/awesome-malware-analysis)\n\nA curated list of awesome malware analysis tools and resources. Inspired by\n[awesome-python](https://github.com/vinta/awesome-python) and\n[awesome-php](https://github.com/ziadoz/awesome-php).\n\n- [Awesome Malware Analysis](#awesome-malware-analysis)\n    - [Malware Collection](#malware-collection)\n        - [Anonymizers](#anonymizers)\n        - [Honeypots](#honeypots)\n        - [Malware Corpora](#malware-corpora)\n    - [Open Source Threat Intelligence](#open-source-threat-intelligence)\n        - [Tools](#tools)\n        - [Other Resources](#other-resources)\n    - [Detection and Classification](#detection-and-classification)\n    - [Online Scanners and Sandboxes](#online-scanners-and-sandboxes)\n    - [Domain Analysis](#domain-analysis)\n    - [Browser Malware](#browser-malware)\n    - [Documents and Shellcode](#documents-and-shellcode)\n    - [File Carving](#file-carving)\n    - [Deobfuscation](#deobfuscation)\n    - [Debugging and Reverse Engineering](#debugging-and-reverse-engineering)\n    - [Network](#network)\n    - [Memory Forensics](#memory-forensics)\n    - [Windows Artifacts](#windows-artifacts)\n    - [Storage and Workflow](#storage-and-workflow)\n    - [Miscellaneous](#miscellaneous)\n- [Resources](#resources)\n    - [Books](#books)\n    - [Twitter](#twitter)\n    - [Other](#other)\n- [Related Awesome Lists](#related-awesome-lists)\n- [Contributing](#contributing)\n- [Thanks](#thanks)\n\n---\n\n## Malware Collection\n\n### Anonymizers\n\n*Web traffic anonymizers for analysts.*\n\n* [Anonymouse.org](http://anonymouse.org/) - A free, web based anonymizer.\n* [OpenVPN](https://openvpn.net/) - VPN software and hosting solutions.\n* [Privoxy](http://www.privoxy.org/) - An open source proxy server with some\n  privacy features.\n* [Tor](https://www.torproject.org/) - The Onion Router, for browsing the web\n  without leaving traces of the client IP.\n\n### Honeypots\n\n*Trap and collect your own samples.*\n\n* [Conpot](https://github.com/mushorg/conpot) - ICS/SCADA honeypot.\n* [Cowrie](https://github.com/micheloosterhof/cowrie) - SSH honeypot, based\n  on Kippo.\n* [Dionaea](http://dionaea.carnivore.it/) - Honeypot designed to trap\n  malware.\n* [Glastopf](https://github.com/mushorg/glastopf) - Web application honeypot.\n* [Honeyd](http://www.honeyd.org/) - Create a virtual honeynet.\n* [HoneyDrive](http://bruteforce.gr/honeydrive) - Honeypot bundle Linux distro.\n* [Mnemosyne](https://github.com/johnnykv/mnemosyne) - A normalizer for\n  honeypot data; supports Dionaea.\n* [Thug](https://github.com/buffer/thug) - Low interaction honeyclient, for\n  investigating malicious websites.\n\n### Malware Corpora\n\n*Malware samples collected for analysis.*\n\n* [Clean MX](http://support.clean-mx.de/clean-mx/viruses.php) - Realtime\n  database of malware and malicious domains.\n* [Contagio](http://contagiodump.blogspot.com/) - A collection of recent\n  malware samples and analyses.\n* [Exploit Database](https://www.exploit-db.com/) - Exploit and shellcode\n  samples.\n* [Malshare](http://malshare.com) - Large repository of malware actively\n  scrapped from malicious sites.\n* [maltrieve](https://github.com/krmaxwell/maltrieve) - Retrieve malware\n  samples directly from a number of online sources.\n* [MalwareDB](http://malwaredb.malekal.com/) - Malware samples repository.\n* [Open Malware Project](http://openmalware.org/) - Sample information and\n  downloads. Formerly Offensive Computing.\n* [theZoo](https://github.com/ytisf/theZoo) - Live malware samples for\n  analysts.\n* [ViruSign](http://www.virusign.com/) - Malware database that detected by\n  many anti malware programs except ClamAV.\n* [VirusShare](https://virusshare.com/) - Malware repository, registration\n  required.\n* [Zeltser's Sources](https://zeltser.com/malware-sample-sources/) - A list\n  of malware sample sources put together by Lenny Zeltser.\n* [Zeus Source Code](https://github.com/Visgean/Zeus) - Source for the Zeus\n  trojan leaked in 2011.\n\n## Open Source Threat Intelligence\n\n### Tools\n\n*Harvest and analyze IOCs.*\n\n* [AbuseHelper](https://github.com/abusesa/abusehelper) - An open-source\n  framework for receiving and redistributing abuse feeds and threat intel.\n* [AlienVault Open Threat Exchange](https://otx.alienvault.com/) - Share and\n  collaborate in developing Threat Intelligence.\n* [Combine](https://github.com/mlsecproject/combine) - Tool to gather Threat\n  Intelligence indicators from publicly available sources.\n* [IntelMQ](https://www.enisa.europa.eu/topics/csirt-cert-services/community-projects/incident-handling-automation) -\n  A tool for CERTs for processing incident data using a message queue.\n* [IOC Editor](https://www.fireeye.com/services/freeware/ioc-editor.html) -\n  A free editor for XML IOC files.\n* [ioc_writer](https://github.com/mandiant/ioc_writer) - Python library for\n  working with OpenIOC objects, from Mandiant.\n* [Massive Octo Spice](https://github.com/csirtgadgets/massive-octo-spice) -\n  Previously known as CIF (Collective Intelligence Framework). Aggregates IOCs\n  from various lists. Curated by the [CSIRT Gadgets Foundation](http://csirtgadgets.org/collective-intelligence-framework).\n* [MISP](https://github.com/MISP/MISP) - Malware Information Sharing\n  Platform curated by [The MISP Project](http://www.misp-project.org/).\n* [PassiveTotal](https://www.passivetotal.org/) - Research, connect, tag and\n  share IPs and domains.\n* [PyIOCe](https://github.com/pidydx/PyIOCe) - A Python OpenIOC editor.\n* [threataggregator](https://github.com/jpsenior/threataggregator) -\n  Aggregates security threats from a number of sources, including some of\n  those listed below in [other resources](#other-resources).\n* [ThreatCrowd](https://www.threatcrowd.org/) - A search engine for threats,\n  with graphical visualization.\n* [ThreatTracker](https://github.com/michael-yip/ThreatTracker) - A Python\n  script to monitor and generate alerts based on IOCs indexed by a set of\n  Google Custom Search Engines.\n* [TIQ-test](https://github.com/mlsecproject/tiq-test) - Data visualization\n  and statistical analysis of Threat Intelligence feeds.\n\n### Other Resources\n\n*Threat intelligence and IOC resources.*\n\n* [Autoshun](https://www.autoshun.org/) ([list](https://www.autoshun.org/files/shunlist.csv)) -\n  Snort plugin and blocklist.\n* [Bambenek Consulting Feeds](http://osint.bambenekconsulting.com/feeds/) -\n  OSINT feeds based on malicious DGA algorithms.\n* [Fidelis Barncat](https://www.fidelissecurity.com/resources/fidelis-barncat) -\n  Extensive malware config database (must request access).\n* [CI Army](http://cinsscore.com/) ([list](http://cinsscore.com/list/ci-badguys.txt)) -\n  Network security blocklists.\n* [Critical Stack- Free Intel Market](https://intel.criticalstack.com) - Free\n  intel aggregator with deduplication featuring 90+ feeds and over 1.2M indicators.\n* [CRDF ThreatCenter](http://threatcenter.crdf.fr/) - List of new threats detected\n  by CRDF anti-malware.\n* [FireEye IOCs](https://github.com/fireeye/iocs) - Indicators of Compromise\n  shared publicly by FireEye.\n* [FireHOL IP Lists](https://iplists.firehol.org/) - Analytics for 350+ IP lists\n  with a focus on attacks, malware and abuse. Evolution, Changes History,\n  Country Maps, Age of IPs listed, Retention Policy, Overlaps.\n* [hpfeeds](https://github.com/rep/hpfeeds) - Honeypot feed protocol.\n* [Internet Storm Center (DShield)](https://isc.sans.edu/) - Diary and\n  searchable incident database, with a web [API](https://dshield.org/api/)\n  ([unofficial Python library](https://github.com/rshipp/python-dshield)).\n* [malc0de](http://malc0de.com/database/) - Searchable incident database.\n* [Malware Domain List](http://www.malwaredomainlist.com/) - Search and share\n  malicious URLs.\n* [OpenIOC](http://openioc.org/) - Framework for sharing threat intelligence.\n* [Palevo Blocklists](https://palevotracker.abuse.ch/blocklists.php) - Botnet\n  C&C blocklists.\n* [Proofpoint Threat Intelligence (formerly Emerging Threats)](https://www.proofpoint.com/us/threat-intelligence-overview) -\n  Rulesets and more.\n* [STIX - Structured Threat Information eXpression](http://stixproject.github.io) -\n  Standardized language to represent and share cyber threat information.\n  Related efforts from [MITRE](https://www.mitre.org/):\n  - [CAPEC - Common Attack Pattern Enumeration and Classification](http://capec.mitre.org/)\n  - [CybOX - Cyber Observables eXpression](http://cyboxproject.github.io)\n  - [MAEC - Malware Attribute Enumeration and Characterization](http://maec.mitre.org/)\n  - [TAXII - Trusted Automated eXchange of Indicator Information](http://taxiiproject.github.io)\n* [threatRECON](https://threatrecon.co/) - Search for indicators, up to 1000\n  free per month.\n* [Yara rules](https://github.com/Yara-Rules/rules) - Yara rules repository.\n* [ZeuS Tracker](https://zeustracker.abuse.ch/blocklist.php) - ZeuS\n  blocklists.\n\n## Detection and Classification\n\n*Antivirus and other malware identification tools*\n\n* [AnalyzePE](https://github.com/hiddenillusion/AnalyzePE) - Wrapper for a\n  variety of tools for reporting on Windows PE files.\n* [chkrootkit](http://www.chkrootkit.org/) - Local Linux rootkit detection.\n* [ClamAV](http://www.clamav.net/) - Open source antivirus engine.\n* [Detect-It-Easy](https://github.com/horsicq/Detect-It-Easy) - A program for\n  determining types of files.\n* [ExifTool](http://www.sno.phy.queensu.ca/~phil/exiftool/) - Read, write and\n  edit file metadata.\n* [hashdeep](https://github.com/jessek/hashdeep) - Compute digest hashes with\n  a variety of algorithms.\n* [Loki](https://github.com/Neo23x0/Loki) - Host based scanner for IOCs.\n* [Malfunction](https://github.com/Dynetics/Malfunction) - Catalog and\n  compare malware at a function level.\n* [MASTIFF](https://github.com/KoreLogicSecurity/mastiff) - Static analysis\n  framework.\n* [MultiScanner](https://github.com/MITRECND/multiscanner) - Modular file\n  scanning/analysis framework\n* [nsrllookup](https://github.com/rjhansen/nsrllookup) - A tool for looking\n  up hashes in NIST's National Software Reference Library database.\n* [packerid](http://handlers.sans.org/jclausing/packerid.py) - A cross-platform\n  Python alternative to PEiD.\n* [PEV](http://pev.sourceforge.net/) - A multiplatform toolkit to work with PE\n  files, providing feature-rich tools for proper analysis of suspicious binaries.\n* [Rootkit Hunter](http://rkhunter.sourceforge.net/) - Detect Linux rootkits.\n* [ssdeep](http://ssdeep.sourceforge.net/) - Compute fuzzy hashes.\n* [totalhash.py](https://gist.github.com/gleblanc1783/3c8e6b379fa9d646d401b96ab5c7877f) - Python script\n  for easy searching of the [TotalHash.cymru.com](https://totalhash.cymru.com/) database.\n* [TrID](http://mark0.net/soft-trid-e.html) - File identifier.\n* [YARA](https://plusvic.github.io/yara/) - Pattern matching tool for\n  analysts.\n* [Yara rules generator](https://github.com/Neo23x0/yarGen) - Generate\n  yara rules based on a set of malware samples. Also contains a good\n  strings DB to avoid false positives.\n\n## Online Scanners and Sandboxes\n\n*Web-based multi-AV scanners, and malware sandboxes for automated analysis.*\n* [APK Analyzer](https://www.apk-analyzer.net/) - Free dynamic analysis of APKs.\n* [AndroTotal](https://andrototal.org/) - Free online analysis of APKs\n  against multiple mobile antivirus apps.\n* [AVCaesar](https://avcaesar.malware.lu/) - Malware.lu online scanner and\n  malware repository.\n* [Cryptam](http://www.cryptam.com/) - Analyze suspicious office documents.\n* [Cuckoo Sandbox](https://cuckoosandbox.org/) - Open source, self hosted\n  sandbox and automated analysis system.\n* [cuckoo-modified](https://github.com/brad-accuvant/cuckoo-modified) - Modified\n  version of Cuckoo Sandbox released under the GPL. Not merged upstream due to\n  legal concerns by the author.\n* [DeepViz](https://www.deepviz.com/) - Multi-format file analyzer with\n  machine-learning classification.\n* [detux](https://github.com/detuxsandbox/detux/) - A sandbox developed to do traffic analysis\n  of Linux malwares and capturing IOCs.\n* [Document Analyzer](https://www.document-analyzer.net/) - Free dynamic analysis of DOC and PDF files.\n* [DRAKVUF](https://github.com/tklengyel/drakvuf) - Dynamic malware analysis\n  system.\n* [File Analyzer](https://www.file-analyzer.net/) - Free dynamic analysis of PE files.\n* [firmware.re](http://firmware.re/) - Unpacks, scans and analyzes almost any firmware package.\n* [Hybrid Analysis](https://www.hybrid-analysis.com/) - Online malware\n  analysis tool, powered by VxSandbox.\n* [IRMA](http://irma.quarkslab.com/) - An asynchronous and customizable\n  analysis platform for suspicious files.\n* [Joe Sandbox](https://www.joesecurity.org) - Deep malware analysis with Joe Sandbox.\n* [Jotti](https://virusscan.jotti.org/en) - Free online multi-AV scanner.\n* [Limon](https://github.com/monnappa22/Limon) - Sandbox for Analyzing Linux Malwares\n* [Malheur](https://github.com/rieck/malheur) - Automatic sandboxed analysis\n  of malware behavior.\n* [Malwr](https://malwr.com/) - Free analysis with an online Cuckoo Sandbox\n  instance.\n* [MASTIFF Online](https://mastiff-online.korelogic.com/) - Online static\n  analysis of malware.\n* [Metadefender.com](https://www.metadefender.com) - Scan a file, hash or IP\n  address for malware (free)\n* [NetworkTotal](https://www.networktotal.com/index.html) - A service that analyzes\n  pcap files and facilitates the quick detection of viruses, worms, trojans, and all\n  kinds of malware using Suricata configured with EmergingThreats Pro.\n* [Noriben](https://github.com/Rurik/Noriben) - Uses Sysinternals Procmon to\n  collect information about malware in a sandboxed environment.\n* [PDF Examiner](http://www.pdfexaminer.com/) - Analyse suspicious PDF files.\n* [Recomposer](https://github.com/secretsquirrel/recomposer) - A helper\n  script for safely uploading binaries to sandbox sites.\n* [SEE](https://github.com/F-Secure/see) - Sandboxed Execution Environment (SEE)\n  is a framework for building test automation in secured Environments.\n* [URL Analyzer](https://www.url-analyzer.net/) - Free dynamic analysis of URL files.\n* [VirusTotal](https://www.virustotal.com/) - Free online analysis of malware\n  samples and URLs\n* [Zeltser's List](https://zeltser.com/automated-malware-analysis/) - Free\n  automated sandboxes and services, compiled by Lenny Zeltser.\n\n## Domain Analysis\n\n*Inspect domains and IP addresses.*\n\n* [Desenmascara.me](http://desenmascara.me) - One click tool to retrieve as\n  much metadata as possible for a website and to assess its good standing.\n* [Dig](http://networking.ringofsaturn.com/) - Free online dig and other\n  network tools.\n* [dnstwist](https://github.com/elceef/dnstwist) - Domain name permutation\n  engine for detecting typo squatting, phishing and corporate espionage.\n* [IPinfo](https://github.com/hiddenillusion/IPinfo) - Gather information\n  about an IP or domain by searching online resources.\n* [Machinae](https://github.com/hurricanelabs/machinae) - OSINT tool for\n  gathering information about URLs, IPs, or hashes. Similar to Automator.\n* [mailchecker](https://github.com/FGRibreau/mailchecker) - Cross-language\n  temporary email detection library.\n* [MaltegoVT](https://github.com/michael-yip/MaltegoVT) - Maltego transform\n  for the VirusTotal API. Allows domain/IP research, and searching for file\n  hashes and scan reports.\n* [SenderBase](http://www.senderbase.org/) - Search for IP, domain or network\n  owner.\n* [SpamCop](https://www.spamcop.net/bl.shtml) - IP based spam block list.\n* [SpamHaus](https://www.spamhaus.org/lookup/) - Block list based on\n  domains and IPs.\n* [Sucuri SiteCheck](https://sitecheck.sucuri.net/) - Free Website Malware\n  and Security Scanner.\n* [TekDefense Automater](http://www.tekdefense.com/automater/) - OSINT tool\n  for gathering information about URLs, IPs, or hashes.\n* [URLQuery](http://urlquery.net/) - Free URL Scanner.\n* [Whois](https://whois.domaintools.com/) - DomainTools free online whois\n  search.\n* [Zeltser's List](https://zeltser.com/lookup-malicious-websites/) - Free\n  online tools for researching malicious websites, compiled by Lenny Zeltser.\n* [ZScalar Zulu](http://zulu.zscaler.com/#) - Zulu URL Risk Analyzer.\n\n## Browser Malware\n\n*Analyze malicious URLs. See also the [domain analysis](#domain-analysis) and\n[documents and shellcode](#documents-and-shellcode) sections.*\n\n* [Firebug](http://getfirebug.com/) - Firefox extension for web development.\n* [Java Decompiler](http://jd.benow.ca/) - Decompile and inspect Java apps.\n* [Java IDX Parser](https://github.com/Rurik/Java_IDX_Parser/) - Parses Java\n  IDX cache files.\n* [JSDetox](http://www.relentless-coding.com/projects/jsdetox/) - JavaScript\n  malware analysis tool.\n* [jsunpack-n](https://github.com/urule99/jsunpack-n) - A javascript\n  unpacker that emulates browser functionality.\n* [Krakatau](https://github.com/Storyyeller/Krakatau) - Java decompiler,\n  assembler, and disassembler.\n* [Malzilla](http://malzilla.sourceforge.net/) - Analyze malicious web pages.\n* [RABCDAsm](https://github.com/CyberShadow/RABCDAsm) - A \"Robust\n  ActionScript Bytecode Disassembler.\"\n* [swftools](http://www.swftools.org/) - Tools for working with Adobe Flash\n  files.\n* [xxxswf](http://hooked-on-mnemonics.blogspot.com/2011/12/xxxswfpy.html) - A\n  Python script for analyzing Flash files.\n\n## Documents and Shellcode\n\n*Analyze malicious JS and shellcode from PDFs and Office documents. See also\nthe [browser malware](#browser-malware) section.*\n\n* [AnalyzePDF](https://github.com/hiddenillusion/AnalyzePDF) - A tool for\n  analyzing PDFs and attempting to determine whether they are malicious.\n* [diStorm](http://www.ragestorm.net/distorm/) - Disassembler for analyzing\n  malicious shellcode.\n* [JS Beautifier](http://jsbeautifier.org/) - JavaScript unpacking and deobfuscation.\n* [JS Deobfuscator](http://www.kahusecurity.com/2015/new-javascript-deobfuscator-tool/) -\n  Deobfuscate simple Javascript that use eval or document.write to conceal\n  its code.\n* [libemu](http://libemu.carnivore.it/) - Library and tools for x86 shellcode\n  emulation.\n* [malpdfobj](https://github.com/9b/malpdfobj) - Deconstruct malicious PDFs\n  into a JSON representation.\n* [OfficeMalScanner](http://www.reconstructer.org/code.html) - Scan for\n  malicious traces in MS Office documents.\n* [olevba](http://www.decalage.info/python/olevba) - A script for parsing OLE\n  and OpenXML documents and extracting useful information.\n* [Origami PDF](https://code.google.com/archive/p/origami-pdf) - A tool for\n  analyzing malicious PDFs, and more.\n* [PDF Tools](https://blog.didierstevens.com/programs/pdf-tools/) - pdfid,\n  pdf-parser, and more from Didier Stevens.\n* [PDF X-Ray Lite](https://github.com/9b/pdfxray_lite) - A PDF analysis tool,\n  the backend-free version of PDF X-RAY.\n* [peepdf](http://eternal-todo.com/tools/peepdf-pdf-analysis-tool) - Python\n  tool for exploring possibly malicious PDFs.\n* [QuickSand](https://www.quicksand.io/) - QuickSand is a compact C framework\n  to analyze suspected malware documents to identify exploits in streams of different\n  encodings and to locate and extract embedded executables.\n* [Spidermonkey](https://developer.mozilla.org/en-US/docs/Mozilla/Projects/SpiderMonkey) -\n  Mozilla's JavaScript engine, for debugging malicious JS.\n\n## File Carving\n\n*For extracting files from inside disk and memory images.*\n\n* [bulk_extractor](https://github.com/simsong/bulk_extractor) - Fast file\n  carving tool.\n* [EVTXtract](https://github.com/williballenthin/EVTXtract) - Carve Windows\n  Event Log files from raw binary data.\n* [Foremost](http://foremost.sourceforge.net/) - File carving tool designed\n  by the US Air Force.\n* [Hachoir](https://bitbucket.org/haypo/hachoir) - A collection of Python\n  libraries for dealing with binary files.\n* [Scalpel](https://github.com/sleuthkit/scalpel) - Another data carving\n  tool.\n\n## Deobfuscation\n\n*Reverse XOR and other code obfuscation methods.*\n\n* [Balbuzard](https://bitbucket.org/decalage/balbuzard/wiki/Home) - A malware\n  analysis tool for reversing obfuscation (XOR, ROL, etc) and more.\n* [de4dot](https://github.com/0xd4d/de4dot) - .NET deobfuscator and\n  unpacker.\n* [ex_pe_xor](http://hooked-on-mnemonics.blogspot.com/2014/04/expexorpy.html)\n  & [iheartxor](http://hooked-on-mnemonics.blogspot.com/p/iheartxor.html) -\n  Two tools from Alexander Hanel for working with single-byte XOR encoded\n  files.\n* [FLOSS](https://github.com/fireeye/flare-floss) - The FireEye Labs Obfuscated\n  String Solver uses advanced static analysis techniques to automatically\n  deobfuscate strings from malware binaries.\n* [NoMoreXOR](https://github.com/hiddenillusion/NoMoreXOR) - Guess a 256 byte\n  XOR key using frequency analysis.\n* [PackerAttacker](https://github.com/BromiumLabs/PackerAttacker) - A generic\n  hidden code extractor for Windows malware.\n* [unpacker](https://github.com/malwaremusings/unpacker/) - Automated malware\n  unpacker for Windows malware based on WinAppDbg.\n* [unxor](https://github.com/tomchop/unxor/) - Guess XOR keys using\n  known-plaintext attacks.\n* [VirtualDeobfuscator](https://github.com/jnraber/VirtualDeobfuscator) -\n  Reverse engineering tool for virtualization wrappers.\n* [XORBruteForcer](http://eternal-todo.com/var/scripts/xorbruteforcer) -\n  A Python script for brute forcing single-byte XOR keys.\n* [XORSearch & XORStrings](https://blog.didierstevens.com/programs/xorsearch/) -\n  A couple programs from Didier Stevens for finding XORed data.\n* [xortool](https://github.com/hellman/xortool) - Guess XOR key length, as\n  well as the key itself.\n\n## Debugging and Reverse Engineering\n\n*Disassemblers, debuggers, and other static and dynamic analysis tools.*\n\n* [angr](https://github.com/angr/angr) - Platform-agnostic binary analysis\n  framework developed at UCSB's Seclab.\n* [bamfdetect](https://github.com/bwall/bamfdetect) - Identifies and extracts\n  information from bots and other malware.\n* [BARF](https://github.com/programa-stic/barf-project) - Multiplatform, open\n  source Binary Analysis and Reverse engineering Framework.\n* [binnavi](https://github.com/google/binnavi) - Binary analysis IDE for\n  reverse engineering based on graph visualization.\n* [Binwalk](http://binwalk.org/) - Firmware analysis tool.\n* [Bokken](http://www.bokken.re/) - GUI for Pyew and Radare.\n* [Capstone](https://github.com/aquynh/capstone) - Disassembly framework for\n  binary analysis and reversing, with support for many architectures and\n  bindings in several languages.\n* [codebro](https://github.com/hugsy/codebro) - Web based code browser using\n  clang to provide basic code analysis.\n* [dnSpy](https://github.com/0xd4d/dnSpy) - .NET assembly editor, decompiler\n  and debugger.\n* [Evan's Debugger (EDB)](http://codef00.com/projects#debugger) - A\n  modular debugger with a Qt GUI.\n* [Fibratus](https://github.com/rabbitstack/fibratus) - Tool for exploration\n  and tracing of the Windows kernel.\n* [GDB](http://www.sourceware.org/gdb/) - The GNU debugger.\n* [GEF](https://github.com/hugsy/gef) - GDB Enhanced Features, for exploiters\n  and reverse engineers.\n* [hackers-grep](https://github.com/codypierce/hackers-grep) - A utility to\n  search for strings in PE executables including imports, exports, and debug\n  symbols.\n* [IDA Pro](https://www.hex-rays.com/products/ida/index.shtml) - Windows\n  disassembler and debugger, with a free evaluation version.\n* [Immunity Debugger](http://debugger.immunityinc.com/) - Debugger for\n  malware analysis and more, with a Python API.\n* [ltrace](http://ltrace.org/) - Dynamic analysis for Linux executables.\n* [objdump](https://en.wikipedia.org/wiki/Objdump) - Part of GNU binutils,\n  for static analysis of Linux binaries.\n* [OllyDbg](http://www.ollydbg.de/) - An assembly-level debugger for Windows\n  executables.\n* [PANDA](https://github.com/moyix/panda) - Platform for Architecture-Neutral Dynamic Analysis\n* [PEDA](https://github.com/longld/peda) - Python Exploit Development\n  Assistance for GDB, an enhanced display with added commands.\n* [pestudio](https://winitor.com/) - Perform static analysis of Windows\n  executables.\n* [plasma](https://github.com/joelpx/plasma) - Interactive disassembler for\n  x86/ARM/MIPS.\n* [PPEE (puppy)](https://www.mzrst.com/) - A Professional PE file Explorer for\n  reversers, malware researchers and those who want to statically inspect PE\n  files in more detail.\n* [Process Monitor](https://technet.microsoft.com/en-us/sysinternals/bb896645.aspx) -\n  Advanced monitoring tool for Windows programs.\n* [Pyew](https://github.com/joxeankoret/pyew) - Python tool for malware\n  analysis.\n* [Radare2](http://www.radare.org/r/) - Reverse engineering framework, with\n  debugger support.\n* [RetDec](https://retdec.com/) - Retargetable machine-code decompiler with an\n  [online decompilation service](https://retdec.com/decompilation/) and\n  [API](https://retdec.com/api/) that you can use in your tools.\n* [ROPMEMU](https://github.com/vrtadmin/ROPMEMU) - A framework to analyze, dissect\n  and decompile complex code-reuse attacks.\n* [SMRT](https://github.com/pidydx/SMRT) - Sublime Malware Research Tool, a\n  plugin for Sublime 3 to aid with malware analyis.\n* [strace](https://sourceforge.net/projects/strace/) - Dynamic analysis for\n  Linux executables.\n* [Triton](http://triton.quarkslab.com/) - A dynamic binary analysis (DBA) framework.\n* [Udis86](https://github.com/vmt/udis86) - Disassembler library and tool\n  for x86 and x86_64.\n* [Vivisect](https://github.com/vivisect/vivisect) - Python tool for\n  malware analysis.\n* [X64dbg](https://github.com/x64dbg/) - An open-source x64/x32 debugger for windows.\n\n## Network\n\n*Analyze network interactions.*\n\n* [Bro](https://www.bro.org) - Protocol analyzer that operates at incredible\n  scale; both file and network protocols.\n* [BroYara](https://github.com/hempnall/broyara) - Use Yara rules from Bro.\n* [CapTipper](https://github.com/omriher/CapTipper) -  Malicious HTTP traffic\n  explorer.\n* [chopshop](https://github.com/MITRECND/chopshop) - Protocol analysis and\n  decoding framework.\n* [Fiddler](http://www.telerik.com/fiddler) - Intercepting web proxy designed\n  for \"web debugging.\"\n* [Hale](https://github.com/pjlantz/Hale) - Botnet C&C monitor.\n* [Haka](http://www.haka-security.org/) - An open source security oriented\n  language for describing protocols and applying security policies on (live)\n  captured traffic.\n* [INetSim](http://www.inetsim.org/) - Network service emulation, useful when\n  building a malware lab.\n* [Laika BOSS](https://github.com/lmco/laikaboss) - Laika BOSS is a file-centric\n  malware analysis and intrusion detection system.\n* [Malcom](https://github.com/tomchop/malcom) - Malware Communications\n  Analyzer.\n* [Maltrail](https://github.com/stamparm/maltrail) - A malicious traffic\n  detection system, utilizing publicly available (black)lists containing\n  malicious and/or generally suspicious trails and featuring an reporting\n  and analysis interface.\n* [mitmproxy](https://mitmproxy.org/) - Intercept network traffic on the fly.\n* [Moloch](https://github.com/aol/moloch) - IPv4 traffic capturing, indexing\n  and database system.\n* [NetworkMiner](http://www.netresec.com/?page=NetworkMiner) - Network\n  forensic analysis tool, with a free version.\n* [ngrep](http://ngrep.sourceforge.net/) - Search through network traffic\n  like grep.\n* [PcapViz](https://github.com/mateuszk87/PcapViz) - Network topology and traffic visualizer.\n* [Tcpdump](http://www.tcpdump.org/) - Collect network traffic.\n* [tcpick](http://tcpick.sourceforge.net/) - Trach and reassemble TCP streams\n  from network traffic.\n* [tcpxtract](http://tcpxtract.sourceforge.net/) - Extract files from network\n  traffic.\n* [Wireshark](https://www.wireshark.org/) - The network traffic analysis\n  tool.\n\n## Memory Forensics\n\n*Tools for dissecting malware in memory images or running systems.*\n\n* [DAMM](https://github.com/504ensicsLabs/DAMM) - Differential Analysis of\n  Malware in Memory, built on Volatility\n* [evolve](https://github.com/JamesHabben/evolve) - Web interface for the\n  Volatility Memory Forensics Framework.\n* [FindAES](http://jessekornblum.livejournal.com/269749.html) - Find AES\n  encryption keys in memory.\n* [Muninn](https://github.com/ytisf/muninn) - A script to automate portions\n  of analysis using Volatility, and create a readable report.\n* [Rekall](http://www.rekall-forensic.com/) - Memory analysis framework,\n  forked from Volatility in 2013.\n* [TotalRecall](https://github.com/sketchymoose/TotalRecall) - Script based\n  on Volatility for automating various malware analysis tasks.\n* [VolDiff](https://github.com/aim4r/VolDiff) - Run Volatility on memory\n  images before and after malware execution, and report changes.\n* [Volatility](https://github.com/volatilityfoundation/volatility) - Advanced\n  memory forensics framework.\n* [VolUtility](https://github.com/kevthehermit/VolUtility) - Web Interface for\n  Volatility Memory Analysis framework.\n* [WinDbg](https://developer.microsoft.com/en-us/windows/hardware/windows-driver-kit) -\n  Live memory inspection and kernel debugging for Windows systems.\n\n## Windows Artifacts\n\n* [AChoir](https://github.com/OMENScan/AChoir) - A live incident response\n  script for gathering Windows artifacts.\n* [python-evt](https://github.com/williballenthin/python-evt) - Python\n  library for parsing Windows Event Logs.\n* [python-registry](http://www.williballenthin.com/registry/) - Python\n  library for parsing registry files.\n* [RegRipper](http://brettshavers.cc/index.php/brettsblog/tags/tag/regripper/)\n  ([GitHub](https://github.com/keydet89/RegRipper2.8)) -\n  Plugin-based registry analysis tool.\n\n## Storage and Workflow\n\n* [Aleph](https://github.com/trendmicro/aleph) - OpenSource Malware Analysis\n  Pipeline System.\n* [CRITs](https://crits.github.io/) - Collaborative Research Into Threats, a\n  malware and threat repository.\n* [Malwarehouse](https://github.com/sroberts/malwarehouse) - Store, tag, and\n  search malware.\n* [Polichombr](https://github.com/ANSSI-FR/polichombr) - A malware analysis\n  platform designed to help analysts to reverse malwares collaboratively.\n* [Viper](http://viper.li/) - A binary management and analysis framework for\n  analysts and researchers.\n\n## Miscellaneous\n\n* [al-khaser](https://github.com/LordNoteworthy/al-khaser) - A PoC malware\n  with good intentions that aimes to stress anti-malware systems.\n* [Binarly](http://www.binar.ly/search) - Search engine for bytes in a large\n  corpus of malware.\n* [DC3-MWCP](https://github.com/Defense-Cyber-Crime-Center/DC3-MWCP) -\n  The Defense Cyber Crime Center's Malware Configuration Parser framework.\n* [MalSploitBase](https://github.com/misterch0c/malSploitBase) - A database\n  containing exploits used by malware.\n* [Pafish](https://github.com/a0rtega/pafish) - Paranoid Fish, a demonstration\n  tool that employs several techniques to detect sandboxes and analysis\n  environments in the same way as malware families do.\n* [REMnux](https://remnux.org/) - Linux distribution and docker images for\n  malware reverse engineering and analysis.\n* [Santoku Linux](https://santoku-linux.com/) - Linux distribution for mobile\n  forensics, malware analysis, and security.\n\n# Resources\n\n## Books\n\n*Essential malware analysis reading material.*\n\n* [Malware Analyst's Cookbook and DVD](https://amzn.com/dp/0470613033) -\n  Tools and Techniques for Fighting Malicious Code.\n* [Practical Malware Analysis](https://amzn.com/dp/1593272901) - The Hands-On Guide\n  to Dissecting Malicious Software.\n* [The Art of Memory Forensics](https://amzn.com/dp/1118825098) - Detecting\n  Malware and Threats in Windows, Linux, and Mac Memory.\n* [The IDA Pro Book](https://amzn.com/dp/1593272898) - The Unofficial Guide\n  to the World's Most Popular Disassembler.\n\n## Twitter\n\n*Some relevant Twitter accounts.*\n\n* Adamb [@Hexacorn](https://twitter.com/Hexacorn)\n* Andrew Case [@attrc](https://twitter.com/attrc)\n* Binni Shah [@binitamshah](https://twitter.com/binitamshah)\n* Claudio [@botherder](https://twitter.com/botherder)\n* Dustin Webber [@mephux](https://twitter.com/mephux)\n* Glenn [@hiddenillusion](https://twitter.com/hiddenillusion)\n* jekil [@jekil](https://twitter.com/jekil)\n* Jurriaan Bremer [@skier_t](https://twitter.com/skier_t)\n* Lenny Zeltser [@lennyzeltser](https://twitter.com/lennyzeltser)\n* Liam Randall [@hectaman](https://twitter.com/hectaman)\n* Mark Schloesser [@repmovsb](https://twitter.com/repmovsb)\n* Michael Ligh (MHL) [@iMHLv2](https://twitter.com/iMHLv2)\n* Monnappa [@monnappa22](https://twitter.com/monnappa22)\n* Open Malware [@OpenMalware](https://twitter.com/OpenMalware)\n* Richard Bejtlich [@taosecurity](https://twitter.com/taosecurity)\n* Volatility [@volatility](https://twitter.com/volatility)\n\n## Other\n\n* [APT Notes](https://github.com/kbandla/APTnotes) - A collection of papers\n  and notes related to Advanced Persistent Threats.\n* [File Formats posters](https://github.com/corkami/pics) - Nice visualization\n  of commonly used file format (including PE & ELF).\n* [Honeynet Project](http://honeynet.org/) - Honeypot tools, papers, and\n  other resources.\n* [Kernel Mode](http://www.kernelmode.info/forum/) - An active community devoted to\n  malware analysis and kernel development.\n* [Malicious Software](https://zeltser.com/malicious-software/) - Malware\n  blog and resources by Lenny Zeltser.\n* [Malware Analysis Search](https://cse.google.com/cse/home?cx=011750002002865445766%3Apc60zx1rliu) -\n  Custom Google search engine from [Corey Harrell](journeyintoir.blogspot.com/).\n* [Malware Analysis Tutorials](http://fumalwareanalysis.blogspot.nl/p/malware-analysis-tutorials-reverse.html) -   The Malware Analysis Tutorials by Dr. Xiang Fu, a great resource for learning\n  practical malware analysis.\n* [Malware Samples and Traffic](http://malware-traffic-analysis.net/) - This\n  blog focuses on network traffic related to malware infections.\n* [Practical Malware Analysis Starter Kit](https://bluesoul.me/practical-malware-analysis-starter-kit/) -\n  This package contains most of the software referenced in the Practical Malware\n  Analysis book.\n* [RPISEC Malware Analysis](https://github.com/RPISEC/Malware) - These are the\n  course materials used in the Malware Analysis course at at Rensselaer Polytechnic\n  Institute during Fall 2015.\n* [WindowsIR: Malware](http://windowsir.blogspot.com/p/malware.html) - Harlan\n  Carvey's page on Malware.\n* [Windows Registry specification](https://github.com/msuhanov/regf/blob/master/Windows%20registry%20file%20format%20specification.md) - Windows registry file format specification.\n* [/r/csirt_tools](https://www.reddit.com/r/csirt_tools/) - Subreddit for CSIRT\n  tools and resources, with a\n  [malware analysis](https://www.reddit.com/r/csirt_tools/search?q=flair%3A%22Malware%20analysis%22&sort=new&restrict_sr=on) flair.\n* [/r/Malware](https://www.reddit.com/r/Malware) - The malware subreddit.\n* [/r/ReverseEngineering](https://www.reddit.com/r/ReverseEngineering) -\n  Reverse engineering subreddit, not limited to just malware.\n\n\n\n\n# Related Awesome Lists\n\n* [Android Security](https://github.com/ashishb/android-security-awesome)\n* [AppSec](https://github.com/paragonie/awesome-appsec)\n* [CTFs](https://github.com/apsdehal/awesome-ctf)\n* [\"Hacking\"](https://github.com/carpedm20/awesome-hacking)\n* [Honeypots](https://github.com/paralax/awesome-honeypots)\n* [Industrial Control System Security](https://github.com/hslatman/awesome-industrial-control-system-security)\n* [Incident-Response](https://github.com/meirwah/awesome-incident-response)\n* [Infosec](https://github.com/onlurking/awesome-infosec)\n* [PCAP Tools](https://github.com/caesar0301/awesome-pcaptools)\n* [Pentesting](https://github.com/enaqx/awesome-pentest)\n* [Security](https://github.com/sbilly/awesome-security)\n* [Threat Intelligence](https://github.com/hslatman/awesome-threat-intelligence)\n\n# [Contributing](CONTRIBUTING.md)\n\nPull requests and issues with suggestions are welcome! Please read the\n[CONTRIBUTING](CONTRIBUTING.md) guidelines before submitting a PR.\n\n# Thanks\n\nThis list was made possible by:\n\n* Lenny Zeltser and other contributors for developing REMnux, where I\n  found many of the tools in this list;\n* Michail Hale Ligh, Steven Adair, Blake Hartstein, and Mather Richard for\n  writing the *Malware Analyst's Cookbook*, which was a big inspiration for\n  creating the list;\n* And everyone else who has sent pull requests or suggested links to add here!\n\nThanks!\n",
    "timestamp": "2025-05-23T16:33:32.031603",
    "tags": [],
    "severity": "high",
    "services_affected": [
      "api",
      "web",
      "database",
      "cache",
      "queue",
      "monitoring"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "docker",
      "azure",
      "postgresql",
      "redis",
      "elasticsearch",
      "kafka",
      "rabbitmq",
      "nginx",
      "grafana",
      "jenkins"
    ],
    "failure_pattern": "configuration_drift",
    "timeline_events": [],
    "blast_radius": "localized",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 0.9400000000000001
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/dastergon/postmortem-templates/blob/ebdaf8f122cf1d9f5c2983b37861be038c9acc89/templates/postmortem-template-michael.kehoe.md",
    "title": "postmortem-template-michael.kehoe.md",
    "content": "> Template from: [Michael Kehoe](https://michael-kehoe.io/post/postmortem-template/)\n\n# Postmortem Template\n\n### Summary\n| Incident Summary   |   |                       |   |\n|--------------------|---|-----------------------|---|\n| Incident Number    |   | Incident Severity     |   |\n| Postmortem Date    |   | War-room Required     |   |\n| SRE Lead           |   | Developer Lead        |   |\n| Incident Mgmt Lead |   | Chaos Eng Preventable |   |\n| Postmortem Lead    |   | Recording             |   |\n\n### Postmortem Attendees\n| Name | Role | In attendence |\n|------|------|---------------|\n|      |      |               |\n|      |      |               |\n|      |      |               |\n\n### Incident Timing\n| Start Time      |       | Incident Detected By(User-reported/ Ad-hoc monitoring/ Alerting system) |      |\n|-----------------|-------|-------------------------------------------------------------------------|------|\n| Detection Time  |       | Time to Detect (TTD)                                                    |      |\n| Mitigation Time |       | Time to Mitigate (TTM)                                                  |      |\n| Resolution Time |       | Time to Resolve (TTR)                                                   |      |\n\n### Incident Timeline\n| Date/Time | Who/What | Action/ Impact |\n|-----------|----------|----------------|\n|           |          |                |\n|           |          |                |\n|           |          |                |\n\n### Impact\n\n#### End User Impact\n\n#### Infrastructure Impact\n\n#### Productivity Impact\n\n### What caused the incident?\n\n#### Trigger(s)\n\n#### Process Breakdown(s)\n\n#### Root Cause(s)\n\n### Mitigation & Resolution\n\n### Open Questions\n| Person            | Question/ Answer |\n|-------------------|------------------|\n| Q (who): A (who): |                  |\n| Q (who): A (who): |                  |\n| Q (who): A (who): |                  |\n\n### Lessons Learnt\n\n#### What went well\n\n#### What went badly\n\n#### Where did we get lucky\n\n### Action Items & Followups\n| Action Item | Type (Mitigate/ Prevent/ Process/ Other) | Who | Priority | Bug # | Due Date |\n|-------------|------------------------------------------|-----|----------|-------|----------|\n|             |                                          |     |          |       |          |\n|             |                                          |     |          |       |          |\n|             |                                          |     |          |       |          |\n\n### Supporting Documents\n",
    "timestamp": "2025-05-23T16:34:03.105532",
    "tags": [],
    "severity": "high",
    "services_affected": [
      "web",
      "monitoring"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "prometheus",
      "grafana"
    ],
    "failure_pattern": "monitoring_blind_spot",
    "timeline_events": [],
    "blast_radius": "localized",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 0.8999999999999999
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/RandomSort/postmortems/blob/70050234405a3978f53e48b24b2f477867ff2ee8/postmortem-template.md",
    "title": "postmortem-template.md",
    "content": "# Example Postmortem\n\nAdapted from: [SRE Book - Appendix D - Example Postmortem](https://landing.google.com/sre/sre-book/chapters/postmortem/)\n\nThis template is the example given in the SRE book for an example postmortem, and simply converted to Markdown. This can be used as a template for doing your own postmortems. Copy this file per postmortem, and substitute your own findings. \nOver time you can replace this example from Google with one from your own organization to better fit your integrations and way of working.\n\n# Sharespeare Sonnet++ Postmortem (incident #465)\n\n- **Date**: 2015-10-21\n- **Authors**: jennifer, martym, agoogler\n- **Status**: Complete, action items in progress\n- **Summary**: Shakespeare Search down for 66 minutes during period of very high interest in Shakespeare due to discovery of a new sonnet.\n- **Impact**: Estimated 1.21B queries lost, no revenue impact.\n- **Root Causes**: Cascading failure due to combination of exceptionally high load and a resource leak when searches failed due to terms not being in the Shakespeare corpus. The newly discovered sonnet used a word that had never before appeared in one of Shakespeare’s works, which happened to be the term users searched for. Under normal circumstances, the rate of task failures due to resource leaks is low enough to be unnoticed.\n- **Trigger**: Latent bug triggered by sudden increase in traffic.\n- **Resolution**: Directed traffic to sacrificial cluster and added 10x capacity to mitigate cascading failure. Updated index deployed, resolving interaction with latent bug. Maintaining extra capacity until surge in public interest in new sonnet passes. Resource leak identified and fix deployed.\n- **Detection**: Borgmon detected high level of HTTP 500s and paged on-call.\n\n## Action Items\n\n| **Action Item**                                                                                                                                               | **Type** | **Owner** | **Bug**              |\n|---------------------------------------------------------------------------------------------------------------------------------------------------------------|----------|-----------|----------------------|\n| Update playbook with instructions for responding to cascading failure                                                                                         | mitigate | jennifer  | n/a **DONE**         |\n| Use flux capacitor to balance load between clusters                                                                                                           | prevent  | martym    | Bug 5554823 **TODO** |\n| Schedule cascading failure test during next DiRT                                                                                                              | process  | docbrown  | n/a **TODO**         |\n| Investigate running index MR/fusion continuously                                                                                                              | prevent  | jennifer  | Bug 554824 **TODO**  |\n| Plug file descriptor leak in search ranking subsystem                                                                                                         | prevent  | agoogler  | Bug 554825 **DONE**  |\n| Add load shedding capabilities to Shakespeare search                                                                                                          | prevent  | agoogler  | Bug 554826 **TODO**  |\n| Build regression tests to ensure servers respond sanely to queries of death                                                                                   | prevent  | clarac    | Bug 5554827 **TODO** |\n| Deploy updated search ranking subsystem to prod                                                                                                               | prevent  | jennifer  | n/a **DONE**         |\n| Freeze production until 2015-11-20 due to error budget exhaustion, or seek exception due to grotesque, unbelievable, bizarre, and unprecedented circumstances | other    | docbrown  | n/a **TODO**         |\n\n## Lessons Learned\n\n### What went well\n\n- Monitoring quickly alerted us to high rate (reaching ~100%) of HTTP 500s\n- Rapidly distributed updated Shakespeare corpus to all clusters\n\n### What went wrong\n\n- We’re out of practice in responding to cascading failure\n- We exceeded our availability error budget (by several orders of magnitude) due to the exceptional surge of traffic that essentially all resulted in failures\n\n### Where we got lucky\n\n- Mailing list of Shakespeare aficionados had a copy of new sonnet available\n- Server logs had stack traces pointing to file descriptor exhaustion as cause for crash\n- Query-of-death was resolved by pushing new index containing popular search term\n\n## Timeline\n\n### 2015-10-21 (all times UTC)\n\n- 14:51 News reports that a new Shakespearean sonnet has been discovered in a Delorean’s glove compartment\n- 14:53 Traffic to Shakespeare search increases by 88x after post to /r/shakespeare points to Shakespeare search engine as place to find new sonnet (except we don’t have the sonnet yet)\n- 14:54 OUTAGE BEGINS — Search backends start melting down under load\n- 14:55 docbrown receives pager storm, ManyHttp500s from all clusters\n- 14:57 All traffic to Shakespeare search is failing: see http://monitor\n- 14:58 docbrown starts investigating, finds backend crash rate very high\n- 15:01 INCIDENT BEGINS docbrown declares incident #465 due to cascading failure, coordination on #shakespeare, names jennifer incident commander\n- 15:02 someone coincidentally sends email to shakespeare-discuss@ re sonnet discovery, which happens to be at top of martym’s inbox\n- 15:03 jennifer notifies shakespeare-incidents@ list of the incident\n- 15:04 martym tracks down text of new sonnet and looks for documentation on corpus update\n- 15:06 docbrown finds that crash symptoms identical across all tasks in all clusters, investigating cause based on application logs\n- 15:07 martym finds documentation, starts prep work for corpus update\n- 15:10 martym adds sonnet to Shakespeare’s known works, starts indexing job\n- 15:12 docbrown contacts clarac & agoogler (from Shakespeare dev team) to help with examining codebase for possible causes\n- 15:18 clarac finds smoking gun in logs pointing to file descriptor exhaustion, confirms against code that leak exists if term not in corpus is searched for\n- 15:20 martym’s index MapReduce job completes\n- 15:21 jennifer and docbrown decide to increase instance count enough to drop load on instances that they’re able to do appreciable work before dying and being restarted\n- 15:23 docbrown load balances all traffic to USA-2 cluster, permitting instance count increase in other clusters without servers failing immediately\n- 15:25 martym starts replicating new index to all clusters\n- 15:28 docbrown starts 2x instance count increase\n- 15:32 jennifer changes load balancing to increase traffic to nonsacrificial clusters\n- 15:33 tasks in nonsacrificial clusters start failing, same symptoms as before\n- 15:34 found order-of-magnitude error in whiteboard calculations for instance count increase\n- 15:36 jennifer reverts load balancing to resacrifice USA-2 cluster in preparation for additional global 5x instance count increase (to a total of 10x initial capacity)\n- 15:36 OUTAGE MITIGATED, updated index replicated to all clusters\n- 15:39 docbrown starts second wave of instance count increase to 10x initial capacity\n- 15:41 jennifer reinstates load balancing across all clusters for 1% of traffic\n- 15:43 nonsacrificial clusters’ HTTP 500 rates at nominal rates, task failures intermittent at low levels\n- 15:45 jennifer balances 10% of traffic across nonsacrificial clusters\n- 15:47 nonsacrificial clusters’ HTTP 500 rates remain within SLO, no task failures observed\n- 15:50 30% of traffic balanced across nonsacrificial clusters\n- 15:55 50% of traffic balanced across nonsacrificial clusters\n- 16:00 OUTAGE ENDS, all traffic balanced across all clusters\n- 16:30 INCIDENT ENDS, reached exit criterion of 30 minutes’ nominal performance\n\n## Supporting Information\n\n- Monitoring dashboard,\n\n    http://monitor/shakespeare?end_time=20151021T160000\n&duration=7200",
    "timestamp": "2025-05-23T16:34:07.622751",
    "tags": [],
    "severity": "high",
    "services_affected": [
      "api",
      "web",
      "monitoring"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "azure",
      "elasticsearch",
      "haproxy",
      "grafana",
      "jenkins"
    ],
    "failure_pattern": "cascading_failure",
    "timeline_events": [],
    "blast_radius": "global",
    "detection_time": null,
    "mitigation_actions": [
      "- 15:23 docbrown load balances all traffic to USA-2 cluster, permitting instance count increase in other clusters without servers failing immediately",
      "pushing new index containing popular search term"
    ],
    "quality_score": 1.0
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/cloudfour/guides/blob/6ed34d0b282c3483e013aee776782c6ae064c8f8/rituals/postmortems.md",
    "title": "postmortems.md",
    "content": "# Incident Postmortems\n\nPostmortem documents are a ritual designed to examine serious incidents or outages. Google’s [book on Site Reliability Engineering](https://landing.google.com/sre/book.html) says:\n\n> A postmortem is a written record of an incident, its impact, the actions taken to mitigate or resolve it, the root cause(s), and the follow-up actions to prevent the incident from recurring.\n\n## Purpose\n\nWe practice postmortems to ensure we understand and address the root cause of severe incidents such as outages, data loss, or serious production bugs.\n\n> \"Don't make the mistake of neglecting a post-mortem after an incident. Without a post-mortem you fail to recognize what you're doing right, where you could improve, and most importantly, how to avoid making the same exact mistakes next time around. A well-designed, blameless post-mortem allows teams to continuously learn, and serves as a way to iteratively improve your infrastructure and incident response process.\" — [PagerDuty](https://response.pagerduty.com/after/post_mortem_process/)\n\n### What is a Postmortem?\n\nA postmortem is a document that examines an incident in detail, including:\n\n- An summary of what happened\n- The incident's impact\n- What caused the incident\n- How the incident was resolved\n- A detailed timeline\n- What could have prevented the incident\n\n### Why Do We Do Postmortems?\n\nThe goal of the postmortem is to gain a detailed understanding of the root causes of the incident to avoid it happening again in the future. A secondary goal can be to reassure the client, since the actions taken during an incident response may not be visible to them.\n\nFor postmortems to be effective at reducing repeat incidents, the review process has to incentivize teams to honestly identify root causes and fix them. For this reason, we practice **blameless postmortems** (see below).\n\n### When is a Postmortem Needed?\n\nIt depends on the client or project. For applications or sites with an service-level agreement, postmortems are commonly carried out for high-severity incidents that violate the SLA. For client applications or site, a postmortem may only be called for following a major outage or quality-control problem.\n\n> \"Incidents in your organization should have clear and measurable severity levels. These severity levels can be used to trigger the post-mortem process. For example, any incident Sev-1 or higher triggers the postmortem process, while the postmortem can be optional for less severe incidents.\" — [Atlassian](https://www.atlassian.com/blog/statuspage/incident-postmortem-writing-tips)\n\nThe postmortem document should be produced within 24-48 hours of the incident's resolution, while it's still fresh in everyone's memory.\n\n> \"Despite how painful an outage may have been, the worst thing you can do is to bury it and never properly close the incident in a clear and transparent way. Most humans come together in times of crisis and communication around outage post-mortems, in my experience, has always been met with positive energy, understanding comments, constructive suggestions and numerous offers to help.\" — [Daniel Doubrovkine says](https://artsy.github.io/blog/2014/11/19/how-to-write-great-outage-post-mortems/)\n\n### Who Completes the Postmortem?\n\nIn a small company like ours, the most senior engineer with direct knowledge should be writing an outage postmortem. It's their job and responsibility to acknowledge, understand and explain what happened. For particularly sensitive topics, it may make sense to escalate this responsibility to an engineering manager or founder.\n\n> \"Focusing attention away from the individual contributors allows the team to learn from the mistakes and address the root causes in time without the unnecessary stress or pressure during a crisis.\" — [Daniel Doubrovkine](https://artsy.github.io/blog/2014/11/19/how-to-write-great-outage-post-mortems/)\n\n### Who is the Postmortem For?\n\nThe postmortem is intended for public consumption, especially by clients. It's a visible way to document not just the problem that happened, but how you addressed it and are ensuring it won't happen again. A properly written postmortem should increase your customer's faith in you.\n\n> \"The postmortem audience includes customers, direct reports, peers, the company's executive team and often investors. The document may be published on your website, and otherwise goes to the entire team. It's critical to bcc everyone. This is the equivalent of a locked thread, avoiding washing the laundry in public: one of the worst possible things to see is when a senior manager replies back pointing an individual who made a mistake, definitely not an email you want accidentally sent to the entire company.\" — [Daniel Doubrovkine](https://artsy.github.io/blog/2014/11/19/how-to-write-great-outage-post-mortems/)\n\n### Running a Postmortem Meeting\n\nSome teams hold a meeting after the postmortem document is produced. These meetings are generally short, only 15-30 minutes, and are intended to be a wrap-up of the postmortem process. We discuss what happened, what could have gone better, and any followup actions we need to take. The point of the meeting is to ensure there's no disagreement on the analysis, and spread a wider awareness of problems the team is facing.\n\n## Blameless Postmortems\n\nMany teams have adopted “blameless” postmortems, which focus on systemic problems and root causes without naming individuals or casting blame onto people or teams. Here's John Allspaw, from [Blameless Postmortems and a Just Culture](https://codeascraft.com/2012/05/22/blameless-postmortems/)\n\n> Having a “blameless” Post-Mortem process means that engineers whose actions have contributed to an accident can give a detailed account of:\n\n> - what actions they took at what time,\n> - what effects they observed,\n> - expectations they had,\n> - assumptions they had made,\n> - and their understanding of timeline of events as they occurred.\n\n> …and that they can give this detailed account without fear of punishment or retribution.\n\n> Why shouldn’t they be punished or reprimanded? Because an engineer who thinks they’re going to be reprimanded are disincentivized to give the details necessary to get an understanding of the mechanism, pathology, and operation of the failure. This lack of understanding of how the accident occurred all but guarantees that it will repeat. If not with the original engineer, another one in the future.\n\nFor a good example of why blameless postmortems matter, I strongly encourage you to watch [Who Destroyed Three Mile Island?](https://www.youtube.com/watch?v=hMk6rF4Tzsg), a talk by Nickolas Means from Lead Dev London 2018.\n\n## Tips\n\n- Make sure the timeline is an accurate representation of events.\n- Use the [Five Whys](https://en.wikipedia.org/wiki/5_Whys) technique to traverse the causal chain until you find a good true root cause.\n- Don't change details or events to make things \"look better\". We need to be honest in our post-mortems, even to ourselves, otherwise they lose their effectiveness.\n- Don't name and shame someone. We keep our post-mortems blameless. If someone deployed a change that broke things, it's not their fault, it's our fault for having a system that allowed them to deploy a breaking change, etc.\n- Avoid the concept of \"human error\". This is related to the point above about \"naming and shaming\", but there's a subtle difference - very rarely is the mistake \"rooted\" in a human performing an action, there are often several contributing factors (the script the human ran didn't have rate limiting, the documentation was out of date, etc...) that can and should be addressed.\n\n## Resources\n\n* [Postmortem Template](https://docs.google.com/document/d/12Prd33SDG1U0yE_gwXUgwa85Vn6dS_Qo5RdEWwFzFEo) document on Google Drive\n* [Postmortem Handbook from Atlassian](https://www.atlassian.com/incident-management/handbook/postmortems)\n* [Postmortem Process from PagerDuty](https://response.pagerduty.com/after/post_mortem_process/)\n* [Effective Postmortem Tips from PagerDuty](https://response.pagerduty.com/after/effective_post_mortems/)\n* [Blameless Postmortems and a Just Culture](https://codeascraft.com/2012/05/22/blameless-postmortems/)\n* [How to Write Great Outage Postmortems](https://artsy.github.io/blog/2014/11/19/how-to-write-great-outage-post-mortems/)\n",
    "timestamp": "2025-05-23T16:34:08.090982",
    "tags": [],
    "severity": "high",
    "services_affected": [
      "web",
      "database"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "kafka"
    ],
    "failure_pattern": "resource_exhaustion",
    "timeline_events": [],
    "blast_radius": "global",
    "detection_time": null,
    "mitigation_actions": [
      "a change that broke things, it's not their fault, it's our fault for having a system that allowed them to deploy a breaking change, etc"
    ],
    "quality_score": 0.85
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/esdc-devcop/esdc-devcop.github.io/blob/66ec253bccc2d0dc97c730ebd6e8cf490736051f/docs/_guides/postmortem.md",
    "title": "postmortem.md",
    "content": "---\ntitle: Blameless Postmorterm Guideline\nlayout: default\ncategory: Practices\nsummary: Detailing what would be expected when running and recording a postmorterm.\ndate: 2019-01-01\n---\n\n## Intro\n\nA postmortem is a written record of an incident, its impact, the actions taken to mitigate or resolve it, the root cause(s), and the follow-up actions to prevent the incident from recurring.\n\n## Why Have Them\n\n\"Only by analyzing our shortcomings can we learn to do better\"\n\nWith our large scale, complex and distributed systems, its inevitable that incidents and outages will occur.\nLeft unchecked, incidents can multiply in complexity which could overwhelm a system and its operators.\nPerforming a post-mortem shows commitment to reducing technical debt in your solution and shows a will to improve and do better.\n\nThey help with the following:\n\n* Document the incident\n* Ensure the cause is well understood\n* Preventive actions are put in place\n* Contribute to the knowledge base\n* Reduce technical debt\n* Motivates the team to reflect and do better\n* Bring value to the team and organization\n* Provide trend analysis of incidents\n\n## When to have them\n\nHaving a postmortem is not punishment—it is a learning opportunity for the entire organization.\nThe postmortem process does present an inherent cost in terms of time and effort, so you can be deliberate in choosing when to write one.\nHowever certain triggers can be used to determine at a minimum when one should occur.\nIt is important to define your postmortem criteria before an incident occurs so that everyone knows when a post-mortem is necessary.\n\n* System downtime or degradation of service beyond a certain threshold\n* Data loss of any kind\n* On-call engineer intervention (release rollback, rerouting of traffic, etc.)\n* A resolution time above a certain threshold\n* A monitoring failure\n\n## Components of a Post-mortem\n\n* A well run post-mortem is composed of the following pieces.\n\n### Planning\n\n* Post-mortem are a scheduled activity\n* Time is required for a meeting with all parties involved in the issue\n* Time is required for someone to document the postmortem\n\n### Meeting\n\n* Includes representation of all required groups\n* The facilitator establishes parameters and reiterates the goals of the post-mortem\n* Review and clarify timelines and chain of events\n\n### Documenting\n\nDocumenting the post-mortem will contribute to the knowledge base and allow us to share the lesson learned. Key contents include:\n\n* Summary\n* Impact\n* Root Causes\n* Resolution\n* Actions items\n* Lessons Learned\n* Timeline\n* Google's Sample Template\n\n### Review\n\n* Teams share the first post-mortem draft internally and solicit the groups involved to assess the draft for completeness\n\n### Publication\n\n* Once reviewed the post-mortem can be published openly.\n* The goal is to share post-mortems to the widest possible audience that would benefit from the knowledge or lessons imparted\n\n## Postmortem Templates and Samples\n\n[Google's Postmortem Example](https://landing.google.com/sre/sre-book/chapters/postmortem/ )\n\n## Do's\n\n* Focus on identifying the contributing causes of the incident without indicting any individual or team for bad or inappropriate behavior\n* Assume everyone involved in an incident had good intentions and did the right thing with the information they had at the time\n* See every \"mistake\" as an opportunity to strengthen the system\n* Create a culture of continuous improvement\n* Have it asap so that timelines and activities are fresh in peoples memory\n* Involve everyone that participated in the troubleshooting and resolution and also everyone with an interest\n* Be open, listen to input\n* Share your post-mortem with others\n\n## Don'ts\n\n* Finger pointing\n* Assigning blame\n* Punish people for being honest\n* Leave a post-mortem undocumented\n* Leave action items unresolved\n\n## Templates & Tools\n\n[Google's Postmortem Example](https://landing.google.com/sre/sre-book/chapters/postmortem/)\n\n[Etsy Morgue](https://github.com/etsy/morgue)\n\n## References\n\n[https://en.wikipedia.org/wiki/Postmortem_documentation](https://en.wikipedia.org/wiki/Postmortem_documentation)\n\n[https://sre.google/sre-book/postmortem-culture/](https://sre.google/sre-book/postmortem-culture/)\n\n[https://sre.google/workbook/postmortem-analysis/](https://sre.google/workbook/postmortem-analysis/)\n\n[https://www.freecodecamp.org/news/what-is-a-software-post-mortem/](https://www.freecodecamp.org/news/what-is-a-software-post-mortem/)\n",
    "timestamp": "2025-05-23T16:34:10.343959",
    "tags": [],
    "severity": "high",
    "services_affected": [
      "api",
      "web",
      "monitoring"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [],
    "failure_pattern": "data_corruption",
    "timeline_events": [],
    "blast_radius": "global",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 0.7999999999999999
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/MicrosoftDocs/windows-driver-docs/blob/1ff5b7503dad10d8b139ca27f02d3590ea8131fc/windows-driver-docs-pr/debugger/enabling-postmortem-debugging.md",
    "title": "enabling-postmortem-debugging.md",
    "content": "---\ntitle: Enabling Postmortem Debugging\ndescription: This topic covers how to enable postmortem debugging\nkeywords: debugging. debug, Windbg, postmortem debugging, just-in-time debugging, JIT debugging, AeDebug registry key\nms.date: 12/15/2021\nms.topic: how-to\n---\n\n# Enabling Postmortem Debugging\n\n\n## <span id=\"ddk_enabling_postmortem_debugging_dbg\"></span><span id=\"DDK_ENABLING_POSTMORTEM_DEBUGGING_DBG\"></span>User Mode Exception Handling\n\n\n**Exceptions and Breakpoints**\n\nThe most common application errors are called exceptions. These include access violations, division-by-zero errors, numerical overflows, CLR exceptions, and many other kinds of errors. Applications can also cause breakpoint interrupts. These occur when Windows is unable to run the application (for example, when a necessary module cannot be loaded) or when a breakpoint is encountered. Breakpoints can be inserted into the code by a debugger, or invoked through a function such as [**DebugBreak**](/windows/win32/api/debugapi/nf-debugapi-debugbreak).\n\n**Exception Handlers Precedence**\n\nBased on configuration values and which debuggers are active, Windows handles user-mode errors in a variety of ways. The following sequence shows the precedence used for user mode error handling:\n\n1.  If a user-mode debugger is currently attached to the faulting process, all errors will cause the target to break into this debugger.\n\n    As long as the user-mode debugger is attached, no other error-handling methods will be used -- even if the [**gn (Go With Exception Not Handled)**](../debuggercmds/gn--gn--go-with-exception-not-handled-.md) command is used.\n\n2.  If no user-mode debugger is attached and the executing code has its own exception handling routines (for example, **try - except**), this exception handling routine will attempt to deal with the error.\n\n3.  If no user-mode debugger is attached, and Windows has an open kernel-debugging connection, and the error is a breakpoint interrupt, Windows will attempt to contact the kernel debugger.\n\n    Kernel debugging connections must be opened during Windows' boot process. If you wish to prevent a user-mode interrupt from breaking into the kernel debugger, you can use the KDbgCtrl utility with the **-du** parameter. For details on how to configure kernel-debugging connections and how to use KDbgCtrl, see [Getting Set Up for Debugging](getting-set-up-for-debugging.md).\n\n    In the kernel debugger, you can use [**gh (Go With Exception Handled)**](../debuggercmds/gh--go-with-exception-handled-.md) to disregard the error and continue running the target. You can use [**gn (Go With Exception Not Handled)**](../debuggercmds/gn--gn--go-with-exception-not-handled-.md) to bypass the kernel debugger and go on to step 4.\n\n4.  If the conditions in steps 1, 2, and 3 do not apply, Windows will activate a debugging tool configured in the AeDebug registry values. Any program can be selected in advance as the tool to use in this situation. The chosen program is referred to as the *postmortem debugger*.\n\n5.  If the conditions in steps 1, 2, and 3 do not apply, and there is no postmortem debugger registered, Windows Error Reporting (WER) displays a message and provides solutions if any are available. WER also writes a memory dump file if the appropriate values are set in the Registry. For more information, see [Using WER](/windows/win32/wer/using-wer) and [Collecting User-Mode Dumps](/windows/win32/wer/collecting-user-mode-dumps).\n\n**DebugBreak Function**\n\nIf a postmortem debugger has been installed, you can deliberately break into the debugger from a user-mode application by calling the **DebugBreak** function.\n\n## <span id=\"Specifying_a_Postmortem_Debugger\"></span><span id=\"specifying_a_postmortem_debugger\"></span><span id=\"SPECIFYING_A_POSTMORTEM_DEBUGGER\"></span>Specifying a Postmortem Debugger\n\n\nThis section describes how to configure tools such as WinDbg as the postmortem debugger. Once configured, the postmortem debugger will be automatically started whenever an application crashes.\n\n**Post Mortem Debugger Registry Keys**\n\nWindows Error Reporting (WER) creates the postmortem debugger process using the values set in the AeDebug registry key.\n\n**HKLM**\\\\**Software**\\\\**Microsoft**\\\\**Windows NT**\\\\**CurrentVersion**\\\\**AeDebug**\n\nThere are two primary registry values of interest, *Debugger* and *Auto*. The *Debugger* registry value specifies the command line for the postmortem debugger. The *Auto* registry value specifies if the postmortem debugger is automatically started, or if a confirmation message box is presented first.\n\n<span id=\"Debugger__REG_SZ_\"></span><span id=\"debugger__reg_sz_\"></span><span id=\"DEBUGGER__REG_SZ_\"></span>**Debugger (REG\\_SZ)**  \n\nThis REG\\_SZ value specifies the debugger that will handle postmortem debugging.\n\nThe full path to the debugger must be listed unless the debugger is located in a directory that is in the default path.\n\nThe command line is generated from the Debugger string via a printf style call that includes 3 parameters. Although the order is fixed, there is no requirement to use any or all of the available parameters.\n\nDWORD (%ld) - Process ID of the target process.\n\nDWORD (%ld) - Event Handle duplicated into the postmortem debugger process. If the postmortem debugger signals the event, WER will continue the target process without waiting for the postmortem debugger to terminate. The event should only be signaled if the issue has been resolved. If the postmortem debugger terminates without signaling the event, WER continues the collection of information about the target processes.\n\nvoid\\* (%p) - Address of a JIT\\_DEBUG\\_INFO structure allocated in the target process’s address space. The structure contains additional exception information and context.\n\n<span id=\"Auto__REG_SZ_\"></span><span id=\"auto__reg_sz_\"></span><span id=\"AUTO__REG_SZ_\"></span>**Auto (REG\\_SZ)**\nThis REG\\_SZ value is always either **0** or **1**.\n\nIf **Auto** is set to **0**, a confirmation message box is displayed prior to postmortem debugging process being started.\n\nIf **Auto** is set to **1**, the postmortem debugger is immediately created.\n\nWhen you manually edit the registry, do so very carefully, because improper changes to the registry may not allow Windows to boot.\n\n**Example Command Line Usage**\n\nMany postmortem debuggers use a command line that includes -p and -e switches to indicate the parameters are a PID and Event (respectively). For example, installing WinDbg via `windbg.exe -I` creates the following values:\n\n```console\nDebugger = \"<Path>\\WinDbg -p %ld -e %ld -g\"\nAuto = 1\n```\n\nThere is flexibility in how the WER %ld %ld %p parameters can be used. For example. there is no requirement to specify any switches around or between the WER parameters. For example, installing [Windows Sysinternals ProcDump](/sysinternals/downloads/procdump) using `procdump.exe -i` creates the following values with no switches between the WER %ld %ld %p parameters:\n\n```console\nDebugger = \"<Path>\\procdump.exe\" -accepteula -j \"c:\\Dumps\" %ld %ld %p\nAuto = 1\n```\n\n**32 and 64 bit Debuggers**\n\nOn a 64-bit platform, the Debugger (REG\\_SZ) and Auto (REG\\_SZ) registry values are defined individually for 64-bit and 32-bit applications. An additional Windows on Windows (WOW) key is used to store the 32 bit application post mortem debugging values.\n\n**HKLM**\\\\**Software**\\\\**Wow6432Node**\\\\**Microsoft**\\\\**Windows NT**\\\\**CurrentVersion**\\\\**AeDebug**\n\nOn a 64-bit platform, use a 32-bit post-mortem debugger for 32-bit processes and a 64-bit debugger for 64-bit processes. This avoids a 64-bit debugger focusing on the WOW64 threads, instead of the 32-bit threads, in a 32-bit process.\n\nFor many postmortem debuggers, including the Debugging Tools for Windows postmortem debuggers, this involves running the installation command twice; once with the x86 version and once with the x64 version. For example, to use WinDbg as the interactive postmortem debugger, the `windbg.exe -I` command would be run twice, once for each version.\n\n64-bit Installation:\n\n```console\nC:\\Program Files (x86)\\Windows Kits\\10\\Debuggers\\x64\\windbg.exe –I\n```\n\nThis updates the registry key with these values.\n\n```reg\nHKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\AeDebug\nDebugger = \"C:\\Program Files (x86)\\Windows Kits\\10\\Debuggers\\x64\\windbg.exe\" -p %ld -e %ld –g\n```\n\n32-bit Installation:\n\n```console\nC:\\Program Files (x86)\\Windows Kits\\10\\Debuggers\\x86\\windbg.exe –I\n```\n\nThis updates the registry key with these values.\n\n```reg\nHKEY_LOCAL_MACHINE\\SOFTWARE\\WOW6432Node\\Microsoft\\Windows NT\\CurrentVersion\\AeDebug\nDebugger = \"C:\\Program Files (x86)\\Windows Kits\\10\\Debuggers\\x86\\windbg.exe\" -p %ld -e %ld –g\n```\n\n## <span id=\"Configuring\"></span><span id=\"configuring\"></span><span id=\"CONFIGURING\"></span>Configuring Post Mortem Debuggers\n\n\n### <span id=\"Debugging_Tools_for_Windows\"></span><span id=\"debugging_tools_for_windows\"></span><span id=\"DEBUGGING_TOOLS_FOR_WINDOWS\"></span>Debugging Tools for Windows\n\nThe Debugging Tools for Windows debuggers all support being set as the postmortem debugger. The install command intends for the process to be debugged interactively.\n\n**WinDbg**\n\nTo set the postmortem debugger to WinDbg, run `windbg -I`. (The `I` must be capitalized.) This command will display a success or failure message after it is used. To work with both 32 and 64 bit applications, run the command for the both the 64 and 32 debuggers.\n\n```console\nC:\\Program Files (x86)\\Windows Kits\\10\\Debuggers\\x64\\windbg.exe –I\nC:\\Program Files (x86)\\Windows Kits\\10\\Debuggers\\x86\\windbg.exe –I\n```\n\nThis is how the AeDebug registry entry will be configured when `windbg -I` is run.\n\n```console\nDebugger = \"<Path>\\WinDbg -p %ld -e %ld -g\"\nAuto = 1\n```\n\nIn the examples, *&lt;Path&gt;* is the directory where the debugger is located.\n\nThe -p and -e parameters pass the Process ID and Event, as discussed previously.\n\nThe **-g** passes the g (Go) command to WinDbg and continues execution from the current instruction.\n\n**Note**  \nThere is a significant issue passing the g (Go) command. The issue with this approach, is that exceptions do not always repeat, typically, because of a transient condition that no longer exists when the code is restarted. For more information about this issue, see [**.jdinfo (Use JIT\\_DEBUG\\_INFO)**](../debuggercmds/-jdinfo--use-jit-debug-info-.md).\n\nTo avoid this issue, use .jdinfo or .dump /j. This approach allows the debugger to be in the context of the code failure of interest. For more information, see [Just In Time (JIT) Debugging](#jit) later in this topic.\n\n \n\n**CDB**\n\nTo set the postmortem debugger to CDB, run **cdb -iae** (Install AeDebug) or **cdb -iaec** *KeyString* (Install AeDebug with Command).\n\n```console\nC:\\Program Files (x86)\\Windows Kits\\10\\Debuggers\\x64\\cdb.exe -iae\nC:\\Program Files (x86)\\Windows Kits\\10\\Debuggers\\x86\\cdb.exe -iae\n```\n\nWhen the **-iaec** parameter is used, *KeyString* specifies a string to be appended to the end of command line used to launch the postmortem debugger. If *KeyString* contains spaces, it must be enclosed in quotation marks.\n\n```console\nC:\\Program Files (x86)\\Windows Kits\\10\\Debuggers\\x64\\cdb.exe -iaec [KeyString]\nC:\\Program Files (x86)\\Windows Kits\\10\\Debuggers\\x86\\cdb.exe -iaec [KeyString]\n```\n\nThis command display nothing if it succeeds, and an error message if it fails.\n\n**NTSD**\n\nTo set the postmortem debugger to NTSD, run **ntsd -iae** (Install AeDebug) or **ntsd -iaec** *KeyString* (Install AeDebug with Command).\n\n```console\nC:\\Program Files (x86)\\Windows Kits\\10\\Debuggers\\x64\\ntsd.exe -iae\nC:\\Program Files (x86)\\Windows Kits\\10\\Debuggers\\x86\\ntsd.exe -iae\n```\n\nWhen the **-iaec** parameter is used, *KeyString* specifies a string to be appended to the end of command line used to launch the postmortem debugger. If *KeyString* contains spaces, it must be enclosed in quotation marks.\n\n```console\nC:\\Program Files (x86)\\Windows Kits\\10\\Debuggers\\x64\\ntsd.exe -iaec [KeyString]\nC:\\Program Files (x86)\\Windows Kits\\10\\Debuggers\\x86\\ntsd.exe -iaec [KeyString]\n```\n\nThis command display nothing if it succeeds, and an error to a new console window on failure.\n\n**Note**  Because the -p %ld -e %ld -g parameters always appear first on the command line of the postmortem debugger, you should not use the -iaec switch to specify the -server parameter because -server will not work unless it appears first on the command line. To install a postmortem debugger that includes this parameter, you must edit the registry manually.\n\n \n\n### <span id=\"Visual_Studio_JIT_Debugger\"></span><span id=\"visual_studio_jit_debugger\"></span><span id=\"VISUAL_STUDIO_JIT_DEBUGGER\"></span>Visual Studio JIT Debugger\n\nIf Visual Studio has been installed, vsjitdebugger.exe will be registered as the post mortem debugger. The Visual Studio JIT Debugger intends for the process to be debugged interactively.\n\n```console\nDebugger = \"C:\\WINDOWS\\system32\\vsjitdebugger.exe\" -p %ld -e %ld\n```\n\nIf Visual Studio is updated or re-installed, this entry will be re-written, overwriting any alternate values set.\n\n### <span id=\"Window_Sysinternals_ProcDump\"></span><span id=\"window_sysinternals_procdump\"></span><span id=\"WINDOW_SYSINTERNALS_PROCDUMP\"></span>Window Sysinternals ProcDump\n\nThe Windows Sysinternals ProcDump utility can also be used for postmortem dump capture. For more information about using and downloading ProcDump, see [ProcDump](/sysinternals/downloads/procdump).\n\nLike the [**.dump**](../debuggercmds/-dump--create-dump-file-.md) WinDbg command, ProcDump is able to be capture a dump of the crash non-interactively. The capture may occur in any Windows system session.\n\nProcDump exits when the dump file capture completes, WER then reports the failure and the faulting process is terminated.\n\nUse `procdump -i` to install procdump and -u to uninstall ProcDump for both the 32 and 64 bit post mortem debugging.\n\n```console\n<Path>\\procdump.exe -i\n```\n\nThe install and uninstall commands output the registry values modified on success, and the errors on failure.\n\nThe ProcDump command line options in the registry are set to:\n\n```console\nDebugger = <Path>\\ProcDump.exe -accepteula -j \"<DumpFolder>\" %ld %ld %p\n```\n\nProcDump uses all 3 parameters - PID, Event and JIT\\_DEBUG\\_INFO. For more information on the JIT\\_DEBUG\\_INFO parameter, see [Just In Time (JIT) Debugging](#jit) below.\n\nThe size of dump captured defaults to Mini (process/threads/handles/modules/address space) without a size option set, MiniPlus (Mini plus MEM\\_PRIVATE pages) with -mp set, or Full (all memory - equivalent to \".dump /mA\") with -ma set.\n\nFor systems with sufficient drive space, a Full (-ma) capture is recommended.\n\nUse -ma with the -i option to specify an all memory capture. Optionally, provide a path for the dump files.\n\n```console\n<Path>\\procdump.exe -ma -i c:\\Dumps\n```\n\nFor systems with limited drive space, a MiniPlus (-mp) capture is recommended.\n\n```console\n<Path>\\procdump.exe -mp -i c:\\Dumps\n```\n\nThe folder to save the dump file to is optional. The default is the current folder. The folder should secured with an ACL that is equal or better than what is used for C:\\\\Windows\\\\Temp. For more information on managing security related to folders, see [Security During Postmortem Debugging](security-during-postmortem-debugging.md).\n\nTo uninstall ProcDump as the postmortem debugger, and restore the previous settings, use the -u (Uninstall) option.\n\n```console\n<Path>\\procdump.exe -u\n```\n\nFor additional information on ProcDump, see [ProcDump](/sysinternals/downloads/procdump) and *Windows SysInternals Administrator's Reference* by Mark Russinovich and Aaron Margosis published by Microsoft Press.\n\n## <span id=\"JIT\"></span><span id=\"jit\"></span> Just In Time (JIT) Debugging\n\n\n**Setting Context to the Faulting Application**\n\nAs discussed previously, it is very desirable to set the context to the exception that caused the crash using the JIT\\_DEBUG\\_INFO parameter. For more information about this, see [**.jdinfo (Use JIT\\_DEBUG\\_INFO)**](../debuggercmds/-jdinfo--use-jit-debug-info-.md).\n\n**Debugging Tools for Windows**\n\nThis example shows how to edit the registry to run an initial command (-c) that uses the .jdinfo &lt;address&gt; command to display the additional exception information, and change the context to the location of the exception (similar to how .ecxr is used set the context to the exception record).\n\n```console\nDebugger = \"<Path>\\windbg.exe -p %ld -e %ld -c \".jdinfo 0x%p\"\nAuto = 1\n```\n\nThe %p parameter is the address of a JIT\\_DEBUG\\_INFO structure in the target process’s address space. The %p parameter is pre-appended with 0x so that it is interpreted as a hex value. For more information, see [**.jdinfo (Use JIT\\_DEBUG\\_INFO)**](../debuggercmds/-jdinfo--use-jit-debug-info-.md).\n\nTo debug a mix of 32 and 64 bit apps, configure both the 32 and 64 bit registry keys (described above), setting the proper path to the location of the 64-bit and 32-bit WinDbg.exe.\n\n**Creating a dump file using .dump**\n\nTo capture a dump file whenever a failure occurs that includes the JIT\\_DEBUG\\_INFO data, use .dump /j &lt;address&gt;.\n\n```console\n<Path>\\windbg.exe -p %ld -e %ld -c \".dump /j %p /u <DumpPath>\\AeDebug.dmp; qd\"\n```\n\nUse the /u option to generate a unique filename to allow multiple dump files to be automatically created. For more information about the options see, [**.dump (Create Dump File)**](../debuggercmds/-dump--create-dump-file-.md).\n\nThe created dump will have the JITDEBUG\\_INFO data stored as the default exception context. Instead of using .jdinfo to view the exception information and set the context, use .exr -1 to display the exception record and .ecxr to set the context. For more information see [**.exr (Display Exception Record)**](../debuggercmds/-exr--display-exception-record-.md) and [**.ecxr (Display Exception Context Record)**](../debuggercmds/-ecxr--display-exception-context-record-.md).\n\n**Windows Error Reporting - q / qd**\n\nThe way the debug session ends determines if Windows Error Reporting reports the failure.\n\nIf the debug session is detached using qd prior to the closing of the debugger, WER will report the failure.\n\nIf the debug session is quit using q (or if the debugger is closed without detaching), WER will not report the failure.\n\nAppend *;q* or *;qd* to the end of the command string to invoke the desired behavior.\n\nFor example, to allow WER to report the failure after CDB captures a dump, configure this command string.\n\n```console\n<Path>\\cdb.exe -p %ld -e %ld -c \".dump /j 0x%p /u c:\\Dumps\\AeDebug.dmp; qd\"\n```\n\nThis example would allow WER to report the failure after WinDbg captures a dump.\n\n```console\n<Path>\\windbg.exe -p %ld -e %ld -c \".dump /j %p /u <DumpPath>\\AeDebug.dmp; qd\"\"\n```\n\n## <span id=\"security_vulnerabilities\"></span><span id=\"SECURITY_VULNERABILITIES\"></span>Security Vulnerabilities\n\n\nIf you are considering enabling postmortem debugging on a computer that you share with other people, see [Security During Postmortem Debugging](security-during-postmortem-debugging.md).\n\n \n\n",
    "timestamp": "2025-05-23T16:34:18.073605",
    "tags": [],
    "severity": "high",
    "services_affected": [
      "api",
      "web",
      "database"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "docker",
      "aws",
      "kafka"
    ],
    "failure_pattern": "configuration_drift",
    "timeline_events": [],
    "blast_radius": "global",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 0.87
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/hadley/stats337/blob/c285022b83e4fbc58e86e3eec2bb08c359475368/annotated-bibs/blameless-postmortems.md",
    "title": "blameless-postmortems.md",
    "content": "Stats 337, Applied Readings in Data Science (Spring 2018)\n================\n\n# Annotated bibliography\n\n-----\n\n### Theme: Blameless postmortems for data science?\n\n### Executive summary\n\nThe idea of postmortems to evaluate failure events has long been\nconsidered an important practice for effective risk management. The idea\nof blameless postmortems goes further to emphasize the need to create\nand facilitate a postmortem process where participants are incentivized\nto provide detailed accounts and analyses of what happened without fear\nof punishment.\n\nMy readings for this annotated bibliography were guided by a desire to\nlearn more about the idea of blameless postmortems, with particular\nattention to how they might be implemented for data analysis errors and\ndata science issues. I’ve outlined a number of potential reasons that\nblameless postmortems may have not yet been widely adopted within data\nscience practices, as well as some potential suggestions for trying to\nencourage this practice.\n\n### Barriers & Interventions to blameless postmortems for data science\n\nWhile the idea of blameless postmortems have been adopted by many\nsoftware engineering and devop teams (with many referring to Etsy’s\nprocess as a model), it seems that blameless postmortems have not yet\ninfiltrated standard data science practices.\n\nThis may be because of a number of reasons, such as the following:\n\n  - Data science is a relatively new field and there are not yet set\n    “standard” data science practices\n  - The definition of a data analysis success or failure may be more\n    nebulous, such that the errors or failures due to data science may\n    be less clearly identifiable - contrast this with some of the\n    obvious software engineering failures (e.g. cloud service is\n    disrupted).\n  - There may be less incentives for small data science teams or data\n    scientists spread across an organization to prioritize postmortem\n    processes and learning over efficiency, and/or they may be in a\n    weaker position to establish a culture of blameless postmortems.\n  - There are a lack of examples or case studies about blameless\n    postmortems as applied to data analysis errors – and likewise, there\n    are a lack of templates for conducting these kinds of postmortems.\n  - Data scientists may underestimate the degree to which decisions made\n    as part of data science practices are subject to human bias and\n    error.\n  - Changing organizational culture is hard work\\! And managing\n    blameless postmortem processes effectively may sometimes be\n    delicate, and/or require specific training and practice. These\n    skills likely lie outside the typical scope of what a data scientist\n    thinks their job constitutes.\n\nFrom this list and from the readings, some thoughts about potential\ninterventions to accelerate the adoption of blameless postmortems in\ndata science are the following:\n\n  - Have data scientists create a blameless post-mortem template for\n    data science failures within their own organization. Doing so would\n    likely catalyze thoughtful and explicit discussions on what data\n    science success and failure looks like, as well as help establish\n    group norms about what a blameless post-mortem process looks like\n    before a crisis forces the issue.\n  - If they already exist elsewhere in the organization, communicate and\n    learn about the postmortem processes already in-place within\n    software engineering groups, etc – and use these resources as\n    potential templates for data science postmortems, or if appropriate,\n    see if data science postmortems would belong within existing\n    processes.\n  - Consider when it would be appropriate and/or beneficial to the\n    community to make a data science post-mortem public\n  - Consider conducting systematic and internally reviewed premortems to\n    identify potential risks and human biases before embarking on a data\n    science project; revisit and iterate as necessary as the project\n    unfolds\n\nAny feedback, thoughts, critiques, additions, welcome\\!\n\n### Top 3 articles\n\n**1. [Blameless PostMortems and a Just\nCulture](https://codeascraft.com/2012/05/22/blameless-postmortems/).\nJohn** **Allspaw (from Etsy). *Code as Craft* (May 2012).**\n\n*Why you should read this*: If there was a canon of readings on\nblameless postmortem, this article would be on it. The article is\nrelatively short, but lays out the philosophy behind blameless\npostmortems in a cogent and persuasive manner and at a digestible pace –\nit’s a great way to quickly get up to speed on the ideas as well as the\nactions that blameless postmortems involve. As in, John not only\npresents simple explanations of key principles from the literature on\nrisk management and safety (e.g. from Sidney Dekker), but also lays out\nconcrete steps that Etsy takes to implement these ideas. And it seems\nlike everyone writing about blameless postmortems links to this article…\nso don’t be out of the loop\\!\n\n*Winning Quotations*:\n\n  - “So technically, engineers are not at all “off the hook” with a\n    blameless PostMortem process. They are very much on the hook for\n    helping Etsy become safer and more resilient, in the end.”\n  - “We enable and encourage people who do make mistakes to be the\n    experts on educating the rest of the organization how not to make\n    them in the future.”\n\n**2. [What is a Successful Data\nAnalysis?](https://simplystatistics.org/2018/04/17/what-is-a-successful-data-analysis/)**\n**Roger Peng. *Simplystats* (Apr 2018).**\n\n*Why you should read this*: Maybe this article should come first,\nbecause fundamental to the question of postmortems for data science is\nthe question: what does data analysis failure look like? What metrics do\nwe use to identify it when we see it?\n\nThis article is a great entry into these questions – you’ll inevitably\npush your thinking by observing your own reactions and thoughts in\nresponse to Roger’s proposed definition, which he suggests might be\nunsettling (or not\\!).\n\nIn terms of content: Roger presents a framework with which to think\nabout the question of success in data analysis, and contrasts his ideas\nabout “acceptance” and “audience” to other notions such as that of using\ninternal and external validity as a measure of successful data analysis.\nHe also brings two critical yet underappreciated points into the\nconversation: 1) the importance of considering the context in which an\nanalysis is performed when trying to evaluate what analysis is\nappropriate; and 2) that human nature plays a big role in defining the\nsuccess of data analysis.\n\n*Winning quotations*:\n\n  - “Success depends on human beings, unfortunately, and this is\n    something analysts must be prepared to deal with.”\n  - “When an audience is upset by a data analysis, and they are being\n    honest, they are usually upset with the chosen narrative, not with\n    the facts per se.”\n\n**3. [Fearless shared postmortems – CRE life\nlessons](https://cloudplatform.googleblog.com/2017/11/fearless-shared-postmortems-CRE-life-lessons.html).**\n**Adrian Hilton, Gwendolyn Stockman. *Google Cloud Platform Blog* (Nov\n2017).**\n\n*Why you should read this*: This is a bit of an oddball reading\nsuggestion (so maybe that’s reason enough\\!). While the motivation for\nwhy teams for Google’s Site Reliability Engineering are thinking about\nthe mechanics of writing an external postmortem may be obvious, it is\nless obvious why data scientists may want to think about the value of\nexternal postmortems. So here are two reasons to read this article: 1)\nAs the importance and role of data science grows, the likelihood that\ndata science decisions and failures will affect customers more directly\nand obviously may also grow (e.g. think facebook experiments that the\npublic has pushed back on) – and thus the value of external postmortems.\nAnd 2) this article has a nice section at the very bottom called “A side\nnote on the role of luck”, which offers something both wise and unique\nto most descriptions of postmortem write-ups.\n\n*Winning quotations*:\n\n  - “We have found that, with a combination of automation and practice,\n    we can produce a shareable version of an internal postmortem with\n    about 10% additional work, plus internal review.”\n  - “An internal postmortem assumes the reader has basic knowledge of\n    the technical and operational background; this is unlikely to be\n    true for your customer. We try to write the least detailed\n    explanation that still allows the reader to understand why the\n    incident happened; too much detail here is more likely to be\n    off-putting than helpful.”\n\n## Bibliography\n\n*Note about citation formats*:\n\n  - Most citations follow the convention used in the GitHub syllabus,\n    reverting to a more traditional academic citation format for\n    academic publications.\n  - Readings are generally grouped by topic and listed in reverse\n    chronological order, except for the priority readings which are\n    placed first.\n\n**General**\n\n  - [What is a Successful Data\n    Analysis?](https://simplystatistics.org/2018/04/17/what-is-a-successful-data-analysis/)\n    Roger Peng. *Simplystats* (Apr 2018).\n  - Parker H. (2017) Opinionated analysis development. PeerJ Preprints\n    5:e3210v1 <https://doi.org/10.7287/peerj.preprints.3210v1>\n  - [Why ‘Blameless’ ‘Postmortems’ Can Feel\n    Wrong](https://medium.com/@jpaulreed/why-blameless-postmortems-might-feel-wrong-cbeee00d51b2).\n    Paul Reed. *Medium* (Aug 2016)\n  - [It’s Not Your Fault Blameless\n    post-mortems](https://www.slideshare.net/jhand2/its-not-your-fault-blameless-post-mortems).\n    Jason Hand. (Jul 2014)\n  - Dekker, S., Paul, C., & Hofmeyr, J-H. (2011) [The complexity of\n    failure: Implications of complexity theory for safety\n    investigations](https://www.sciencedirect.com/science/article/pii/S0925753511000105).\n    Safety Science, 49: 939-945.\n  - Dekker, S. (2002) [Reconstructing human contributions to accidents:\n    the new view on error and\n    performance](https://ac.els-cdn.com/S0022437502000324/1-s2.0-S0022437502000324-main.pdf?_tid=a5bf53cb-4092-4a%20be-bbfd-ec56bac96588&acdnat=1528328624_9f90fafde4c783a8175f94bce923aced).\n    Journal of Safety Research, 33: 371-385.\n\n**Company case studies**\n\n  - [Fearless shared postmortems – CRE life\n    lessons](https://cloudplatform.googleblog.com/2017/11/fearless-shared-postmortems-CRE-life-lessons.html).\n    Adrian Hilton, Gwendolyn Stockman. *Google Cloud Platform Blog* (Nov\n    2017).\n      - This blog posts also points to other great examples of public\n        postmortems by [Google Cloud\n        Platform](https://status.cloud.google.com/incident/compute/16007),\n        [Gitlab](https://about.gitlab.com/2017/02/10/postmortem-of-database-outage-of-january-31/),\n        [CloudFlare](https://blog.cloudflare.com/incident-report-on-memory-leak-caused-by-cloudflare-parser-bug/),\n        and\n        [Honeycomb.io](https://www.honeycomb.io/blog/2017/10/bitten-by-a-kafka-bug-postmortem/)\n  - [5 Whys – how we conduct blameless post-mortems after something goes\n    wrong](http://code.hootsuite.com/blameless-post-mortems/). Noel\n    Pullen. *Hootsuite Development* (2017)\n  - [Chapter 15: Postmortem Culture: Learning from\n    Failure](https://landing.google.com/sre/book/chapters/postmortem-culture.html).\n    John Lunney, Sue Lueder, edited by Gary O’Connor. (2017)\n      - [Postmortem culture: how you can learn from\n        failure](https://rework.withgoogle.com/blog/postmortem-culture-how-you-can-learn-from-failure/).\n        John Lunney, Sue Lueder, Gary O’Connor. *Re: Work* (Apr 2018).\n      - Provides an [example\n        postmortem](https://landing.google.com/sre/book/chapters/postmortem.html)\n        and this [postmortem exercise\n        template](https://docs.google.com/document/d/1ob0dfG_gefr_gQ8kbKr0kS4XpaKbc0oVAk4Te9tbDqM/edit)\n      - [Google: Engineering excellence requires a “blameless\n        post-mortem culture” for fault\n        fixing](https://www.v3.co.uk/v3-uk/news/3013962/google-engineering-excellence-requires-a-blameless-post-mortem-culture-fo%20r-fault-fixing).\n        Stuart Sumner. V3 (July 2017).\n  - [Postmortems at\n    Airbnb](https://medium.com/airbnb-engineering/postmortems-at-airbnb-dde936fd7877).\n    Ben Hughes. Medium (Oct 2013).\n  - [Blameless PostMortems and a Just\n    Culture](https://codeascraft.com/2012/05/22/blameless-postmortems/).\n    John Allspaw (from Etsy). Code as Craft (May 2012).\n      - Dekker, S. & Breakey, H. (2016) [‘Just culture:’ Improving\n        safety by achieving substantive, procedural and restorative\n        justice](https://www.sciencedirect.com/science/article/pii/S0925753516000321).\n        Safety Science. 85: 187-193.\n      - [What blameless really\n        means](http://www.jessicaharllee.com/notes/what-blameless-really-means/).\n        Jessica Harlee (Mar 2014)\n\n**How to run a postmortem debrief and other postmortem resources**\n\n  - [A collection of postmortem\n    templates](https://github.com/dastergon/postmortem-templates).\n    Dastergon GitHub repo.\n  - [What Etsy Does When Things Go Wrong: A 7-Step\n    Guide](https://www.fastcodesign.com/3064726/what-etsy-does-when-things-go-wrong-a-7-step-guide).\n    John Allspaw, Morgan Evans, Daniel Schauenberg. *Co.Design* (Nov\n    2016).\n      - [Etsy github Morgue](https://github.com/etsy/morgue)\n      - [Practical Postmortems at\n        Etsy](https://www.infoq.com/articles/postmortems-etsy). Daniel\n        Schauenberg. *InfoQ* (Aug 2015)\n  - [A Project Postmortem Toolkit: Apps and Approaches that Help You\n    Learn More from\n    Retrospectives](https://zapier.com/blog/project-retrospective-postmortem/).\n    Genevieve Conti. *Zapier* (Nov 2015).\n  - [A Leader’s Guide to After-Action\n    Reviews](http://www.au.af.mil/au/awc/awcgate/army/tc_25-20/tc25-20.pdf).\n    Headquarters, Department of the Army (Sep 1993).\n\n**Other**\n\n  - [After a Major Cyberattack, Does the Public Deserve an\n    Explanation?](https://www.nextgov.com/cybersecurity/2018/06/after-major-cyber-attack-does-public-deserve-explanation/148692/)\n    Mitch Herckis. Nextgov (Jun 4, 2018).\n      - [The City of Atlanta should publish a blameless post-mortem of\n        the ransomware\n        attack](https://www.change.org/p/mayor-keisha-lance-bottoms-the-city-of-atlanta-should-publish-a-blameless-post-mortem-of-the-ransomware-attack?recruiter=867558611&utm_source=share_petition&utm_medium=twitter&utm_campaign=share_petition).\n        *Change.org petition*. (Mar 2018)\n  - [Tool: Foster psychological\n    safety](https://rework.withgoogle.com/guides/understanding-team-effectiveness/steps/foster-psychological-safety/).\n    *Re:Work*\n      - [The Head of “X” Explains How To Make Audacity the Path of Least\n        Resistance](https://www.wired.com/2016/04/the-head-of-x-explains-how-to-make-audacity-the-path-of-least-resistance/#.aeio3w645).\n        Astro Teller. *Wired* (Apr 2016).\n  - [Upserve – Software\n    Engineer](https://jobs.lever.co/upserve/ad9b5e26-3118-430c-aeae-d5331c41a5d3)\n    – mentioned in the job posting directly as part of what a day might\n    look like\n\n-----\n\n#### Articles about “a case for data literacy”\n\nI didn’t go with this topic, but in case this is helpful to anyone…\\!\n\n**General:**\n\n  - [Why companies must close the data literacy\n    divide](https://www.forbes.com/sites/brentdykes/2017/03/09/why-companies-must-close-the-data-literacy-divide/#75639da369d9).\n    Brent Dykes. *Forbes* (March 9, 2017).\n  - [Beyond Data Literacy: Reinventing Community Engagement and\n    Empowerment in the Age of\n    Data](http://datapopalliance.org/wp-content/uploads/2015/11/Beyond-Data-Literacy-2015.pdf).\n    *Data-Pop Alliance* (Oct 2015).\n  - [Facebook Spawned a Data Crisis. Here’s What We Do\n    Next](https://magenta.as/thank-you-facebook-now-suffer-the-consequences-beee86038439).\n    Michael Horn. *Magenta* (Apr 4, 2018).\n  - Matthews, P. (2016) [Data literacy conceptions, community\n    capabilities](http://eprints.uwe.ac.uk/30506/1/ci-journal-datalit-matthews-preprintep16.pdf).\n    The Journal of Community Informatics, 12 (3). ISSN 1712-4441\n    Available from: <http://eprints.uwe.ac.uk/30506>\n      - Helpful framing: four varieties of data competencies including\n        research (academic), classroom (secondary education), carpentry\n        (practical training), and inclusion (community development).\n  - [Becoming Data Literate in 3 Simple\n    Steps](http://datajournalismhandbook.org/1.0/en/understanding_data_0.html).\n    Nicolas Kayser-Bril. *Data Journalism Handbook 1.0 Beta*\n  - [Data Literacy – Quantitative Research\n    Part 2](https://uxknowledgebase.com/data-literacy-quantitative-research-part-2-de07607f1127).\n    Krisztina Szerovay. *Medium* (May 16, 2018).\n  - [Where if Your Organization on the Marketing Data Literacy\n    Spectrum?](https://medium.com/aimarketingassociation/where-is-your-organization-on-the-marketing-data-literacy-spectrum-b0988740b9e2)\n    Jim Sterne. *Medium* (Apr 9, 2018).\n  - [Why Data Science and UX Research Teams are Better\n    Together](https://www.mindtheproduct.com/2018/02/data-science-ux-research-teams-better-together/).\n    Julie Stanescu. (Feb 7, 2018).\n  - [Data literacy: Your data-driven advantage starts with your\n    people](https://www.bdcnetwork.com/blog/data-literacy-your-data-driven-advantage-starts-your-people).\n    Nathan Miller. *Building Design + Construction* (May 24, 2017).\n  - [Why Data Literacy\n    Matters](https://data36.com/why-data-literacy-matters/). Gabor Papp.\n    *Data36* (Oct 17, 2016).\n  - [Why We Should All Be Data\n    Literate](http://alistapart.com/article/why-we-should-all-be-data-literate).\n    Dan Turner. *A List Apart* (Sep 20, 2016).\n  - [Is Design Metrically\n    Opposed?](https://www.uie.com/jared-live/transcripts/Is_Design_Metrically_Opposed.html)\n    Jared Spool. *Transcript of talk, UXIM Salt Lake City* (Apr 2015)\n  - Martin, Elaine R. (2014). [What is Data\n    Literacy?](https://escholarship.umassmed.edu/cgi/viewcontent.cgi?article=1069&context=jeslib)\n    Journal of eScience Librarianship 3(1): e1069.\n    <http://dx.doi.org/10.7191/> jeslib.2014.1069\n  - [Data Literacy: Definition, Importance and\n    scope](http://epgp.inflibnet.ac.in/epgpdata/uploads/epgp_content/S000021LI/P001449/M021913/ET/1503055537ModuleID-MIL-10-etext-DataLiteracyDefinition,Importanceandscope.pdf).\n    Anubhuti Yadav.\n\n**In higher ed:**\n\n  - [Strategies and Best Practices for Data Literacy Education,\n    Knowledge Synthesis\n    Report](http://www.mikesmit.com/wp-content/papercite-data/pdf/data_literacy.pdf).\n    Chantel Ridsdale, James Rothwell, Mike Smit, Hossam Ali-Hassan,\n    Michael Bliemel, Dean Irvine, Daniel Kelley, Stan Matwin, and Brad\n    Wuetherick. *Dalhousie University* (2015). \\* [The Data Literacy\n    Disruption: It’s Time to Change the Education\n    Mindset](https://medium.com/@sarah_32155/the-data-literacy-disruption-its-time-to-change-the-education-mindset-d0dfcaa0782c).\n    Sarah Nell. *Medium* (April 30, 2018).\n  - [The importance of data literacy in secondary\n    education](https://edexec.co.uk/the-importance-of-data-literacy-in-secondary-education/).\n    Executive Education. (Mar 14, 2018).\n  - [The importance of data literacy in higher\n    education](http://edquarter.com/Article/the-importance-of-data-literacy-in-higher-education).\n    Charley Rogers. *edquarter* (Jan 5, 2018).\n\n**For educators:**\n\n  - [Why data literacy training is important, and how I-TECH\n    helps](https://edscoop.com/why-training-and-data-literacy-are-important-and-how-i-tech-helps).\n    Paige Kowalski. *edscoop* (Oct 30, 2015).\n      - [State Progress, Data Quality\n        Campaign](https://dataqualitycampaign.org/why-education-data/state-progress).\n        *Data Quality Campaign* (2015).\n  - [Ethical and appropriate data use requires data\n    literacy](https://datafordecisions.wested.org/wp-content/uploads/2015/03/Kappan-Ethical-and-Appropriate-Data-Use-Requires-Data-Literacy.pdf).\n    Ellen Mandinach, Brennan Parton, Edith Gummer, Rachel Anderson.\n    *Data for Decisions, WestEd* (March 2015)\n",
    "timestamp": "2025-05-23T16:34:18.861435",
    "tags": [],
    "severity": "high",
    "services_affected": [
      "api",
      "web",
      "database",
      "monitoring"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "postgresql",
      "elasticsearch",
      "kafka",
      "prometheus",
      "jenkins"
    ],
    "failure_pattern": "resource_exhaustion",
    "timeline_events": [],
    "blast_radius": "localized",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 0.96
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/JohnEarnest/Mako/blob/c17b64b641049d698e30bacf055f7bf317d7c205/docs/postmortem-Deep.md",
    "title": "postmortem-Deep.md",
    "content": "Deep: A Postmortem\n==================\n\nAs I begin to make more sophisticated games for the MakoVM platform, I thought it would be a good idea to try to record some of my experiences, both from the perspective of programming in Forth and lessons learned in game design.\n\nBackground\n----------\nWith Deep, I set out to create an arcade-style action game in the vein of Space Invaders. I was also deeply inspired by the minimalist but impactful \"storytelling mechanics\" of Missile Command, so I wanted to try to capture some of that spirit. In an arcade game, I think the main storytelling element that must be included is a setting, which provides framing for what the game will communicate to the player. The way the rules of the game cause elements to act can express ideas within this context.\n\nAnd so the game begins with a man in a small boat, in the middle of a deep ocean. I spent a lot of time building a nice animated background that sets the scene before I built any significant gameplay logic, which was quite satisfying.\n\nEntities\n--------\nStructurally, I tried some different ideas with this game. The core is what I call the 'Entity' system. In previous games I'd always allocated sprite registers statically. Sprite 0 for the player, sprite 1 for a door, sprites 10-30 for enemies, etc. This becomes fairly clumsy for complex scenes, since you have to keep track of which registers are free for various types of objects and you may not make the best use of the available space. The alternative is to allocate the registers dynamically via a malloc/free-like mechanism. Here's a simplified version of the relevant words:\n\n\t:array types    257 0\n\t:array sprites 1024 0\n\t:array bogus      4 0\n\t\n\t: valid ( id -- flag )\n\t\ttypes + @ if true else false then\n\t;\n\t\n\t: alloc ( -- n )\n\t\t0 256 types + !\n\t\t0 loop\n\t\t\tdup valid -if exit then\n\t\t\t1 +\n\t\tagain\n\t;\n\t\n\t: free ( id -- )\n\t\tdup types + 0 swap !\n\t\tsprite@     0 swap !\n\t;\n\nThe `types' array is used to keep track of the object type associated with the corresponding sprite register. A value of zero indicates a free register. Rather than coming up with a table of unique IDs and having a dispatch loop elsewhere to link objects up with their game logic I just store function pointers in the type table. They're consistent and unique, so they work as well as anything for an identifier.\n\nIn a normal malloc, I might need to worry about what happens when I run out of space. In games, failing to spawn an entity is often not a big deal- who cares if the screen is full of enemies and I can't create all five bubble sprites for my particle effect? Rather than forcing code throughout the game engine to worry about handling this error condition, I make the sprite table and the type table one entry larger than they need to be. If allocating a real sprite register fails, the index of this 'bogus' sprite register is returned. Game logic that cares about getting a valid register can check for the error condition and deal with it, while more forgiving scripts can harmlessly write to this slot.\n\nHigher-Order Functions\n----------------------\nI also wanted to try to use as few loops as possible in this game. I've been working my way through _The Structure and Interpretation of Computer Programs_  (SICP) and I'm really seeing the value of abstracting patterns like iteration and dispatch. Forth doesn't have lexical scope or closures, but you can get pretty far on just function pointers.\n\n\t: whoever ( 'filter 'func -- )\n\t\t>r >r first-e\n\t\tloop\n\t\t\tdup i exec over valid and\n\t\t\tif dup j exec then\n\t\t\t1 + dup last-e <=\n\t\twhile\n\t\tdrop r> r> 2drop\n\t;\n\n\t: count+      drop swap 1 + swap            ;\n\t: count       0 swap ' count+ whoever       ; ( 'filter -- )\n\t: always      drop true                     ;\n\t: apply-type  dup types + @ exec            ;\n\t: think       ' always ' apply-type whoever ;\n\n`whoever` is the single end-all be-all word that iterates over valid entities and does something to them. It incorporates a filter because I often want to work with a subset of the objects in the game. Think of `whoever` as a combination of filter() and map() from SICP.\n\nCounting the number of entities which match a predicate and evaluating the game logic for all valid entities falls out very cleanly. Definitions like `always` suggest that working with higher-order functions like this can benefit from having an anonymous function syntax for throwaway predicates and helpers- definitely something worth considering for the future.\n\nOne thing I was a little unsatisified with about `count` is the fact that it's actually very tightly coupled with the way `whoever` manipulates the stack. `whoever` cannot be treated as a black box, since we want to keep a running total floating around between the stack arguments it uses. If I'd needed to keep track of more than one value for `count`'s purposes, the solution would need to become more invasive. Passing individual values around on the stack seems to lead to this sort of abstraction problem pretty frequently- I think object-oriented concatenative languages like PostScript and Factor have a big advantage in this area. If you can bundle an arbitrary number of values together as one 'thing', you can write generic functions which don't care about the datatypes they manipulate. In Forth I think the best alternative is trying a C-like technique of allocating structures on the stack and passing a pointer to them along to 'deeper' functions. Perhaps there's some kind of syntactic sugar I can build which will ease the process?\n\nEntity Scripting\n----------------\nNormally entities are controlled by some sort of state machine- game objects transfer between states as they go about their animations, experience stimuli and get exploded. In the past I might've given entities a field which indicates their current state and written a branching dispatch structure like a case block to choose which behaviors should be carried out.\n\nI already have a better mechanism for this, though. Why do a bunch of checks and branches every time my entities act when I can simply remap the function pointer in their 'type' field? In effect, I've turned the state machine inside-out by letting the states drive the conditions rather than the other way around. I also get the side benefit that entities can very easily transform into other types of entities. Check out how nicely this works:\n\n\t: menace\n\t\t32 wave-time\n\t\tsprite@ .sprite-t dup @ 1 xor swap !\n\t;\n\n\t: seek-player\n\t\tdup can-capsize if capsize then\n\t\tspeed @ 2 / wave-time\n\t\tdup py 40 > if dup sprite@ .sprite-y dec@ then\n\t\tdup px player px < if 2 else -2 then\n\t\tover sprite@ .sprite-x +@\n\t\tmenace\n\t;\n\n\t: swim\n\t\tdup py 64 < if ' seek-player type! exit then\n\t\t4 wave-time\n\t\tdirection @ over sprite@ .sprite-x +@\n\t\t\tspeed @ wave-time\n\t\tdup sprite@ .sprite-y dec@\n\t\tmenace\n\t;\n\nAn entity that is swimming can turn into an entity that seeks the player with a simple `' seek-player type!`- the state transitions are extremely clear to an observer. By using this type of organization, the previously discussed higher-order functions and an opt-out condition checking style I was able to write virtually all entity logic without using loops or nesting if statements. Now that's clean!\n\nYou may have noticed the `wave-time` function there. Remember how I started the project by building an animated background with rolling waves? As it so happens, entities frequently have use for a global timer to control their animations and movement. The waves need one too, and it has a longer cycle than virtually any other timer in the game. Co-opting the system for entity logic was natural, so I built a helper word which could be used to exit an entity script early based on some cyclic period of the global timer. A+ for code reuse, but if I was doing it again from scratch (or my next game) I'd build a global timer from the start and give it a better name.\n\nAt the end of the day, I was very happy with my main loop:\n\n\t: main\n\t\treset-game\n\t\tloop\n\t\t\tmove-player\n\t\t\tfire\n\t\t\twaves\n\t\t\tstorm\n\t\t\tbounce\n\t\t\tdraw-score\n\t\t\tspawn-crab\n\t\n\t\t\t' is-monster count -if spawn-wave then\n\t\t\tended @ gameover @ keys key-a and and and if reset-game then\n\t\n\t\t\tthink\n\t\t\tsync\n\t\tagain\n\t;\n\nIt comes pretty close to the goal of describing what needs to happen in a readable, high-level fashion which glosses over all the unimportant details. The main routines don't really depend on one another to function properly and could be re-ordered freely, indicating a good separation of concerns.\n\nEmergent Game Design\n--------------------\nI started out with the idea of building a game that communicated some kind of narrative without using words, and I think the places I succeeded were almost entirely accidental.\n\nWhen I writing the code to spawn waves of enemies, I quite straightforwardly said \"when there are no enemies alive, spawn the next wave\". When I later added crabs which spawn randomly and add a little chaos to the strategy of gameplay I didn't initially realize that as written a crab would always spawn before the first wave. This meant that the game would start with a lone crab attacking the player, and if he was destroyed a horde of his allies from the deep would immediately appear, as if to avenge his death. Genius! Not only does this slow start give the player a brief chance to get used to the basic game mechanics, it also raises a question- does the player bring inevitable destruction upon themselves? Who is really the protagonist here?\n\nPerhaps not as deep and socially-aware as Missile Command's statement about nuclear proliferation and hard real-life decisionmaking, but I'll settle for anything thought provoking.\n\nGame design lesson: pay attention to unintended consequences and bugs. As Bob Ross would say, we don't have mistakes here, we just have happy accidents.\n\nSummary\n-------\nDynamically allocating sprite registers via the entity system is a good abstraction. Reserving \"bogus buffers\" and failing silently can prevent error checking code from leaking out into main game logic. Factoring loops and conditionals into utility words and providing the 'loop bodies' via function pointers can lead to very terse, clean code. Inverting the usual structure of a state machine results in code which more closely resembles the transition diagram, lessening the maintenance problems traditionally associated with using state machines. Sometimes great design ideas can arise completely by accident- it's important to pay attention to bugs and try to use them to the game's favor.",
    "timestamp": "2025-05-23T16:34:19.261543",
    "tags": [],
    "severity": "medium",
    "services_affected": [
      "web"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "aws",
      "azure",
      "jenkins"
    ],
    "failure_pattern": null,
    "timeline_events": [],
    "blast_radius": "global",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 0.49
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/rust-lang/blog.rust-lang.org/blob/6ab4ffd8757282e05fb4fda83d59949e7e31107a/content/inside-rust/crates-io-postmortem.md",
    "title": "crates-io-postmortem.md",
    "content": "+++\npath = \"inside-rust/2023/07/21/crates-io-postmortem\"\ntitle = \"crates.io Postmortem: Broken Crate Downloads\"\nauthors = [\"Tobias Bieniek\"]\naliases = [\"inside-rust/2023/07/21/crates-io-postmortem.html\"]\n\n[extra]\nteam = \"the crates.io team\"\nteam_url = \"https://www.rust-lang.org/governance/teams/crates-io\"\n+++\n\n(based on https://www.atlassian.com/incident-management/postmortem/templates)\n\n## Summary\n\nOn 2023-07-20 between 12:17 and 12:30 UTC all crate downloads from crates.io were broken due to a deployment that contained a bug in the download URL generation. \n\nDuring this time we had an average of 4.71K requests per second to crates.io, resulting in about 3.7M failed requests, including the retry attempts from cargo.\n\nThe incident was noticed by the developer triggering the production deployment after seeing elevated request-per-second numbers in our monitoring dashboard after the deployment. At this point the root cause for the elevated numbers was not clear yet, but a community member notified the developer via [Zulip](https://rust-lang.zulipchat.com/#narrow/stream/318791-t-crates-io/topic/deployments/near/376960060).\n\nImmediately after the notification, the broken deployment was rolled back to the previous deployment, fixing the downloads again.\n\n## Leadup\n\nAt 17:41 UTC on 2023-07-19 a [pull request](https://github.com/rust-lang/crates.io/pull/6834) to crates.io was merged, finishing the migration of the crates.io codebase to use the [object_store](https://crates.io/crates/object_store) crate for AWS S3 access, instead of our previous custom solution.\n\nThis pull request refactored the way the crate and readme download endpoints generated redirect URLs.\n\n## Fault\n\nThe pull request introduced a few tests for the previously untested functionality, though unfortunately it was using values different from the environment variable content that is used by crates.io in production. This led to the production code path not being tested properly.\n\nThe production code path contained a bug where the URL generated from the \"CDN prefix\" and \"path\" components was missing a slash (`/`) separator. \n\nThis led to <https://crates.io/api/v1/crates/smallvec/1.10.0/download> redirecting to <https://static.crates.iocrates/smallvec/smallvec-1.10.0.crate> instead of <https://static.crates.io/crates/smallvec/smallvec-1.10.0.crate>.\n\n## Impact\n\nFor about 13 minutes, between 12:17 and 12:30 UTC on 2023-07-20, our users experienced this incident.\n\nThis incident affected all users trying to download crate files from crates.io during that time.\n\nThe issue manifest in our users seeing errors like this when running `cargo`:\n\n```\nwarning: spurious network error (3 tries remaining): [6] Couldn't resolve host name (Could not resolve host: static.crates.iocrates)\nwarning: spurious network error (2 tries remaining): [6] Couldn't resolve host name (Could not resolve host: static.crates.iocrates)\nwarning: spurious network error (1 tries remaining): [6] Couldn't resolve host name (Could not resolve host: static.crates.iocrates)\nerror: failed to download from `https://crates.io/api/v1/crates/serde_derive/1.0.173/download`\n```\n\n<https://github.com/rust-lang/crates.io/issues/6850> was submitted and upvoted 12 times.\n\n## Detection\n\nThe developer triggering the production deployment was monitoring the crates.io Grafana dashboard during the deployment and noticed elevated levels of request-per-second numbers for the download endpoint. This was a symptom of cargo retrying the download multiple times before giving up.\n\nAbout 11 minutes after the deployment, a community member notified the crates.io team via [Zulip](https://rust-lang.zulipchat.com/#narrow/stream/318791-t-crates-io/topic/deployments/near/376960060) about the [GitHub issue](https://github.com/rust-lang/crates.io/issues/6850) that was opened, describing the failing downloads.\n\n## Response\n\nAfter the incident was detected, the deploying developer immediately initiated a rollback to the previous deployment through the Heroku user interface. This process took about one minute due to the login procedure and ensuring that the right buttons in the user interface are used.\n\n## Recovery\n\nAfter rolling back to the previous deployment the system immediately recovered itself and produced correct redirect URLs again.\n\nA fix for the broken pull request was subsequently developed and merged, including more tests for the broken code path with more real-world values. The fix was then tested on the staging environment before it got deployed to production too.\n\n## Timeline\n\n### 2023-07-19\n\n- 12:32 UTC – <https://github.com/rust-lang/crates.io/pull/6834> (Migrate remaining `Uploaders` code into `Storage` system) was opened\n- 17:41 UTC – <https://github.com/rust-lang/crates.io/pull/6834> (Migrate remaining `Uploaders` code into `Storage` system) was merged, automatically deploying to the staging environment\n\n### 2023-07-20\n\n- 10:00 UTC – <https://github.com/rust-lang/crates.io/pull/6848> (Fix `readme` field parsing of `Cargo.toml` files) was opened\n- 10:13 UTC – <https://github.com/rust-lang/crates.io/pull/6848> (Fix `readme` field parsing of `Cargo.toml` files) was merged, automatically deploying to the staging environment\n- 12:08 UTC – <https://staging.crates.io/crates/crates-staging-test-tb/0.69.30> was published to the staging environment to smoke test the publish process and the `Cargo.toml` parsing fix\n- 12:16 UTC – A [message](https://rust-lang.zulipchat.com/#narrow/stream/318791-t-crates-io/topic/deployments/near/376956537) was sent to the `deployments` topic of the `t-crates-io` Zulip stream, notifying users of the upcoming deployment.\n- 12:17 UTC – The staging deployment was promoted to the production environment\n- 12:18 UTC – Another [message](https://rust-lang.zulipchat.com/#narrow/stream/318791-t-crates-io/topic/deployments/near/376957223) was sent to the Zulip stream, notifying users that the deployment was completed.\n- 12:24 UTC – <https://github.com/rust-lang/crates.io/issues/6850> (Crates.io crate download API is redirecting to invalid URL) was opened\n- 12:25 UTC – The continuing request-per-second anomaly was deemed unusual enough to trigger another [message](https://rust-lang.zulipchat.com/#narrow/stream/318791-t-crates-io/topic/deployments/near/376959143) to the Zulip stream.\n- 12:28 UTC – A community member notified the crates.io team on the [Zulip stream](https://rust-lang.zulipchat.com/#narrow/stream/318791-t-crates-io/topic/deployments/near/376960060) about the GitHub issue and the deploying developer acknowledged the incident.\n- 12:30 UTC – The deployment was rolled back, temporarily fixing the issue for our users.\n- 13:38 UTC – <https://github.com/rust-lang/crates.io/pull/6851> (Fix download URL generation) was opened\n- 13:49 UTC – <https://github.com/rust-lang/crates.io/pull/6851> (Fix download URL generation) was merged, automatically deploying to the staging environment\n- 14:08 UTC – <https://staging.crates.io/crates/crates-staging-test-tb/0.69.31> was published to the staging environment to smoke test the publish process and check that the download URL generation fix was working correctly\n- 14:10 UTC – The staging deployment was promoted to the production environment\n\n## Root cause identification: The Five Whys\n\n- The redirect URLs for crate and readme downloads were broken in production.\n\n  **Why were the redirect URLs broken?**\n\n  - There was a bug introduced in pull request [#6834](https://github.com/rust-lang/crates.io/pull/6834) which made it all the way into our production environment.\n\n    **Why was there a bug introduced in this pull request?**\n\n    - The pull request introduced tests, but did not test all code paths.\n\n      **Why did the pull request not test all code paths?**\n\n      - The code was structured in a way that made testing with different \"CDN prefix\" values complicated.\n\n        **Why was the code structured in a way that made testing different values complicated?**\n\n        - The code had not been unit tested before and the refactoring stopped at a point where the code could at least be tested with a hardcoded value.\n\n          **Why did the refactoring stop at that point?**\n\n          - It was deemed \"good enough for now\" by the developer.\n\n    - The pull request was not reviewed by another developer.\n\n      **Why was the pull request not reviewed by another developer?**\n\n      - The developer creating the pull request misjudged the potential impact of a bug in the pull request. They did not explicitly request a review from the crates.io team and merged it themselves after a few hours.\n\n        **Why was no code review requested from the crates.io team?**\n\n        - The number of active team members in the [crates.io team](https://www.rust-lang.org/governance/teams/crates-io) is quite small. Reviewing dozens of pull requests per months from the one developer who is employed to work fulltime on crates.io would be a recipe for burnout for the other members of the crates.io team. For that employed fulltime developer it would also not work well if they were blocked on waiting for reviews for the majority of their time. The current way of working is that code reviews are only requested for high-impact pull requests. \n\n        **Why was the potential impact misjudged?**\n\n        - The developer forgot to think about the fact that this change affected the crate download endpoint of crates.io, which is the endpoint that handles 99% of the traffic to the server.\n\n          **Why did the developer forget to check if a high-priority endpoint is affected?**\n\n          - There is no checklist or guide describing in which case a pull request should be seen as having a high potential impact and thus needing explicit code review from the crates.io team.\n\n    **Why did the bug make it into production?**\n\n    - The crate download endpoint was not tested on the staging environment before promoting it to production.\n\n      **Why was the crate download not tested?**\n\n      - The test plan for the staging environment only includes publishing a new version and seeing that reflected on the website and in the package index repository.\n\n        **Why does the test plan not include crate downloads?**\n\n        - Since 99% of all requests to crates.io are for crate downloads, the test plan definitely should include this process. There is intentionally no download button on the webpage though, so the URL for the download has to be constructed manually.\n  \n          **Why does the download URL need to be constructed manually?**\n  \n          - Because the smoke test procedure on our staging environment is currently a completely manual process without any automation.\n\n## Root causes\n\n- The failing code was structured in a way that made it hard to test different variants and code paths.\n- There is no checklist describing which pull requests should be seen as high-impact.\n- The smoke test procedure on the staging environment does not include crate downloads and is a manual process.\n\n## Backlog check\n\nThere are no specific items in the backlog that could have prevented this incident.\n\n## Recurrence\n\nA previous incident caused crate publishing to not work anymore. The learning from this incident was to ensure that the smoke testing procedure includes the publishing process. Unfortunately, this did not include the crate file download though. \n\n## Lessons learned\n\n- The detection time from deployment to incident notification could have been faster if the symptom was identified earlier to be caused by the cargo retry behavior. The heightened awareness of the deploying developer due to the change in Grafana numbers however contributed to this issue being fixed faster.\n- The response time from incident notification to rollback and fixing the issue was fast.\n- All code should be structured in a way that makes testing the different code paths easy.\n- We need clearer rules on which pull requests require code reviews.\n- The smoke test procedure should include crate downloads.\n- The smoke test procedure should be automated as much as possible.\n\n## Corrective actions\n\n- **HIGH** Include crate downloads in the smoke test plan for the staging environment\n- **MEDIUM** Automate the staging environment smoke tests\n- **MEDIUM** Develop rules on which pull requests require explicit code review\n",
    "timestamp": "2025-05-23T16:34:19.771667",
    "tags": [],
    "severity": "high",
    "services_affected": [
      "api",
      "web",
      "database",
      "auth",
      "monitoring"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "kubernetes",
      "aws",
      "kafka",
      "grafana",
      "jenkins"
    ],
    "failure_pattern": "configuration_drift",
    "timeline_events": [],
    "blast_radius": "global",
    "detection_time": null,
    "mitigation_actions": [
      "to production too",
      "to the previous deployment, fixing the downloads again"
    ],
    "quality_score": 1.0
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/HarleyCoops/Math-To-Manim/blob/7130ed2c4278c585add6915306ba4967bccba0eb/MCPPostMortem.md",
    "title": "MCPPostMortem.md",
    "content": "# MCP Server Troubleshooting Guide\n\n## Overview\n\nThis guide documents the issues encountered with Model Context Protocol (MCP) servers in Cline/Claude and the steps taken to resolve them. The primary problem was that MCP servers were failing to connect, showing errors like \"spawn npx ENOENT\" in the MCP Servers panel.\n\n## Initial Problems\n\nThere were several issues that needed to be addressed:\n\n1. **JSON Syntax Errors**: The MCP configuration files had syntax errors that prevented proper parsing.\n2. **PATH Environment Variable**: The `npx` command wasn't accessible from the PATH when the MCP server tried to run it.\n3. **NPX Module Resolution**: There was an issue with how `npx` was trying to find the firecrawl-mcp package.\n\n## Step-by-Step Troubleshooting Process\n\n### 1. Fixing JSON Syntax Errors\n\nThe first issue was with the JSON syntax in the configuration files:\n\n**Original Cline MCP settings file** (with errors):\n```json\nmcpServers\": {\n    \"github.com/mendableai/firecrawl-mcp-server\": {\n      \"command\": \"npx\"\n      \"args\": [\"-y\" \"firecrawl-mcp\"]\n      \"env\": {\n        \"FIRECRAWL_API_KEY\": \"YOUR_API_KEY_HERE\"\n      }\n      \"disabled\": false\n      \"autoApprove\": []\n    }\n  }\n}\n```\n\nProblems:\n- Missing opening curly brace\n- Missing commas after each property\n- Missing comma in the args array\n\n**Fixed Cline MCP settings file**:\n```json\n{\n  \"mcpServers\": {\n    \"github.com/mendableai/firecrawl-mcp-server\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"firecrawl-mcp\"],\n      \"env\": {\n        \"FIRECRAWL_API_KEY\": \"YOUR_API_KEY_HERE\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n```\n\n**Original Claude desktop config file** (with errors):\n```json\nmcpServers\": {}\n}\n```\n\nProblems:\n- Missing opening curly brace\n\n**Fixed Claude desktop config file**:\n```json\n{\n  \"mcpServers\": {}\n}\n```\n\n### 2. Addressing PATH Issues\n\nAfter fixing the JSON syntax, we encountered a \"spawn npx ENOENT\" error, indicating that the system couldn't find the `npx` command. We verified that Node.js and npm were installed:\n\n```\nnode -v  # Output: v20.18.0\nnpx -v   # Output: 10.8.2\n```\n\nWe found the location of the `npx` command:\n```\ndir \"C:\\Users\\chris\\AppData\\Roaming\\npm\\npx*\"\n```\n\nThis showed that `npx` was located at `C:\\Users\\chris\\AppData\\Roaming\\npm\\npx.cmd`.\n\nWe updated the MCP settings to use the full path to `npx.cmd`:\n```json\n{\n  \"mcpServers\": {\n    \"github.com/mendableai/firecrawl-mcp-server\": {\n      \"command\": \"C:\\\\Users\\\\chris\\\\AppData\\\\Roaming\\\\npm\\\\npx.cmd\",\n      \"args\": [\"-y\", \"firecrawl-mcp\"],\n      \"env\": {\n        \"FIRECRAWL_API_KEY\": \"YOUR_API_KEY_HERE\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n```\n\n### 3. Resolving NPX Module Resolution Issues\n\nAfter updating to use the full path to `npx.cmd`, we encountered a new error:\n```\nError: Cannot find module 'C:\\Users\\chris\\AppData\\Roaming\\npm\\node_modules\\npm\\bin\\npx-cli.js'\n```\n\nThis indicated an issue with how `npx` was trying to find the firecrawl-mcp package. We verified that the firecrawl-mcp package was installed globally:\n```\nnpm list -g firecrawl-mcp  # Output: firecrawl-mcp@1.3.3\n```\n\nWe found the main entry point for the firecrawl-mcp package by examining its package.json:\n```\ndir \"C:\\Users\\chris\\AppData\\Roaming\\npm\\node_modules\\firecrawl-mcp\"\ntype \"C:\\Users\\chris\\AppData\\Roaming\\npm\\node_modules\\firecrawl-mcp\\package.json\"\n```\n\nWe confirmed that the script could run directly with Node.js:\n```\nnode \"C:\\Users\\chris\\AppData\\Roaming\\npm\\node_modules\\firecrawl-mcp\\dist\\index.js\"\n```\n\nThis gave an expected error about the missing FIRECRAWL_API_KEY environment variable, confirming that the script itself worked.\n\n## Final Solution\n\nThe ultimate solution was to bypass `npx` entirely and run the firecrawl-mcp script directly with Node.js:\n\n```json\n{\n  \"mcpServers\": {\n    \"github.com/mendableai/firecrawl-mcp-server\": {\n      \"command\": \"node\",\n      \"args\": [\"C:\\\\Users\\\\chris\\\\AppData\\\\Roaming\\\\npm\\\\node_modules\\\\firecrawl-mcp\\\\dist\\\\index.js\"],\n      \"env\": {\n        \"FIRECRAWL_API_KEY\": \"YOUR_API_KEY_HERE\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n```\n\n## How to Apply the Fix\n\n1. Edit the MCP settings file:\n   - For Cline (VSCode extension): `c:\\Users\\chris\\AppData\\Roaming\\Cursor\\User\\globalStorage\\saoudrizwan.claude-dev\\settings\\cline_mcp_settings.json`\n   - For Claude Desktop app: `C:\\Users\\chris\\AppData\\Roaming\\Claude\\claude_desktop_config.json`\n\n2. Update the configuration to use the direct Node.js approach as shown above.\n\n3. Reload the application:\n   - For Cline (VSCode extension): Press Ctrl+Shift+P, type \"Developer: Reload Window\" and press Enter\n   - For Claude Desktop app: Close and reopen the application\n\n4. Click \"Retry Connection\" in the MCP Servers panel.\n\n## Lessons Learned\n\n1. **JSON Syntax is Critical**: Even small syntax errors in JSON configuration files can cause the entire configuration to fail.\n\n2. **PATH Environment Variables**: MCP servers may not have access to the same PATH environment variables as your terminal. Using absolute paths to executables is more reliable.\n\n3. **Direct Execution**: When troubleshooting complex command chains (like using `npx` to run a package), try running the target script directly to isolate issues.\n\n4. **Verify Each Component**: Test each part of the system independently to identify where the failure is occurring.\n\n## Troubleshooting Tips for Future MCP Issues\n\n1. Check the JSON syntax in your configuration files.\n2. Use absolute paths to executables rather than relying on PATH.\n3. Test running the MCP server script directly to see if it works.\n4. Check if all required environment variables are properly set.\n5. Look for error messages in the MCP Servers panel for clues about what's going wrong.\n\n## Additional Resources\n\n- [Model Context Protocol Documentation](https://modelcontextprotocol.github.io/docs/)\n- [FireCrawl MCP Server GitHub Repository](https://github.com/mendableai/firecrawl-mcp-server)\n",
    "timestamp": "2025-05-23T16:34:20.559612",
    "tags": [],
    "severity": "high",
    "services_affected": [
      "api",
      "web",
      "database"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [],
    "failure_pattern": "configuration_drift",
    "timeline_events": [],
    "blast_radius": "global",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 0.72
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/AlvarBer/Persimmon/blob/da08ed854dd0305d7e4684e97ee828acffd76b4d/docs/src/postmortem.md",
    "title": "postmortem.md",
    "content": "Postmortem\n==========\n\nAfter the evaluation it is time to make a retrospective, look what Persimmon\nhas achieved.\n\n\nObjectives Review\n-----------------\n<!--\nResearch:\n:   Background research was conducted on fields covered by the\n    system. It was particularly interesting learning about the dataflow paradigm,\n    because it is a niche I was not familiar with.\n    It was also great looking at the available commercial solutions, they prove\n    that there is a lot of enterprise interests on this kind of systems.\n\nRequirements:\n:   The bi-weekly iterations worked reasonably well, there was not\n    anything that got stuck or delayed more than one additional iteration.\n    It also proved useful for having a usable system from even the first iteration.\n\nTesting:\n:   Probably the weakest part of the project because all the backend\n    is based around visual elements unit testing proved pretty useless, and this\n    part comprised the biggest part of the code.\n-->\n\nFeasibility:\n:   Evaluation seems to show that it is possible to create a machine learning\n    visual interface that is both flexible and relatively easy to use, even\n    for learners, including a type system and errors in compilation time.\n\nDesign and Usability:\n:   The final implementation closely followed the initial sketches, proving the\n    initial design had solid fundamentals.\n    The good evaluation scores, and final remarks given by participants, seem to\n    demonstrate that the interface has accomplished its objectives of\n    producing a powerful yet simple to use interface.\n\nEvaluation:\n:   Despite having a low number of participants the evaluation\n    resulted in a mostly unanimous good reviews of the software, as well as\n    providing very useful feedback for future improvements.\n\nLearning Tool:\n:   Because most of the milestones were achieved the final system has reached a\n    state where it is useful enough for its use as a learning tool thanks to\n    supporting the simplest (and most common) workflows, it was even\n    remarked by two participants how easy it was to use, and how easy it was to do\n    complex actions (such as hyper-parameter tuning) compared to other\n    frameworks/libraries.\n\nFaster Exploratory Work:\n:   Like last objective thanks to the current state of the system it is pretty\n    fast to perform early ml analysis, when limited by the lack of a block it\n    was pretty easy and fast adding a block that solved the problem (in around\n    ~20 lines of code).\n\nImplementation:\n:   At the end of the project the non-functional requirements have been met,\n    delivering a windows single executable file that participants used for the\n    evaluation, while keeping a good performance, handling many blocks without\n    a hitch, and keeping the frame rate steady while modifying connections and\n    running the execution of the pipeline simultaneously.\n\nRetrospective\n-------------\nWith over 7k lines of code, 10 [releases], and more than 200 commits, Persimmon\nstands as a medium size codebase, since its inception it has gathered\nattention, with over 3000 visits, and more than 90 stars on [Github].\n\n<!--\n![Lines of code](images/loc.png)\n-->\n\nIt has been featured on [multiple], [websites], and even won [best project] at\nthe 2017 compshow at University of Hertfordshire.\n\n![Chinese machine learning forum](images/china.png)\n\n\nConclusion\n----------\nIn conclusion the system has managed to reach a testable state in which\nparticipants have remarked its usability, flexibility and potential.\nThis seems to indicate that is is possible for small improvements on visual\nmachine learning tools do make an impact on the user experience\nFeatures like the smart bubble that use introspection to suggest suitable\nblocks to connect leverage the type system to help the user create the\npipelines faster and easier.\n\nThis corresponds with the hypothesis of the project, as well as the objective\nthat the system should not only make it hard or impossible to construct\nincorrect graphs, but should make it easier and faster to create correct graphs.\n\nGiving more power to the user does not mean convoluting the interface,\nin fact it can be the opposite.\n\n\nFuture Work\n-----------\n* Surface of optional parameters.\n* Visual Polish.\n    - Smart Bubble breakdown by category.\n    - More indicators when dragging/dropping.\n* Graph Serialization.\n* Support move and zoom in background.\n* Automatic block generation from Python function.\n* Undo functionality (Command pattern).\n* Area drag select.\n* Skeletons of common workflows.\n* Unit/Integration/End to end testing.\n* Automatic windows deployment.\n* Continuous integration.\n* Cache results similar to a REPL[^REPL].\n\nBibliography\n============\n\n[Github]: htttps://github.com/AlvarBer/Persimmon\n[releases]: htttps://github.com/AlvarBer/Persimmon/releases\n[multiple]: http://mailchi.mp/pythonweekly/python-weekly-issue-295\n[websites]: http://forum.ai100.com.cn/blog/thread/ml-2017-05-10/\n[best project]: https://twitter.com/HertfordshireCS/status/857266574356598785\n\n[^REPL]: A Read Eval Print Loop is an interactive console many modern\n    programming languages that allows for the interactive execution of\n    expressions, saving the results in a local session.\n\n",
    "timestamp": "2025-05-23T16:34:21.098037",
    "tags": [],
    "severity": "high",
    "services_affected": [
      "api",
      "web",
      "database",
      "cache"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "kubernetes",
      "aws",
      "redis",
      "elasticsearch",
      "jenkins"
    ],
    "failure_pattern": "resource_exhaustion",
    "timeline_events": [],
    "blast_radius": "localized",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 0.9400000000000001
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/alantech/iasql/blob/e192f8d8887d23bfd399b252a6f9ee8d55a288e9/postmortems/000%20-%20Postmortem%20Template.md",
    "title": "000 - Postmortem Template.md",
    "content": "# 000 - Postmortem for [descriptive name here]\n\n## Level: [Internal, Outage, Corruption, Breach]\n\n## Author(s)\n\n- Some Body <oncetoldme@iasql.com>\n\n## Summary\n\nThis is a postmortem template for outages. In this section you should put a short summary of what happened and how it was resolved. Only one or two paragraphs at most.\n\nAlso, to explain the levels. An \"Internal\" outage is when our internal dev processes are broken and negatively impact the team. An \"Outage\" level is when service is interrupted for users, but zero impact on customer cloud accounts occurred. A \"Corruption\" level we hope to never see, which would imply accidental destruction of cloud resources in a customer account caused by us. Similarly \"Breach\" is a security breach which is similarly very harmful for users.\n\n## Timeline\n\n- **2022-09-14**: A timeline of events that occurred. No need to be super precise, but please use the ISO date format and UTC time if necessary since we're all over the globe.\n\n## Detection\n\nDescribe in a paragraph how the issue was found out.\n\n## Response\n\nDescribe in a paragraph or two what was done to resolve the issue.\n\n## Cause\n\nTry to describe a root cause for the issue in a paragraph.\n\n## Prevention\n\nProposed changes to code and/or company process to avoid this in the future *or* a detailed explanation on why the cure would be worse than the disease.\n\nThis section can be structured however you like to get your point across, and is likely to have the most back-and-forth during postmortem review.\n\nThis is a *blameless* process. As long as no one was being actively malicious a proposal of punishment is not allowed.",
    "timestamp": "2025-05-23T16:34:21.517769",
    "tags": [],
    "severity": "high",
    "services_affected": [],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "postgresql"
    ],
    "failure_pattern": null,
    "timeline_events": [],
    "blast_radius": "localized",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 0.41
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/akhealth/EIS-Modernization/blob/39872addbb9d528bbabb28b26a53f179fbef7bba/first-buy-postmortem.md",
    "title": "first-buy-postmortem.md",
    "content": "# Alaska’s Eligibility Information System Modernization Project Post-Mortem\n\n## Reflecting on the good and the bad from Alaska and 18F’s first contract\n\nJuly 25, 2018\n\n\n## Background\n\nIn December 2017, Alaska’s Department of Public Assistance [announced the award](https://github.com/AlaskaDHSS/EIS-Modernization/blob/ffe20eeb7f7ca2b3b5606ddc5ee26838ee05f80f/vendor-info/RFP-Search-Unification-Award.md) of their first agile software development contract to Resource Data, Inc., an Alaskan company based out of Anchorage, AK. Work began in January, and concluded at the beginning of June. This was the first of many smaller contracts that Alaska is going to award as part of implementing their modular approach to modernizing their Eligibility Information System (EIS). See Alaska’s GitHub repositories for additional background information on the [modernization strategy](https://github.com/AlaskaDHSS/EIS-Modernization/blob/master/README.md) and the first RFP that will update the [Search](https://github.com/AlaskaDHSS/RFP-Search-Unification/blob/master/README.md) functionality of the existing systems. An [initial post-mortem about the RFP process](https://github.com/AlaskaDHSS/RFP-Search-Unification/blob/master/post-award-vendor-info/Post-Mortem_on_the_first_Alaska_buy.v2.pdf) was held after the contract was awarded, but before work had started; this post-mortem was held in June, after the vendor’s work had been completed.\n\n## Purpose\n\nOn June 14, 2018, the EIS-R (Replacement) Product Team from Alaska and 18F held a \"Post-Mortem\" session as part of our commitment to continuous improvement. In thinking about the first buy in our modular procurement strategy, we considered what things worked well, and what things did not work well. The context for this exercise was the post-award period, during which [Resource Data, Inc.](https://www.resourcedata.com/) (RDI) was working.\n\n## What worked well?\n\nThe team was asked to identify a number of items that worked well during the procurement, whether it was under our team’s control or not.\n\n### The vendor’s work was very good\n\nThe team agreed that the work of RDI was high-quality, and that they proved to be a good partner.\n\n- \"Selected vendor did a solid job on delivery.\"\n- \"Procurement resulted in very clear top candidates.\"\n- \"Good trust with vendor.\"\n- \"What they said, they did.\"\n- \"This vendor was real from the get-go, and delivered what we asked for.\"\n\n### DPA’s capacity for \"owning product\" and product management *grew significantly* over the course of the engagement\n\nThe team noted that DPA staff on the team had improved in their own work during the five-month process.\n\n- \"There was a great escalation in DHSS’ work over the course of the project.\"\n- \"Got to try out new things and experiment with new ways of working.\"\n- \"After some initial process hiccups, State tech staff got into delivery pattern for our responsibilities.\"\n- \"State staff paired well into new processes like code reviews.\"\n- \"Alaska started taking on more and more of the code reviews from 18F.\"\n- \"We hit a rhythm with regard to our process about halfway through.\"\n\n### The vendor and DPA collaborated well\n\nRDI worked in the style that DPA is transitioning to working in, and proved a good partner for this first procurement because of that.\n\n- \"The tone of the engagement was really trusting, open, and collaborative.\"\n- \"RDI led in the ways that we needed them to lead (crucially for this first procurement), and followed in the ways that we needed them to follow.\"\n- \"There were several occasions when we needed RDI to be flexible, and they did so well.\"\n- \"RDI called out issues when the State wasn’t doing what they committed — the contract document actually provided useful guidelines.\"\n\n## What didn’t work well?\n\n### DPA is yet to deploy software to users\n\nWhile the product was built incrementally each sprint, the DPA team failed to successfully facilitate deploying that code to end-users at the end of each sprint, or even by the end of the engagement, failing to employ agile correctly and gain the associated benefits. This was primarily the result of security policies and practices, crafted for monolithic software procurements that are not compatible with the rapid delivery of user-tested software increments, that resulted in extensive Authority to Operate (ATO) work which is ongoing. Although the software produced during this buy was informed by user research, and iteratively built, users were not able to interact with functional code and reliable data and provide direct feedback on the built product, missing the benefits of the agile feedback loop.\n\n- \"We got stuck when it came time to actually access data and put it in front of users.\"\n- \"The failure to actually employ agile — delivering value to end-users — was far and away the biggest problem.\"\n- \"Delivering iteratively to actual users, and getting their feedback into the process, was a persistent challenge.\"\n\n#### Action Items\n\n- Do not begin agile projects without a clear path to deploy to staging at the end of the first sprint, and to production early and frequently.\n- Ensure that projects under development have access to test data that is a realistic, complete simulation of the live data.\n- Unblock the organizational obstacles to a path to deployment (which are specified as other issues, below).\n\n### DPA and DHSS aren’t yet set up to support agile fully\n\nIt is not enough to hire an agile development team and have a DPA product team work with them in an agile fashion, because the entire process is dependent on people within DPA and DHSS who are not a part of that process, and may not have benefited from the resources and freedoms afforded to the product team. This disconnect, between those who were part of the process and those who weren’t, prevented the development team and the product team from completing their work.\n\n- \"Tension between a new approach and old one.\"\n- \"Now we’ve had to deal with a whole bunch of security issues we’ve never had to deal with before. Trying this in a new way uncovers those issue.\"\n- \"We’re not across the chasm of DevOps.\"\n- \"We focused on ’security plan,’ but we missed prioritizing and prototyping make-or-break technical security controls.\"\n- \"The state wasn’t able to keep pace with the vendor because of infrastructure/security issues.\"\n\n#### Action Items\n\n- Before beginning any new projects, research and document the security requirements, and engage with the security team as early as possible.\n- Do a better job of helping the security team to perceive the time- and resource-saving value of DevSecOps.\n- DHSS needs to adequately staff the security office. All indications are that three people is an insufficient number.\n- Ensure that there is buy-in at all levels to help remove unnecessary friction when working with security, network, and ops teams.\n\n### Critical design work fell to 18F\n\nThe initial design work was not what we believed that the project needed, necessitating a significant correction. That happened at a crucial point early in the development process, and required that we lean heavily on 18F to perform design work, to ensure a smooth transition and to keep the team from losing velocity. This was handled quickly and smoothly by all involved, and little time was lost as a result.\n\n- \"Initial design approach and subsequent need for 18F to establish the initial design direction to keep things moving.\"\n- \"Vendor pivoted agreeably\"\n\n#### Action Items\n\n- When design is a critical part of an increment, be  thoughtful about design expertise representation on future vendor-assessment panels.\n- Reconsider the point weighting that goes towards design expertise.\n- Personnel changes are difficult to anticipate, and must be dealt with _in situ_, but should not be avoided if a course correction is necessary. This case was handled directly, and should serve as a guide for handling similar problems in the future.\n\n### Unsustainable levels of involvement were needed from some staff\n\nSome DPA staff on the project found it challenging to maintain the necessary level of work for their role, due to unrelated obligations on other projects. This sometimes blocked the work of others, preventing progress on the project.\n\n- \"People were spread across too many projects, not as focused as they should be.\"\n- \"Lack of availability for product owner in the engagement.\"\n- \"There were AK tech staff resource constraints.\"\n\n#### Action Items\n\n- When staffing a project, set expectations for how much time that it is going to require over what duration, and ensure that the necessary supervisors are prepared to support that commitment. This is especially true if the supervisors are in different organizations than most of the product team.\n- Get adequate time from a project’s assigned staff, rather than adding additional staff to an inadequately-resourced project, in order to minimize complexity.\n- If there is a need for staff that cannot be met with the current team, hire the right kind of talent to fill that staffing need.\n",
    "timestamp": "2025-05-23T16:34:22.471081",
    "tags": [],
    "severity": "high",
    "services_affected": [
      "api",
      "web",
      "database"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "kubernetes",
      "aws",
      "elasticsearch",
      "jenkins"
    ],
    "failure_pattern": "resource_exhaustion",
    "timeline_events": [],
    "blast_radius": "global",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 0.92
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/gopheracademy/gopheracademy-web/blob/f7d8cdb252a7e17a4d639d7edb332d19b3599e4b/content/advent-2018/postmortem-debugging-delve.md",
    "title": "postmortem-debugging-delve.md",
    "content": "+++\nauthor = [\"Vladimir Varankin\"]\ntitle = \"Postmortem debugging Go services with Delve\"\nlinktitle = \"Postmortem debugging Go services with Delve\"\ndate = 2018-12-02\nseries = [\"Advent 2018\"]\n+++\n\nOne day, several instances of one of our production services stopped accepting incoming traffic. HTTP requests successfully went through the load balancer reaching the instance and just hanged. What followed became an exciting exercise in debugging of a running production service written in Go.\n\nBelow is a step-by-step guide that demonstrates the process which helped us in identifying the root causes of the problem.\n\nTo make things easier we will take a simple HTTP service, written in Go, as our debugging target. The implementation details of the service are not very important now (we will dig into the code later). A real-world production service will likely to consist of many different components, that implement business logic and the infrastructure of the service. Let’s convince ourselves that the service was already “battle-tested” by running it production for many months :)\n\nThe source code and the details about the setup can be found in [repository][] on GitHub. To follow along, you will need a VM running Linux. I use Vagrant with the [vagrant-hostmanager](https://github.com/sevos/vagrant-hostmanager) plugin. Have a look at the [`Vagrantfile`](https://github.com/narqo/postmortem-debug-go/blob/master/Vagrantfile) in the root of the repository for detailed information.\n\nTo debug the problem, we need to bump into the problem first. Let’s start the VM, build our HTTP service, run it and see what will happen:\n\n```\n$ vagrant up\nBringing machine 'server-test-1' up with 'virtualbox' provider...\n\n$ vagrant ssh server-test-1\nWelcome to Ubuntu 18.04.1 LTS (GNU/Linux 4.15.0-33-generic x86_64)\n···\nvagrant@server-test-1:~$ cd /vagrant/example/server\nvagrant@server-test-1:/vagrant/example/server$ go build\nvagrant@server-test-1:/vagrant/example/server$ ./server --addr=:10080\nserver listening addr=:10080\n```\n\nWe can test the server is workin by sending a request using curl. In a new terminal window run the following command:\n\n```\n$ curl 'http://server-test-1:10080'\nOK\n```\n\nTo simulate the failure we want to debug we need to send a bunch of requests. We can do this with [wrk][] HTTP benchmarking tool. My MacBook has four cores, so running wrk with four threads and 1000 connections is usually enough.\n\n```\n$ wrk -d1m -t4 -c1000 'http://server-test-1:10080'\nRunning 1m test @ http://server-test-1:10080\n  4 threads and 1000 connections\n  ···\n```\n\nAfter a brief period the server freezes. Even after wrk finished the run, the server is unable to process an incoming request:\n\n```\n$ curl --max-time 5 'http://server-test-1:10080/'\ncurl: (28) Operation timed out after 5001 milliseconds with 0 bytes received\n```\n\nIndeed, we have a problem! Let's have a look.\n\n---\n\n*In the real situation with our production service, after the server has started, the total number of spawned goroutines for incoming requests has risen so much that the server became unresponsive. Requests to pprof debug handlers were s-u-u-u-per slow, making it look like the server was completely \"dead\". Similarly, our attempts to kill the process with `SIGQUIT` to [get the stack dump of running goroutines][1] didn't seem to work.*\n\n---\n\n### GDB and Coredump\n\nWe can start with trying to inspect the running service with GDB (GNU Debugger).\n\n---\n\n*Running a debugger in the production environment will likely require additional privileges. If in doubt, be wise and always consult with your operations team first.*\n\n---\n\nConnect to another SSH session on the VM, find server's process id, and attach to the process with the debugger:\n\n```\n$ vagrant ssh server-test-1\nWelcome to Ubuntu 18.04.1 LTS (GNU/Linux 4.15.0-33-generic x86_64)\n···\nvagrant@server-test-1:~$ pgrep server\n1628\nvagrant@server-test-1:~$ cd /vagrant\nvagrant@server-test-1:/vagrant$ sudo gdb --pid=1628 example/server/server\nGNU gdb (Ubuntu 8.1-0ubuntu3) 8.1.0.20180409-git\n···\n```\n\nWith the debugger attached to the process, we can run GDB's `bt` command (aka backtrace) to check the stack trace of the current thread:\n\n```\n(gdb) bt\n#0  runtime.futex () at /usr/local/go/src/runtime/sys_linux_amd64.s:532\n#1  0x000000000042b08b in runtime.futexsleep (addr=0xa9a160 <runtime.m0+320>, ns=-1, val=0) at /usr/local/go/src/runtime/os_linux.go:46\n#2  0x000000000040c382 in runtime.notesleep (n=0xa9a160 <runtime.m0+320>) at /usr/local/go/src/runtime/lock_futex.go:151\n#3  0x0000000000433b4a in runtime.stoplockedm () at /usr/local/go/src/runtime/proc.go:2165\n#4  0x0000000000435279 in runtime.schedule () at /usr/local/go/src/runtime/proc.go:2565\n#5  0x00000000004353fe in runtime.park_m (gp=0xc000066d80) at /usr/local/go/src/runtime/proc.go:2676\n#6  0x000000000045ae1b in runtime.mcall () at /usr/local/go/src/runtime/asm_amd64.s:299\n#7  0x000000000045ad39 in runtime.rt0_go () at /usr/local/go/src/runtime/asm_amd64.s:201\n#8  0x0000000000000000 in ?? ()\n```\n\nHonestly, I’m not a GDB expert, but it seems that Go runtime is putting threads to sleep. *But why?*\n\nDebugging a working process is “fun” but let’s save a coredump of the process and analyse it offline. We can do this with GDB's `gcore` command. The core file will be saved as `core.<process_id>` in the current working directory.\n\n```\n(gdb) gcore\nSaved corefile core.1628\n(gdb) quit\nA debugging session is active.\n\n\tInferior 1 [process 1628] will be detached.\n\nQuit anyway? (y or n) y\nDetaching from program: /vagrant/example/server/server, process 1628\n```\n\nWith core file saved, we're no longer required to keep the process running. Feel free to “kill -9” it.\n\nNote that even for our simple server, the core file will be pretty big (for me it was 1.2G). For a real production service it’s likely to be huge.\n\n*For more info on the topic of debugging with GDB, check out Go’s own \"[Debugging Go Code with GDB][2]\".*\n\n### Enter Delve, Debugger for Go\n\n[Delve][] is the debugger for Go programs. It is similar to GDB but is aware of Go's runtime, data structures and other internals of the language.\n\nI highly recommend a talk by Alessandro Arzilli “[Internal Architecture of Delve, a Debugger For Go](https://www.youtube.com/watch?v=IKnTr7Zms1k)” from GopherCon EU 2018 if you're interested to know about Delve's internals.\n\nDelve is written in Go so installing it as simple as running:\n\n```\n$ go get -u github.com/derekparker/delve/cmd/dlv\n```\n\nWith Delve installed we can start analysing the core file by running `dlv core <path to service binary> <core file>`. We start by listing all goroutines that were running when the coredump was taken. Delve's `goroutines` command does exactly this:\n\n```\n$ dlv core example/server/server core.1628\n\n(dlv) goroutines\n  ···\n  Goroutine 4611 - User: /vagrant/example/server/metrics.go:113 main.(*Metrics).CountS (0x703948)\n  Goroutine 4612 - User: /vagrant/example/server/metrics.go:113 main.(*Metrics).CountS (0x703948)\n  Goroutine 4613 - User: /vagrant/example/server/metrics.go:113 main.(*Metrics).CountS (0x703948)\n```\n\nUnfortunately, in a real case scenario, the list can be so big, it doesn't even fit into terminal's scroll buffer. Remember that the server spawns a goroutine for each incoming request, so `goroutines` command has shown us a list of almost a million items. Let's pretend that we faced exactly that and think of a way to work through this situation ;)\n\nDelve allows running it in the \"headless\" mode and interact with the debugger via [JSON-RPC API](https://github.com/derekparker/delve/tree/master/Documentation/api).\n\nRun the same `dlv core` command as we just did, but this time specify that we want starting Delve’s API server:\n\n```\n$ dlv core example/server/server core.1628 --listen :44441 --headless --log\nAPI server listening at: [::]:44441\nINFO[0000] opening core file core.1628 (executable example/server/server)  layer=debugger\n```\n\nAfter debug server is running, we can send commands to its TCP port and store the output as raw JSON. Let's get the same list of running goroutines we've just seen, but this time saving the results to a file:\n\n```\n$ echo -n '{\"method\":\"RPCServer.ListGoroutines\",\"params\":[],\"id\":2}' | nc -w 1 localhost 44441 > server-test-1_dlv-rpc-list_goroutines.json\n```\n\nNow we have a (pretty big) JSON file with lots of raw information. I like to use [jq][] command to inspect any JSON data and just to have an idea of what the data looks like, I query the first three objects in the JSON's `result` field:\n\n```\n$ jq '.result[0:3]' server-test-1_dlv-rpc-list_goroutines.json\n[\n  {\n    \"id\": 1,\n    \"currentLoc\": {\n      \"pc\": 4380603,\n      \"file\": \"/usr/local/go/src/runtime/proc.go\",\n      \"line\": 303,\n      \"function\": {\n        \"name\": \"runtime.gopark\",\n        \"value\": 4380368,\n        \"type\": 0,\n        \"goType\": 0,\n        \"optimized\": true\n      }\n    },\n    \"userCurrentLoc\": {\n      \"pc\": 6438159,\n      \"file\": \"/vagrant/example/server/main.go\",\n      \"line\": 52,\n      \"function\": {\n        \"name\": \"main.run\",\n        \"value\": 6437408,\n        \"type\": 0,\n        \"goType\": 0,\n        \"optimized\": true\n      }\n    },\n    \"goStatementLoc\": {\n      \"pc\": 4547433,\n      \"file\": \"/usr/local/go/src/runtime/asm_amd64.s\",\n      \"line\": 201,\n      \"function\": {\n        \"name\": \"runtime.rt0_go\",\n        \"value\": 4547136,\n        \"type\": 0,\n        \"goType\": 0,\n        \"optimized\": true\n      }\n    },\n    \"startLoc\": {\n      \"pc\": 4379072,\n      \"file\": \"/usr/local/go/src/runtime/proc.go\",\n      \"line\": 110,\n      \"function\": {\n        \"name\": \"runtime.main\",\n        \"value\": 4379072,\n        \"type\": 0,\n        \"goType\": 0,\n        \"optimized\": true\n      }\n    },\n    \"threadID\": 0,\n    \"unreadable\": \"\"\n  },\n  ···\n]\n```\n\nEvery object in the JSON represents a single goroutine. [`goroutines` command manual](https://github.com/derekparker/delve/blob/master/Documentation/cli/README.md#goroutines) tells us what Delve knows about each goroutine. We're interested in `userCurrentLoc` field, which is, as manual describes it, the \"topmost stackframe in user code\", meaning it is the last location in the service code the goroutine came across.\n\nIn order to get an overview of what goroutines did at the moment the core file was created, let's collect and count all distinct function names and line numbers for all `userCurrentLoc` fields in the JSON.\n\n```\n$ jq -c '.result[] | [.userCurrentLoc.function.name, .userCurrentLoc.line]' server-test-1_dlv-rpc-list_goroutines.json | sort | uniq -c\n\n   1 [\"internal/poll.runtime_pollWait\",173]\n1000 [\"main.(*Metrics).CountS\",95]\n   1 [\"main.(*Metrics).SetM\",105]\n   1 [\"main.(*Metrics).startOutChannelConsumer\",179]\n   1 [\"main.run\",52]\n   1 [\"os/signal.signal_recv\",139]\n   6 [\"runtime.gopark\",303]\n```\n\nThe majority of goroutines (1000 in the snippet above) have stuck in function `main.(*Metrics).CountS` at line 95. Now, this is the time to look at the [source code][repository] of our service.\n\nIn the package `main`, find `Metrics` struct and look at its `CountS` method (see [`example/server/metrics.go`](https://github.com/narqo/postmortem-debug-go/blob/2c42ca73ebd500fe8da1c6ac8ecaf4af143aca78/example/server/metrics.go#L94)):\n\n```go\n// CountS increments counter per second.\nfunc (m *Metrics) CountS(key string) {\n    m.inChannel <- NewCountMetric(key, 1, second)\n}\n```\n\nOur server has stuck on sending to the `inChannel` channel. Let’s find out who is supposed to read from this channel. After inspecting the code, we should find the [following function](https://github.com/narqo/postmortem-debug-go/blob/2c42ca73ebd500fe8da1c6ac8ecaf4af143aca78/example/server/metrics.go#L109):\n\n```\n// starts a consumer for inChannel\nfunc (m *Metrics) startInChannelConsumer() {\n    for inMetrics := range m.inChannel {\n   \t    // ···\n    }\n}\n```\n\nThe function reads values out of the channel and does something with them, one by one. In what possible situations could the sending to this channel being blocked?\n\nWhen working with channels, there are only four possible \"oopsies\", according to Dave Cheney's \"[Channel Axioms](https://dave.cheney.net/2014/03/19/channel-axioms)\":\n\n- send to a nil channel blocks forever\n- receive from a nil channel blocks forever\n- send to a closed channel panics\n- receive from a closed channel returns the zero value immediately.\n\n\"Send to a nil channel block forever\" – at first sight, this seems like something possible. But, after double-checking with the code, `inChannel` is [initialised in the `Metrics` constructor](https://github.com/narqo/postmortem-debug-go/blob/2c42ca73ebd500fe8da1c6ac8ecaf4af143aca78/example/server/metrics.go#L73). So it can't be nil.\n\nAs you may notice, there was no `startInChannelConsumer` method in the list of function we've previously collected with jq. Could this (buffered) channel become full because we've stuck somewhere inside [`main.(*Metrics).startInChannelConsumer`](https://github.com/narqo/postmortem-debug-go/blob/2c42ca73ebd500fe8da1c6ac8ecaf4af143aca78/example/server/metrics.go#L109)?\n\nDelve provides the start position from where we came to the location in the code described in `userCurrentLoc` field in the JSON. This location is stored in `startLoc` field. With the following jq command search for all goroutines whose start location was in `startInChannelConsumer` function:\n\n```\n$ jq '.result[] | select(.startLoc.function.name | test(\"startInChannelConsumer$\"))' server-test-1_dlv-rpc-list_goroutines.json\n\n{\n  \"id\": 20,\n  \"currentLoc\": {\n    \"pc\": 4380603,\n    \"file\": \"/usr/local/go/src/runtime/proc.go\",\n    \"line\": 303,\n    \"function\": {\n      \"name\": \"runtime.gopark\",\n      \"value\": 4380368,\n      \"type\": 0,\n      \"goType\": 0,\n      \"optimized\": true\n    }\n  },\n  \"userCurrentLoc\": {\n    \"pc\": 6440847,\n    \"file\": \"/vagrant/example/server/metrics.go\",\n    \"line\": 105,\n    \"function\": {\n      \"name\": \"main.(*Metrics).SetM\",\n      \"value\": 6440672,\n      \"type\": 0,\n      \"goType\": 0,\n      \"optimized\": true\n    }\n  },\n  \"startLoc\": {\n    \"pc\": 6440880,\n    \"file\": \"/vagrant/example/server/metrics.go\",\n    \"line\": 109,\n    \"function\": {\n      \"name\": \"main.(*Metrics).startInChannelConsumer\",\n      \"value\": 6440880,\n      \"type\": 0,\n      \"goType\": 0,\n      \"optimized\": true\n    }\n  },\n  ···\n}\n```\n\nThere is a single item in the result. That's promising!\n\nA goroutine with id \"20\" started in `main.(*Metrics).startInChannelConsumer` at line 109 (see `startLoc` field in the result) and went up to the `main.(*Metrics).SetM` line 105 (`userCurrentLoc` field), and got stuck there.\n\nKnowing the id of the goroutine dramatically narrows down our scope of interest (*and we don't need to dig into raw JSON anymore, I promise* :). With Delve's `goroutine` command we change current goroutine to the one we've found. Then we can use `stack` command to print the stack trace of this goroutine:\n\n```\n$ dlv core example/server/server core.1628\n\n(dlv) goroutine 20\nSwitched from 0 to 20 (thread 1628)\n\n(dlv) stack -full\n0  0x000000000042d7bb in runtime.gopark\n   at /usr/local/go/src/runtime/proc.go:303\n       lock = unsafe.Pointer(0xc000104058)\n       reason = waitReasonChanSend\n···\n3  0x00000000004066a5 in runtime.chansend1\n   at /usr/local/go/src/runtime/chan.go:125\n       c = (unreadable empty OP stack)\n       elem = (unreadable empty OP stack)\n\n4  0x000000000062478f in main.(*Metrics).SetM\n   at /vagrant/example/server/metrics.go:105\n       key = (unreadable empty OP stack)\n       m = (unreadable empty OP stack)\n       value = (unreadable empty OP stack)\n\n5  0x0000000000624e64 in main.(*Metrics).sendMetricsToOutChannel\n   at /vagrant/example/server/metrics.go:146\n       m = (*main.Metrics)(0xc000056040)\n       scope = 0\n       updateInterval = (unreadable could not find loclist entry at 0x89f76 for address 0x624e63)\n\n6  0x0000000000624a2f in main.(*Metrics).startInChannelConsumer\n   at /vagrant/example/server/metrics.go:127\n       m = (*main.Metrics)(0xc000056040)\n       inMetrics = main.Metric {Type: TypeCount, Scope: 0, Key: \"server.req-incoming\",...+2 more}\n       nextUpdate = (unreadable could not find loclist entry at 0x89e86 for address 0x624a2e)\n```\n\nBottom to top:\n\n(6) At `main.(*Metrics).startInChannelConsumer` a new `inMetrics` value from the channel has been received\n\n(5) We called `main.(*Metrics).sendMetricsToOutChannel` and processed to line 146 of `example/server/metrics.go`\n\n(4) Then `main.(*Metrics).SetM` was called.\n\nAnd so on until we've been blocked in `runtime.gopark` with `waitReasonChanSend`.\n\nEverything makes sense now!\n\nWithin a single goroutine, the function that reads values out of a buffered channel tried to put additional values into the channel. As the number of incoming values to the channel became close to its capacity, the consumer-function deadlocked itself trying to add value to the full channel. Since the single channel's consumer was deadlocked, every new incoming request that tried adding values into the channel became blocked as well.\n\n----\n\nAnd that’s the story. Using the described technique we’ve managed to find the root cause of the problem. The original piece of code was written many years ago. Nobody even looked at it and never thought it might bring such issues.\n\nAs you just saw not everything is ideal with the tooling yet. But the tools exist and become better over time. I hope, I’ve encouraged you to give them a try. And I’m very interested to hear about other ways to work around a similar scenario.\n\n\n*Vladimir is a Backend Developer at adjust.com. @tvii on Twitter, @narqo on Github.*\n\n[1]: https://golang.org/pkg/os/signal/#hdr-Default_behavior_of_signals_in_Go_programs\n[2]: https://golang.org/doc/gdb\n[repository]: https://github.com/narqo/postmortem-debug-go\n[wrk]: https://github.com/wg/wrk\n[Delve]: https://github.com/derekparker/delve\n[jq]: https://stedolan.github.io/jq/\n",
    "timestamp": "2025-05-23T16:34:22.910785",
    "tags": [],
    "severity": "high",
    "services_affected": [
      "api",
      "web",
      "database",
      "monitoring"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "azure",
      "postgresql",
      "elasticsearch",
      "kafka",
      "nginx",
      "prometheus",
      "jenkins"
    ],
    "failure_pattern": "resource_exhaustion",
    "timeline_events": [],
    "blast_radius": "global",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 0.9400000000000001
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/daeken/Benjen/blob/6fd44323ed6703f1f5149a9a51bdc692eca7553c/daeken.com/entries/alky-postmortem.md",
    "title": "alky-postmortem.md",
    "content": "title: Alky Postmortem\ndate: 2009-12-27\n\nA lot of people have asked me what happened to the Alky project. The short answer is that we made a lot of bad business moves, but that answer glances over a lot of the fun little details. Having gained considerable knowledge from other stories of failed startups, I figure I'll throw one of my own into the ring.\n\n# History\n\nThe Alky project's history can be split into a few phases:\n\n## Conception\n\nAlky began as an experiment to see how easily I could convert Windows PE files to run natively on Mac OS X (x86). If it were to work, it may make it possible for me to convert Windows games to run natively on OS X, which was my primary focus. I started by writing a converter that ripped the segments out of the original file and throw them into a Mach-O binary, then linking it against 'libalky'.\n\nLibAlky was a reimplementation of the Win32 API. At first, I tested with files that just called a few simple things, like user32:MessageBoxA, and it worked spectacularly. It was at this point that I realized the basic concept was not only sound, it made a whole lot of sense.\n\n## Actual project creation\n\nOnce the initial prototype worked, it was time to get people interested. I went to Michael Robertson (who was my employer at the time) and gave him a rundown. He offered to buy the domain, host the project, and get some resources behind it, primarily PR-wise. Within a few days, the project started actually feeling real. We got the site up, wrote some copy to explain what we were doing, and then put it out on Slashdot.\n\nUnsurprisingly, we received three types of responses:\n\n1.  This is impossible, it simply can't work from a technical point of view. (This was especially hilarious coming from a Transitive engineer, considering that what they did is considerably more complicated.)\n2.  This is possible, but it won't happen due to the immense amount of work involved. (Half right -- more on this later.)\n3.  Wine sucks, I hope you guys can do it better. (We couldn't -- more on this later.)\n\nBut more importantly than anything else, we got some developers involved. However, they ended up being driven away.\n\n## Mismanagement of the open source project\n\nAlky was the first open source project I'd ever managed that consisted of more than myself and a few friends, and as a result it was mismanaged at every possible turn. It was unclear what people should've been working on, no effort was made to document the project, and no real effort was made to include the developers that were so interested in working on the project.\n\nThis was compounded by a rewrite and redesign, which I decided (foolishly) to take on entirely by myself. Some of the design was done as a group, but none of it ever left my hard drive, so work stalled on the existing codebase and the project started to wither.\n\nShortly thereafter, Falling Leaf Systems was incorporated to back the development of Alky. This further increased the rift between the open source developers and the \"core\" group (consisting of myself and one of the cofounders of the company). Originally, we planned to dual-license the codebase, but as we got more into discussions of the goals of the business, it became clear that closing the source was the right move. However, we couldn't have picked a poorer way to do it.\n\nRather than be upfront about the move to closing the source, we simply killed the IRC channel and took down the site. The open source developers were left wondering what happened, while we moved on the rewrite.\n\n## Prey and the Sapling Program\n\nAlky was completely rewritten with the new design, and work quickly moved forward on getting the first game running. We released a converter for the demo of Prey (Mac OS X only at first), as part of our new Sapling Program. The Sapling Program was created as a way to get some upfront money for the company, so we could get needed hardware, go to the GDC (which was a horrendous waste of money, for the record), etc. We sold memberships for $50, which gained access to the Prey converter and all future converters. Of course, after we finished Prey for Linux, there were no more converters.\n\n## Loss of focus\n\nAfter Prey was done, we'd planned on implementing DirectX 9 with hopes of running Oblivion, but we lost sight of this goal. Instead, we decided to go after DirectX 10. Along with this shift in focus came an even bigger one: we were no longer targeting Mac OS X and Linux primarily, but Windows XP. We saw that Vista was tanking, and DirectX 10 was only available there, so we decided that we only had a limited window to make money off of that.\n\nShortly after we made the change, we released a library to allow a few of the DX10 SDK demos to run on Windows XP via OpenGL, albeit with serious missing features (e.g. no shaders). It got some attention, but few people were able to actually get it working. After this was out, I started work on reverse-engineering the shader format and writing a recompiler that would allow Direct3D 10 shaders to work with OpenGL, and even more importantly, without DX10-class hardware. Geometry shaders were planned to run on the CPU if the hardware wasn't available to handle it, and work progressed quickly.\n\n## Alky for Applications\n\nWe discovered a project known as VAIO to allow Vista applications (non-DX10) to run on Windows XP, and after some talks with the developers, they (or more specifically, one of them -- we'll call him Joe) were sucked into Falling Leaf. We rebranded VAIO and it was released as Alky for Applications. After this, Joe was tasked with making Halo 2 and Shadowrun -- Vista-exclusive but non-DX10 games -- run on Windows XP. We were so confident in our ability to do this, we set up an Amazon referral system and made it such that anyone who purchased either game through us would get a copy of the converter for free.\n\nAt this point, I was working heavily on DX10 stuff, and was under tight deadlines to show things off to a company that was interested in our technology, but the clock was ticking. About a week before the planned release of the Halo 2 and Shadowrun compatibility system, Joe came to us and told us that he'd not been able to get anything working, and had very little to show for the time spent. In retrospect, it was my fault for not checking up on him (my job as his manager), but at that point it just made me realize there was no way it was going to be done in time.\n\nI picked it up -- dropping DX10 in the process -- and attempted, feebly, to get it done. Of course, I picked the most difficult way to approach it; reverse-engineering the Windows application compatibility system. By the time I got anything remotely close to working, we'd already missed our deadlines for both the DX10 work and the Halo 2/Shadowrun converter.\n\n## The death of Falling Leaf\n\nAfter all this went down, I fell into a bit of a depression. I became demoralized to the point of just not wanting to go on anymore, in the face of repeated failures, very much in public. Despite us not walking away with a dime -- we made approximately $7000 in total, none of which went to any of the founders of the company -- I felt that we'd ripped people off, despite the best of intentions. It wasn't long after this that Brian (one of my co-founders) stepped down as CEO, and I closed the doors on the company. The source to Alky and Philosopher (the compiler framework used in the shader work) were released at the same time.\n\n# Lessons Learned\n\n1.  If you're going to run an open source project, make it easy for people to contribute. Not only that, make it worthwhile for them to contribute and make them a part of the project, not just free workers.\n2.  If you're going to kill an open source project, be up front with the people involved. It's not only dishonest not to do so, you lose people who may well go to bat for you even if you are commercial. This is especially important for a project like Alky, where we faced nearly universal negativity.\n3.  If you're going to change focus, be clear with your users as to what's going on, and make sure you make it clear that the old stuff is dead and gone. If you don't, you come off looking terrible in the press, and it just makes you look like amateurs (which we were).\n4.  Make sure your employees are actually doing what they're supposed to be doing, especially if they're working remotely. This was really the final nail in the coffin for Falling Leaf.\n\n# Alky Reborn\n\nNow, with all of that said, there's a light at the end of the tunnel perhaps. The source for Alky has been pulled into [Github][1] and it seems that development is picking up again. Perhaps I can shed some light into what design decisions were made, how it was implemented, and how I'd do it now if I were so inclined. I don't plan on working on Alky again (that time has passed), but I'd still love to see it succeed.\n\n [1]: http://github.com/callen/Alky-Reborn\n\n## The old Alky design\n\nAlky's original prototype had a very simple design, library-wise. There was one big LibAlky which contained all of the Win32 API implementations, each talking directly to native APIs. This design very quickly became unworkable, as we had tons of duplicated, unmaintainable code.\n\n## The new Alky design\n\nAlky was redesigned such that we had the Nucleus and the Win32 APIs. The Nucleus was intended to abstract away the platform-specific details and expose a universal API that the Win32 APIs could sit on cleanly. While a good idea, it quickly broke down in implementation. I ended up writing code that straddled the Nucleus and the Linux/OS X APIs, rather than abstracting everything away. This led to slower development and an even more complicated code base.\n\n## Potential new design\n\nHaving done two implementations of Alky and quite a few other projects that relate to it in concept (IronBabel, Renraku (OS design plays a factor here), etc), I think I'm at a place where I can perhaps come up with a workable design.\n\nThe key point where both Alky implementations (and Wine, IMHO) failed is in maintainability. The codebase was a rats nest, much like the real Win32 APIs, and neither implementation managed to help this at all. I think this needs to be the absolute top priority, above performance, compatibility, and all else. If your code is maintainable, all the rest can happen.\n\nWith that focus in mind, here are the things I'd do with a new design.\n\n*   Implement the APIs on top of Mono, taking advantage of the flexible marshalling that P/Invoke gives you. This will allow you to simplify things greatly, and will only have a marginal performance hit in most cases.\n*   In cases where performance is critical, drop down and implement things in C, C , or assembly. If this chunk of the project is greater than 10% of the codebase, you've got bigger problems.\n*   Abstract, abstract, abstract. Break things into the smallest chunks possible and reuse them. This is what we tried to do with the Nucleus idea, but it was easy to just ignore it for complex pieces.\n*   Write thorough unit tests for every API that's implemented (public and internal). Regression testing would also make things really nice.\n*   Rather than trying to get real games/applications running immediately, write your own simple applications that test specific chunks. This would've cut down considerably on the development time in the old revisions of Alky.\n*   Write a great debugger to be able to step through applications cleanly. In the old days, I'd break out IDA Pro and step through a game on Windows, then compare the behavior to the Alkified version, but this was just downright painful.\n*   Make it work on Windows, to allow easy side-by-side comparisons.\n\nThe suggestion that this should be built on top of Mono/.NET sounds ridiculous, I'm sure, but I do think it'd give the project a shot.\n\n# In Closing\n\nI hope this has given you some insight into what went down with Falling Leaf, some ideas of what not to do (obviously, it's easy to completely overlook these things when you're down in the trenches, as we did), and where Alky could one day go. I wish the Alky Reborn folks the best of luck, and I hope some of my advice helps.\n\nHappy Hacking,   \n- Cody Brocious (Daeken)\n",
    "timestamp": "2025-05-23T16:34:23.320133",
    "tags": [],
    "severity": "high",
    "services_affected": [
      "api",
      "web"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [],
    "failure_pattern": null,
    "timeline_events": [],
    "blast_radius": "global",
    "detection_time": null,
    "mitigation_actions": [
      "the rift between the open source developers and the \"core\" group (consisting of myself and one of the cofounders of the company)"
    ],
    "quality_score": 0.44
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/r9y-dev/r9y-map/blob/900ec11a60c8997168f359904dc593c2210b06fe/docs/Blameless_Postmortems.md",
    "title": "Blameless_Postmortems.md",
    "content": "# Blameless Postmortems\n\n**Definition:**\n\nA blameless postmortem is a meeting or process that is held after an incident or outage to analyze what happened and why, and to identify ways to prevent similar incidents from happening in the future. Blameless postmortems are conducted in a non-punitive environment, where the goal is to learn from mistakes and improve processes, rather than to assign blame to individuals.\n\n**Key Principles:**\n\n* **Focus on learning:** The primary goal of a blameless postmortem is to learn from the incident and identify ways to prevent similar incidents from happening in the future.\n* **No blame:** Blameless postmortems are conducted in a non-punitive environment, where the focus is on identifying the root causes of the incident, rather than assigning blame to individuals.\n* **Encourage participation:** All relevant stakeholders, including engineers, operations staff, and management, should be encouraged to participate in the postmortem.\n* **Use data:** Postmortems should be based on data, such as logs, metrics, and incident reports. This data can help to identify the root causes of the incident and to develop effective prevention strategies.\n* **Document and share findings:** The findings of the postmortem should be documented and shared with all relevant stakeholders. This can help to ensure that the lessons learned from the incident are applied to future projects and initiatives.\n\n**Benefits:**\n\n* **Improved incident response:** Blameless postmortems can help to improve incident response by identifying common causes of incidents and developing effective prevention strategies.\n* **Increased collaboration:** Blameless postmortems can help to increase collaboration between different teams, such as engineering and operations, by providing a forum for them to discuss and learn from each other.\n* **Improved decision-making:** Blameless postmortems can help to improve decision-making by providing leaders with a better understanding of the risks and potential consequences of different courses of action.\n* **Increased trust:** Blameless postmortems can help to increase trust between teams and between leaders and employees by creating a culture of learning and continuous improvement.\n\n**Examples:**\n\n* [Google's Postmortem Culture](https://landing.google.com/sre/sre-book/chapters/postmortem-culture/)\n* [Netflix's Blameless Postmortem Process](https://netflixtechblog.com/the-netflix-postmortem-culture-b3f460886882)\n* [Etsy's Postmortem Process](https://codeascraft.com/2010/06/16/postmortem-culture-at-etsy/)\n\n**References:**\n\n* [The Site Reliability Workbook](https://landing.google.com/sre/sre-book/chapters/postmortem-culture/)\n* [Postmortem Culture: Learning from Failure](https://www.oreilly.com/library/view/postmortem-culture/9781098118123/)\n* [Blameless Postmortems: A Guide to Learning from Mistakes](https://itrevolution.com/blameless-postmortems-a-guide-to-learning-from-mistakes/)\n\n## Related Tools and Products\n\n**Tools:**\n\n* **Blameless:** A SaaS platform that helps teams conduct blameless postmortems. It provides a structured process for gathering data, identifying root causes, and developing action plans. [Website](https://blameless.com/)\n* **Postmortem.io:** A free and open-source tool for conducting blameless postmortems. It provides a simple interface for gathering data and generating reports. [Website](https://postmortem.io/)\n* **Incident Management:** Many incident management tools, such as PagerDuty and VictorOps, have built-in features for conducting postmortems. These features can help teams to track the progress of postmortems and to ensure that action plans are implemented.\n\n**Resources:**\n\n* **Google's Postmortem Template:** Google's postmortem template is a comprehensive guide that can help teams to conduct effective blameless postmortems. [Template](https://docs.google.com/document/d/15dPELUcXClaiJ-qLoH_NpVmtz9s7gcmmV0-DGodze80/edit)\n* **Netflix's Postmortem Guide:** Netflix's postmortem guide provides a detailed overview of their blameless postmortem process. [Guide](https://netflixtechblog.com/the-netflix-postmortem-culture-b3f460886882)\n* **Etsy's Postmortem Process:** Etsy's postmortem process is a lightweight and effective approach to blameless postmortems. [Process](https://codeascraft.com/2010/06/16/postmortem-culture-at-etsy/)\n\n**Additional Tips:**\n\n* Use a structured process for conducting postmortems. This will help to ensure that all relevant information is gathered and that the root causes of the incident are identified.\n* Encourage participation from all relevant stakeholders. This includes engineers, operations staff, and management.\n* Focus on learning from the incident, rather than assigning blame. The goal is to identify ways to prevent similar incidents from happening in the future.\n* Document the findings of the postmortem and share them with all relevant stakeholders. This will help to ensure that the lessons learned from the incident are applied to future projects and initiatives.\n\n## Related Terms\n\n**Related Terms:**\n\n* **Incident:** An unplanned interruption to a service or process.\n* **Outage:** A period of time when a service or process is unavailable.\n* **Root Cause Analysis (RCA):** A process for identifying the underlying causes of an incident or outage.\n* **Corrective Action:** An action taken to address the root cause of an incident or outage and prevent it from happening again.\n* **Preventive Action:** An action taken to reduce the likelihood of an incident or outage occurring in the future.\n* **Service Level Agreement (SLA):** A contract between a service provider and a customer that defines the level of service that the provider is expected to deliver.\n* **Mean Time to Repair (MTTR):** The average time it takes to repair an incident or outage.\n* **Mean Time Between Failures (MTBF):** The average time between incidents or outages.\n* **Disaster Recovery (DR):** A plan for recovering from a major incident or outage.\n* **Business Continuity Planning (BCP):** A plan for ensuring that a business can continue to operate in the event of a major incident or outage.\n\n**Other Related Terms:**\n\n* **Availability:** The percentage of time that a service or process is available.\n* **Reliability:** The ability of a service or process to perform its intended function without failure.\n* **Scalability:** The ability of a service or process to handle an increasing amount of work without significantly impacting performance.\n* **Resilience:** The ability of a service or process to recover from failures and continue to operate.\n* **Observability:** The ability to monitor and understand the state of a service or process.\n* **Automation:** The use of technology to automate tasks and processes.\n\nThese terms are all related to the field of Site Reliability Engineering (SRE), which is the practice of applying software engineering principles to the operation of large-scale distributed systems. SREs are responsible for ensuring that these systems are reliable, scalable, and efficient.\n\n## Prerequisites\n\nBefore you can do Blameless Postmortems, you need to have the following in place:\n\n* **A culture of learning and continuous improvement:** Blameless Postmortems are only effective if there is a culture of learning and continuous improvement within the organization. This means that teams are encouraged to report incidents and outages, and that they are not punished for making mistakes.\n* **A structured process for conducting postmortems:** You need to have a structured process in place for conducting postmortems. This process should include steps for gathering data, identifying root causes, and developing action plans.\n* **The right tools and resources:** There are a number of tools and resources available to help you conduct Blameless Postmortems. These include incident management tools, postmortem templates, and RCA tools.\n* **Trained facilitators:** It is helpful to have trained facilitators who can lead Blameless Postmortems. These facilitators can help to ensure that the postmortems are conducted in a productive and non-blaming manner.\n\nIn addition to the above, you also need to have the following in place:\n\n* **A commitment from leadership:** Leadership needs to be committed to the Blameless Postmortem process. This means that they need to provide the necessary resources and support, and that they need to create a culture where it is safe to report incidents and outages.\n* **Buy-in from teams:** Teams need to buy into the Blameless Postmortem process. This means that they need to understand the benefits of the process and that they need to be willing to participate in postmortems.\n* **A willingness to learn from mistakes:** Blameless Postmortems are only effective if teams are willing to learn from their mistakes. This means that teams need to be open to feedback and that they need to be willing to make changes to their processes and procedures.\n\nOnce you have all of these things in place, you can begin conducting Blameless Postmortems.\n\n## What's next?\n\nAfter you have Blameless Postmortems, the next steps are to:\n\n1. **Implement the action plan:** The action plan should outline the steps that need to be taken to address the root causes of the incident and to prevent similar incidents from happening in the future. This may involve changes to processes, procedures, or technology.\n2. **Monitor the effectiveness of the action plan:** Once the action plan has been implemented, you need to monitor its effectiveness to ensure that it is actually preventing similar incidents from happening. This may involve tracking metrics such as the number of incidents, the severity of incidents, and the mean time to repair (MTTR).\n3. **Make adjustments to the action plan as needed:** If the action plan is not effective, you need to make adjustments as needed. This may involve adding new steps to the plan, modifying existing steps, or removing steps that are not effective.\n4. **Continuously improve the Blameless Postmortem process:** The Blameless Postmortem process should be continuously improved. This may involve making changes to the process itself, or it may involve adopting new tools and techniques.\n\nIn addition to the above, you should also:\n\n* **Share the findings of the Blameless Postmortem with other teams:** This will help to ensure that other teams can learn from the mistakes that were made.\n* **Use the findings of the Blameless Postmortem to improve training and documentation:** This will help to prevent similar incidents from happening in the future.\n* **Celebrate successes:** When a Blameless Postmortem leads to improvements in reliability or availability, it is important to celebrate the success. This will help to motivate teams to continue conducting Blameless Postmortems.\n\nBy following these steps, you can ensure that Blameless Postmortems are used to their full potential to improve the reliability and availability of your systems.",
    "timestamp": "2025-05-23T16:34:24.096612",
    "tags": [],
    "severity": "high",
    "services_affected": [
      "web",
      "database",
      "monitoring"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "azure",
      "prometheus"
    ],
    "failure_pattern": "monitoring_blind_spot",
    "timeline_events": [],
    "blast_radius": "localized",
    "detection_time": null,
    "mitigation_actions": [
      "to reduce the likelihood of an incident or outage occurring in the future",
      "to address the root cause of an incident or outage and prevent it from happening again"
    ],
    "quality_score": 0.8999999999999999
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/rubygems/rubygems.github.io/blob/7f07feeda1ae3197b15fd0b85a10f2cfbda4d79e/_posts/2015-08-13-postmortem.md",
    "title": "2015-08-13-postmortem.md",
    "content": "---\ntitle: Post-Mortem of Connectivity Issues on August 10th\nlayout: post\nauthor: David Radcliffe\nauthor_email: radcliffe.david@gmail.com\n---\n\nRubyGems.org had intermittent connectivity problems for several periods on August 10th from about 7:08 UTC until 10:40 UTC, and again from 19:03 UTC until 19:19 UTC. This primarily disrupted gem downloads, and may have caused intermittent errors for gem pushes as well. This post aims to explain the issue and how we'll work to prevent a similar problem in the future.\n\nAll gems are stored in Amazon's Simple Storage Service, also known as S3. On August 10th, AWS had an extended outage in their Virginia region that affected several services, including S3. Requests to S3 to get gem files (and gemspecs) where intermittently failing, as well as requests to save new gems/gemspecs into S3. Our monitoring showed that **during this period, about 4% of download requests were failing**.\n\nAll gem downloads pass through Fastly, our CDN partner, where we cache gems in locations near you all around the world. Caching really saved us, since about 88% of requests were cached and didn't need to hit S3 at all. This means that 8% of all requests were hitting S3 successfully during this period.\n\nThat being said, having all our files stored in one region is still not ideal. We have plans to start replicating all our files into a second region. This will provide a backup for disaster recovery and hopefully we will also be able to serve download requests from the second region if the primary region is down.\n\nI'm sorry we had trouble serving requests this week, and we're making some changes to improve this for the future.\n",
    "timestamp": "2025-05-23T16:34:24.525579",
    "tags": [],
    "severity": "high",
    "services_affected": [
      "database",
      "cache",
      "monitoring"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "aws",
      "redis"
    ],
    "failure_pattern": "data_corruption",
    "timeline_events": [],
    "blast_radius": "partial",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 0.7
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/PagerDuty/postmortem-docs/blob/93bdc0694e9b5d61875eb07f73187a823069a1aa/docs/how_to_write/effective_postmortems.md",
    "title": "effective_postmortems.md",
    "content": "---\ncover:\ndescription: Here are concrete steps for producing a postmortem document. You will learn the most important information to include in the postmortem, how to collect and present that information, and how to conduct an effective analysis that results in system improvements.\n---\n![Effective Postmortems](../assets/img/headers/Postmortems-Tips.png)\n\nWriting detailed and accurate postmortems allows you to learn quickly from mistakes and improve systems and processes for everyone. This guide lists some of the things we do to make sure our postmortems are effective.\n\n## Do\n- Make sure the timeline is an accurate representation of events.\n- Define any technical lingo/acronyms you use that newcomers may not understand.\n- [Separate what happened from how to fix it](https://www.youtube.com/watch?v=TqaFT-0cY7U).\n- Write follow-up tasks that are actionable, specific, and bounded in scope.\n- [Discuss how the incident fits into our understanding of the health and resiliency of the services affected](https://www.pagerduty.com/blog/postmortem-understand-service-reliability/).\n\n## Do Not\n- Use the word \"outage\" unless it really was an outage. Accurately reflect the impact of an incident. Outage is usually too broad a term to use. It can lead customers to think the product was fully unavailable when that likely was nowhere near the case.\n- Change details or events to make things \"look better.\" Be honest in postmortems, otherwise they lose their effectiveness.\n- Name and shame someone. Keep postmortems blameless. If someone deployed a change that broke things, it's not their fault. Everyone is collectively responsible for building a system that allowed them to deploy a breaking change.\n- Blame \"human error.\" Very rarely is the mistake \"rooted\" in a human performing an action. There are often several contributing factors (the script the human ran didn't have rate limiting, the documentation was out of date, etc.) that can and should be addressed.\n- Only point out what went wrong. Drill down to the underlying causes of the issue.",
    "timestamp": "2025-05-23T16:34:24.935428",
    "tags": [],
    "severity": "high",
    "services_affected": [
      "web"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "jenkins"
    ],
    "failure_pattern": "resource_exhaustion",
    "timeline_events": [],
    "blast_radius": "localized",
    "detection_time": null,
    "mitigation_actions": [
      "a change that broke things, it's not their fault"
    ],
    "quality_score": 0.83
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/evmos/mainnet/blob/f407ec770cb73e1f574e0921b8ca97e44bda3c0b/incidents/postmortem-2.md",
    "title": "postmortem-2.md",
    "content": "# Evmos - Keplr Signing Issues\n\n## Authors\n\n* Austin Chandra (evmos.org)\n* Adit Gupta (evmos.org)\n* Akash Khosla (evmos.org)\n\n### Date\n\n2022-03-10\n\n## Brief Overview\n\n- Users were unable to send tokens, delegate, or vote on governance using Keplr. Any attempt to do so triggered a variant of the following error messages: \"*pubKey does not match signer address*\" and \"*signature verification failed*\"\n- Many users resorted to using community-built alternatives (namely [Disperze](https://evmos.disperze.network/) and [Evmos.me](https://evmos.me)) to claim their airdrops and start staking their tokens\n- While these websites served as an appropriate temporary substitute for Keplr, launching without official wallet support increased the risk assumed by the community and created difficulties in claiming and staking tokens\n- Ledger users signing into Keplr derived and displayed the wrong public key, so attempts to send funds to the Ledger accounts resulted in stuck funds\n\n## Timeline\n\n> *NOTE*: All times in UTC\n\n\n### March 3rd, 2022\n\n*03:21* - Evmos team encounters and flags a public key bug preventing Keplr from signing Evmos transactions.\n\n*06:17* - Fix for Keplr public key bug is completed \n\n*06:17* - Evmos team identifies another bug after correcting the public key bug and begins debugging Keplr signature verification bug \n\n*20:05* - Evmos team discovers that Keplr is displaying incorrect public keys for users signed in with Ledger\n\n### March 4th, 2022\n\n*00:57* - Evmos team discusses whether to temporarily pull Keplr support to avoid community confusion and potential loss of funds\n\n*01:49* - Following dicussions, team decides to keep current Keplr release as community platforms such as Disperze offered limited Keplr functionality. Pulling the release would result in an abrupt service interruption and contribute to further confusion within the community.\n\n*21:10* - Evmos team is still unable to isolate the Keplr signature verification bug\n\n### March 5th, 2022\n\n*06:08* - Evmos team identifies short-term solution to Keplr signature verification in changing Evmos node service provider's configuration\n\n*06:14* - Evmos team engages in discussions with aforementioned node service provider\n\n*06:32* - Fix for Keplr public key bug is [pushed](https://github.com/chainapsis/keplr-wallet/pull/313#issue-1160260958) \n\n*07:20* - Fix for Keplr public key bug is merged into Keplr\n\n*07:21* - Fix for Keplr signature verification bug, which was via altering the gas config is [merged](https://github.com/chainapsis/keplr-wallet/pull/308) into Keplr\n\n*07:50* - New Keplr build released with public key bug fix and signature verification fix\n\n*19:06* - Node service provider updates their configuration to match Evmos provided specification\n\n\n## Five Whys\n\n> Use the [root cause identification technique](https://en.wikipedia.org/wiki/Five_whys). Start with the impact and ask why it happened and why it have the impact it did. Continue asking why until you arrive at the root cause. Document your \"whys\" as a list here or in a diagram attached to the issue.\n\n### Problem: Users could not send tokens, delegate, or vote on governance within Keplr\n\n**Why were users unable to perform these core actions?**\n1. The public key type generated by Keplr did not match the expected public key type\n2. The payload verification failed upon reaching the Evmos mainnet nodes (meaning the signature didn't match up)\n\n---\n\n**Why did the public key type generated by Keplr not match the expected public key type?**\n\n* Keplr was returning the default `cosmos.crypto.secp256k1` key type rather than the expected `ethermint.crypto.v1.ethsecp256k1` keytype\n\n**Why was Keplr returning the Cosmos keytype rather than the Ethermint keytype?**\n\n* The `coinType` was not being fetched properly, so attempts to see whether we were on an Ethereum-based chain by checking `coinType = 60` were unsuccessful\n\n\n**Why was Keplr unable to fetch the `coinType`?**\n\n* The Keplr config for the Evmos (Beta) mainnet chain had a different structure from the Keplr config for the Evmos testnet. Our signing code relied on the config matching that used by the testnet.\n    ```\n    // Testnet Configuration\n    {\n      bip44: {\n        coinType: 60,  \n      },\n      coinType: 60,\n      ...\n    }\n    ```\n    \n    ```\n    // Mainnet Configuration\n    {\n      bip44: {\n        coinType: 60,  \n      },\n      ...\n    }\n    ```\n\n**Why did Keplr have a different config in Mainnet?**\n\n* Evmos team modelled the final mainnet config off of the mainnet configs by other chains, not off of the Evmos testnet config, and thus correctly did not include the extraneous `coinType` field\n* Evmos team did not, however, test for differences between the testnet and mainnet configs, and thus was not aware of the `coinType` issue\n\n**Why was Keplr able to approve signs generated by Evmos.me and Disperze, but not core actions performed within Keplr?**\n\n* Evmos.me and Disperze used Keplr's `signDirect` endpoint, an offline signer, to generate the signature payload, which they manually broadcasted to an Evmos node\n* This was successful because Keplr's offline signer worked without issue, and by broadcasting the signature and payload outside of Keplr, the dashboards avoided both the `coinType` and gas-related issues\n\n---\n\n**Why did signature payload verification fail upon reaching the Evmos mainnet nodes?**\n\n* The deployed mainnet nodes responded with a gas-related error\n\n**Why did the deployed mainnet nodes respond with a gas-related error?**\n\n* The deployed mainnet nodes had set the `minimum-gas-prices = 0.25aevmos`, but Keplr was sending insufficient gas for the transactions\n\n**Why was Keplr sending insufficient gas for the transactions?**\n\n* Evmos's mainnet config within Keplr set the minimum gas levels to the following:\n\n```\ngasPriceStep: {\n  low: 0.005,\n  average: 0.025,\n  high: 0.04,\n},\n```\n* Since Evmos recognizes denomations to 18 decimal places (compared to 6 decimal places for Cosmos chains), after being scaled, these gas values became 12 orders of magnitude smaller than expected\n\n**Why couldn't users manually increase the gas to compensate for this?**\n\n* There is a distinction between the fee amount and the gas, and both values are sent separately. While users can adjust the gas, the fee amount is determined by the config, and the Evmos nodes expected a range of values for the fee amount that was not satisfied\n\n**Why did Keplr's configuration contain incorrect fee amounts?**\n\n* In testing, Evmos's testnet node had a `minimum_gas_fee = 0aevmos`, so although the Keplr config still used a low gas step price, the issue was never enforced by the  node\n* Evmos team reused this Keplr configuration in mainnet, in addition to updating the `minimum_gas_fee` to `0.25aevmos`, without realizing this could cause an issue\n\n\n\n## Remediation\n\n### Upstream Changes in Keplr\n* [x] Properly derive `coinType` given mainnet configuration ([PR - Merged](https://github.com/chainapsis/keplr-wallet/pull/313))\n\n### Update Keplr Configuration\n* [x] Update gas price step configuration to correct values ([PR by Community Member - Merged](https://github.com/chainapsis/keplr-wallet/pull/308/files))\n\n### Update Mainnet Configuration\n* [x] Set the minimum mainnet gas price to `0aevmos` as a temporary workaround solution\n\n### Engineering\n* [ ] Create documentation regarding configuration variables across the project\n* [x] Post Mortem document of the incident and remediations\n* [x] Bring up extra `coinType` field in Keplr config to Keplr team's attention, as it ended up being a footgun and is redundant ([copy-paste example](https://keplr.crunch.help/integrating-your-chain/how-to-suggest-a-chain))\n* [ ] Construct a QA guide for Keplr (based on the ones we already have) to include a mainnet config modification step so that we're using the mainnet config but with correct RPCs\n",
    "timestamp": "2025-05-23T16:34:25.400049",
    "tags": [],
    "severity": "low",
    "services_affected": [
      "api",
      "web"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "aws",
      "azure",
      "nginx",
      "grafana",
      "jenkins"
    ],
    "failure_pattern": "configuration_drift",
    "timeline_events": [],
    "blast_radius": "global",
    "detection_time": null,
    "mitigation_actions": [
      "the risk assumed by the community and created difficulties in claiming and staking tokens",
      "mainnet nodes responded with a gas-related error",
      "mainnet nodes had set the `minimum-gas-prices = 0",
      "mainnet nodes respond with a gas-related error?**"
    ],
    "quality_score": 0.8600000000000001
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/EricaJoy/techdiversity/blob/c23a7a2ab25f3451b173b04308c92adfd85023c6/diversityinclusionpostmortem.md",
    "title": "diversityinclusionpostmortem.md",
    "content": "# Tech Diversity and Inclusion Post-mortem\n\n## Date\n\n2017-06-22\n\n## Authors\n\n* @ericajoy\n\n## Status\n\nOngoing, action items assigned, in progress\n\n## Summary\n\nAt halfway through 2017, we are approaching the 10 year anniversary of the first forays into focus on Diversity and Inclusion in the tech industry. The industry has spent over $500M on Diversity and Inclusion efforts with little to no improvements to show for it. Diversity numbers remain stagnant, we see little to no representation of URMs at the executive or board level, reports of harassment at various tech companies continue to trickle out, and VC money for women of color founders might as well be non-existent. For any project in business, that kind of spend with such low ROI indicates a major failure in the project. Because we are in tech, when we have a major failure, a post-mortem follows shortly thereafter.\n\n## Impact\n\nImpact too great to be accurately quantified. \n\n## Root Causes\n\nCascading failure due to the following:\n- bias\n- reliance on pattern matching\n- cargo-culting\n- gatekeeping\n- harassment\n\n\n## Detection\n\nTracy Chou started tracking Women in engineering in 2013, with company diversity reports soon to follow. A pattern of poor results soon appeared.\n\n\n## Lessons Learned\n\n### What went well\n\n* Implementation of monitoring of Diversity numbers quickly alerted us to a low presence of all intersections of URMs and Women. \n\n\n### What went wrong\n\n* We have not defined what good outcomes look like.\n* We have not created any methods of accountability.\n* We're not measuring and reporting indicators of Inclusion like retention, promotions, and pay equity.\n* We're not monitoring across all groups and intersections, to include age, veteran status, lgbtq status, and disability status.\n* Too much reliance on Unconscious Bias training as a cure-all.\n* Companies have not responded well to reports of harassment. (To date there have been no reports of apologies to any employees that have experienced harassment at companies.)\n* We have not yet implemented safe methods for people to speak out that doesn't result in them being subjected to more harassment.\n\n### Where we got lucky\n\n* Numbers have stayed flat instead of dropping for women, indicating that for some reason, people still want to come to the tech industry\n* Despite lack of improvement, people still want to work on this.\n* Many companies have avoided Uber style public tire fires, despite being equally problematic.\n\n## Timeline\n\n| Time  | Description |\n| ----- | ----------- |\n| Early 2008 | Mike Swift from the San Jose Mercury news files FOIA requests for Labor Department demographic data for 15 companies. Lawyers for companies including Google, Apple, and Oracle fought the request citing \"commercial harm.\" http://www.mercurynews.com/2010/02/11/five-silicon-valley-companies-fought-release-of-employment-data-and-won/|\n| Nov 2011 | CNN asks 20 Tech companies to release their EEO-1 reports. 3 agree. http://money.cnn.com/2013/03/17/technology/diversity-silicon-valley/index.html |\n| May 2012 | Ellen Pao files a gender discrimination lawsuit against her employer. She ultimately lost her case 3 years later, despite an outside investigation substantiating her claims. https://en.wikipedia.org/wiki/Pao_v._Kleiner_Perkins |\n| Oct 2013 | Tracy Chou asks \"Where are the numbers?\" and starts collecting data about representation of women in engineering https://medium.com/@triketora/where-are-the-numbers-cb997a57252 |\n| Mar 2014 | Julie Ann Horvath is harassed out of GitHub http://geekfeminism.wikia.com/wiki/Julie_Ann_Horvath_quit_GitHub |\n| May 2014 | Jesse Jackson and Rainbow PUSH begin pushing tech companies to release employee demographics http://fortune.com/2014/12/20/jesse-jackson-talks-diversity-in-silicon-valley/ |\n| May 2014 | Google releases its first diversity report admitting it is not \"where it wants to be\" on diversity. https://googleblog.blogspot.com/2014/05/getting-to-work-on-diversity-at-google.html |\n| Jun 2014 | Facebook releases its first Diversity Report https://newsroom.fb.com/news/2014/06/building-a-more-diverse-facebook/ |\n| Jul 2014 | eBay releases its first Diversity Report https://web.archive.org/web/20140801234333/http://blog.ebay.com/building-stronger-better-diverse-ebay/ |\n| Jul 2014 | Twitter releases its first Diversity Report https://blog.twitter.com/official/en_us/a/2014/building-a-twitter-we-can-be-proud-of.html |\n| Jul 2014 | 9 months after Engineer Tracy Chou asked \"where are the numbers,\" Pinterest releases its first Diversity Report https://medium.com/@Pinterest_Engineering/diversity-and-inclusion-at-pinterest-8711ae9c8d29 |\n| Aug 2014 | Apple releases its first Diversity Report https://www.apple.com/diversity/ |\n| Aug 2014 | Pandora releases its first Diversity Report https://www.linkedin.com/pulse/20140820200555-62614725-diversity?published=t |\n| Aug 2014 | Indiegogo releases its first Diversity Report https://go.indiegogo.com/blog/2014/08/diversity-matters-always.html |\n| Sep 2014 | Google implements and touts Unconscious Bias training as part of a solution to improving diversity. The rest of the tech industry follows suit. https://googleblog.blogspot.com/2014/09/you-dont-know-what-you-dont-know-how.html |\n| Oct 2014 | Microsoft CEO Satya Nadella suggests that women should not ask for raises, instead trust in karma. He later apologizes for this. http://readwrite.com/2014/10/09/nadella-women-dont-ask-for-raise/ |\n| Nov 2014 | Amazon releases its first Diversity Report https://web.archive.org/web/20150319133426/http://www.amazon.com/b?ie=UTF8&node=10080092011 |\n| Nov 2014 | Then Googler Erica Baker writes about her experiences being a Black woman in the tech industry, noting specific experiences at Google. Google does not comment. https://medium.com/this-is-hard/the-other-side-of-diversity-1bb3de2f053e|\n| Jan 2015 | Microsoft releases its EEO-1 Report as a PDF download https://web.archive.org/web/20150105153901/http://www.microsoft.com/global/en-us/diversity/RenderingAssets/Microsoft_EEO-1_Report_2014.pdf |\n| Mar 2015 | Ex-Googler Kelly Ellis goes on record about being sexually harassed while employed at Google. Google does not comment. https://www.buzzfeed.com/salvadorhernandez/google-kelly-ellis |\n| Jul 2015 | Google Photos, echoing a well-worn racist and derogatory term, labels Black people \"gorillas\" (and Google issues the rare apology for doing so). https://www.usatoday.com/story/tech/2015/07/01/google-apologizes-after-photos-identify-black-people-as-gorillas/29567465/ |\n| Sep 2015 | Marc Benioff publicly states at Dreamforce that their \"major focus\" right then, was \"the women’s issue,\" meaning Salesforce was intentionally not focusing on all intersections of Diversity https://medium.com/this-is-hard/ffffff-diversity-1bd2b3421e8a|\n| Jan 2016 | Google releases its most recent Diversity Report, showing no improvement from its 2014 report, save a 1% increase in Women |\n| Mar 2016 | Amélie Lamont recounts her experiences of  racism and sexism at Squarespace https://medium.com/@amelielamont/not-a-black-chair-8a8e7e2b9140 |\n| Dec 2016 | ABI releases its first Diversity Report https://anitaborg.org/news/announcements/abi-2016-advancing-diversity/ |\n| Feb 2017 | Susan Fowler recounts her experiences of harassment at Uber. https://www.susanjfowler.com/blog/2017/2/19/reflecting-on-one-very-strange-year-at-uber |\n| Feb 2017 | Uber begins an internal investigation into sexual harassment and discrimination led by US Attorney General, Eric Holder. http://money.cnn.com/2017/02/20/technology/uber-eric-holder-sexism-investigation/index.html |\n| Mar 2017 | Uber releases its first Diversity Report https://www.uber.com/diversity/ |\n| Jun 2017 | Lyft releases its first Diversity Report. https://take.lyft.com/diversity/ |\n| Jun 2017 | Square releases its first Diversity Report. https://squareup.com/news/diversity-report |\n| Jun 2017 | Uber releases the results of Eric Holder's investigation http://fortune.com/2017/06/13/uber-internal-investigation-results-public/ |\n| Jun 2017 | Uber CEO Travis Kalanick resigns |\n\n## Action Items\n\n| Action Item | Type | Owner | Status |\n| ----------- | ---- | ----- | --- |\n| Define good outcomes/goals. | prevent | Most Tech Companies | **TODO** |\n| Track and report retention across demographics | monitor | All Tech Companies | **TODO** |\n| Track and report promotion rates across demographics | monitor | All Tech Companies | **TODO** |\n| Track and report company equity breakdowns across demographics | monitor | All Tech Companies | **TODO** |\n| Track and report pay equity across demographics| monitor | All Tech Companies | **TODO** |\n| Implement all suggestions from Uber's firm | prevent | All Tech Companies | **TODO** |\n| Move Diversity and Inclusion out of HR/PR/Finance/etc and into it's own org reporting directly to the CEO | mitigate | Most Tech Companies | **IN PROGRESS** |\n| Implement Unconscious Bias, Ally Skills, and Racial Justice training and make all mandatory. | prevent | Most Tech Companies | **IN PROGRESS** |\n| Define and make available to the entire company a playbook for responding to issues | mitigate | All Tech Companies | **TODO** |\n| Implement the recommendations in projectinclude.org | prevent | Most Startups | **IN PROGRESS** |\n| Implement innovative recruiting practices instead of relying on overused \"standards.\" | mitigate | All Tech Companies | **TODO** |\n| Hire more URMs, especially into Executive and Board positions. | prevent | All Tech Companies | **TODO** |\n\n\n## Resolution\n\nThis failure is still in progress. \n\n\n## Supporting Information\n\n* Ally Skills Workshop - Frame Shift Consulting, <https://frameshiftconsulting.com/ally-skills-workshop/>\n",
    "timestamp": "2025-05-23T16:34:25.822196",
    "tags": [],
    "severity": "high",
    "services_affected": [
      "api",
      "web",
      "monitoring"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "aws",
      "jenkins"
    ],
    "failure_pattern": "cascading_failure",
    "timeline_events": [],
    "blast_radius": "global",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 0.8799999999999999
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/HackerDom/ructf-2023/blob/0cc333e44f2ba6908ff6c5d613146e3b00173315/POSTMORTEM.md",
    "title": "POSTMORTEM.md",
    "content": "# RuCTF 2023 | Post-mortem\n\nAlthough the competition went smoothly enough, there were some problems before and during the competition.\n\n## Tokens issues\n\nThis year we had no resources to create a fully-functional website for the competition. So we decided to use Google Docs for the registration.\n\nBefore the game we need to send cloud tokens by email, and do it by hands. So we write a simple Python script which sends emails using Gmail. But we did some mistakes and send invalid tokens twice.\n\n1. Gmail throttles consecutive sends, but accepts emails by batches. We ran our script some times, but forgot to update mapping (team to email). It lead to problem: first N participants got first N tokens, next N participants got the same N tokens and so on.\n\n2. During the second attempt we tried to fix this, but failed. We added updates to mapping (team to email), but did it wrong. So the teams got invalid tokens again.\n\n3. The third attempt was success, we send correct tokens to teams.\n\nWhen we realized that tokens are invalid, we closed our VMs cloud and restarted it. It took some time, so we decided to publish services in Discord: participants could start to solve.\n\nTimeline:\n\n```\n10:00 UTC - cloud open\n10:40 UTC - we realized the mistake, cloud closed\n10:44 UTC - services was published to Discord\n11:15 UTC - we started to resend correct tokens\n11:30 UTC - cloud open\n12:00 UTC - network open\n```\n\nThe conclusion is simple: prepare such critical scripts earlier and review it harder.\n\n## Checkers issues\n\nWe started the game with 3 machines for checkers, each have 16 CPU cores (3x16). Shortly after the network was opened there turned out a problem: the checkers was stopped to run. Checksystem had utilize all available cores, and CPU resources was exhausted.\n\nThe first assumption regarding the root cause was that one of the checkers was consuming excessive resources. We disabled this checker, but it did not resolve the issue. We also suspected that the checking queue on the checksystem's master was full of jobs, so we attempted to restart the workers, but this action also had not fixed the issue. Then we attempted to upscale the checker's workers' pool size to 5, but it took a while. Simultaneously, we increased the size of the initial workers to 48 cores, the maximum available on DigitalOcean, which finaly helped and services goes \"green\" on scoreboard. However, immediately after this fix, the checksystem manager (main coordinator) went down due to a misconfiguration issue during the setup of the new workers in ansible. Fix missconfiguration had been fixed asap as well as 2 new workes was added into the pool.\n\nWe could restart the entire game, but we did not want to do this, because the game was already started and some teams already got flag points for attacks. Now we think that it was not a good solution: restarting the entire game was better, because it also would refresh SLA (decreased by not-working checkers).\n\nTimeline:\n\n```\n12:00 UTC - network open\n12:11 UTC - we realized that checkers is not working\n12:20 UTC - we understood that the problem is caused by exhausted CPU\n12:41 UTC - we upscaled checkers machines\n12:48 UTC - checkers was ressurected\n```\n\nNext time we will use more powerful machines for checkers and stress test the game with more load.\n\n## VPN issues\n\nWe used [DigitalOcean](https://www.digitalocean.com/) cloud provider to build our game infrastructure.\n\nSince Russian government bans a lot of foreign IPs, some participants from Russia could not connect to their VPN, and therefore have no access to VMs.\n\nDuring the game we did not manage to find out the solution, but some people setup their own VPNs, and connected to game network through their own tunnels.\n\nWe don't know the good solution here, since many countries have a practice to ban external IPs. Next time we will try to use a different provider.\n\n## Service `werk` issues\n\nFirst we planned to release a service called `werk`, it should have big codebase and implement complex logic. Unfortunately, we was not on time and did not success to finish it before the competition.\n\nIn 12 hours before the game there are only 5 services, and we thought it will not be enough, it seemed to us that 5 services will be solved quite fast (later it turned out that only 3/5 services was solved). So we made a decision to write an entirely new service, which would be simple, in order to reach 6 services.\n\nThis was a bad decision, because the new service `werk` was not well-tested, and the intended solution required too much bruteforce. Luckily, the service was solvable, and there was another solution, found by participants (see [writeup](/writeups/werk/)).\n\nNow we understand that release less services is better than release unfinished service.\n",
    "timestamp": "2025-05-23T16:34:26.726997",
    "tags": [],
    "severity": "high",
    "services_affected": [
      "api",
      "web",
      "queue"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "azure",
      "jenkins"
    ],
    "failure_pattern": "configuration_drift",
    "timeline_events": [],
    "blast_radius": "localized",
    "detection_time": null,
    "mitigation_actions": [
      "the size of the initial workers to 48 cores, the maximum available on DigitalOcean, which finaly helped and services goes \"green\" on scoreboard",
      "checkers machines",
      "by not-working checkers)"
    ],
    "quality_score": 0.84
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/usegalaxy-eu/website/blob/203bca324d8f04c782e6228b0567c3fb0f295c7d/_posts/2018-09-26-DNS-handover-postmortem.md",
    "title": "2018-09-26-DNS-handover-postmortem.md",
    "content": "---\nsite: freiburg\ntags: [devops, downtime]\ntitle: Cloud Migration Postmortem\nlocation: Freiburg, Germany\n---\n\nThe bwCloud which we relied on for cloud hosting has reach end of life, and is\nbeing replaced with bwCloud SCOPE. This documents our migration between the two\nclouds.\n\n## Timeline\n\nDate         | State\n------------ | ------\nSeptember 17 | bwCloud SCOPE becomes stable enough to rely upon\nSeptember \nSeptember 21 | An unplanned downtime of UseGalaxy.eu gave us opportunity to move our cloud-based Condor Cluster\nSeptember 26 | We swap HAProxies, switching all of our traffic to going through the new cloud\nSeptember 27 | Last VMs are backed up or moved (GitLab)\nSeptember 28 | The old cloud shuts down\n{: .table.table-striped }\n\n## What Went Right\n\n**Using Terraform**: In the months prior to the cloud shutdown we\nbrought all of our OpenStack resources under Terraform's control. This allowed\nus to get started in the new cloud by replacing a few variables (cloud URL,\nnetwork name, image names), and having our infrastructure instantly replicated\nin the new cloud.\n\n**Enforcing Automation**: We internally developed a strict policy that if a\ntask wasn't automated, then it didn't really happen. Naturally, we had Ansible\nplaybooks for all of the setup steps required for each service that we run, and\nwe could easily re-run these on our new infrastructure.\n\nAs part of the migration we developed a [small script](https://github.com/usegalaxy-eu/infrastructure/blob/master/bin/find-unmanaged.sh)\nwhich will identify any resources created in either OpenStack or Route53 which\nare not managed by terraform. We can then consider automatically deleting such\nunmanaged resources to help ensure that all infrastructure changes are done in\na reproducible way.\n\n\n\n\n\n## What Went Wrong\n\n",
    "timestamp": "2025-05-23T16:34:27.552772",
    "tags": [],
    "severity": "high",
    "services_affected": [
      "web"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "azure",
      "elasticsearch",
      "terraform"
    ],
    "failure_pattern": null,
    "timeline_events": [],
    "blast_radius": "localized",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 0.49000000000000005
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/GreenXenith/luantigamejam/blob/fd4fe4be7c963bf7be956f838b7453be6634ff2a/2021/POSTMORTEM.md",
    "title": "POSTMORTEM.md",
    "content": "# 2021 Minetest Game Jam Post Mortem\n_Written by GreenXenith_\n\nWhat an event! I took some time to rest after that, but now I can give you a proper recap and post mortem of this awesome occasion!\n\nThe jam went mostly as expected, with some ups and downs. The ContentDB tag was nearly perfect for collecting entries, there was plenty of time to develop and rate (from what we could tell), and we had a lot of submissions!\n\nHowever, like with any plan, some things didn't want to cooperate :)\n\n## What didn't go according to plan\n### Package Criteria\nThe ContentDB has specific policies for name rights, dependencies, etc. During the jam these restrictions were loosened slightly or waived in some cases. This was mostly just a hassle. Fortunately afterwards packages can be unapproved until fixed, and the WIP tag exists for a reason :)\n\n### Community Reviews\nWe spent _a lot_ of time designing the system for submission rating. The final result turned out just fine, but some parts went better than others. ContentDB reviews are not great as a rating system for two reasons:\n* Not granular enough. \"Yay\" or \"Nay\" is simply not enough information compared to something like a 5-star system.\n* Easy to abuse. Whether intentional or not, a few packages got some unfair reviews, both negative and positive.\n\nThe review discarding system should have weighted helpfulness higher, and it would have been good to ignore helpfulness ratings from participants. Unfortunately it required real-world testing to figure that out, and we don't have access to all the data we need. Fortunately the weighted judge system smoothed most of the issues. Remember to check out the [detailed statistics](RESULTS.md) if you'd like to see some breakdowns on how the rating went.\n\n### Deadlines\nTime is confusing. One of the original UTC times was incorrect, and we had to push out one or two times by a little bit. Fortunately no one had any huge issues with it. It is better to use 23:59, not 00:00. The submission deadline was always intended to be slightly loose, since Ludum Dare even has an extra hour to submit things. But we didn't want to announce anything like that, otherwise people would try to use the hour as regular development time and still be late :)\n\n### Announcements\nI'll be honest: I stopped keeping up with the announcements in the data repository after a while. It takes a lot of time and effort to make the announcements on **eight** different platforms. Decentralization is cool and all, but next time I'll be automating it at the very least.\n\n### Outreach\nWe originally intended to have a few people make some YouTube videos announcing the jam, but that ended up getting pushed aside. Being the first time we've done something of this scale, we didn't want to put too much exposure on it in case it crashed and burned. We did get a good amount of exposure on Twitter/Fosstodon and the chat channels, but that still left many people unaware of the event.\n\nBut not everything went awry.\n\n## What went better than expected\n### Submissions\n26 submissions?! Whaat?! Well, I expected almost that much :) But there were many that expected far less, and needless to say, thats a big number for a community like this. With that many submissions we got a wide spread of game ideas and styles. We even have a few really good ones in there too :P\n\n### Prizes\n$720 prize pool?! Whaaaat?! That is an unprecedented amount of money for _many_ game jams, let alone an _open source_ one. Thank you SO MUCH to those that contributed to the pool: **cupOjoseph, Blockhead, MinetestVideos, MisterE, nogajun, and Norojop**.  \n\nPrize payouts were successful and went as expected. There were some conversion and international fees involved, but affiliated parties expected it and still got nearly the full amount listed. Fees are an unfortunate side-effect of third-parties, but it is generally safer and easier than other options. We _may_ explore alternatives in the future, but it went well enough this time.\n\n### Response\nEveryone got on board! (Ignoring one or two edge cases..) Which is weird for this community. The response from the community was overwhelmingly positive, which is wonderful to see! This is not my first time organizing an event like this, but this is the first of it's size, and seeing the support from you guys is really encouraging. I'd like to thank those that also had a hand in organizing the event: **Benrob0329, ExeVirus, MisterE, rubenwardy, and Warr1024**. I am only one man, they really helped flesh out the system.\n\n### Continuation\nPeople are still working on their games! The best thing we could have hoped for in a jam is games that are born during the event but continue to grow afterward and develop a thriving community! I hope to see many of the games grow and improve a long time from now. And bonus, all the activity seems to have breathed new life into engine development. Stay tuned to see how Minetest grows as well!  \n\nSo now what?\n\n## What the future looks like\nMany people have already expressed interest in doing another jam this year, which is awesome! I had a lot of fun seeing the results of this one, and I hope you had a lot of fun participating! There are still a lot of questions to be answered about the next jam that we'll have to discuss thoroughly later:\n* Should it be always be games? Perhaps an engine jam? Or something else entirely?\n* Should it have a theme? Or some kind of new challenge?\n* If we are going to do this regularly, when will we do it? Personally, I want to do it every 11 or 13 months, that way more people can participate if scheduling conflicts.\n\n### Rating System\nWhile the ContentDB reviews have their issues, there may be ways to fix it. Or, we may create a separate interface for jam ratings. Or maybe the ContentDB review system itself will change! This is a complex problem that will take quite a bit of triage.\n\n### Prizes and Judges\n$720 is a lot. In fact, some people were concerned the size of the prize was disproportionate to the amount and quality of submissions. But remember, this is the first time we've done this, so getting people motivated was pretty important :) Now that people know what's up, the participant count might increase. We also may have a stricter prize system.  \n\nThe judge system worked out well for this jam (even if a few judges cut it pretty close), so that will likely stay. But you may see some new faces next time to shake things up.\n\n### Outreach\nNext time we'll likely start announcing earlier, and on more platforms. Hopefully we can reach even more potential participants. We'll also hopefully get some sort of official central site set up for jam information.\n\n## Final Thoughts\nI am relieved that this went so well. The amount of activity this spurred and the response from the community was unlike anything I've seen around here for a while. I don't have much else to say. Again, a heartfelt thank you to everyone that helped and participated. I look forward to the next one.\n\n_- GreenXenith_\n",
    "timestamp": "2025-05-23T16:34:28.569466",
    "tags": [],
    "severity": "high",
    "services_affected": [
      "api",
      "web",
      "database"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "aws"
    ],
    "failure_pattern": null,
    "timeline_events": [],
    "blast_radius": "localized",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 0.44999999999999996
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/pennlabs/website/blob/7349848382f79ff1b4171ab1fcfda94ab268fcda/src/blog/spot-postmortem.md",
    "title": "spot-postmortem.md",
    "content": "---\ntitle: 'Path@Penn Downtime Post-Mortem'\nslug: spot-postmortem\nauthors: ['pawalt']\npublishedAt: 2022-05-02\ncoverPhoto: ../images/blog/nodes.png\n---\n\nOver the past month, our infrastructure has had some intermittent issues, so we wanted to drop a quick postmortem describing what the problem was and how we fixed it so we can solve these problems more quickly in the future!\n\n## Terminology\n\nBefore starting, we should define some terminology:\n\n- **Pod** - one instance of a running application (ex. Penn Courses Backend)\n- **Node** - a physical machine that our pods run on\n- **Cluster** - a collection of nodes that our pods run on\n- **Kubernetes** - a piece of software built to move pods among nodes such that nodes don't get overwhelmed (use too much CPU/RAM)\n\n## Background\n\nFor our cluster, we use [AWS Spot Nodes](https://aws.amazon.com/ec2/spot/). These are machines that may, at any time, be shut down by AWS for use in other places. In exchange for this, we pay a lower price for these nodes. Nodes going down is not a problem for us since we're running in Kubernetes which will automatically move our applications to our other nodes if one goes down.\n\nWhen a spot node goes down, all applications (I'll use the word pods interchangeably) are moved to the other nodes. A new node is then brought up and the pods (hopefully) rebalance between the available nodes.\n\nAdditionally, a few weeks ago, we switched from many smaller nodes to 3 higher-resource nodes. This gave us some cost savings as fewer high-resource nodes are cheaper than many low-resource nodes.\n\n## Symptoms\n\nSymptoms first appeared around the time of the Path@Penn launch.\n\nWe started getting reports of applications failing with no text in the browser other than `Service Unavailable`. This allowed us to immediately know that this was an infrastructure-wide issue for a few reasons:\n\n- If multiple products are failing in the same way, then there cannot be a single-application code change that caused this. It must be that some part of the underlying infrastructure is broken.\n- `Service Unavailable` is an error that typically only our load balancer, [Traefik](https://traefik.io/) will throw. It is almost never sent by actual application code.\n\n## Initial Debugging\n\nUpon looking at the cluster with `kubectl`, we saw that many pods were stuck in the `ContainerCreating` state. This means that a pod has been assigned to a node, but for some reason, the node cannot start the pod up.\n\nTo debug this further, we looked at Datadog, our monitoring system. Datadog showed between 1 and 2 nodes at 100% CPU usage with the third sitting almost idle at ~10% usage.\n\nAt this point, the question becomes: **If Kubernetes is balancing pods, why are some nodes at such higher resource usage than the others?**\n\n## Deduction\n\nAfter further investigation, it looks like the following was happening:\n\n1. A spot node gets scheduled to terminate\n2. All its pods are drained to the other two nodes\n3. The remaining two nodes don't have enough available resources to host all our pods and spike to 100% CPU usage\n4. 100% CPU usage renders the two nodes unusable, and they stop responding to both Kubernetes and Datadog.\n5. Even when the third node comes back online, pods cannot be rebalanced to it because the other two nodes are unreachable due to load.\n\nThe underlying cause of this issue is that while 3 nodes is enough for our cluster, 2 is not. When a spot node termination happens, we don't have enough resources to handle the load, and it creates a cascading failure throughout our infrastructure.\n\n## Solution\n\nTo solve this issue, we've scaled our cluster up to 5 nodes. This should mean that even if we lose a node due to spot lifecycle, we've got plenty of compute to handle things.\n\n## Why did this just happen now?\n\nThis is the main question we've been asking ourselves. Intuitively, it seems like we should have run into these issues as soon as we switched to only using 3 nodes.\n\nHowever, these issues are not just a symptom of having 3 nodes. **They're a symptom of having 3 nodes while under high load**. The Path@Penn launch was the first time we had high load on our products since moving to 3 nodes. Therefore, while this problem existed all along, we didn't notice it until our systems were under stress.\n\n## Next Steps\n\nTo solve these issues more quickly in the future, we should have better alerting and monitoring around application failures. Specifically:\n\n- Alerting when we have a high number of `503 Service Unavailable` responses. These almost always indicate an infrastructure-level error.\n- Alerting when we have high node CPU usage. While pod CPU usage hasn't been great signal for us (pods occasionally spike), high node usage almost always indicates a problem.\n\n## Reach Out\n\nIf any of this looks like it's up your alley or you wanna learn more about our mission, be sure to email us at [contact@pennlabs.org](mailto:contact@pennlabs.org) or [apply to be a part of Labs](https://pennlabs.org/apply)! We've got some fantastic teams working on interesting problems with a direct impact on campus.\n",
    "timestamp": "2025-05-23T16:34:29.071188",
    "tags": [],
    "severity": "high",
    "services_affected": [
      "api",
      "web",
      "monitoring"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "kubernetes",
      "docker",
      "aws",
      "elasticsearch",
      "rabbitmq",
      "nginx",
      "prometheus",
      "grafana"
    ],
    "failure_pattern": "monitoring_blind_spot",
    "timeline_events": [],
    "blast_radius": "localized",
    "detection_time": null,
    "mitigation_actions": [
      "our cluster up to 5 nodes"
    ],
    "quality_score": 0.92
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/delvtech/hyperdrive-frontend/blob/302eb173893603436e48d10da152271cdc06f433/docs/PostMortems.md",
    "title": "PostMortems.md",
    "content": "# Post Mortems on Common Bugs Found\n\n## Format\n\n    ## Title - Date\n\n    ---\n\n    ### Authors\n\n    Name (Position) (optional additional notes or contact info)\n    ---\n\n    ### Summary\n\n    Provide a brief overview of the incident here.\n    ---\n\n    ### Affected Components\n\n    Description or notes about how it was affected.\n    ---\n\n    ### Resolution\n\n    Description of the action taken.\n    ---\n\n    ### Lessons Learned\n\n    Brief description or elaboration of the lesson.\n    ---\n\n    ### References\n\n    - [Reference Title 1](URL1)\n\n## Post Mortems\n\n## Incorrect Chain Id - 07/26/2023\n\n---\n\n### Authors\n\nJack Burrus (Frontend Developer)\n\n---\n\n### Summary\n\nThe browser was caching the response from localhost:80 for the address.json file. Despite being on the same docker container as someone else, the Hyperdrive address returned was different.\n\n---\n\n### Affected Components\n\nAs a result, the useContract hooks are unable to read from the contract as it is looking at the wrong chain id. This breaks the whole app. You can usually tell when this occurs because the hyperdrive config is not logged in the console. The useAppConfig exits before it's able to return the correct config.\n\n---\n\n### Resolution\n\nClearing the browser cache reset the address.json file and the correct Hyperdrive address was returned.\n\n---\n\n### Lessons Learned\n\nStarting at the root of the app and looking for the correct config information. Is the config being logged? What chain id is being logged?\n",
    "timestamp": "2025-05-23T16:34:29.456645",
    "tags": [],
    "severity": "low",
    "services_affected": [
      "web",
      "cache"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "docker",
      "azure",
      "redis"
    ],
    "failure_pattern": null,
    "timeline_events": [],
    "blast_radius": "localized",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 0.39
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/2020PB/police-brutality/blob/38b3f17323e3c28e60afa350f989cf3f33e6f4b0/docs/incident-criteria.md",
    "title": "incident-criteria.md",
    "content": "# Incident Criteria\r\n\r\nWhile the group's name is 2020PoliceBrutality, this moniker does not entirely capture the breadth of incidents the repo intends to include. The repository contains both incidents of police brutality and abuses of power, as defined below.\r\n\r\nIn addition, there are several filters we apply to keep the incidents focused and the messaging clear. The group finds the tight focus amplifies the weight of incidents by constraining them to a specific time period and circumstance.\r\n\r\nThese criteria are as follows:\r\n\r\n1. Occurring at a protest or in relation to a protest in the aftermath of George Floyd's death.\r\n    * This includes Pride rallies and Trump rallies where police appeared emboldened by violence in other protests and where protestors included Black Lives Matter symbolism, chants or messaging in the protest.\r\n1. US-only protests\r\n    * While protests are, of course, occurring wordlwide, both in solidarity with BLM and for other reasons, the focus is currently on U.S. incidents.\r\n1. Incident shows clear police brutality or abuse of power.\r\n    * See [Categories](#Categories) below for additional info.\r\n1. No incidents of looters, except in cases of clear excessive force (see [ca-vallejo-1](https://github.com/2020PB/police-brutality/blob/main/reports/California.md#police-fatally-shoot-unarmed-22-year-old--june-1st))\r\n1. Direct visual evidence is required.\r\n    * See [No Direct Visual Evidence](#No-direct-visual-evidence) for edge cases\r\n\r\nNote: non-protest and non-us incidents are being stored for review. They may be included at a later date.\r\n\r\n## Categories\r\n\r\n### Police Brutality\r\n\r\n1. Use of any riot control rounds or physical violence against bystanders. This includes passersby on foot, homeless people and\r\n1. Use of any riot control rounds or physical violence against children, the elderly or pregnant persons.\r\n1. Use of any riot control rounds against journalists or medics.\r\n1. The use of tear gas at any point.\r\n    * While it has not been studied in depth, there is sufficient antecdotal evidence that tear gas can cause major reproductive harm that 2020PoliceBrutality believes that continued use is inherently brutality.\r\n    * [Comment](https://twitter.com/ProChoiceOH/status/1268253228384292866) from a Pro-Choice Organization stating that tear gas may cause miscarriages\r\n    * [Thread](https://twitter.com/FemFlagCorps/status/1271516751679938560) of antecdotal evidence from Twitter users that tear gas has disrupted their menstrual cycles\r\n    * [ACLU Fact Sheet](https://www.aclu.org/fact-sheet/chemical-irritants-fact-sheet) on considerations for chemical irritant use.\r\n    * [Chemical Weapons Research Consortium](https://www.chemicalweaponsresearch.com/munitions_library.html)\r\n1. The use of a LRAD (or sound cannon) at any point.\r\n    * LRADs are devices designed to emit a sound sufficiently irritating to protestors that they will disperse.\r\n    * Improper use of LRADs is extremely simple. If the settings are modified, the device can easily cause permanent auditory damage to protestors.\r\n    * In addition, the weapon is indiscriminate, affecting police, protestors and bystanders within its radius alike.\r\n    * For more information, see the [ACLU Fact Sheet](https://www.aclu.org/fact-sheet/acoustic-weapons-fact-sheet)\r\n1. Improper use of kinetic projectiles.\r\n    * This includes bean bags, rubber bullets, pepper balls, wooden bullets, plastic bullets, paintballs and other less-lethal munitions.\r\n    * Improper use includes firing at short distance, aiming above the breast bone.\r\n    * See [ACLU Fact Sheet](https://www.aclu.org/fact-sheet/kinetic-impact-projectiles-fact-sheet) on considerations for use.\r\n    * The Fact Sheet states that these weapons are not only dangerous but also ineffective as riot control devices.\r\n1. Use or attempted use of a motor vehicle to strike, scare or chase protestors\r\n1. Use of any riot control rounds against peaceful protestors.\r\n    * This includes use of pepper spray, smoke grenades, flashbangs and kinetic projectiles.\r\n    * See additional [ACLU Fact Sheet](https://www.aclu.org/fact-sheet/disorientation-devices-fact-sheet) on use of disorientation devices (e.g. flashbangs)\r\n    * See additional [ACLU Fact Sheet](https://www.aclu.org/fact-sheet/chemical-irritants-fact-sheet) on considerations for chemical irritant use (e.g. pepper spray).\r\n    * [Chemical Weapons Research Consortium](https://www.chemicalweaponsresearch.com/munitions_library.html)\r\n1. Use of shields, bikes, batons or other objects against peaceful protestors.\r\n1. Kneeling on protestors to make arrests.\r\n    * In particular, this includes kneeling on protestors' necks, as this is the behavior that caused George Floyd's death.\r\n1. Unnecessary violence against protestors (e.g. shoving a protestor for 'walking too slow.')\r\n1. Escalation of violence either without warning or beyond reason.\r\n    * If a protestor strikes an officer without justification, then if officers physically arrest the protestor, this would not be included.\r\n    * However, if an officer strikes a protestor and the protestor responds in kind, police are not justified in escalating to the use of chemical agents or less-lethal munitions.\r\n    * This includes the use of chemical agents or less-lethal munitions if protestors resist being pushed by police (e.g. a police shield line attempts to advance and protestors do not move).\r\n\r\n\r\n### Abuse of Power\r\n\r\nAbuses of power include, but are not limited to:\r\n\r\n1. Removal of body cams and/or hiding badges.\r\n1. Racial profiling (e.g. arresting black protestors while allowing white protestors leniency. See [nd-fargo-1](https://github.com/2020PB/police-brutality/blob/main/reports/Ohio.md#man-struck-by-counter-protestor-while-police-look-on--june-14th)).\r\n1. Selectively enforcing laws (e.g. counter-protestors striking protestors without police intervention. See [oh-bethel-1](https://github.com/2020PB/police-brutality/blob/main/reports/Ohio.md#man-struck-by-counter-protestor-while-police-look-on--june-14th))\r\n1. Agitation and incitement (see [Agitation and incitement](#Agitation-and-incitement))\r\n1. Police arresting protestors for protected free speech (see [ga-valdosta-1](https://github.com/2020PB/police-brutality/blob/main/reports/Georgia.md#sheriff-scuffles-with-protestor-over-fck-trump-sign--june-3rd))\r\n1. Inhumane treatment, especially as part of a protected class (see [ca-losangeles-32](https://github.com/2020PB/police-brutality/blob/main/reports/California.md#police-arrest-protesters-en-masse-and-detain-them-in-poor-conditions--june-2nd) and [oh-cincinnati-4](https://github.com/2020PB/police-brutality/blob/main/reports/Ohio.md#officer-refuses-to-give-diabetic-arrestee-her-insulin-back--june-2nd))\r\n1. Destruction of property, particularly medical supplies.\r\n\r\n## Edge Cases\r\n\r\nThe boundary between police brutality, abuse of power, and other issues with the system isn't always clear. This page is meant to call out some edge cases to refine the definition of what content should be curated in this repo and what shouldn't.\r\n\r\n### Police speaking words that would incite violence, but not actively violent during this video\r\n\r\n- [Cops at Seattle protest brief \"don't kill them but hit them hard\"](https://www.reddit.com/r/PublicFreakout/comments/gwr1gh/cops_at_a_seattle_protest/)\r\n\r\n#### Decision\r\n\r\nThese incidents are generally excluded, unless accompanied by a use of force (see: [fl-ftlauderdale-3](https://github.com/2020PB/police-brutality/blob/main/reports/Florida.md#police-laugh-and-joke-when-they-think-their-body-cams-are-off--may-31st))\r\n\r\n\r\n### Selective enforcement, abuse of power, not necessarily excessive force\r\n\r\n- [Cops arresting only the black individuals in a line](https://www.reddit.com/r/PublicFreakout/comments/gwm2mf/police_using_selective_enforcement_on_protestors/) ✔️ Added in [#260](https://github.com/2020PB/police-brutality/pull/260)\r\n- [Cops giving warning & preferential treatment to Proud Boys and other white supremacists](ttps://www.buzzfeednews.com/article/davidmack/salem-oregon-cop-warn-white-armed-men-playing-favorites) ✔️ Added in [#626](https://github.com/2020PB/police-brutality/pull/626)\r\n\r\n#### Decision\r\n\r\nEgregious selective enforcement will be in scope.\r\n\r\n\r\n### Agitation and incitement\r\n\r\n- [Fargo police chief agitated crowd in plain clothes by carrying a beer can and cursing at police.](https://www.grandforksherald.com/opinion/6520779-Port-Fargo-Deputy-Chief-sends-apology-email-after-he-was-seen-at-George-Floyd-protest-with-a-beer-can-cursing-at-law-enforcement) ✔️ Added in [#620](https://github.com/2020PB/police-brutality/pull/620)\r\n\r\n#### Decision\r\n\r\nAgitation and incitement to riot will be in scope. Apply the `incitement` tag to these reports.\r\n\r\n\r\n### No direct visual evidence\r\n\r\n- [Protester suffered from complications that lead to her death from tear gas](https://twitter.com/ColumbusGov/status/1268295227921641480)\r\n\r\n\r\n#### Decision\r\n\r\nThese incidents are less clear. The preference is to include these non-visual as part of incidents with visual evidence.\r\n\r\nIndirect submissions are acceptable in some cases:\r\n1. Multiple reporters or verified persons (politicians, celebrities, etc) recount the same or similar events.\r\n1. Submissions are accompanied by direct evidence as part of a broader incident (see: [ca-losangeles-19](https://github.com/2020PB/police-brutality/blob/main/reports/California.md#police-arrest-protesters-en-masse-and-detain-them-in-poor-conditions--june-1st))\r\n1. Eyewitness accounts are provided by reputable sources (news outlets, legal aid groups, etc).\r\n\r\n\r\n### Police intimidation and indirect threats\r\n\r\n- [Police show up at teens house to ask questions about teen's social media posts concerning protests.](https://twitter.com/greg_doucette/status/1268649159952936962) ❌ No direct threats made and nothing for which police could be held accountable. [#627](https://github.com/2020PB/police-brutality/pull/627) was closed.\r\n\r\n\r\n#### Decision\r\n\r\nThese incidents are not included.\r\n",
    "timestamp": "2025-05-23T16:34:32.096498",
    "tags": [],
    "severity": "medium",
    "services_affected": [
      "api",
      "web",
      "queue"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "aws",
      "elasticsearch"
    ],
    "failure_pattern": null,
    "timeline_events": [],
    "blast_radius": "localized",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 0.42000000000000004
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/madneal/articles-translator/blob/50416387f1408710436fa0cf2919db6d03a616fe/circleci-incident.md",
    "title": "circleci-incident.md",
    "content": "# CircleCI 20230104 安全事件报告\n\n>原文：[CircleCI incident report for January 4, 2023 security incident](https://circleci.com/blog/jan-4-2023-incident-report/)\n>\n>译者：[madneal](https://github.com/madneal)\n>\n>welcome to star my [articles-translator](https://github.com/madneal/articles-translator/), providing you advanced articles translation. Any suggestion, please issue or contact [me](mailto:bing@stu.ecnu.edu.cn)\n>\n>LICENSE: [MIT](https://opensource.org/licenses/MIT)\n\n[2023 年 1 月 4 日，我们提醒客户](https://circleci.com/blog/january-4-2023-security-alert/) 一起安全事件。 今天，我们想与您分享发生的事情、我们学到的知识以及我们未来不断改善安全态势的计划。\n\n我们要感谢我们的客户对于重置密钥的关注，并对此次事件可能对您的工作造成的任何干扰表示歉意。我们鼓励尚未采取行动的客户采取行动，以防止未经授权访问第三方系统和存储。此外，我们要感谢我们的客户和社区在我们进行彻底调查期间的耐心等待。为了实现负责任的披露，我们已尽最大努力在共享信息的速度与保持调查的完整性之间取得平衡。\n\n**本报告包含:**\n\n* 发生了什么？\n* 我们怎么知道这个攻击向量已经关闭并且可以安全构建？\n* 与客户的沟通和支持\n* 如何判断我是否受影响？\n* 可能有助于您的团队进行内部调查的详细信息\n* 我们从这次事件中学到了什么以及我们下一步将做什么\n* 关于员工责任与系统保障措施的说明\n* 安全最佳实践\n* 结语\n\n## 发生了什么？\n\n*除非另有说明，否则所有日期和时间均以 UTC 报告。*\n\n2022 年 12 月 29 日，我们的一位客户提醒我们注意可疑的 GitHub OAuth 活动。此通知启动了 CircleCI 的安全团队与 GitHub 的更深入审查。\n\n2022 年 12 月 30 日，我们了解到该客户的 GitHub OAuth 令牌已被未经授权的第三方泄露。尽管该客户能够迅速解决问题，但出于谨慎考虑，我们在 2022 年 12 月 31 日代表客户主动启动了更换所有 GitHub OAuth 令牌的流程。尽管与 GitHub 合作提高 API 速率限制，但轮换过程需要时间 虽然目前尚不清楚其他客户是否受到影响，但我们继续扩大分析范围。\n\n到 2023 年 1 月 4 日，我们的内部调查已经确定了未经授权的第三方入侵的范围和攻击的进入路径。迄今为止，我们了解到未经授权的第三方利用部署到 CircleCI 工程师笔记本电脑上的恶意软件来窃取有效的、支持 2FA 的 SSO session。这台机器于 2022 年 12 月 16 日遭到入侵。我们的防病毒软件未检测到该恶意软件。我们的调查表明，该恶意软件能够执行 session cookie 盗窃，使他们能够在远程位置冒充目标员工，然后升级为对我们生产系统子集的访问。\n\n由于目标员工有权生成生产访问令牌作为员工日常职责的一部分，因此未经授权的第三方能够从数据库和存储的子集访问和泄露数据，包括客户环境变量、令牌和密钥。我们有理由相信，未经授权的第三方在 2022 年 12 月 19 日进行了侦察活动。2022 年 12 月 22 日 发生了泄露事件，这是我们生产系统中最后一次未经授权活动的记录。尽管所有泄露的数据都是静态加密的，但第三方从正在运行的进程中提取了加密密钥，使他们能够访问加密数据。\n\n虽然我们对内部调查的结果充满信心，但我们已聘请第三方网络安全专家协助我们进行调查并验证我们的调查结果。我们迄今为止的发现基于对我们的身份验证、网络和监控工具的分析，以及我们合作伙伴提供的系统日志和日志分析。\n\n针对这一事件，我们采取了以下行动：\n\n* 2023 年 1 月 4 日 16:35 UTC，我们关闭了帐户被盗员工的所有访问权限。\n* 2023 年 1 月 4 日 28:30 UTC，我们关闭了几乎所有员工的生产访问权限，限制了极少数群体的访问权限以解决运营问题。在此调查期间，我们从未有任何证据表明任何其他员工或他们的设备的凭证已被泄露，但我们采取此行动是为了限制潜在的攻击面。\n* 2023 年 1 月 4 日 22:30 UTC，我们修改了了所有可能暴露的生产主机，以确保安全的生产机器。\n* 2023 年 1 月 5 日 03:26 UTC，我们撤销了所有项目 API 令牌。\n* 2023 年 1 月 6 日 05:00 UTC，我们撤销了在 2023 年 1 月 5 日 00:00 UTC 之前创建的所有个人 API 令牌。\n* 2023 年 1 月 6 日 06:40 UTC，我们开始与 Atlassian 的合作伙伴合作，代表我们的客户轮换所有 Bitbucket token。这项工作于 2023 年 1 月 6 日 10:15 UTC 完成。\n* 2023 年 1 月 7 日 07:30 UTC，我们完成了 GitHub OAuth 令牌的修改，该修改是我们于 2022 年 12 月 31 日 04:00 UTC 开始的。\n* 2023 年 1 月 7 日 18:30 UTC，我们开始与 AWS 的合作伙伴合作，通知客户可能受影响的 AWS token。据我们了解，这些通知已于 2023 年 1 月 12 日 00:00 UTC 时完成。\n\n在此期间，我们在外部调查人员的支持下继续进行取证调查，在我们的平台上推出额外的安全层，并构建和分发额外的工具（更多详情见下文）以支持我们的客户保护他们的 secrets。\n\n## 我们怎么知道这个攻击向量已经关闭并且可以安全构建？\n\n我们相信客户可以安全地在 CircleCI 上构建。\n\n自从意识到这种攻击以来，我们采取了许多措施，既关闭了攻击向量，又增加了额外的安全层，包括：\n\n* 通过我们的 MDM 和 A/V 解决方案添加了针对此次攻击中使用的恶意软件表现出的特定行为的检测和阻止。\n* 由于我们实施了额外的安全措施，因此仅限极少数员工访问生产环境 我们对我们平台的安全性充满信心，并且没有迹象表明任何其他员工的设备遭到入侵。\n* 对于保留生产访问权限的员工，我们添加了额外的升级身份验证步骤和控制。 这将帮助我们防止可能的未经授权的生产访问，即使在 2FA 支持的 SSO session 被盗的情况下也是如此。\n* 跨多个触发器并通过各种第三方供应商对我们在此场景中确定的特定行为模式实施监控和警报。\n\n我们知道安全工作永远不会结束。除了关闭这个特定的向量，我们还进行了增强和持续的审查，以确保加强对潜在攻击的防御。\n\n## 与客户的沟通和支持\n\n在 2023 年 1 月 4 日 22:30 UTC 完成所有生产主机的轮换后，我们确信我们已经消除了攻击向量和破坏主机的可能性。\n\n2023 年 1 月 5 日 02:30 UTC，我们发送了披露电子邮件，[在我们的博客上发布了安全通知](https://circleci.com/blog/january-4-2023-security-alert/)，通过我们的社交媒体帐户和我们的讨论论坛通知客户，并创建了一篇关于如何执行建议的安全步骤的支持文章。\n\n我们建议所有客户更改他们的 secrets，包括 OAuth 令牌、项目 API 令牌、SSH 密钥等（有关更多详细信息，请参阅博客文章或讨论文章）。\n\n此披露启动了与我们客户的积极和持续的沟通期。我们要感谢我们的客户对这一事件的一致响应，以及帮助我们找到机会为您提供额外的工具。我们接受了这些反馈，并作为回应构建并发布了新工具并修改了我们现有的工具，以通过以下方式为客户加快修复速度：\n\n* [秘密发现脚本](https://github.com/CircleCI-Public/CircleCI-Env-Inspector) 以创建可操作的秘密轮换列表。\n* CircleCI API 的两个关键变化：\n     * 返回结帐密钥的 SHA-256 签名的新功能，以便更好地匹配 GitHub UI。\n     * `updated_at` 字段已添加到 Contexts API 中，以便客户可以验证这些变量是否已成功轮换。\n* 免费和付费计划的所有客户都可以访问审计日志，以帮助客户审查 CircleCI 平台活动。\n\n我们感谢客户就我们可以改进沟通的地方提供的所有反馈，包括让事件在我们的渠道中更加明显的机会。\n\n## 我怎么知道我是否受到了影响？\n\n### 我的数据有风险吗？\n\n在此事件中，未经授权的行为者于 2022 年 12 月 22 日窃取了客户信息，其中包括第三方系统的环境变量、密钥和令牌。如果您在此期间将机密信息存储在我们的平台上，请假设它们已被访问并采取建议的缓解措施。我们建议您从 2022 年 12 月 16 日开始调查系统中的可疑活动，并在我们于 2023 年 1 月 4 日披露后完成机密修改之日结束。2023 年 1 月 5 日之后进入系统的任何内容都可以被认为是安全的。\n\n### 是否有未经授权的行为者使用该数据访问我的任何系统？\n\n由于此事件涉及第三方系统的密钥和令牌外泄，我们无法知道您的 secret 是否被用于未经授权访问这些第三方系统。 我们在下面提供了一些详细信息，以帮助客户进行调查。\n\n**在发布时，只有不到 5 位客户通知我们由于此事件而未经授权访问第三方系统。**\n\n## 可能有助于您的团队进行内部调查的详细信息\n\n在第三方取证调查员的帮助下，我们最近确认了可能有助于客户进行审计和调查的更多详细信息。\n\n### 影响日期：\n\n* 我们在 2022 年 12 月 19 日看到未经授权的第三方访问，数据泄露发生在 2022 年 12 月 22 日。\n* 我们没有证据表明 2022 年 12 月 19 日之前有影响客户的活动。出于谨慎考虑，我们建议您调查从 2022 年 12 月 16 日事件开始到 1 月之后修改 secret 之间的这段时间系统中存在异常活动。\n\n### 识别为被威胁行为者使用的 IP 地址：\n\n* 178.249.214.10\n* 89.36.78.75\n* 89.36.78.109\n* 89.36.78.135\n* 178.249.214.25\n* 72.18.132.58\n* 188.68.229.52\n* 111.90.149.55\n\n### Data centers and VPN providers identified as being used by the threat actor:\n\n### 数据中心和 VPN 提供商被识别为被威胁行为者使用：\n\n* Datacamp Limited\n* Globalaxs Quebec Noc\n* Handy Networks, LLC\n* Mullvad VPN\n\n### Malicious files to search for and remove:\n\n### 搜索和删除的恶意文件：\n\n* /private/tmp/.svx856.log\n* /private/tmp/.ptslog\n* PTX-Player.dmg (SHA256: 8913e38592228adc067d82f66c150d87004ec946e579d4a00c53b61444ff35bf)\n* PTX.app\n\n### 拦截以下域名\n\n* potrax[.]com\n\n### 查看 GitHub 审核日志文件以查找意外命令，例如：\n\n* repo.download_zip\n\n## 我们从这次事件中学到了什么以及我们接下来要做什么\n\n**我们了解到：虽然我们有适当的工具来阻止和检测攻击，但总有机会加强我们的安全态势。**\n\n我们拥有的身份验证、安全和跟踪工具使我们能够全面诊断和修复问题。随着恶意攻击者越来越复杂，我们正在不断改进我们的安全标准并推动最佳实践以保持领先于未来的威胁。我们将越来越积极地使用安全工具。展望未来，为了支持更保守的立场并防止攻击者不当访问我们的系统，我们将优化现有工具的配置以创建额外的防御层。\n\n### 我们的计划：\n\n首先，我们将为所有客户启动定期自动 OAuth 令牌轮换。 我们的计划还包括从 OAuth 到 GitHub 应用程序的转变，使我们能够在令牌中实施更精细的权限。我们还计划完成对我们所有工具配置的全面分析，包括第三方审查。我们将继续采取其他措施，包括扩大告警范围、减少会话信任、添加额外的身份验证因素以及执行更定期的访问轮换。最后，我们将使我们的系统权限更加短暂，严格限制从类似事件中获得的任何令牌的目标值。\n\n### 我们学习到：我们可以让客户更轻松地采用我们最先进的安全功能。\n\n通过 CircleCI 的发展，我们不断引入功能来提高客户构建管道的安全性。虽然客户可以使用高级安全功能，但我们可以做更多工作来提高这些功能的采用率。\n\n### 我们的计划：\n\n客户必须更容易无缝地采用可用的最新和最先进的安全功能，包括 OIDC 和 IP 范围。我们还在探索其他主动步骤，例如，自动令牌过期和未使用 secret 的通知。我们将使我们的客户更简单、更方便地创建和维护高度安全的管道，在智能管理风险的同时实现云的每一个优势。\n\n## 关于员工责任与系统保障措施的说明\n\n我们想说清楚。虽然一名员工的笔记本电脑通过这种复杂的攻击被利用，但安全事件是系统故障。作为一个组织，我们的责任是建立多层防护措施来抵御所有攻击向量。\n\n## 安全最佳实践\n\n鉴于成熟和有动机的攻击者越来越多，我们致力于与我们的客户分享最佳实践，以加强我们对未来不可避免的尝试的集体防御。以下是客户可以用来提高管道安全性的建议：\n\n* 尽可能使用 [OIDC 令牌](https://circleci.com/docs/openid-connect-tokens/) 以避免在 CircleCI 中存储长期存在的凭据。\n* 利用 [IP 范围](https://circleci.com/docs/ip-ranges/) 将您系统的入站连接限制为仅已知 IP 地址。\n* 使用 [Contexts](https://circleci.com/docs/contexts/) 合并共享机密并将对机密的访问限制为特定项目，然后可以[通过 API 自动轮换](https://circleci.com /docs/contexts/#rotating-environment-variables）。\n* 对于特权访问和其他控制，您可以选择使用 [runners](https://circleci.com/docs/runner-overview/#circleci-runner-use-cases)，它允许您将 CircleCI 平台连接到 您自己的计算和环境，包括 IP 限制和 IAM 管理。\n\n## 结语\n\n我们知道没有合适的时间来响应关键系统上的安全事件，我们要衷心感谢所有在事件发生后立即采取行动的客户。正是通过这种集体行动，我们将能够更有力地应对未来的威胁。我们还亲眼目睹了我们客户社区的力量和慷慨，你们中的许多人前往我们的讨论论坛分享知识并互相帮助。感谢您在我们努力解决此事件时的支持和耐心。",
    "timestamp": "2025-05-23T16:34:32.521758",
    "tags": [],
    "severity": "high",
    "services_affected": [
      "api",
      "web",
      "auth"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "aws",
      "elasticsearch"
    ],
    "failure_pattern": null,
    "timeline_events": [],
    "blast_radius": "global",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 0.52
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/TonyPhipps/SIEM/blob/dacbe207f7788822f14c78ca380d20690eed7f0c/incident-tracking.md",
    "title": "incident-tracking.md",
    "content": "Tables and their fields are listed below.\n- Fields are focused on enabling information sharing between analysts and useful metrics.\n- Fields with dropdowns have selection values provided in-line.\n- Tables may \"lookup\" entries in another table to establish a relationship.\n\n- [Incidents](#incidents)\n- [Indicator of Compromise](#indicator-of-compromise)\n- [Adversary](#adversary)\n- [Software](#software)\n- [Affected Systems](#affected-systems)\n- [Affected Users](#affected-users)\n- [Attack Techniques](#attack-techniques)\n- [Emails](#emails)\n- [Use Cases/Plays](#use-casesplays)\n- [Work Log](#work-log)\n- [Mitigations](#mitigations)\n- [Owner](#owner)\n- [Signature](#signature)\n- [Hunts](#hunts)\n- [Hunt Backlog](#hunt-backlog)\n\n# Incidents\n- Adversary (Lookup)\n- Signature (lookup)\n  - Use Cases/Plays (Lookup)\n    - Attack Techniques (Lookup)\n    - Mitigations (Lookup)\n- Affected Software (Lookup)\n- Affected Systems (Lookup)\n- Affected Users (Lookup)\n- Emails (Lookup)\n- Related Incidents (Lookup)\n- Work Log (Lookup)\n- Resolutions (Lookup)\n- Owner (Lookup)\n- Date Activity Started\n- Date Activity Stopped\n- Date Client Notified\n- Date Closed\n- Closed By\n- Date Reported\n- Reported By\n- Date Reviewed\n- Reviewed by\n- Date Last Updated\n- Last updated by\n- Date Created\n- Created By\n- Title/Subject\n- Executive Summary\n- Internal Comments\n- Origination\n  - Threat Hunting\n  - SIEM Correlation\n  - Alarm from EDR\n  - Alarm from AV\n  - Alarm from IDS/IPS\n  - Reported by Internal User\n  - Reported by Third Party\n  - Reported by Adversary\n  - Threat Hunting\n  - Audit\n- Origination Details\n- External Related IDs\n- Priority\n  - Emergency\n  - High\n  - Medium\n  - Low\n- Outcome\n  - True Positive\n  - False Positive\n  - Benign\n  - Indeterminate\n- Root Cause\n  - Training/Awareness\n  - Policy Violation\n  - Missing Patch\n  - Zero Day\n  - Configuration Weakness\n  - Power Failure\n  - Hardware Failure\n  - Software Failure\n  - Sabotage\n- Scope of Compromise\n  - Initial Access\n  - Execution\n  - Persistence\n  - Privilege Escalation\n  - Defense Evasion\n  - Credential Access\n  - Discovery\n  - Lateral Movement\n  - Collection\n  - Command and Control\n  - Exfiltration\n  - Impact\n  - No Compromise\n- Status\n  - New\n  - In Progress\n  - Closed\n  - Pending\n  - On Hold\n  - Cancelled\n  - Duplicate\n- Escalation Level\n  - Level 1\n  - Level 2\n  - Level 3\n  - External\n- Attachments\n- Change Log\n\n\n# Indicator of Compromise\n- IP\n- Hostname\n- Domain Name\n- Date Last Observed\n\n\n# Adversary\n- Name\n- Aliases\n- References\n- Signatures (lookup)\n- Attack Techniques (lookup)\n\n\n\n# Software\n- Vendor\n- Product\n- Version\n\n# Affected Systems\n- Internal IP(s)\n- Public IP(s)\n- MAC(s)\n- Hostname\n- User (Lookup)\n- Location\n- Platform\n- Operating System\n- Operating System Version\n\n# Affected Users\n- Name\n- Email\n- Phone\n- Username\n\n# Attack Techniques\n- ID\n- Name\n- URL\n\n# Emails\n- Subject\n- Sender\n- Recipients\n- Body\n- Attachments\n- Date Sent\n- Header\n\n\n# Use Cases/Plays\n- Title\n- Link\n\n# Work Log\n- Owner (Lookup)\n- Date and Time of Work\n- Title\n- Details\n\n# Mitigations\n- Title\n- Description\n\n# Owner\n- Username\n- Full Name\n\n\n# Signature\n- Name\n- Use Case (Lookup)\n- Event Feed (lookup)\n- Adversaries (lookup)\n- Use Case (lookup)\n  - Attack Techniques (lookup)\n- Date Last Reviewed\n- Date Last Validated\n- Severity\n- Fidelity\n- Status\n- References\n- Attack Simluation\n- Notess\n- Change Log\n- Sample Source Events\n- Pseudologic\n- Deployed Logic\n- Sigma Logic\n\n# Hunts\n- Name - Hypothesis statement - what is being hunted for\n- Description - Details to provide context surrounding who, what, when, where, how, etc. Anticipate questions and answer them here.\n- Data Sources - Types of data to be analyzed and where they come from\n- Duration - Dataset mininum and maximum age\n- Scope - which systems, assets, etc. should be included\n- MITRE Tactics (lookup) - if any are applicable\n- MITRE Techniques (lookup) - if any are applicable\n- Adversary Groups (lookup) - or related recognizable names like botnet names, ransomware as a service names, etc.\n- Script - how the hunt is actually conducted. May be geared toward a specific tool, but should have enough detail to allow reproduction in another tool. Should include specific techniques and detail sufficient for another hunter to reproduce the hunt.\n- Resources (links, report names)\n\n# Hunt Backlog\n- Hunt (lookup)\n- Name (hypothesis or trigger)\n- Hunt Model - Reactive or Proactive\n- Date performed\n- Hunters\n- Result (proven, disproven, inconclusive)\n- Lessons Learned\n- Script (how this specific hunt was conducted)\n- Count of incidents created\n- Count of use cases/signatures updated\n- Threat Intelligence output produced\n- Security Recommendations produced\n- Vulnerability findings produced\n- Knowledge gained\n- Visiblity gained\n- New analysis techniques extracted\n- New data sources obtained\n- Time Spent\n\n",
    "timestamp": "2025-05-23T16:34:33.752570",
    "tags": [],
    "severity": "high",
    "services_affected": [
      "database",
      "monitoring"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "prometheus"
    ],
    "failure_pattern": "dependency_failure",
    "timeline_events": [],
    "blast_radius": "localized",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 0.85
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/18F/tock/blob/f8d640ee01b6c69c787fe755742d973701295b62/docs/incident-response.md",
    "title": "incident-response.md",
    "content": "## Responding to Security Incidents\n\n1. [Start the report process as per the TTS Handbook.](https://handbook.tts.gsa.gov/security-incidents/) Note that all incidents must be reported within one hour of their discovery.\n\n1. Because Tock is hosted on cloud.gov, you also need to follow their [Security Incident Response Guide](https://cloud.gov/docs/ops/security-ir/).\n\n1. If the incident impacts the availability of the Tock app, notify the Tock team in #tock-dev. A member of the Tock team will then notify Tock users by posting in #tock.\n\n\nIf, as a member of the Tock dev team, you need to respond to an incident reported in #tock-dev, follow the additional steps outlined below.\n\n1. Open an issue in GitHub to track the response to the incident. Label it \"investigating.\"\n\n1. Follow the [cloud.gov security response process](https://cloud.gov/docs/ops/security-ir-checklist/), updating the GitHub issue as appropriate.\n\n## CircleCI\n\nCircleCI secrets (stored in environment variables) correspond to cloud.gov [service keys](https://docs.cloudfoundry.org/devguide/services/service-keys.html).\n\nTo rotate these secrets, it is necessary to re-create the service keys and then update the CircleCI environment variables with the new values:\n\n- `cf delete-service-key service-account-$env-tock service-key-$env-tock`\n- `cf create-service-key service-account-$env-tock service-key-$env-tock`\n- Update these environment variables using the CircleCI project settings page:\n  - `CF_DEPLOYER_USERNAME_$env` and `CF_DEPLOYER_PASSWORD_$env`\n\n(where `$env` is the name of the deployment environment)\n",
    "timestamp": "2025-05-23T16:34:34.151445",
    "tags": [],
    "severity": "low",
    "services_affected": [
      "web",
      "database"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "kubernetes",
      "jenkins"
    ],
    "failure_pattern": "configuration_drift",
    "timeline_events": [],
    "blast_radius": "localized",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 0.62
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/iZettle/api-documentation/blob/333074c1d8433a7fab09d0560d3c1a3ca369adf5/incidents.md",
    "title": "incidents.md",
    "content": "Incidents\n=====================\nIf you have questions about any incident, contact our developer support at [Zettle Developer Portal](https://developer.zettle.com).\n\n## March 2021\n### Finance API returned wrong transaction type for transactions made with cards.\n\nMar 30, 16:03 to 16:59 UTC<br>\nThis incident has been resolved. __Action needed to fix data.__<br>\nWe apologize for the inconvenience.\n<details><!-- start tag of the incident section-->\n<summary>Click for details</summary>\n\n### Incident summary\nThere was a problem with the `originatorTransactionType` field in the response for transactions made with cards for the following endpoint:\n\n```\nGET /organizations/{organizationUuid}/accounts/{accountTypeGroup}/transactions\n```\n\nThe following table lists the expected and actual values for the field:\n\n|Expected value in `originatorTransactionType` |Actual value in `originatorTransactionType` during the incident\n|:---- |:----\n|CARD_PAYMENT |PAYMENT\n|CARD_PAYMENT_FEE |PAYMENT\n|CARD_REFUND |PAYMENT\n|CARD_PAYMENT_FEE_REFUND |PAYMENT\n\nTransactions made between the following timestamps were affected:\n\nStart time:  2021-03-30 16:03:11.437237 UTC<br>\nEnd time:  2021-03-30 16:59:45.00856  UTC<br>\nThe total duration was approximately 56 minutes.\n\n### What do you need to do as a consumer?\nTo fix your data, you would need to refetch transactions for merchants that your integration serves between the affected timestamps.\n\nIf your integration disregards transactions with `originatorTransactionType` `PAYMENT` and `PAYMENT_FEE` you would need to handle those transactions as you used to do with card related types. In other words `CARD_PAYMENT` and `CARD_REFUND` should be expected as `PAYMENT`.<br>\n`CARD_PAYMENT_FEE` and `CARD_PAYMENT_FEE_REFUND` should be expected as `PAYMENT_FEE`.\n\nSee the following example to understand better:\n\n```\nGET/organizations/self/accounts/liquid/transactions?start=2021-03-30T16:03:10&end=2021-03-30T16:59:46\n```\n\n__Actual response during the time of incident after a partial fix when refetching:__\n \n\n```\n{\n  \"data\": [\n    {\n      \"timestamp\": \"2021-04-23T00:08:40.171+0000\",\n      \"amount\": 5533,\n      \"originatorTransactionType\": \"PAYMENT_FEE\", // Instead of CARD_PAYMENT_FEE_REFUND\n      \"originatingTransactionUuid\": \"63a5073a-a386-11eb-9017-db0e39c91814\"\n    },\n    {\n      \"timestamp\": \"2021-04-23T00:08:40.168+0000\",\n      \"amount\": -201200,\n      \"originatorTransactionType\": \"PAYMENT\", // Instead of CARD_REFUND\n      \"originatingTransactionUuid\": \"63a5073a-a386-11eb-9017-db0e39c91814\"\n    },\n    {\n      \"timestamp\": \"2021-04-23T00:08:40.165+0000\",\n      \"amount\": -110,\n      \"originatorTransactionType\": \"PAYMENT_FEE\", // Instead of CARD_PAYMENT_FEE\n      \"originatingTransactionUuid\": \"40a35d88-a387-11eb-850d-127e2d49c7a5\"\n    },\n    {\n      \"timestamp\": \"2021-04-23T00:08:40.163+0000\",\n      \"amount\": 3990,\n      \"originatorTransactionType\": \"PAYMENT\", // Instead of CARD_PAYMENT\n      \"originatingTransactionUuid\": \"40a35d88-a387-11eb-850d-127e2d49c7a5\"\n    }\n  ]\n}\n\n```\n\n\n</details>\n",
    "timestamp": "2025-05-23T16:34:34.958080",
    "tags": [],
    "severity": "low",
    "services_affected": [
      "api",
      "web",
      "database"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "aws"
    ],
    "failure_pattern": "data_corruption",
    "timeline_events": [
      {
        "timestamp": "16:03",
        "event": "11.437237 UTC<br>"
      },
      {
        "timestamp": "16:59",
        "event": "45.00856  UTC<br>"
      },
      {
        "timestamp": "16:03",
        "event": "10&end=2021-03-30T16:59:46"
      },
      {
        "timestamp": "00:08",
        "event": "40.171+0000\","
      },
      {
        "timestamp": "00:08",
        "event": "40.168+0000\","
      },
      {
        "timestamp": "00:08",
        "event": "40.165+0000\","
      },
      {
        "timestamp": "00:08",
        "event": "40.163+0000\","
      },
      {
        "timestamp": "2021-03-30 16:03",
        "event": "11.437237 UTC<br>"
      },
      {
        "timestamp": "2021-03-30 16:59",
        "event": "45.00856  UTC<br>"
      }
    ],
    "blast_radius": "partial",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 0.77
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/satan1a/awesome-cybersecurity-blueteam-cn/blob/a09f2049d4e51f9bb529d8c0c5aea17314a7e1af/docs/0x4_incident_response.md",
    "title": "0x4_incident_response.md",
    "content": "---\ntitle: 🚑 应急响应大合集\n\n---\n\n>   转载自[awesome-incident-response](https://github.com/meirwah/awesome-incident-response)\n\n# 应急响应大合集\n\n用于安全事件响应的工具与资源的列表，旨在帮助安全分析师与 [DFIR](http://www.acronymfinder.com/Digital-Forensics%2c-Incident-Response-(DFIR).html) 团队。\n\nDFIR 团队是组织中负责安全事件响应（包括事件证据、影响修复等）的人员组织，以防止组织将来再次发生该事件。\n\n## 目录\n\n- [对抗模拟](#对抗模拟)\n- [工具集](#工具集)\n- [书籍](#书籍)\n- [社区](#社区)\n- [磁盘镜像创建工具](#磁盘镜像创建工具)\n- [证据收集](#证据收集)\n- [事件管理](#事件管理)\n- [Linux 发行版](#Linux发行版)\n- [Linux 证据收集](#Linux证据收集)\n- [日志分析工具](#日志分析工具)\n- [内存分析工具](#内存分析工具)\n- [内存镜像工具](#内存镜像工具)\n- [OSX 证据收集](#osx证据收集)\n- [其它清单](#其它清单)\n- [其他工具](#其他工具)\n- [Playbooks](#playbooks)\n- [进程 Dump 工具](#进程Dump工具)\n- [沙盒 / 逆向工具](#沙盒/逆向工具)\n- [时间线工具](#时间线工具)\n- [视频](#视频)\n- [Windows 证据收集](#Windows证据收集)\n\n## IR 工具收集\n\n### 对抗模拟\n\n* [APTSimulator](https://github.com/NextronSystems/APTSimulator) - 使用一组工具与输出文件处理操作系统的 Windows 批处理脚本，使得系统看上去像被攻陷了。\n* [Atomic Red Team (ART)](https://github.com/redcanaryco/atomic-red-team) - 与 Mitre ATT＆CK 框架匹配的便携测试工具。\n* [AutoTTP](https://github.com/jymcheong/AutoTTP) - 自动策略技术与程序。手动重复运行复杂序列进行回归测试，产品评估，为研究人员生成数据。\n* [Blue Team Training Toolkit (BT3)](https://www.bt3.no/) - 用于防御性安全培训的软件，将网络分析培训课程，事件响应演练和 Red Team 合作提升到一个新的水平。\n* [Caldera](https://github.com/mitre/caldera) - 在 Windows Enterprise 网络中攻陷系统后执行敌对行为的自动对手仿真系统。运行时的行为由计划系统和基于 ATT＆CK™ 项目预先配置的对手模型生成。\n* [DumpsterFire](https://github.com/TryCatchHCF/DumpsterFire) - DumpsterFire 工具集是一个模块化、菜单驱动的跨平台工具，用于构建可重复的分布式安全事件。创建 Blue Team 演戏与传感器报警映射关系的自定义事件链。Red Team 可以制造诱饵事件，分散防守方的注意力以支持和扩大战果。\n* [Metta](https://github.com/uber-common/metta) - 用于进行敌对模拟的信息安全防御工具。\n* [Network Flight Simulator](https://github.com/alphasoc/flightsim) - 用于生成恶意网络流量并帮助安全团队评估安全控制和网络可见性的轻量级程序。\n* [Red Team Automation (RTA)](https://github.com/endgameinc/RTA) - RTA 提供了一个旨在让 Blue Team 在经历过 MITRE ATT&CK 模型为指导的攻击行为后的检测能力的脚本框架。\n* [RedHunt-OS](https://github.com/redhuntlabs/RedHunt-OS) - 用于模拟对手与威胁狩猎的虚拟机。\n\n### 工具集\n\n* [Belkasoft Evidence Center](https://belkasoft.com/ec) -  该工具包可以快速从多个数据源提取电子证据，包括硬盘、硬盘镜像、内存转储、iOS、黑莓与安卓系统备份、UFED、JTAG 与 chip-off 转储。\n* [CimSweep](https://github.com/PowerShellMafia/CimSweep) - CimSweep 是一套基于 CIM/WMI 的工具，提供在所有版本的 Windows 上执行远程事件响应和追踪。\n* [CIRTkit](https://github.com/byt3smith/CIRTKit) - CIRTKit 不仅是一个工具集合，更是一个框架，统筹事件响应与取证调查的进程。\n* [Cyber Triage](http://www.cybertriage.com) - Cyber Triage 远程收集分析终端数据，以帮助确定计算机是否被入侵。其专注易用性与自动化，采用无代理的部署方法使公司在没有重大基础设施及取证专家团队的情况下做出响应。其分析结果用于决定该终端是否应该被擦除或者进行进一步调查。\n* [Digital Forensics Framework](http://www.arxsys.fr/discover/) - DFF 是一个建立在专用 API 之上的开源计算机取证平台，DFF 提出了一种替代目前老旧的数字取证解决方案。其设计简单、更加易于自动化。DFF 接口可以帮助用户进行数字调查取证的主要步骤，专业与非专业人员都可以快速的进行数字取证并执行事件响应。\n* [Doorman](https://github.com/mwielgoszewski/doorman) - Doorman 是一个 osquery 的管理平台，可以远程管理节点的 osquery 配置。它利用 osquery 的 TLS 配置\\记录器\\分布式读写等优势仅以最小开销和侵入性为管理员提供一组设备的管理可见性。\n* [Envdb](https://github.com/mephux/envdb) - Envdb 将你的生产\\开发\\云等环境变成数据库集群，你可以使用 osquery 作为基础搜索。它将 osquery 的查询进程和一个agent打包在一起向一个集中位置发送。\n* [Falcon Orchestrator](https://github.com/CrowdStrike/falcon-orchestrator) - Falcon Orchestrator 是由 CrowdStrike 提供的一个基于 Windows 可扩展的应用程序，提供工作流自动化、案例管理与安全应急响应等功能。\n* [GRR Rapid Response](https://github.com/google/grr) - GRR Rapid Response 是一个用来远程现场实时取证的应急响应框架，其带有一个python客户端安装在目标系统以及一个可以管理客户端的 Python 编写的服务器。\n* [Kolide Fleet](https://kolide.com/fleet) - Kolide Fleet 是一个为安全专家定制的先进的主机监控平台。通过利用Facebook经过实战检验的 osquery 项目，Kolide 能够快速回答复杂问题。\n* [Limacharlie](https://github.com/refractionpoint/limacharlie) - 一个终端安全平台，它本身是一个小项目的集合，并提供了一个跨操作系统的低级环境，你可以管理并推送附加功能进入内存给程序扩展功能。\n* [MIG](http://mig.mozilla.org/) - Mozilla Investigator (MIG) 是一个在远程终端执行调查的平台，它可以在大量系统中并行获取数据，从而加速事故调查与日常业务安全\n* [MozDef](https://github.com/mozilla/MozDef) - Mozilla Defense Platform (MozDef) 旨在帮助安全事件处理自动化，并促进事件的实时处理。\n* [nightHawk](https://github.com/biggiesmallsAG/nightHawkResponse) - nightHawk Response Platform 是一个以 ElasticSearch 为后台的异步取证数据呈现的应用程序，设计与 Redline 配合调查。\n* [Open Computer Forensics Architecture](http://sourceforge.net/projects/ocfa/) - Open Computer Forensics Architecture (OCFA) 是另一个分布式开源计算机取证框架，这个框架建立在 Linux 平台上，并使用 postgreSQL 数据库来存储数据。\n* [Osquery](https://osquery.io/) - osquery 可以找到 Linux 与 OSX 基础设施的问题,无论你是要入侵检测、基础架构可靠性检查或者合规性检查，osquery 都能够帮助你提高公司内部的安全组织能力, *incident-response pack* 可以帮助你进行检测\\响应活动。\n* [Redline](https://www.fireeye.com/services/freeware/redline.html) - 为用户提供主机调查工具，通过内存与文件分析来找到恶意行为的活动迹象，包括对威胁评估配置文件的开发\n* [The Sleuth Kit & Autopsy](http://www.sleuthkit.org) - Sleuth Kit 是基于 Unix 和 Windows 的工具，可以帮助计算机取证分析，其中包含各种协助取证的工具，比如分析磁盘镜像、文件系统深度分析等\n* [TheHive](https://thehive-project.org/) - TheHive 是一个可扩展的三合一开源解决方案，旨在让 SOC、CSIRT、CERT 或其他任何信息安全从业人员快速地进行安全事件调查。\n* [X-Ways Forensics](http://www.x-ways.net/forensics/) - X-Ways 是一个用于磁盘克隆、镜像的工具，可以查找已经删除的文件并进行磁盘分析。\n* [Zentral](https://github.com/zentralopensource/zentral) - 与 osquery 强大的端点清单保护能力相结合，通知与行动都灵活的框架，可以快速对 OS X 与 Linux 客户机上的更改做出识别与响应。\n\n### 书籍\n\n* [Dfir intro](https://medium.com/@sroberts/introduction-to-dfir-d35d5de4c180/)) - 作者:Scott J. Roberts\n* [The Practice of Network Security Monitoring: Understanding Incident Detection and Response](http://www.amazon.com/gp/product/1593275099) - 作者:Richard Bejtlich\n\n### 社区\n\n* [augmentd](http://augmentd.co/) - 这是一家社区驱动的网站，上面提供了一个可通过不同的常用安全工具部署执行的搜索清单\n* [Sans DFIR mailing list](https://lists.sans.org/mailman/listinfo/dfir) - Mailing list by SANS for DFIR\n* [Slack DFIR channel](https://dfircommunity.slack.com) - Slack DFIR Communitiy channel - [Signup here](https://rishi28.typeform.com/to/sTbTI8)\n\n### 磁盘镜像创建工具\n\n* [AccessData FTK Imager](http://accessdata.com/product-download/?/support/adownloads#FTKImager) - AccessData FTK Imager 是一个从任何类型的磁盘中预览可恢复数据的取证工具，FTK Imager 可以在 32\\64 位系统上实时采集内存与页面文件。\n* [Bitscout](https://github.com/vitaly-kamluk/bitscout) - Vitaly Kamluk 开发的 Bitscout 可以帮助你定制一个完全可信的 LiveCD/LiveUSB 镜像以供远程数字取证使用（或者你需要的其它任务）。它对系统所有者透明且可被监控，同时可用于法庭质证、可定制且紧凑。 \n* [GetData Forensic Imager](http://www.forensicimager.com/) - GetData Forensic Imager 是一个基于 Windows 程序，将常见的镜像文件格式进行获取\\转换\\验证取证\n* [Guymager](http://guymager.sourceforge.net) - Guymager 是一个用于 Linux 上媒体采集的免费镜像取证器。\n* [Magnet ACQUIRE](https://www.magnetforensics.com/magnet-acquire/) - Magnet Forensics 开发的 ACQUIRE 可以在不同类型的磁盘上执行取证,包括 Windows\\Linux\\OS X 与移动操作系统。\n\n### 证据收集\n\n* [bulk_extractor](https://github.com/simsong/bulk_extractor) - bulk_extractor 是一个计算机取证工具，可以扫描磁盘镜像、文件、文件目录，并在不解析文件系统或文件系统结构的情况下提取有用的信息，由于其忽略了文件系统结构，程序在速度和深入程度上都相比其它工具有了很大的提高。\n* [Cold Disk Quick Response](https://github.com/rough007/CDQR) - 使用精简的解析器列表来快速分析取证镜像文件(dd, E01, .vmdk, etc)并输出报告。\n* [ir-rescue](https://github.com/diogo-fernan/ir-rescue) - *ir-rescue* 是一个 Windows 批处理脚本与一个 Unix Bash 脚本,用于在事件响应期在主机全面收集证据。\n* [Live Response Collection](https://www.brimorlabs.com/tools/) - BriMor 开发的 Live Response collection 是一个用于从 Windows、OSX、*nix 等操作系统中收集易失性数据的自动化工具。\n* [Margarita Shotgun](https://github.com/ThreatResponse/margaritashotgun) - 用于并行远程内存获取的命令行程序\n\n### 事件管理\n\n* [CyberCPR](https://www.cybercpr.com) - 处理敏感事件时为支持 GDPR 而构建的社区和商业事件管理工具\n* [Cyphon](https://www.cyphon.io/) - Cyphon 通过一个单一的平台来组织一系列相关联的工作消除了事件管理的开销。它对事件进行收集、处理、分类。\n* [Demisto](https://www.demisto.com/product/) - Demisto 免费的社区版提供全事件生命周期的管理，事件披露报告，团队任务分配与协作，以及众多增强自动化的系统集成（如 Active Directory, PagerDuty, Jira 等）。\n* [FIR](https://github.com/certsocietegenerale/FIR/) - Fast Incident Response (FIR) 是一个网络安全事件管理平台，在设计时考虑了敏捷性与速度。其可以轻松创建、跟踪、报告网络安全应急事件并用于 CSIRT、CERT 与 SOC 等人员。\n* [KAPE](https://www.kroll.com/en/services/cyber-risk/investigate-and-respond/kroll-artifact-parser-extractor-kape) - 审核工具，用于查找最普遍的数字证据然后进行快速地解析，效率很高。\n* [RTIR](https://www.bestpractical.com/rtir/) - Request Tracker for Incident Response (RTIR) 对于安全团队来说是首要的开源事件处理系统,其与世界各地的十多个 CERT 与 CSIRT 合作，帮助处理不断增加的事件报告，RTIR 包含 Request Tracker 的全部功能。\n* [Sandia Cyber Omni Tracker (SCOT)](http://getscot.sandia.gov/) - Sandia Cyber Omni Tracker (SCOT) 是一个应急响应协作与知识获取工具，为事件响应的过程在不给用户带来负担的情况下增加价值。\n* [threat_note](https://github.com/defpoint/threat_note) - 一个轻量级的调查笔记，允许安全研究人员注册、检索他们需要的 IOC 数据。\n\n### Linux 发行版\n\n* [ADIA](https://forensics.cert.org/#ADIA) - Appliance for Digital Investigation and Analysis (ADIA) 是一个基于 VMware 的应用程序，用于进行数字取证。其完全由公开软件构建，包含的工具有 Autopsy\\Sleuth Kit\\Digital Forensics Framework\\log2timeline\\Xplico\\Wireshark。大多数系统维护使用 Webmin。它为中小规模的数字取证设计，可在 Linux、Windows 及 Mac OS 下使用。\n* [CAINE](http://www.caine-live.net/index.html) - Computer Aided Investigative Environment (CAINE) 包含许多帮助调查人员进行分析的工具，包括取证工具。\n* [CCF-VM](https://github.com/rough007/CCF-VM) - CyLR CDQR Forensics Virtual Machine (CCF-VM): 一款多合一的解决方案，能够解析收集的数据，将它转化得易于使用內建的常见搜索，也可并行搜索一个或多个主机。\n* [DEFT](http://www.deftlinux.net/) - Digital Evidence & Forensics Toolkit (DEFT) 是一个用于计算机取证的 Linux 发行版，它与 Windows 上的 Digital Advanced Response Toolkit (DART) 捆绑在一起。DEFT 的轻量版被成为 DEFT Zero，主要关注可用于法庭质证的取证环节。\n* [NST - Network Security Toolkit](https://sourceforge.net/projects/nst/files/latest/download?source=files) - 包括大量的优秀开源网络安全应用程序的 Linux 发行版\n* [PALADIN](https://sumuri.com/software/paladin/) - PALADIN 是一个附带许多开源取证工具的改 Linux 发行版，用于以可被法庭质证的方式执行取证任务\n* [Security Onion](https://github.com/Security-Onion-Solutions/security-onion) - Security Onion 是一个特殊的 Linux 发行版，旨在利用高级的分析工具进行网络安全监控\n* [SIFT Workstation](http://digital-forensics.sans.org/community/downloads) - SANS Investigative Forensic Toolkit (SIFT) 使用前沿的优秀开源工具以实现高级事件响应与入侵深度数字取证，这些功能免费提供并且经常更新。\n\n### Linux 证据收集\n\n* [FastIR Collector Linux](https://github.com/SekoiaLab/Fastir_Collector_Linux) - FastIR 在 Linux 系统上收集不同的信息并将结果存入 CSV 文件\n\n### 日志分析工具\n\n* [Kaspersky CyberTrace](https://support.kaspersky.com/13850) - 将威胁数据与 SIEM 集成的分析工具，用户可以在现有安全运营和工作流中利用威胁情报进行安全监控与事件响应。\n* [Lorg](https://github.com/jensvoid/lorg) - 一个用 HTTPD 日志进行高级安全分析与取证的工具\n* [Logdissect](https://github.com/dogoncouch/logdissect) - 用于分析日志文件和其他数据的 CLI 实用程序和 Python API\n* [StreamAlert](https://github.com/airbnb/streamalert) - Serverless, real-time log data analysis framework, capable of ingesting custom data sources and triggering alerts using user-defined logic.\n* [SysmonSearch](https://github.com/JPCERTCC/SysmonSearch) - SysmonSearch 通过聚合事件日志使分析 Windows 事件日志的效率更高。\n\n### 内存分析工具\n\n* [Evolve](https://github.com/JamesHabben/evolve) - Volatility 内存取证框架的 Web 界面\n* [inVtero.net](https://github.com/ShaneK2/inVtero.net) - 支持 hypervisor 的 Windows x64 高级内存分析\n* [KnTList](http://www.gmgsystemsinc.com/knttools/) - 计算机内存分析工具\n* [LiME](https://github.com/504ensicsLabs/LiME) - LiME 是 Loadable Kernel Module (LKM)，可以从 Linux 以及基于 Linux 的设备采集易失性内存数据。\n* [MalConfScan](https://github.com/JPCERTCC/MalConfScan) - MalConfScan 是使用 Volatility 提取已知恶意软件配置信息的插件，Volatility 是用于事件响应与恶意软件分析的开源内存取证框架。该插件在内存中搜索恶意软件并提取配置信息，此外该工具具有列出恶意代码使用的字符串的功能。\n* [Memoryze](https://www.fireeye.com/services/freeware/memoryze.html) - 由 Mandiant 开发的 Memoryze 是一个免费的内存取证软件，可以帮助应急响应人员在内存中定位恶意部位, Memoryze 也可以分析内存镜像或者在正在运行的系统上把页面文件加入它的分析。\n* [Memoryze for Mac](https://www.fireeye.com/services/freeware/memoryze-for-the-mac.html) - Memoryze for Mac 是 Memoryze 但仅限于 Mac,且功能较少。\n* [Rekall](http://www.rekall-forensic.com/) - 用于从 RAM 中提取样本的开源工具\n* [Responder PRO](http://www.countertack.com/responder-pro) - Responder PRO 是一个工业级的物理内存及自动化恶意软件分析解决方案\n* [Volatility](https://github.com/volatilityfoundation/volatility) - 高级内存取证框架\n* [VolatilityBot](https://github.com/mkorman90/VolatilityBot) - VolatilityBot 是一个自动化工具，帮助研究员减少在二进制程序提取解析阶段的手动任务，或者帮助研究人员进行内存分析调查的第一步\n* [VolDiff](https://github.com/aim4r/VolDiff) - 基于 Volatility 的 恶意软件足迹分析\n* [WindowsSCOPE](http://www.windowsscope.com/index.php?page=shop.product_details&flypage=flypage.tpl&product_id=35&category_id=3&option=com_virtuemart) - 一个用来分析易失性内存的取证与逆向工程工具，被用于对恶意软件进行逆向分析，提供了分析 Windows 内核\\驱动程序\\DLL\\虚拟与物理内存的功能。\n\n### 内存镜像工具\n\n* [Belkasoft Live RAM Capturer](http://belkasoft.com/ram-capturer) - 轻量级取证工具,即使有反调试\\反转储的系统保护下也可以方便地提取全部易失性内存的内容。\n* [Linux Memory Grabber](https://github.com/halpomeranz/lmg/) - 用于 dump Linux 内存并创建 Volatility 配置文件的脚本。\n* [Magnet RAM Capture](https://www.magnetforensics.com/free-tool-magnet-ram-capture/) - Magnet RAM Capture 是一个免费的镜像工具，可以捕获可疑计算机中的物理内存，支持最新版的 Windows。\n* [OSForensics](http://www.osforensics.com/) - OSForensics 可以获取 32/64 位系统的实时内存，可以将每个独立进程的内存空间 dump 下来。\n\n### OSX 证据收集\n\n* [Knockknock](https://github.com/synack/knockknock) - 显示那些在 OSX 上被设置为自动执行的那些脚本、命令、程序等。\n* [mac_apt - macOS Artifact Parsing Tool](https://github.com/ydkhatri/mac_apt) - 基于插件的取证框架，可以对正在运行的系统、硬盘镜像或者单个文件。\n* [OSX Auditor](https://github.com/jipegit/OSXAuditor) - OSX Auditor 是一个面向 Mac OS X 的免费计算机取证工具。\n* [OSX Collector](https://github.com/yelp/osxcollector) - OSX Auditor 的实时响应版。\n\n### 其它清单\n\n* [Eric Zimmerman Tools](https://ericzimmerman.github.io/) - 由 SANS 的讲师 Eric Zimmerman 创建的取证工具列表\n* [List of various Security APIs](https://github.com/deralexxx/security-apis) - 一个包括了在安全领域使用的公开 JSON API 的汇总清单\n\n### 其他工具\n\n* [Cortex](https://thehive-project.org) - Cortex 可以通过 Web 界面逐个或批量对 IP 地址\\邮件地址\\URL\\域名\\文件哈希的分析,还可以使用 REST API 来自动执行这些操作\n* [Crits](https://crits.github.io/) - 一个将分析引擎与网络威胁数据库相结合且带有 Web 界面的工具\n* [Diffy](https://github.com/Netflix-Skunkworks/diffy) - Netflix de  SIRT 开发的 DFIR 工具，允许调查人员快速地跨越云主机（AWS 的 Linux 实例）并通过审查基线的的差异来有效地审查这些实例以便进行后续操作\n* [domfind](https://github.com/diogo-fernan/domfind) - *domfind* 一个用 Python 编写的 DNS 爬虫，它可以找到在不同顶级域名下面的相同域名.\n* [Fenrir](https://github.com/Neo23x0/Fenrir) - Fenrir 是一个简单的 IOC 扫描器,可以在纯 bash 中扫描任意 Linux/Unix/OSX  系统,由 THOR 与 LOKI 的开发者创作\n* [Fileintel](https://github.com/keithjjones/fileintel) - 为每个文件哈希值提供情报\n* [HELK](https://github.com/Cyb3rWard0g/HELK) - 威胁捕捉\n* [Hindsight](https://github.com/obsidianforensics/hindsight) - 针对 Google Chrome/Chromium 中浏览历史的数字取证\n* [Hostintel](https://github.com/keithjjones/hostintel) - 为每个主机提供情报\n* [imagemounter](https://github.com/ralphje/imagemounter) - 命令行工具及 Python 包，可以简单地 mount/unmount 数字取证的硬盘镜像\n* [Kansa](https://github.com/davehull/Kansa/) - Kansa 是一个 PowerShell 的模块化应急响应框架\n* [PyaraScanner](https://github.com/nogoodconfig/pyarascanner) - PyaraScanner 是一个非常简单的多线程、多规则、多文件的 YARA 扫描脚本\n* [rastrea2r](https://github.com/aboutsecurity/rastrea2r) - 使用 YARA 在 Windows、Linux 与 OS X 上扫描硬盘或内存\n* [RaQet](https://raqet.github.io/) - RaQet 是一个非常规的远程采集与分类工具，允许对那些为取证构建的操作系统进行远端计算机的遴选\n* [Stalk](https://www.percona.com/doc/percona-toolkit/2.2/pt-stalk.html) - 收集关于 MySQL 的取证数据\n* [Scout2](https://nccgroup.github.io/Scout2/) - 帮助 Amazon Web 服务管理员评估其安全态势的工具\n* [SearchGiant](https://github.com/jadacyrus/searchgiant_cli) - 从云服务中获取取证数据的命令行程序\n* [Stenographer](https://github.com/google/stenographer) - Stenographer 是一个数据包捕获解决方案，旨在快速将全部数据包转储到磁盘中，然后提供对这些数据包的快速访问。它存储尽可能多的历史记录并且管理磁盘的使用情况，在大小达到设定的上限时删除记录，非常适合在事件发生前与发生中捕获流量，而不是显式存储所有流量。\n* [sqhunter](https://github.com/0x4d31/sqhunter) - 一个基于 osquery 和 Salt Open (SaltStack) 的威胁捕捉工具，它无需 osquery 的 tls 插件就能发出临时的或者分布式的查询。 sqhunter 也可以查询开放的 sockets，并将它们与威胁情报进行比对。\n* [traceroute-circl](https://github.com/CIRCL/traceroute-circl) - 由 Computer Emergency Responce Center Luxembourg 开发的 traceroute-circl 是一个增强型的 traceroute 来帮助 CSIRT\\CERT 的工作人员，通常 CSIRT 团队必须根据收到的 IP 地址处理事件\n* [X-Ray 2.0](https://www.raymond.cc/blog/xray/) - 一个用来向反病毒厂商提供样本的 Windows 实用工具(几乎不再维护)\n\n\n### Playbooks\n\n* [Demisto Playbooks Collection](https://www.demisto.com/category/playbooks/) - Playbook 集锦\n* [IRM](https://github.com/certsocietegenerale/IRM) - CERT Societe Generale 开发的事件响应方法论\n* [IR Workflow Gallery](https://www.incidentresponse.com/playbooks/) - 不同的通用事件响应工作流程,例如恶意软件爆发、数据窃取、未经授权的访问等，每个工作流程都有七个步骤:准备、检测、分析、遏制、根除、恢复、事后处理。\n* [PagerDuty Incident Response Documentation](https://response.pagerduty.com/) - 描述 PagerDuty 应急响应过程的文档，不仅提供了关于事件准备的信息，还提供了在此前与之后要做什么工作，源在 [GitHub](https://github.com/PagerDuty/incident-response-docs) 上。\n\n### 进程 Dump 工具\n\n* [Microsoft User Mode Process Dumper](http://www.microsoft.com/en-us/download/details.aspx?id=4060) - 用户模式下的进程 dump 工具，可以 dump 任意正在运行的 Win32 进程内存映像\n* [PMDump](http://www.ntsecurity.nu/toolbox/pmdump/) - PMDump 是一个可以在不停止进程的情况下将进程的内存内容 dump 到文件中的工具\n\n### 沙盒／逆向工具\n\n* [AMAaaS](https://amaaas.com/index.php/AMAaaS/dashboard) - 安卓恶意软件分析服务，在原生安卓环境中执行\n* [Any Run](https://app.any.run/) - 交互式恶意软件分析服务，对大多数类型的威胁进行静态与动态分析\n* [CAPE](https://github.com/ctxis/CAPE) - 恶意软件配置与 Payload 提取\n* [Cuckoo](https://github.com/cuckoobox) - 开源沙盒工具，高度可定制化\n* [Cuckoo-modified](https://github.com/spender-sandbox/cuckoo-modified) - 社区基于 Cuckoo 的大修版\n* [Cuckoo-modified-api](https://github.com/keithjjones/cuckoo-modified-api) - 一个用来控制 Cuckoo 沙盒设置的 Python 库\n* [Hybrid-Analysis](https://www.hybrid-analysis.com/) - Hybrid-Analysis 是一个由 Payload Security 提供的免费在线沙盒\n* [Intezer](https://analyze.intezer.com/#/) - 深入分析 Windows 二进制文件，检测与已知威胁的 micro-code 相似性，以便提供准确且易于理解的结果\n* [Joe Sandbox (Community)](https://www.joesandbox.com/) - Joe Sandbox 沙盒分析检测 Windows、Android、Mac OS、Linux 和 iOS 中的恶意软件与 URL，查找可疑文件并提供全面、详细的分析报告\n* [Mastiff](https://github.com/KoreLogicSecurity/mastiff) - MASTIFF 是一个静态分析框架，可以自动化的从多种文件格式中提取关键特征。\n* [Metadefender Cloud](https://www.metadefender.com) - Metadefender 是一个免费的威胁情报平台，提供多点扫描、数据清理以及对文件的脆弱性分析\n* [Reverse.IT](https://www.reverse.it/) - 由 CrowdStrike 提供支持的分析工具\n* [Valkyrie Comodo](https://valkyrie.comodo.com) - Valkyrie 使用运行时行为与文件的数百个特征进行分析\n* [Viper](https://github.com/viper-framework/viper) - Viper 是一个基于 Python 的二进制程序分析及管理框架，支持 Cuckoo 与 YARA\n* [Virustotal](https://www.virustotal.com) - Virustotal, Google 的子公司，一个免费在线分析文件/URL的厂商，可以分析病毒\\蠕虫\\木马以及其他类型被反病毒引擎或网站扫描器识别的恶意内容\n* [Visualize_Logs](https://github.com/keithjjones/visualize_logs) - Cuckoo、Procmon等日志的开源可视化库\n\n\n### 时间线工具\n\n* [Highlighter](https://www.fireeye.com/services/freeware/highlighter.html) - Fire/Mandiant 开发的免费工具，来分析日志/文本文件，可以对某些关键字或短语进行高亮显示，有助于时间线的整理\n* [Morgue](https://github.com/etsy/morgue) - 一个 Etsy 开发的 PHP Web 应用，可用于管理事后处理\n* [Plaso](https://github.com/log2timeline/plaso) -  一个基于 Python 用于 log2timeline 的后端引擎\n* [Timesketch](https://github.com/google/timesketch) - 用于协作取证时间线分析的开源工具\n\n\n### 视频\n\n* [Demisto IR video resources](https://www.demisto.com/category/videos/) - 应急响应与取证分析的视频资源\n* [The Future of Incident Response](https://www.youtube.com/watch?v=bDcx4UNpKNc) - Bruce Schneier 在 OWASP AppSecUSA 2015 上的分享\n\n### Windows 证据收集\n\n* [AChoir](https://github.com/OMENScan/AChoir) - Achoir 是一个将对 Windows 的实时采集工具脚本化变得更标准与简单的框架\n* [Binaryforay](http://binaryforay.blogspot.co.il/p/software.html) - 一个 Windows 取证的免费工具列表 (http://binaryforay.blogspot.co.il/)\n* [Crowd Response](http://www.crowdstrike.com/community-tools/) - 由 CrowdStrike 开发的 Crowd Response 是一个轻量级 Windows 终端应用,旨在收集用于应急响应与安全操作的系统信息，其包含许多模块与输出格式。\n* [DFIR ORC](https://dfir-orc.github.io/) - DFIR ORC 是专门用于证据收集的关键组件，提供了 Windows 计算机的取证快照，代码在 [GitHub](https://github.com/DFIR-ORC/dfir-orc) 上找到\n* [FastIR Collector](https://github.com/SekoiaLab/Fastir_Collector) - FastIR Collector 在 Windows 系统中实时收集各种信息并将结果记录在 CSV 文件中，通过对这些信息的分析，我们可以发现早期的入侵痕迹\n* [FECT](https://github.com/jipegit/FECT) - Fast Evidence Collector Toolkit (FECT) 是一个轻量级的应急响应工具集，用于在可疑的 Windows 计算机上取证，它可以让非技术调查人员更专业的进行应急处理。\n* [Fibratus](https://github.com/rabbitstack/fibratus) - 探索与跟踪 Windows 内核的工具。\n* [IREC](https://binalyze.com/products/irec-free/) - 免费、高效、易用的集成 IR 证据收集工具，可收集内存映像、$MFT、事件日志、WMI 脚本、注册表，系统还原点等\n* [IOC Finder](https://www.fireeye.com/services/freeware/ioc-finder.html) - IOC Finder 是由 Mandiant 开发的免费工具，用来收集主机数据并报告存在危险的 IOC，仅支持 Windows。\n* [Fidelis ThreatScanner](https://www.fidelissecurity.com/resources/fidelis-threatscanner) - Fidelis ThreatScanner 是一个由 Fidelis Cybersecurity 开发的免费工具，使用 OpenIOC 和 YARA 来报告终端设备的安全状态，ThreatScanner 衡量系统的运行状态后会出具匹配情况的报告，仅限 Windows。\n* [LOKI](https://github.com/Neo23x0/Loki) - Loki 是一个使用 YARA 与其他 IOC 对终端进行扫描的免费 IR 扫描器\n* [Panorama](https://github.com/AlmCo/Panorama) - Windows 系统运行时的快速事件概览\n* [PowerForensics](https://github.com/Invoke-IR/PowerForensics) - PowerShell 开发的实时硬盘取证框架\n* [PSRecon](https://github.com/gfoss/PSRecon/) - PSRecon 使用 PowerShell 在远程 Windows 主机上提取/整理数据，并将数据发送到安全团队，数据可以通过邮件来传送数据或者在本地留存\n* [RegRipper](https://code.google.com/p/regripper/wiki/RegRipper) - Regripper 是用 Perl 编写的开源工具，可以从注册表中提取/解析数据(键\\值\\数据)提供分析\n* [TRIAGE-IR](https://code.google.com/p/triage-ir/) - Triage-IR 是一个 Windows 下的 IR 收集工具",
    "timestamp": "2025-05-23T16:34:35.361957",
    "tags": [],
    "severity": "high",
    "services_affected": [
      "api",
      "web",
      "database",
      "monitoring"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "aws",
      "azure",
      "postgresql",
      "elasticsearch",
      "grafana"
    ],
    "failure_pattern": "configuration_drift",
    "timeline_events": [],
    "blast_radius": "localized",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 0.96
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/wortell/AZSentinel/blob/898246abaf1b7932ae6b5f0aec0afcdbf97d85b3/docs/Get-AzSentinelIncident.md",
    "title": "Get-AzSentinelIncident.md",
    "content": "---\r\nexternal help file: AzSentinel-help.xml\r\nModule Name: AzSentinel\r\nonline version:\r\nschema: 2.0.0\r\n---\r\n\r\n# Get-AzSentinelIncident\r\n\r\n## SYNOPSIS\r\nGet Azure Sentinel Incident\r\n\r\n## SYNTAX\r\n\r\n```\r\nGet-AzSentinelIncident [-SubscriptionId <String>] -WorkspaceName <String> [-IncidentName <String[]>]\r\n [-CaseNumber <Int32[]>] [-All] [-WhatIf] [-Confirm] [<CommonParameters>]\r\n```\r\n\r\n## DESCRIPTION\r\nWith this function you can get a list of open incidents from Azure Sentinel.\r\nYou can can also filter to Incident with speciefiek case namber or Case name\r\n\r\n## EXAMPLES\r\n\r\n### EXAMPLE 1\r\n```\r\nGet-AzSentinelIncident -WorkspaceName \"\"\r\nGet a list of the last 200 Incidents\r\n```\r\n\r\n### EXAMPLE 2\r\n```\r\nGet-AzSentinelIncident -WorkspaceName \"\" -All\r\nGet a list of all Incidents\r\n```\r\n\r\n### EXAMPLE 3\r\n```\r\nGet-AzSentinelIncident -WorkspaceName \"\" -CaseNumber\r\nGet information of a specifiek incident with providing the casenumber\r\n```\r\n\r\n### EXAMPLE 4\r\n```\r\nGet-AzSentinelIncident -WorkspaceName \"\" -IncidentName \"\", \"\"\r\nGet information of one or more incidents with providing a incident name, this is the name of the alert rule that triggered the incident\r\n```\r\n\r\n## PARAMETERS\r\n\r\n### -SubscriptionId\r\nEnter the subscription ID, if no subscription ID is provided then current AZContext subscription will be used\r\n\r\n```yaml\r\nType: String\r\nParameter Sets: (All)\r\nAliases:\r\n\r\nRequired: False\r\nPosition: Named\r\nDefault value: None\r\nAccept pipeline input: False\r\nAccept wildcard characters: False\r\n```\r\n\r\n### -WorkspaceName\r\nEnter the Workspace name\r\n\r\n```yaml\r\nType: String\r\nParameter Sets: (All)\r\nAliases:\r\n\r\nRequired: True\r\nPosition: Named\r\nDefault value: None\r\nAccept pipeline input: False\r\nAccept wildcard characters: False\r\n```\r\n\r\n### -IncidentName\r\nEnter incident name, this is the same name as the alert rule that triggered the incident\r\n\r\n```yaml\r\nType: String[]\r\nParameter Sets: (All)\r\nAliases:\r\n\r\nRequired: False\r\nPosition: Named\r\nDefault value: None\r\nAccept pipeline input: True (ByValue)\r\nAccept wildcard characters: False\r\n```\r\n\r\n### -CaseNumber\r\nEnter the case number to get specfiek details of a open case\r\n\r\n```yaml\r\nType: Int32[]\r\nParameter Sets: (All)\r\nAliases:\r\n\r\nRequired: False\r\nPosition: Named\r\nDefault value: None\r\nAccept pipeline input: True (ByValue)\r\nAccept wildcard characters: False\r\n```\r\n\r\n### -All\r\nUse -All switch to get a list of all the incidents\r\n\r\n```yaml\r\nType: SwitchParameter\r\nParameter Sets: (All)\r\nAliases:\r\n\r\nRequired: False\r\nPosition: Named\r\nDefault value: False\r\nAccept pipeline input: True (ByValue)\r\nAccept wildcard characters: False\r\n```\r\n\r\n### -WhatIf\r\nShows what would happen if the cmdlet runs.\r\nThe cmdlet is not run.\r\n\r\n```yaml\r\nType: SwitchParameter\r\nParameter Sets: (All)\r\nAliases: wi\r\n\r\nRequired: False\r\nPosition: Named\r\nDefault value: None\r\nAccept pipeline input: False\r\nAccept wildcard characters: False\r\n```\r\n\r\n### -Confirm\r\nPrompts you for confirmation before running the cmdlet.\r\n\r\n```yaml\r\nType: SwitchParameter\r\nParameter Sets: (All)\r\nAliases: cf\r\n\r\nRequired: False\r\nPosition: Named\r\nDefault value: None\r\nAccept pipeline input: False\r\nAccept wildcard characters: False\r\n```\r\n\r\n### CommonParameters\r\nThis cmdlet supports the common parameters: -Debug, -ErrorAction, -ErrorVariable, -InformationAction, -InformationVariable, -OutVariable, -OutBuffer, -PipelineVariable, -Verbose, -WarningAction, and -WarningVariable. For more information, see [about_CommonParameters](http://go.microsoft.com/fwlink/?LinkID=113216).\r\n\r\n## INPUTS\r\n\r\n## OUTPUTS\r\n\r\n## NOTES\r\n\r\n## RELATED LINKS\r\n",
    "timestamp": "2025-05-23T16:34:35.782637",
    "tags": [],
    "severity": "medium",
    "services_affected": [
      "web"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "azure",
      "jenkins"
    ],
    "failure_pattern": null,
    "timeline_events": [],
    "blast_radius": "localized",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 0.42000000000000004
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/demisto/demisto-py/blob/15f61de8d2cbb1d8946a9b73f887165debf4f9c3/docs/IncidentField.md",
    "title": "IncidentField.md",
    "content": "# IncidentField\n\n## Properties\nName | Type | Description | Notes\n------------ | ------------- | ------------- | -------------\n**associated_to_all** | **bool** |  | [optional] \n**associated_types** | **list[str]** | AssociatedTypes - list of incident (case) types IDs related to specific incident field | [optional] \n**breach_script** | **str** |  | [optional] \n**case_insensitive** | **bool** |  | [optional] \n**cli_name** | **str** |  | [optional] \n**close_form** | **bool** |  | [optional] \n**columns** | [**list[GridColumn]**](GridColumn.md) |  | [optional] \n**commit_message** | **str** |  | [optional] \n**content** | **bool** |  | [optional] \n**default_rows** | **list[dict(str, object)]** |  | [optional] \n**description** | **str** |  | [optional] \n**edit_form** | **bool** |  | [optional] \n**field_calc_script** | **str** |  | [optional] \n**group** | [**FieldGroup**](FieldGroup.md) |  | [optional] \n**hidden** | **bool** |  | [optional] \n**id** | **str** |  | [optional] \n**is_read_only** | **bool** |  | [optional] \n**locked** | **bool** |  | [optional] \n**modified** | **datetime** |  | [optional] \n**name** | **str** |  | [optional] \n**never_set_as_required** | **bool** |  | [optional] \n**owner_only** | **bool** |  | [optional] \n**placeholder** | **str** |  | [optional] \n**prev_name** | **str** |  | [optional] \n**required** | **bool** |  | [optional] \n**script** | **str** |  | [optional] \n**select_values** | **list[str]** |  | [optional] \n**should_commit** | **bool** |  | [optional] \n**sla** | **int** |  | [optional] \n**sort_values** | **list[str]** |  | [optional] \n**system** | **bool** |  | [optional] \n**system_associated_types** | **list[str]** |  | [optional] \n**threshold** | **float** |  | [optional] \n**type** | **str** |  | [optional] \n**unmapped** | **bool** |  | [optional] \n**unsearchable** | **bool** |  | [optional] \n**use_as_kpi** | **bool** |  | [optional] \n**validated_error** | **str** |  | [optional] \n**validation_regex** | **str** |  | [optional] \n**vc_should_ignore** | **bool** |  | [optional] \n**version** | **int** |  | [optional] \n\n[[Back to Model list]](README.md#documentation-for-models) [[Back to API list]](README.md#documentation-for-api-endpoints) [[Back to README]](README.md)\n\n\n",
    "timestamp": "2025-05-23T16:34:36.190573",
    "tags": [],
    "severity": "low",
    "services_affected": [
      "api",
      "web"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "elasticsearch"
    ],
    "failure_pattern": null,
    "timeline_events": [],
    "blast_radius": "localized",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 0.37
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/martindstone/pagerduty-cli/blob/bdcd19714ebff43aa1d09e75cc1a23f16a581682/docs/incident.md",
    "title": "incident.md",
    "content": "`pd incident`\n=============\n\nSee/manage incidents\n\n* [`pd incident ack`](#pd-incident-ack)\n* [`pd incident ack`](#pd-incident-ack-1)\n* [`pd incident alerts`](#pd-incident-alerts)\n* [`pd incident analytics`](#pd-incident-analytics)\n* [`pd incident assign`](#pd-incident-assign)\n* [`pd incident create`](#pd-incident-create)\n* [`pd incident field get`](#pd-incident-field-get)\n* [`pd incident field set`](#pd-incident-field-set)\n* [`pd incident list`](#pd-incident-list)\n* [`pd incident log`](#pd-incident-log)\n* [`pd incident merge`](#pd-incident-merge)\n* [`pd incident notes`](#pd-incident-notes)\n* [`pd incident open`](#pd-incident-open)\n* [`pd incident priority`](#pd-incident-priority)\n* [`pd incident assign`](#pd-incident-assign-1)\n* [`pd incident rename`](#pd-incident-rename)\n* [`pd incident resolve`](#pd-incident-resolve)\n* [`pd incident responder add`](#pd-incident-responder-add)\n* [`pd incident responder list`](#pd-incident-responder-list)\n* [`pd incident set`](#pd-incident-set)\n* [`pd incident subscriber add`](#pd-incident-subscriber-add)\n* [`pd incident subscriber list`](#pd-incident-subscriber-list)\n* [`pd incident subscriber remove`](#pd-incident-subscriber-remove)\n* [`pd incident subscriber update`](#pd-incident-subscriber-update)\n* [`pd incident set`](#pd-incident-set-1)\n\n## `pd incident ack`\n\nAcknowledge PagerDuty Incidents\n\n```\nUSAGE\n  $ pd incident ack\n\nFLAGS\n  -F, --from=<value>     Login email of a PD user account for the \"From:\" header. Use only with legacy API tokens.\n  -b, --useauth=<value>  Use the saved REST API token with this alias\n  -h, --help             Show CLI help.\n  -i, --ids=<value>...   Incident ID's to acknowledge. Specify multiple times for multiple incidents.\n  -m, --me               Acknowledge all incidents assigned to me\n  -p, --pipe             Read incident ID's from stdin.\n  -z, --snooze=<value>   Also snooze selected incidents for the specified amount of time (5m, '1 hour', default unit is\n                         seconds).\n  --debug                Print REST API call debug logs\n  --token=<value>        Ignore the saved configuration and use this token\n\nDESCRIPTION\n  Acknowledge PagerDuty Incidents\n\nALIASES\n  $ pd incident acknowledge\n```\n\n## `pd incident ack`\n\nAcknowledge PagerDuty Incidents\n\n```\nUSAGE\n  $ pd incident ack\n\nFLAGS\n  -F, --from=<value>     Login email of a PD user account for the \"From:\" header. Use only with legacy API tokens.\n  -b, --useauth=<value>  Use the saved REST API token with this alias\n  -h, --help             Show CLI help.\n  -i, --ids=<value>...   Incident ID's to acknowledge. Specify multiple times for multiple incidents.\n  -m, --me               Acknowledge all incidents assigned to me\n  -p, --pipe             Read incident ID's from stdin.\n  -z, --snooze=<value>   Also snooze selected incidents for the specified amount of time (5m, '1 hour', default unit is\n                         seconds).\n  --debug                Print REST API call debug logs\n  --token=<value>        Ignore the saved configuration and use this token\n\nDESCRIPTION\n  Acknowledge PagerDuty Incidents\n\nALIASES\n  $ pd incident acknowledge\n```\n\n## `pd incident alerts`\n\nShow Alerts in PagerDuty Incidents\n\n```\nUSAGE\n  $ pd incident alerts\n\nFLAGS\n  -b, --useauth=<value>    Use the saved REST API token with this alias\n  -d, --delimiter=<value>  [default: \\n] Delimiter for fields that have more than one value\n  -h, --help               Show CLI help.\n  -i, --ids=<value>...     Show alerts for these Incident ID's. Specify multiple times for multiple incidents.\n  -j, --json               output full details as JSON\n  -k, --keys=<value>...    Additional fields to display. Specify multiple times for multiple fields.\n  -m, --me                 Show alerts for all incidents assigned to me\n  -p, --pipe               Read incident ID's from stdin.\n  -x, --extended           show extra columns\n  --columns=<value>        only show provided columns (comma-separated)\n  --csv                    output is csv format [alias: --output=csv]\n  --debug                  Print REST API call debug logs\n  --filter=<value>         filter property by partial string matching, ex: name=foo\n  --no-header              hide table header from output\n  --no-truncate            do not truncate output to fit screen\n  --output=<option>        output in a more machine friendly format\n                           <options: csv|json|yaml>\n  --sort=<value>           property to sort by (prepend '-' for descending)\n  --token=<value>          Ignore the saved configuration and use this token\n\nDESCRIPTION\n  Show Alerts in PagerDuty Incidents\n```\n\n## `pd incident analytics`\n\nGet Incident analytics\n\n```\nUSAGE\n  $ pd incident analytics\n\nFLAGS\n  -b, --useauth=<value>    Use the saved REST API token with this alias\n  -d, --delimiter=<value>  [default: \\n] Delimiter for fields that have more than one value\n  -h, --help               Show CLI help.\n  -i, --ids=<value>...     Incident ID's to look at. Specify multiple times for multiple incidents.\n  -j, --json               output full details as JSON\n  -k, --keys=<value>...    Additional fields to display. Specify multiple times for multiple fields.\n  -p, --pipe               Read incident ID's from stdin.\n  -x, --extended           show extra columns\n  --columns=<value>        only show provided columns (comma-separated)\n  --csv                    output is csv format [alias: --output=csv]\n  --debug                  Print REST API call debug logs\n  --filter=<value>         filter property by partial string matching, ex: name=foo\n  --no-header              hide table header from output\n  --no-truncate            do not truncate output to fit screen\n  --output=<option>        output in a more machine friendly format\n                           <options: csv|json|yaml>\n  --sort=<value>           property to sort by (prepend '-' for descending)\n  --token=<value>          Ignore the saved configuration and use this token\n\nDESCRIPTION\n  Get Incident analytics\n```\n\n## `pd incident assign`\n\nAssign/Reassign PagerDuty Incidents\n\n```\nUSAGE\n  $ pd incident assign\n\nFLAGS\n  -E, --assign_to_ep_name=<value>         Escalation policy name to assign incidents to.\n  -F, --from=<value>                      Login email of a PD user account for the \"From:\" header. Use only with legacy\n                                          API tokens.\n  -U, --assign_to_user_emails=<value>...  User emails to assign incidents to. Specify multiple times for multiple\n                                          assignees.\n  -b, --useauth=<value>                   Use the saved REST API token with this alias\n  -e, --assign_to_ep_id=<value>           Escalation policy ID to assign incidents to.\n  -h, --help                              Show CLI help.\n  -i, --ids=<value>...                    Incident ID's to assign. Specify multiple times for multiple incidents.\n  -m, --me                                Reassign all incidents that are currently assigned to me\n  -p, --pipe                              Read incident ID's from stdin.\n  -u, --assign_to_user_ids=<value>...     User ID's to assign incidents to. Specify multiple times for multiple\n                                          assignees.\n  --debug                                 Print REST API call debug logs\n  --token=<value>                         Ignore the saved configuration and use this token\n\nDESCRIPTION\n  Assign/Reassign PagerDuty Incidents\n\nALIASES\n  $ pd incident reassign\n```\n\n## `pd incident create`\n\nCreate a PagerDuty Incident\n\n```\nUSAGE\n  $ pd incident create\n\nFLAGS\n  -E, --escalation_policy=<value>  The name of the escalation policy to assign the incident to\n  -F, --from=<value>               Login email of a PD user account for the \"From:\" header. Use only with legacy API\n                                   tokens.\n  -P, --priority=<value>           Incident priority\n  -S, --service=<value>            The name of the service to create the incident in\n  -U, --user=<value>...            The email of a user to assign the incident to\n  -b, --useauth=<value>            Use the saved REST API token with this alias\n  -d, --details=<value>            Incident details\n  -h, --help                       Show CLI help.\n  -k, --key=<value>                Incident key\n  -o, --open                       Open the new incident in the browser\n  -p, --pipe                       Print the incident ID only to stdout, for use with pipes.\n  -t, --title=<value>              (required) Incident title\n  -u, --urgency=<option>           Incident urgency\n                                   <options: high|low>\n  --debug                          Print REST API call debug logs\n  --escalation_policy_id=<value>   The ID of the escalation policy to assign the incident to\n  --service_id=<value>             The ID of the service to create the incident in\n  --token=<value>                  Ignore the saved configuration and use this token\n  --user_id=<value>...             The ID of a user to assign the incident to\n\nDESCRIPTION\n  Create a PagerDuty Incident\n```\n\n## `pd incident field get`\n\nGet Custom Field Values on PagerDuty Incidents\n\n```\nUSAGE\n  $ pd incident field get\n\nFLAGS\n  -b, --useauth=<value>    Use the saved REST API token with this alias\n  -d, --delimiter=<value>  [default:\n                           ] Delimiter for fields that have more than one value\n  -h, --help               Show CLI help.\n  -i, --ids=<value>...     Incident ID's to show. Specify multiple times for multiple incidents.\n  -m, --me                 Show all incidents that are currently assigned to me\n  -n, --display_name       Show the display names of fields rather than their canonical names.\n  -p, --pipe               Read incident ID's from stdin.\n  --debug                  Print REST API call debug logs\n  --token=<value>          Ignore the saved configuration and use this token\n\nDESCRIPTION\n  Get Custom Field Values on PagerDuty Incidents\n```\n\n## `pd incident field set`\n\nSet Custom Field Values on PagerDuty Incidents\n\n```\nUSAGE\n  $ pd incident field set\n\nFLAGS\n  -b, --useauth=<value>    Use the saved REST API token with this alias\n  -h, --help               Show CLI help.\n  -i, --ids=<value>...     Incident ID's to update. Specify multiple times for multiple incidents.\n  -m, --me                 Update all incidents that are currently assigned to me\n  -n, --names=<value>...   (required) Custom Field names to set. Specify multiple times to set multiple fields.\n  -p, --pipe               Read incident ID's from stdin.\n  -v, --values=<value>...  (required) Custom Field values to set. To set multiple name/values, specify multiple times in\n                           the same order as the names.\n  --debug                  Print REST API call debug logs\n  --[no-]jsonvalues        Interpret values as JSON [default: true]\n  --token=<value>          Ignore the saved configuration and use this token\n\nDESCRIPTION\n  Set Custom Field Values on PagerDuty Incidents\n```\n\n## `pd incident list`\n\nList PagerDuty Incidents\n\n```\nUSAGE\n  $ pd incident list\n\nFLAGS\n  -E, --exact_assignees=<value>...  Return incidents assigned to the PD account whose login email is exactly this text.\n                                    Specify multiple times for multiple assignees.\n  -S, --services=<value>...         Return incidents in services whose names contain this text. Specify multiple times\n                                    for multiple service filters.\n  -T, --exact_teams=<value>...      Return incidents belonging to the team whose name is exactly this text. Specify\n                                    multiple times for multiple teams.\n  -X, --exact_services=<value>...   Return incidents in the service whose name is exactly this text. Specify multiple\n                                    times for multiple services.\n  -b, --useauth=<value>             Use the saved REST API token with this alias\n  -d, --delimiter=<value>           [default: \\n] Delimiter for fields that have more than one value\n  -e, --assignees=<value>...        Return incidents assigned to PD accounts whose login emails contain this text.\n                                    Specify multiple times for multiple assignee filters.\n  -h, --help                        Show CLI help.\n  -j, --json                        output full details as JSON\n  -k, --keys=<value>...             Additional fields to display. Specify multiple times for multiple fields.\n  -m, --me                          Return incidents assigned to me\n  -n, --name=<value>                Select incidents whose names contain the given text\n  -p, --pipe                        Print incident ID's only to stdout, for use with pipes.\n  -s, --statuses=<option>...        [default: open] Return only incidents with the given statuses. Specify multiple\n                                    times for multiple statuses.\n                                    <options: open|closed|triggered|acknowledged|resolved>\n  -t, --teams=<value>...            Return incidents belonging to teams whose names contain this text. Specify multiple\n                                    times for multiple team filters.\n  -u, --urgencies=<option>...       [default: high,low] Urgencies to include.\n                                    <options: high|low>\n  -x, --extended                    show extra columns\n  --columns=<value>                 only show provided columns (comma-separated)\n  --csv                             output is csv format [alias: --output=csv]\n  --debug                           Print REST API call debug logs\n  --filter=<value>                  filter property by partial string matching, ex: name=foo\n  --limit=<value>                   Return no more than this many entries. This option turns off table filtering\n                                    options.\n  --no-header                       hide table header from output\n  --no-truncate                     do not truncate output to fit screen\n  --notes                           Also show incident notes (Uses a lot more HTTPS requests!)\n  --output=<option>                 output in a more machine friendly format\n                                    <options: csv|json|yaml>\n  --since=<value>                   The start of the date range over which you want to search.\n  --sort=<value>                    property to sort by (prepend '-' for descending)\n  --token=<value>                   Ignore the saved configuration and use this token\n  --until=<value>                   The end of the date range over which you want to search.\n\nDESCRIPTION\n  List PagerDuty Incidents\n```\n\n## `pd incident log`\n\nShow PagerDuty Incident Log Entries\n\n```\nUSAGE\n  $ pd incident log\n\nFLAGS\n  -O, --overview           Get only `overview` log entries\n  -b, --useauth=<value>    Use the saved REST API token with this alias\n  -d, --delimiter=<value>  [default: \\n] Delimiter for fields that have more than one value\n  -h, --help               Show CLI help.\n  -i, --ids=<value>...     Select incidents with the given ID. Specify multiple times for multiple incidents.\n  -j, --json               output full details as JSON\n  -k, --keys=<value>...    Additional fields to display. Specify multiple times for multiple fields.\n  -p, --pipe               Read incident IDs from stdin, for use with pipes.\n  -x, --extended           show extra columns\n  --columns=<value>        only show provided columns (comma-separated)\n  --csv                    output is csv format [alias: --output=csv]\n  --debug                  Print REST API call debug logs\n  --filter=<value>         filter property by partial string matching, ex: name=foo\n  --no-header              hide table header from output\n  --no-truncate            do not truncate output to fit screen\n  --output=<option>        output in a more machine friendly format\n                           <options: csv|json|yaml>\n  --sort=<value>           property to sort by (prepend '-' for descending)\n  --token=<value>          Ignore the saved configuration and use this token\n\nDESCRIPTION\n  Show PagerDuty Incident Log Entries\n```\n\n## `pd incident merge`\n\nMerge PagerDuty Incidents\n\n```\nUSAGE\n  $ pd incident merge\n\nFLAGS\n  -F, --from=<value>       Login email of a PD user account for the \"From:\" header. Use only with legacy API tokens.\n  -I, --parent_id=<value>  Use this incident ID as the parent ID.\n  -b, --useauth=<value>    Use the saved REST API token with this alias\n  -h, --help               Show CLI help.\n  -i, --ids=<value>...     Merge incidents with the given ID. Specify multiple times for multiple incidents. If -I is\n                           not given, the first incident in the list will be the parent incident.\n  -o, --open               Open the merged incident in the browser\n  -p, --pipe               Read incident IDs from stdin, for use with pipes. If -I is not given, the first incident ID\n                           from the pipe will be the parent incident.\n  --debug                  Print REST API call debug logs\n  --token=<value>          Ignore the saved configuration and use this token\n\nDESCRIPTION\n  Merge PagerDuty Incidents\n```\n\n## `pd incident notes`\n\nSee or add notes on PagerDuty Incidents\n\n```\nUSAGE\n  $ pd incident notes\n\nFLAGS\n  -F, --from=<value>     Login email of a PD user account for the \"From:\" header. Use only with legacy API tokens.\n  -b, --useauth=<value>  Use the saved REST API token with this alias\n  -h, --help             Show CLI help.\n  -i, --id=<value>       (required) Incident ID.\n  -n, --note=<value>     Note to add\n  -x, --extended         show extra columns\n  --columns=<value>      only show provided columns (comma-separated)\n  --csv                  output is csv format [alias: --output=csv]\n  --debug                Print REST API call debug logs\n  --filter=<value>       filter property by partial string matching, ex: name=foo\n  --no-header            hide table header from output\n  --no-truncate          do not truncate output to fit screen\n  --output=<option>      output in a more machine friendly format\n                         <options: csv|json|yaml>\n  --sort=<value>         property to sort by (prepend '-' for descending)\n  --token=<value>        Ignore the saved configuration and use this token\n\nDESCRIPTION\n  See or add notes on PagerDuty Incidents\n```\n\n## `pd incident open`\n\nOpen PagerDuty Incidents in your browser\n\n```\nUSAGE\n  $ pd incident open\n\nFLAGS\n  -b, --useauth=<value>  Use the saved REST API token with this alias\n  -h, --help             Show CLI help.\n  -i, --ids=<value>...   Incident ID's to open. Specify multiple times for multiple incidents.\n  -m, --me               Open all incidents assigned to me\n  -p, --pipe             Read incident ID's from stdin.\n  --debug                Print REST API call debug logs\n  --token=<value>        Ignore the saved configuration and use this token\n\nDESCRIPTION\n  Open PagerDuty Incidents in your browser\n```\n\n## `pd incident priority`\n\nSet priority on PagerDuty Incidents\n\n```\nUSAGE\n  $ pd incident priority\n\nFLAGS\n  -F, --from=<value>      Login email of a PD user account for the \"From:\" header. Use only with legacy API tokens.\n  -b, --useauth=<value>   Use the saved REST API token with this alias\n  -h, --help              Show CLI help.\n  -i, --ids=<value>...    Incident ID's to set priority on. Specify multiple times for multiple incidents.\n  -m, --me                Set priority on all incidents assigned to me\n  -n, --priority=<value>  (required) The name of the priority to set.\n  -p, --pipe              Read incident ID's from stdin.\n  --debug                 Print REST API call debug logs\n  --token=<value>         Ignore the saved configuration and use this token\n\nDESCRIPTION\n  Set priority on PagerDuty Incidents\n```\n\n## `pd incident assign`\n\nAssign/Reassign PagerDuty Incidents\n\n```\nUSAGE\n  $ pd incident assign\n\nFLAGS\n  -E, --assign_to_ep_name=<value>         Escalation policy name to assign incidents to.\n  -F, --from=<value>                      Login email of a PD user account for the \"From:\" header. Use only with legacy\n                                          API tokens.\n  -U, --assign_to_user_emails=<value>...  User emails to assign incidents to. Specify multiple times for multiple\n                                          assignees.\n  -b, --useauth=<value>                   Use the saved REST API token with this alias\n  -e, --assign_to_ep_id=<value>           Escalation policy ID to assign incidents to.\n  -h, --help                              Show CLI help.\n  -i, --ids=<value>...                    Incident ID's to assign. Specify multiple times for multiple incidents.\n  -m, --me                                Reassign all incidents that are currently assigned to me\n  -p, --pipe                              Read incident ID's from stdin.\n  -u, --assign_to_user_ids=<value>...     User ID's to assign incidents to. Specify multiple times for multiple\n                                          assignees.\n  --debug                                 Print REST API call debug logs\n  --token=<value>                         Ignore the saved configuration and use this token\n\nDESCRIPTION\n  Assign/Reassign PagerDuty Incidents\n\nALIASES\n  $ pd incident reassign\n```\n\n## `pd incident rename`\n\nRename (change the title of) PagerDuty Incidents\n\n```\nUSAGE\n  $ pd incident rename\n\nFLAGS\n  -F, --from=<value>     Login email of a PD user account for the \"From:\" header. Use only with legacy API tokens.\n  -b, --useauth=<value>  Use the saved REST API token with this alias\n  -h, --help             Show CLI help.\n  -i, --ids=<value>...   Incident ID's to rename. Specify multiple times for multiple incidents.\n  -m, --me               Rename all incidents that are currently assigned to me\n  -p, --pipe             Read incident ID's from stdin.\n  -t, --title=<value>    Set the incident title to this string\n  --debug                Print REST API call debug logs\n  --prefix=<value>       Prefix the incident title with this string\n  --token=<value>        Ignore the saved configuration and use this token\n\nDESCRIPTION\n  Rename (change the title of) PagerDuty Incidents\n```\n\n## `pd incident resolve`\n\nResolve PagerDuty Incidents\n\n```\nUSAGE\n  $ pd incident resolve\n\nFLAGS\n  -F, --from=<value>     Login email of a PD user account for the \"From:\" header. Use only with legacy API tokens.\n  -b, --useauth=<value>  Use the saved REST API token with this alias\n  -h, --help             Show CLI help.\n  -i, --ids=<value>...   Incident ID's to resolve. Specify multiple times for multiple incidents.\n  -m, --me               Resolve all incidents assigned to me\n  -p, --pipe             Read incident ID's from stdin.\n  --debug                Print REST API call debug logs\n  --token=<value>        Ignore the saved configuration and use this token\n\nDESCRIPTION\n  Resolve PagerDuty Incidents\n```\n\n## `pd incident responder add`\n\nAdd Responders to PagerDuty Incidents\n\n```\nUSAGE\n  $ pd incident responder add\n\nFLAGS\n  -E, --ep_names=<value>...     Escalation policy names to add as responders. Specify multiple times for multiple EPs\n  -F, --from=<value>            Login email of a PD user account for the \"From:\" header. Use only with legacy API\n                                tokens.\n  -U, --user_emails=<value>...  User emails to add as responders. Specify multiple times for multiple users.\n  -b, --useauth=<value>         Use the saved REST API token with this alias\n  -e, --ep_ids=<value>...       Escalation policy IDs to add as responders. Specify multiple times for multiple EPs\n  -h, --help                    Show CLI help.\n  -i, --ids=<value>...          Incident ID's to add responders to. Specify multiple times for multiple incidents.\n  -m, --me                      Add responders to all incidents that are currently assigned to me\n  -p, --pipe                    Read incident ID's from stdin.\n  -s, --message=<value>         A custom message to send to the responders\n  -u, --user_ids=<value>...     User ID's to add as responders. Specify multiple times for multiple users.\n  --debug                       Print REST API call debug logs\n  --token=<value>               Ignore the saved configuration and use this token\n\nDESCRIPTION\n  Add Responders to PagerDuty Incidents\n```\n\n## `pd incident responder list`\n\nList Responders on PagerDuty Incidents\n\n```\nUSAGE\n  $ pd incident responder list\n\nFLAGS\n  -b, --useauth=<value>  Use the saved REST API token with this alias\n  -h, --help             Show CLI help.\n  -i, --ids=<value>...   Incident ID's to list responders on. Specify multiple times for multiple incidents.\n  -m, --me               List responders on all incidents that are currently assigned to me\n  -p, --pipe             Read incident ID's from stdin.\n  -x, --extended         show extra columns\n  --columns=<value>      only show provided columns (comma-separated)\n  --csv                  output is csv format [alias: --output=csv]\n  --debug                Print REST API call debug logs\n  --filter=<value>       filter property by partial string matching, ex: name=foo\n  --no-header            hide table header from output\n  --no-truncate          do not truncate output to fit screen\n  --output=<option>      output in a more machine friendly format\n                         <options: csv|json|yaml>\n  --sort=<value>         property to sort by (prepend '-' for descending)\n  --token=<value>        Ignore the saved configuration and use this token\n\nDESCRIPTION\n  List Responders on PagerDuty Incidents\n```\n\n## `pd incident set`\n\nUpdate PagerDuty Incidents\n\n```\nUSAGE\n  $ pd incident set\n\nFLAGS\n  -F, --from=<value>     Login email of a PD user account for the \"From:\" header. Use only with legacy API tokens.\n  -b, --useauth=<value>  Use the saved REST API token with this alias\n  -h, --help             Show CLI help.\n  -i, --ids=<value>...   Incident ID's to update. Specify multiple times for multiple incidents.\n  -k, --key=<value>      (required) Attribute key to set\n  -m, --me               Update all incidents that are currently assigned to me\n  -p, --pipe             Read incident ID's from stdin.\n  -v, --value=<value>    (required) Attribute value to set\n  --debug                Print REST API call debug logs\n  --token=<value>        Ignore the saved configuration and use this token\n\nDESCRIPTION\n  Update PagerDuty Incidents\n\nALIASES\n  $ pd incident update\n```\n\n## `pd incident subscriber add`\n\nAdd Subscribers to PagerDuty Incidents\n\n```\nUSAGE\n  $ pd incident subscriber add\n\nFLAGS\n  -T, --team_names=<value>...   Team names to add as subscribers. Specify multiple times for multiple teams\n  -U, --user_emails=<value>...  User emails to add as subscribers. Specify multiple times for multiple users.\n  -b, --useauth=<value>         Use the saved REST API token with this alias\n  -h, --help                    Show CLI help.\n  -i, --ids=<value>...          Incident ID's to add subscribers to. Specify multiple times for multiple incidents.\n  -m, --me                      Add subscribers to all incidents that are currently assigned to me\n  -p, --pipe                    Read incident ID's from stdin.\n  -t, --team_ids=<value>...     Team IDs to add as subscribers. Specify multiple times for multiple teams\n  -u, --user_ids=<value>...     User ID's to add as subscribers. Specify multiple times for multiple users.\n  --debug                       Print REST API call debug logs\n  --token=<value>               Ignore the saved configuration and use this token\n\nDESCRIPTION\n  Add Subscribers to PagerDuty Incidents\n```\n\n## `pd incident subscriber list`\n\nList Responders on PagerDuty Incidents\n\n```\nUSAGE\n  $ pd incident subscriber list\n\nFLAGS\n  -b, --useauth=<value>  Use the saved REST API token with this alias\n  -h, --help             Show CLI help.\n  -i, --ids=<value>...   Incident ID's to list subscribers on. Specify multiple times for multiple incidents.\n  -m, --me               List subscribers on all incidents that are currently assigned to me\n  -p, --pipe             Read incident ID's from stdin.\n  -x, --extended         show extra columns\n  --columns=<value>      only show provided columns (comma-separated)\n  --csv                  output is csv format [alias: --output=csv]\n  --debug                Print REST API call debug logs\n  --filter=<value>       filter property by partial string matching, ex: name=foo\n  --no-header            hide table header from output\n  --no-truncate          do not truncate output to fit screen\n  --output=<option>      output in a more machine friendly format\n                         <options: csv|json|yaml>\n  --sort=<value>         property to sort by (prepend '-' for descending)\n  --token=<value>        Ignore the saved configuration and use this token\n\nDESCRIPTION\n  List Responders on PagerDuty Incidents\n```\n\n## `pd incident subscriber remove`\n\nRemove Subscribers from PagerDuty Incidents\n\n```\nUSAGE\n  $ pd incident subscriber remove\n\nFLAGS\n  -T, --team_names=<value>...   Team names to remove. Specify multiple times for multiple teams\n  -U, --user_emails=<value>...  User emails to remove. Specify multiple times for multiple users.\n  -b, --useauth=<value>         Use the saved REST API token with this alias\n  -h, --help                    Show CLI help.\n  -i, --ids=<value>...          Incident ID's to remove subscribers from. Specify multiple times for multiple incidents.\n  -m, --me                      Remove subscribers from all incidents that are currently assigned to me\n  -p, --pipe                    Read incident ID's from stdin.\n  -t, --team_ids=<value>...     Team IDs to remove. Specify multiple times for multiple teams\n  -u, --user_ids=<value>...     User ID's to remove. Specify multiple times for multiple users.\n  --debug                       Print REST API call debug logs\n  --token=<value>               Ignore the saved configuration and use this token\n\nDESCRIPTION\n  Remove Subscribers from PagerDuty Incidents\n```\n\n## `pd incident subscriber update`\n\nSend a status update to PagerDuty Incident Subscribers\n\n```\nUSAGE\n  $ pd incident subscriber update\n\nFLAGS\n  -F, --from=<value>      Login email of a PD user account for the \"From:\" header. Use only with legacy API tokens.\n  -b, --useauth=<value>   Use the saved REST API token with this alias\n  -h, --help              Show CLI help.\n  -i, --ids=<value>...    Send a status update to subscribers on these Incident ID's. Specify multiple times for\n                          multiple incidents.\n  -m, --me                Send a status update to subscribers on all incidents that are currently assigned to me\n  -p, --pipe              Read incident ID's from stdin.\n  --debug                 Print REST API call debug logs\n  --html_message=<value>  The html content to be sent for the custom html email status update. Required if sending\n                          custom html email.\n  --message=<value>       (required) The message to be posted as a status update.\n  --subject=<value>       The subject to be sent for the custom html email status update. Required if sending custom\n                          html email.\n  --token=<value>         Ignore the saved configuration and use this token\n\nDESCRIPTION\n  Send a status update to PagerDuty Incident Subscribers\n```\n\n## `pd incident set`\n\nUpdate PagerDuty Incidents\n\n```\nUSAGE\n  $ pd incident set\n\nFLAGS\n  -F, --from=<value>     Login email of a PD user account for the \"From:\" header. Use only with legacy API tokens.\n  -b, --useauth=<value>  Use the saved REST API token with this alias\n  -h, --help             Show CLI help.\n  -i, --ids=<value>...   Incident ID's to update. Specify multiple times for multiple incidents.\n  -k, --key=<value>      (required) Attribute key to set\n  -m, --me               Update all incidents that are currently assigned to me\n  -p, --pipe             Read incident ID's from stdin.\n  -v, --value=<value>    (required) Attribute value to set\n  --debug                Print REST API call debug logs\n  --token=<value>        Ignore the saved configuration and use this token\n\nDESCRIPTION\n  Update PagerDuty Incidents\n\nALIASES\n  $ pd incident update\n```\n",
    "timestamp": "2025-05-23T16:34:36.588696",
    "tags": [],
    "severity": "low",
    "services_affected": [
      "api",
      "web",
      "auth",
      "monitoring"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "elasticsearch"
    ],
    "failure_pattern": "configuration_drift",
    "timeline_events": [],
    "blast_radius": "partial",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 0.67
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/opsgenie/opsgenie-python-sdk/blob/0d20d2314522fc0fd8ca5f0faa16f7c96387e123/docs/IncidentApi.md",
    "title": "IncidentApi.md",
    "content": "# opsgenie_sdk.IncidentApi\n\nAll URIs are relative to *https://api.opsgenie.com*\n\nMethod | HTTP request | Description\n------------- | ------------- | -------------\n[**close_incident**](IncidentApi.md#close_incident) | **POST** /v1/incidents/{identifier}/close | Close Incident\n[**create_incident**](IncidentApi.md#create_incident) | **POST** /v1/incidents/create | Create Incident\n[**delete_incident**](IncidentApi.md#delete_incident) | **DELETE** /v1/incidents/{identifier} | Delete Incident\n[**get_incident**](IncidentApi.md#get_incident) | **GET** /v1/incidents/{identifier} | Get Incident\n[**get_incident_request_status**](IncidentApi.md#get_incident_request_status) | **GET** /v1/incidents/requests/{requestId} | Get Request Status of Incident\n[**list_incidents**](IncidentApi.md#list_incidents) | **GET** /v1/incidents/ | List incidents\n\n\n# **close_incident**\n> SuccessResponse close_incident(identifier, identifier_type=identifier_type, close_incident_payload=close_incident_payload)\n\nClose Incident\n\nCloses incident with given identifier\n\n### Example\n\n* Api Key Authentication (GenieKey):\n```python\nfrom __future__ import print_function\nimport time\nimport opsgenie_sdk\nfrom opsgenie_sdk.rest import ApiException\nfrom pprint import pprint\nconfiguration = opsgenie_sdk.Configuration()\n# Configure API key authorization: GenieKey\nconfiguration.api_key['Authorization'] = 'YOUR_API_KEY'\n\n# create an instance of the API class\napi_instance = opsgenie_sdk.IncidentApi(opsgenie_sdk.ApiClient(configuration))\nidentifier = 'identifier_example' # str | Identifier of incident which could be incident id or tiny id\nidentifier_type = 'id' # str | Type of the identifier that is provided as an in-line parameter. Possible values are 'id' or 'tiny. Default is id' (optional) (default to 'id')\nclose_incident_payload = opsgenie_sdk.CloseIncidentPayload() # CloseIncidentPayload | Request payload of closing incident action (optional)\n\ntry:\n    # Close Incident\n    api_response = api_instance.close_incident(identifier, identifier_type=identifier_type, close_incident_payload=close_incident_payload)\n    pprint(api_response)\nexcept ApiException as e:\n    print(\"Exception when calling IncidentApi->close_incident: %s\\n\" % e)\n```\n\n### Parameters\n\nName | Type | Description  | Notes\n------------- | ------------- | ------------- | -------------\n **identifier** | **str**| Identifier of incident which could be incident id or tiny id | \n **identifier_type** | **str**| Type of the identifier that is provided as an in-line parameter. Possible values are &#39;id&#39; or &#39;tiny. Default is id&#39; | [optional] [default to &#39;id&#39;]\n **close_incident_payload** | [**CloseIncidentPayload**](CloseIncidentPayload.md)| Request payload of closing incident action | [optional] \n\n### Return type\n\n[**SuccessResponse**](SuccessResponse.md)\n\n### Authorization\n\n[GenieKey](../README.md#GenieKey)\n\n### HTTP request headers\n\n - **Content-Type**: Not defined\n - **Accept**: application/json\n\n[[Back to top]](#) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to Model list]](../README.md#documentation-for-models) [[Back to README]](../README.md)\n\n# **create_incident**\n> SuccessResponse create_incident(create_incident_payload)\n\nCreate Incident\n\nCreates a new incident\n\n### Example\n\n* Api Key Authentication (GenieKey):\n```python\nfrom __future__ import print_function\nimport time\nimport opsgenie_sdk\nfrom opsgenie_sdk.rest import ApiException\nfrom pprint import pprint\nconfiguration = opsgenie_sdk.Configuration()\n# Configure API key authorization: GenieKey\nconfiguration.api_key['Authorization'] = 'YOUR_API_KEY'\n\n# create an instance of the API class\napi_instance = opsgenie_sdk.IncidentApi(opsgenie_sdk.ApiClient(configuration))\ncreate_incident_payload = opsgenie_sdk.CreateIncidentPayload() # CreateIncidentPayload | Request payload of created incident\n\ntry:\n    # Create Incident\n    api_response = api_instance.create_incident(create_incident_payload)\n    pprint(api_response)\nexcept ApiException as e:\n    print(\"Exception when calling IncidentApi->create_incident: %s\\n\" % e)\n```\n\n### Parameters\n\nName | Type | Description  | Notes\n------------- | ------------- | ------------- | -------------\n **create_incident_payload** | [**CreateIncidentPayload**](CreateIncidentPayload.md)| Request payload of created incident | \n\n### Return type\n\n[**SuccessResponse**](SuccessResponse.md)\n\n### Authorization\n\n[GenieKey](../README.md#GenieKey)\n\n### HTTP request headers\n\n - **Content-Type**: Not defined\n - **Accept**: application/json\n\n[[Back to top]](#) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to Model list]](../README.md#documentation-for-models) [[Back to README]](../README.md)\n\n# **delete_incident**\n> SuccessResponse delete_incident(identifier, identifier_type=identifier_type)\n\nDelete Incident\n\nDeletes an incident using incident id or the tiny id\n\n### Example\n\n* Api Key Authentication (GenieKey):\n```python\nfrom __future__ import print_function\nimport time\nimport opsgenie_sdk\nfrom opsgenie_sdk.rest import ApiException\nfrom pprint import pprint\nconfiguration = opsgenie_sdk.Configuration()\n# Configure API key authorization: GenieKey\nconfiguration.api_key['Authorization'] = 'YOUR_API_KEY'\n\n# create an instance of the API class\napi_instance = opsgenie_sdk.IncidentApi(opsgenie_sdk.ApiClient(configuration))\nidentifier = 'identifier_example' # str | Identifier of incident which could be incident id or tiny id\nidentifier_type = 'id' # str | Type of the identifier that is provided as an in-line parameter. Possible values are 'id' or 'tiny. Default is id' (optional) (default to 'id')\n\ntry:\n    # Delete Incident\n    api_response = api_instance.delete_incident(identifier, identifier_type=identifier_type)\n    pprint(api_response)\nexcept ApiException as e:\n    print(\"Exception when calling IncidentApi->delete_incident: %s\\n\" % e)\n```\n\n### Parameters\n\nName | Type | Description  | Notes\n------------- | ------------- | ------------- | -------------\n **identifier** | **str**| Identifier of incident which could be incident id or tiny id | \n **identifier_type** | **str**| Type of the identifier that is provided as an in-line parameter. Possible values are &#39;id&#39; or &#39;tiny. Default is id&#39; | [optional] [default to &#39;id&#39;]\n\n### Return type\n\n[**SuccessResponse**](SuccessResponse.md)\n\n### Authorization\n\n[GenieKey](../README.md#GenieKey)\n\n### HTTP request headers\n\n - **Content-Type**: Not defined\n - **Accept**: application/json\n\n[[Back to top]](#) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to Model list]](../README.md#documentation-for-models) [[Back to README]](../README.md)\n\n# **get_incident**\n> GetIncidentResponse get_incident(identifier, identifier_type=identifier_type)\n\nGet Incident\n\nReturns incident with given id, tiny id or alias\n\n### Example\n\n* Api Key Authentication (GenieKey):\n```python\nfrom __future__ import print_function\nimport time\nimport opsgenie_sdk\nfrom opsgenie_sdk.rest import ApiException\nfrom pprint import pprint\nconfiguration = opsgenie_sdk.Configuration()\n# Configure API key authorization: GenieKey\nconfiguration.api_key['Authorization'] = 'YOUR_API_KEY'\n\n# create an instance of the API class\napi_instance = opsgenie_sdk.IncidentApi(opsgenie_sdk.ApiClient(configuration))\nidentifier = 'identifier_example' # str | Identifier of incident which could be incident id or tiny id\nidentifier_type = 'id' # str | Type of the identifier that is provided as an in-line parameter. Possible values are 'id' or 'tiny. Default is id' (optional) (default to 'id')\n\ntry:\n    # Get Incident\n    api_response = api_instance.get_incident(identifier, identifier_type=identifier_type)\n    pprint(api_response)\nexcept ApiException as e:\n    print(\"Exception when calling IncidentApi->get_incident: %s\\n\" % e)\n```\n\n### Parameters\n\nName | Type | Description  | Notes\n------------- | ------------- | ------------- | -------------\n **identifier** | **str**| Identifier of incident which could be incident id or tiny id | \n **identifier_type** | **str**| Type of the identifier that is provided as an in-line parameter. Possible values are &#39;id&#39; or &#39;tiny. Default is id&#39; | [optional] [default to &#39;id&#39;]\n\n### Return type\n\n[**GetIncidentResponse**](GetIncidentResponse.md)\n\n### Authorization\n\n[GenieKey](../README.md#GenieKey)\n\n### HTTP request headers\n\n - **Content-Type**: Not defined\n - **Accept**: application/json\n\n[[Back to top]](#) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to Model list]](../README.md#documentation-for-models) [[Back to README]](../README.md)\n\n# **get_incident_request_status**\n> GetIncidentRequestStatusResponse get_incident_request_status(request_id)\n\nGet Request Status of Incident\n\nUsed to track the status and incident details (if any) of the request whose identifier is given\n\n### Example\n\n* Api Key Authentication (GenieKey):\n```python\nfrom __future__ import print_function\nimport time\nimport opsgenie_sdk\nfrom opsgenie_sdk.rest import ApiException\nfrom pprint import pprint\nconfiguration = opsgenie_sdk.Configuration()\n# Configure API key authorization: GenieKey\nconfiguration.api_key['Authorization'] = 'YOUR_API_KEY'\n\n# create an instance of the API class\napi_instance = opsgenie_sdk.IncidentApi(opsgenie_sdk.ApiClient(configuration))\nrequest_id = 'request_id_example' # str | Universally unique identifier of the questioned request\n\ntry:\n    # Get Request Status of Incident\n    api_response = api_instance.get_incident_request_status(request_id)\n    pprint(api_response)\nexcept ApiException as e:\n    print(\"Exception when calling IncidentApi->get_incident_request_status: %s\\n\" % e)\n```\n\n### Parameters\n\nName | Type | Description  | Notes\n------------- | ------------- | ------------- | -------------\n **request_id** | **str**| Universally unique identifier of the questioned request | \n\n### Return type\n\n[**GetIncidentRequestStatusResponse**](GetIncidentRequestStatusResponse.md)\n\n### Authorization\n\n[GenieKey](../README.md#GenieKey)\n\n### HTTP request headers\n\n - **Content-Type**: Not defined\n - **Accept**: application/json\n\n[[Back to top]](#) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to Model list]](../README.md#documentation-for-models) [[Back to README]](../README.md)\n\n# **list_incidents**\n> ListIncidentsResponse list_incidents(query, offset=offset, limit=limit, sort=sort, order=order)\n\nList incidents\n\nReturn list of incidents\n\n### Example\n\n* Api Key Authentication (GenieKey):\n```python\nfrom __future__ import print_function\nimport time\nimport opsgenie_sdk\nfrom opsgenie_sdk.rest import ApiException\nfrom pprint import pprint\nconfiguration = opsgenie_sdk.Configuration()\n# Configure API key authorization: GenieKey\nconfiguration.api_key['Authorization'] = 'YOUR_API_KEY'\n\n# create an instance of the API class\napi_instance = opsgenie_sdk.IncidentApi(opsgenie_sdk.ApiClient(configuration))\nquery = 'query_example' # str | Search query to apply while filtering the incidents.\noffset = 56 # int | Start index of the result set (to apply pagination). Minimum value (and also default value) is 0. (optional)\nlimit = 56 # int | Maximum number of items to provide in the result. Must be a positive integer value. Default value is 20 and maximum value is 100 (optional)\nsort = 'createdAt' # str | Name of the field that result set will be sorted by (optional) (default to 'createdAt')\norder = 'desc' # str | Sorting order of the result set (optional) (default to 'desc')\n\ntry:\n    # List incidents\n    api_response = api_instance.list_incidents(query, offset=offset, limit=limit, sort=sort, order=order)\n    pprint(api_response)\nexcept ApiException as e:\n    print(\"Exception when calling IncidentApi->list_incidents: %s\\n\" % e)\n```\n\n### Parameters\n\nName | Type | Description  | Notes\n------------- | ------------- | ------------- | -------------\n **query** | **str**| Search query to apply while filtering the incidents. | \n **offset** | **int**| Start index of the result set (to apply pagination). Minimum value (and also default value) is 0. | [optional] \n **limit** | **int**| Maximum number of items to provide in the result. Must be a positive integer value. Default value is 20 and maximum value is 100 | [optional] \n **sort** | **str**| Name of the field that result set will be sorted by | [optional] [default to &#39;createdAt&#39;]\n **order** | **str**| Sorting order of the result set | [optional] [default to &#39;desc&#39;]\n\n### Return type\n\n[**ListIncidentsResponse**](ListIncidentsResponse.md)\n\n### Authorization\n\n[GenieKey](../README.md#GenieKey)\n\n### HTTP request headers\n\n - **Content-Type**: Not defined\n - **Accept**: application/json\n\n[[Back to top]](#) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to Model list]](../README.md#documentation-for-models) [[Back to README]](../README.md)\n\n",
    "timestamp": "2025-05-23T16:34:36.996996",
    "tags": [],
    "severity": "low",
    "services_affected": [
      "api",
      "auth"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "elasticsearch"
    ],
    "failure_pattern": "configuration_drift",
    "timeline_events": [],
    "blast_radius": "localized",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 0.67
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/cross-community/study-area-docs/blob/ae3f4298ebb0c328394fbcacfa49110991cac633/docs/Incidents.md",
    "title": "Incidents.md",
    "content": "\n\n## 2019\n\n* 2019/06/28 - 06/29: [Degraded functionality with several features](https://status.slack.com/2019-06/9f63d8e30ee85f46), [Slack服務突槌超過15個小時](https://www.ithome.com.tw/news/131557)\n* 2019/06/24: [How Verizon and a BGP Optimizer Knocked Large Parts of the Internet Offline Today](https://blog.cloudflare.com/how-verizon-and-a-bgp-optimizer-knocked-large-parts-of-the-internet-offline-today/), BGP路由外洩造成全球網路不穩，Cloudflare、臉書、Amazon都遭殃[](https://www.ithome.com.tw/news/131459)\n* 2019/06/03: Google: [An update on Sunday’s service disruption](https://cloud.google.com/blog/topics/inside-google-cloud/an-update-on-sundays-service-disruption) by Benjamin Treynor Sloss\nVP, 24x7\n\n## 2018\n\n* 2018/10/30: [GitHub October 21 post-incident analysis](https://blog.github.com/2018-10-30-oct21-post-incident-analysis/)\n    * [中文簡譯 by Rick Hwang](https://rickhw.github.io/2019/06/05/DevOps/Github-Incident-Analysis/), [草稿](https://www.facebook.com/groups/sre.taiwan/permalink/1176448732521029/)\n* 2018/10/17: [歷史性的一刻，Youtube 爛了。](https://www.facebook.com/groups/sre.taiwan/permalink/1164643200368249/)\n* 2018/10/13: [What I learned by bringing down LinkedIn.com](https://venturebeat.com/2018/10/13/what-i-learned-by-bringing-down-linkedin-com/)\n* 2018/07/18: [沒谷歌不行.. 當機造成寶可夢、Snapchat暫時下線](https://news.cnyes.com/news/id/4167982)\n* 2018/06/27: Slack 異常 https://www.facebook.com/groups/sre.taiwan/permalink/1060397500792820/\n* 2018/09/04 Azure 雷擊事件. 2018年9月4日星期二，VSTS（現名為Azure DevOps）遭遇長時間的故障，影響了在美國中南部地區（全球託管VSTS客户的10個地區之一）設有組織的客户。\n\n\n## 2017\n\n* 2017/02/28: [Summary of the Amazon S3 Service Disruption in the Northern Virginia (US-EAST-1) Region](https://aws.amazon.com/cn/message/41926/)\n* 2017/02/01: [GitLab.com database incident](https://about.gitlab.com/2017/02/01/gitlab-dot-com-database-incident/)\n* 2017/03/27: [【有片】癱瘓2.2萬輛Ubike　內鬼扮駭客恐賠2242萬（動畫）](https://tw.appledaily.com/new/realtime/20170327/1085182/)\n* 2018/11/12: [Google GKE服務故障近19小時，無法使用Cloud Console UI建立新節點](https://www.ithome.com.tw/news/126952)\n\n\n## Misc\n\n* [我是linkedin工程師 我把linkedin搞掛了](https://www.google.com/search?client=firefox-b&ei=7gPpW7u3O4qy8QWhirnQCA&ins=false&q=%E6%88%91%E6%98%AFlinkedin%E5%B7%A5%E7%A8%8B%E5%B8%AB+%E6%88%91%E6%8A%8Alinkedin%E6%90%9E%E6%8E%9B%E4%BA%86&oq=%E6%88%91%E6%98%AFlinkedin%E5%B7%A5%E7%A8%8B%E5%B8%AB+%E6%88%91%E6%8A%8Alinkedin%E6%90%9E%E6%8E%9B%E4%BA%86&gs_l=mobile-gws-wiz-serp.3...6597.17743..18570...4.0..4.441.4060.13j14j1j1j1......0....1.........30i10.u_p70_RXgww&fbclid=IwAR3x2S7hizzbyKUKehMF1oxJgasAeMjfVSaDMQ_rjMOmEaEeHG3pbdGdUcY#)\n",
    "timestamp": "2025-05-23T16:34:38.634772",
    "tags": [],
    "severity": "high",
    "services_affected": [
      "web",
      "database"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "aws",
      "gcp",
      "azure",
      "postgresql",
      "elasticsearch",
      "kafka"
    ],
    "failure_pattern": null,
    "timeline_events": [],
    "blast_radius": "partial",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 0.64
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/IntersectMBO/cardano-updates/blob/cb3e047ba85183e9a4efef968b1b6cdd9661f6c1/blog/2024-09-11-incident.md",
    "title": "2024-09-11-incident.md",
    "content": "---\ntitle: Large Reference Scripts\nslug: 2024-09-11-incident\nauthors: kevinhammond\ntags: [security,incident,consensus,ledger,plutus]\nhide_table_of_contents: false\n---\n\n## Issue Caused by Large Reference Scripts on Cardano Mainnet\n\nOn 25th June 2025, a Cardano user inserted a series of transactions,\neach containing 194 large reference scripts onto the mainnet chain,\nfunded from 3 wallets containing around 20K ada each.  High deserialisation\ncosts for these reference scripts impacted the node,\nresulting in network disruption to block producer nodes, an increase\nin network load, and some slowdown in transaction throughput. \n\nThe direct effect lasted about 12 hours until it was stopped by a community member,\nat a cost of 4603 ada to the user who had created the transactions. \nOverall, the network responded extemely well to the increased load,\nshowing a high level of resilience, with some reduction in transaction\nthroughput related to the overall high system load.  The community response to the\nevent was positive, praising the speed of response, the robustness\nof the Cardano network, the cohesion of the Cardano community, and\nits ability to diagnose and manage issues such as this.\n\n### Mitigations Deployed\n\nThe general issue had already been identified, and a mitigation (costing for\nreference scripts) had been prepared as part of the Chang hard fork,\nbut not yet deployed to mainnet. Based on the event, stronger\nmitigations were prepared, including restricting large reference scripts,\nand changing the cost model. These mitigations were deployed\nvia node versions 8.9.4, 8.12.1 or 8.12.2, and incorporated into node\nversion 9.0.0 or later for the Chang hard fork.\n\n### Public Reports on the Incident\n\n[Coindesk Report](https://www.coindesk.com/tech/2024/06/26/cardano-unfazed-by-failed-ddos-attack-targeting-staked-ada/)\n\n[Nasdaq Report](https://www.nasdaq.com/articles/cardano-mitigates-ddos-attack)\n\n\n",
    "timestamp": "2025-05-23T16:34:39.045946",
    "tags": [],
    "severity": "high",
    "services_affected": [
      "api"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [],
    "failure_pattern": "data_corruption",
    "timeline_events": [],
    "blast_radius": "localized",
    "detection_time": null,
    "mitigation_actions": [
      "The general issue had already been identified, and a mitigation (costing for",
      "to mainnet",
      "via node versions 8"
    ],
    "quality_score": 0.64
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/opendataphilly/opendataphilly-jkan/blob/d3ced9029a07a9c2681bde1b0dfad957decc1f61/_datasets/crime-incidents.md",
    "title": "crime-incidents.md",
    "content": "---\narea_of_interest: null\ncategory:\n- Public Safety\ncreated: '2016-04-21T22:27:16.878591'\nlicense: City of Philadelphia License\nmaintainer: publicsafetygis@phila.gov\nmaintainer_email: publicsafetygis@phila.gov\nmaintainer_link: null\nmaintainer_phone: null\nnotes: \"Crime incidents from the Philadelphia Police Department. Part I crimes include\\\n  \\ violent offenses such as aggravated assault, rape, arson, among others. Part II\\\n  \\ crimes include simple assault, prostitution, gambling, fraud, and other non-violent\\\n  \\ offenses.\\r\\n\\r\\n**Please note that this is a very large dataset. To see all incidents,\\\n  \\ download all datasets for all years.** \\r\\n\\r\\n**If you are comfortable with APIs,\\\n  \\ you can also use the API links to access this data. You can learn more about how\\\n  \\ to use the API at Carto\\u2019s SQL API site and in the Carto guide in the section\\\n  \\ on making calls to the API.**\"\nopendataphilly_rating: null\norganization: City of Philadelphia\nresources:\n- description: 'An online appication that displays summary statistics and enables mapping of recent incidents within a radius of an address.'\n  format: HTML\n  name: Crime Maps and Stats Application\n  url: https://www.phillypolice.com/crimestats\n- description: ''\n  format: HTML\n  name: Crime Incidents (Visualization)\n  url: https://data.phila.gov/visualizations/crime-incidents\n- description: ''\n  format: CSV\n  name: Crime Incidents from 2025 (CSV)\n  url: https://phl.carto.com/api/v2/sql?filename=incidents_part1_part2&format=csv&q=SELECT%20*%20,%20ST_Y(the_geom)%20AS%20lat,%20ST_X(the_geom)%20AS%20lng%20FROM%20incidents_part1_part2%20WHERE%20dispatch_date_time%20%3E=%20%272025-01-01%27%20AND%20dispatch_date_time%20%3C%20%272026-01-01%27\n- description: ''\n  format: CSV\n  name: Crime Incidents from 2024 (CSV)\n  url: https://phl.carto.com/api/v2/sql?filename=incidents_part1_part2&format=csv&q=SELECT%20*%20,%20ST_Y(the_geom)%20AS%20lat,%20ST_X(the_geom)%20AS%20lng%20FROM%20incidents_part1_part2%20WHERE%20dispatch_date_time%20%3E=%20%272024-01-01%27%20AND%20dispatch_date_time%20%3C%20%272025-01-01%27\n- description: ''\n  format: CSV\n  name: Crime Incidents from 2023 (CSV)\n  url: https://phl.carto.com/api/v2/sql?filename=incidents_part1_part2&format=csv&q=SELECT%20*%20,%20ST_Y(the_geom)%20AS%20lat,%20ST_X(the_geom)%20AS%20lng%20FROM%20incidents_part1_part2%20WHERE%20dispatch_date_time%20%3E=%20%272023-01-01%27%20AND%20dispatch_date_time%20%3C%20%272024-01-01%27\n- description: ''\n  format: CSV\n  name: Crime Incidents from 2022 (CSV)\n  url: https://phl.carto.com/api/v2/sql?filename=incidents_part1_part2&format=csv&q=SELECT%20*%20,%20ST_Y(the_geom)%20AS%20lat,%20ST_X(the_geom)%20AS%20lng%20FROM%20incidents_part1_part2%20WHERE%20dispatch_date_time%20%3E=%20%272022-01-01%27%20AND%20dispatch_date_time%20%3C%20%272023-01-01%27\n- description: ''\n  format: CSV\n  name: Crime Incidents from 2021 (CSV)\n  url: https://phl.carto.com/api/v2/sql?filename=incidents_part1_part2&format=csv&q=SELECT%20*%20,%20ST_Y(the_geom)%20AS%20lat,%20ST_X(the_geom)%20AS%20lng%20FROM%20incidents_part1_part2%20WHERE%20dispatch_date_time%20%3E=%20%272021-01-01%27%20AND%20dispatch_date_time%20%3C%20%272022-01-01%27\n- description: ''\n  format: CSV\n  name: Crime Incidents from 2020 (CSV)\n  url: https://phl.carto.com/api/v2/sql?filename=incidents_part1_part2&format=csv&q=SELECT%20*%20,%20ST_Y(the_geom)%20AS%20lat,%20ST_X(the_geom)%20AS%20lng%20FROM%20incidents_part1_part2%20WHERE%20dispatch_date_time%20%3E=%20%272020-01-01%27%20AND%20dispatch_date_time%20%3C%20%272021-01-01%27\n- description: ''\n  format: CSV\n  name: Crime Incidents from 2019 (CSV)\n  url: https://phl.carto.com/api/v2/sql?filename=incidents_part1_part2&format=csv&skipfields=cartodb_id,the_geom,the_geom_webmercator&q=SELECT\n    * , ST_Y(the_geom) AS lat, ST_X(the_geom) AS lng FROM incidents_part1_part2 WHERE\n    dispatch_date_time >= '2019-01-01' AND dispatch_date_time < '2020-01-01'\n- description: ''\n  format: CSV\n  name: Crime Incidents from 2018 (CSV)\n  url: https://phl.carto.com/api/v2/sql?filename=incidents_part1_part2&format=csv&skipfields=cartodb_id,the_geom,the_geom_webmercator&q=SELECT\n    * , ST_Y(the_geom) AS lat, ST_X(the_geom) AS lng FROM incidents_part1_part2 WHERE\n    dispatch_date_time >= '2018-01-01' AND dispatch_date_time < '2019-01-01'\n- description: ''\n  format: CSV\n  name: Crime Incidents from 2017 (CSV)\n  url: https://phl.carto.com/api/v2/sql?filename=incidents_part1_part2&format=csv&skipfields=cartodb_id,the_geom,the_geom_webmercator&q=SELECT\n    * , ST_Y(the_geom) AS lat, ST_X(the_geom) AS lng FROM incidents_part1_part2 WHERE\n    dispatch_date_time >= '2017-01-01' AND dispatch_date_time < '2018-01-01'\n- description: ''\n  format: CSV\n  name: Crime Incidents from 2016 (CSV)\n  url: https://phl.carto.com/api/v2/sql?filename=incidents_part1_part2&format=csv&skipfields=cartodb_id,the_geom,the_geom_webmercator&q=SELECT\n    * , ST_Y(the_geom) AS lat, ST_X(the_geom) AS lng FROM incidents_part1_part2 WHERE\n    dispatch_date_time >= '2016-01-01' AND dispatch_date_time < '2017-01-01'\n- description: ''\n  format: CSV\n  name: Crime Incidents from 2015 (CSV)\n  url: https://phl.carto.com/api/v2/sql?filename=incidents_part1_part2&format=csv&skipfields=cartodb_id,the_geom,the_geom_webmercator&q=SELECT\n    * , ST_Y(the_geom) AS lat, ST_X(the_geom) AS lng FROM incidents_part1_part2 WHERE\n    dispatch_date_time >= '2015-01-01' AND dispatch_date_time < '2016-01-01'\n- description: ''\n  format: CSV\n  name: Crime Incidents from 2014 (CSV)\n  url: https://phl.carto.com/api/v2/sql?filename=incidents_part1_part2&format=csv&skipfields=cartodb_id,the_geom,the_geom_webmercator&q=SELECT\n    * , ST_Y(the_geom) AS lat, ST_X(the_geom) AS lng FROM incidents_part1_part2 WHERE\n    dispatch_date_time >= '2014-01-01' AND dispatch_date_time < '2015-01-01'\n- description: ''\n  format: CSV\n  name: Crime Incidents from 2013 (CSV)\n  url: https://phl.carto.com/api/v2/sql?filename=incidents_part1_part2&format=csv&skipfields=cartodb_id,the_geom,the_geom_webmercator&q=SELECT\n    * , ST_Y(the_geom) AS lat, ST_X(the_geom) AS lng FROM incidents_part1_part2 WHERE\n    dispatch_date_time >= '2013-01-01' AND dispatch_date_time < '2014-01-01'\n- description: ''\n  format: CSV\n  name: Crime Incidents from 2012 (CSV)\n  url: https://phl.carto.com/api/v2/sql?filename=incidents_part1_part2&format=csv&skipfields=cartodb_id,the_geom,the_geom_webmercator&q=SELECT\n    * , ST_Y(the_geom) AS lat, ST_X(the_geom) AS lng FROM incidents_part1_part2 WHERE\n    dispatch_date_time >= '2012-01-01' AND dispatch_date_time < '2013-01-01'\n- description: ''\n  format: CSV\n  name: Crime Incidents from 2011 (CSV)\n  url: https://phl.carto.com/api/v2/sql?filename=incidents_part1_part2&format=csv&skipfields=cartodb_id,the_geom,the_geom_webmercator&q=SELECT\n    * , ST_Y(the_geom) AS lat, ST_X(the_geom) AS lng FROM incidents_part1_part2 WHERE\n    dispatch_date_time >= '2011-01-01' AND dispatch_date_time < '2012-01-01'\n- description: ''\n  format: CSV\n  name: Crime Incidents from 2010 (CSV)\n  url: https://phl.carto.com/api/v2/sql?filename=incidents_part1_part2&format=csv&skipfields=cartodb_id,the_geom,the_geom_webmercator&q=SELECT\n    * , ST_Y(the_geom) AS lat, ST_X(the_geom) AS lng FROM incidents_part1_part2 WHERE\n    dispatch_date_time >= '2010-01-01' AND dispatch_date_time < '2011-01-01'\n- description: ''\n  format: CSV\n  name: Crime Incidents from 2009 (CSV)\n  url: https://phl.carto.com/api/v2/sql?filename=incidents_part1_part2&format=csv&skipfields=cartodb_id,the_geom,the_geom_webmercator&q=SELECT\n    * , ST_Y(the_geom) AS lat, ST_X(the_geom) AS lng FROM incidents_part1_part2 WHERE\n    dispatch_date_time >= '2009-01-01' AND dispatch_date_time < '2010-01-01'\n- description: ''\n  format: CSV\n  name: Crime Incidents from 2008 (CSV)\n  url: https://phl.carto.com/api/v2/sql?filename=incidents_part1_part2&format=csv&skipfields=cartodb_id,the_geom,the_geom_webmercator&q=SELECT\n    * , ST_Y(the_geom) AS lat, ST_X(the_geom) AS lng FROM incidents_part1_part2 WHERE\n    dispatch_date_time >= '2008-01-01' AND dispatch_date_time < '2009-01-01'\n- description: ''\n  format: CSV\n  name: Crime Incidents from 2007 (CSV)\n  url: https://phl.carto.com/api/v2/sql?filename=incidents_part1_part2&format=csv&skipfields=cartodb_id,the_geom,the_geom_webmercator&q=SELECT\n    * , ST_Y(the_geom) AS lat, ST_X(the_geom) AS lng FROM incidents_part1_part2 WHERE\n    dispatch_date_time >= '2007-01-01' AND dispatch_date_time < '2008-01-01'\n- description: ''\n  format: CSV\n  name: Crime Incidents from 2006 (CSV)\n  url: https://phl.carto.com/api/v2/sql?filename=incidents_part1_part2&format=csv&skipfields=cartodb_id,the_geom,the_geom_webmercator&q=SELECT\n    * , ST_Y(the_geom) AS lat, ST_X(the_geom) AS lng FROM incidents_part1_part2 WHERE\n    dispatch_date_time >= '2006-01-01' AND dispatch_date_time < '2007-01-01'\n- description: ''\n  format: SHP\n  name: Crime Incidents from 2025 (SHP)\n  url: https://phl.carto.com/api/v2/sql?filename=incidents_part1_part2&format=shp&skipfields=cartodb_id&q=SELECT%20*%20FROM%20incidents_part1_part2%20WHERE%20dispatch_date_time%20%3E=%20%272025-01-01%27%20AND%20dispatch_date_time%20%3C%20%272026-01-01%27\n- description: ''\n  format: SHP\n  name: Crime Incidents from 2024 (SHP)\n  url: https://phl.carto.com/api/v2/sql?filename=incidents_part1_part2&format=shp&skipfields=cartodb_id&q=SELECT%20*%20FROM%20incidents_part1_part2%20WHERE%20dispatch_date_time%20%3E=%20%272024-01-01%27%20AND%20dispatch_date_time%20%3C%20%272025-01-01%27\n- description: ''\n  format: SHP\n  name: Crime Incidents from 2023 (SHP)\n  url: https://phl.carto.com/api/v2/sql?filename=incidents_part1_part2&format=shp&skipfields=cartodb_id&q=SELECT%20*%20FROM%20incidents_part1_part2%20WHERE%20dispatch_date_time%20%3E=%20%272023-01-01%27%20AND%20dispatch_date_time%20%3C%20%272024-01-01%27\n- description: ''\n  format: SHP\n  name: Crime Incidents from 2022 (SHP)\n  url: https://phl.carto.com/api/v2/sql?filename=incidents_part1_part2&format=shp&skipfields=cartodb_id&q=SELECT%20*%20FROM%20incidents_part1_part2%20WHERE%20dispatch_date_time%20%3E=%20%272022-01-01%27%20AND%20dispatch_date_time%20%3C%20%272023-01-01%27\n- description: ''\n  format: SHP\n  name: Crime Incidents from 2021 (SHP)\n  url: https://phl.carto.com/api/v2/sql?filename=incidents_part1_part2&format=shp&skipfields=cartodb_id&q=SELECT%20*%20FROM%20incidents_part1_part2%20WHERE%20dispatch_date_time%20%3E=%20%272021-01-01%27%20AND%20dispatch_date_time%20%3C%20%272022-01-01%27\n- description: ''\n  format: SHP\n  name: Crime Incidents from 2020 (SHP)\n  url: https://phl.carto.com/api/v2/sql?filename=incidents_part1_part2&format=shp&skipfields=cartodb_id&q=SELECT\n    * FROM incidents_part1_part2 WHERE dispatch_date_time >= '2020-01-01' AND dispatch_date_time\n    < '2021-01-01'\n- description: ''\n  format: SHP\n  name: Crime Incidents from 2019 (SHP)\n  url: https://phl.carto.com/api/v2/sql?filename=incidents_part1_part2&format=shp&skipfields=cartodb_id&q=SELECT\n    * FROM incidents_part1_part2 WHERE dispatch_date_time >= '2019-01-01' AND dispatch_date_time\n    < '2020-01-01'\n- description: ''\n  format: SHP\n  name: Crime Incidents from 2018 (SHP)\n  url: https://phl.carto.com/api/v2/sql?filename=incidents_part1_part2&format=shp&skipfields=cartodb_id&q=SELECT\n    * FROM incidents_part1_part2 WHERE dispatch_date_time >= '2018-01-01' AND dispatch_date_time\n    < '2019-01-01'\n- description: ''\n  format: SHP\n  name: Crime Incidents from 2017 (SHP)\n  url: https://phl.carto.com/api/v2/sql?filename=incidents_part1_part2&format=shp&skipfields=cartodb_id&q=SELECT\n    * FROM incidents_part1_part2 WHERE dispatch_date_time >= '2017-01-01' AND dispatch_date_time\n    < '2018-01-01'\n- description: ''\n  format: SHP\n  name: Crime Incidents from 2016 (SHP)\n  url: https://phl.carto.com/api/v2/sql?filename=incidents_part1_part2&format=shp&skipfields=cartodb_id&q=SELECT\n    * FROM incidents_part1_part2 WHERE dispatch_date_time >= '2016-01-01' AND dispatch_date_time\n    < '2017-01-01'\n- description: ''\n  format: SHP\n  name: Crime Incidents from 2015 (SHP)\n  url: https://phl.carto.com/api/v2/sql?filename=incidents_part1_part2&format=shp&skipfields=cartodb_id&q=SELECT\n    * FROM incidents_part1_part2 WHERE dispatch_date_time >= '2015-01-01' AND dispatch_date_time\n    < '2016-01-01'\n- description: ''\n  format: SHP\n  name: Crime Incidents from 2014 (SHP)\n  url: https://phl.carto.com/api/v2/sql?filename=incidents_part1_part2&format=shp&skipfields=cartodb_id&q=SELECT\n    * FROM incidents_part1_part2 WHERE dispatch_date_time >= '2014-01-01' AND dispatch_date_time\n    < '2015-01-01'\n- description: ''\n  format: SHP\n  name: Crime Incidents from 2013 (SHP)\n  url: https://phl.carto.com/api/v2/sql?filename=incidents_part1_part2&format=shp&skipfields=cartodb_id&q=SELECT\n    * FROM incidents_part1_part2 WHERE dispatch_date_time >= '2013-01-01' AND dispatch_date_time\n    < '2014-01-01'\n- description: ''\n  format: SHP\n  name: Crime Incidents from 2012 (SHP)\n  url: https://phl.carto.com/api/v2/sql?filename=incidents_part1_part2&format=shp&skipfields=cartodb_id&q=SELECT\n    * FROM incidents_part1_part2 WHERE dispatch_date_time >= '2012-01-01' AND dispatch_date_time\n    < '2013-01-01'\n- description: ''\n  format: SHP\n  name: Crime Incidents from 2011 (SHP)\n  url: https://phl.carto.com/api/v2/sql?filename=incidents_part1_part2&format=shp&skipfields=cartodb_id&q=SELECT\n    * FROM incidents_part1_part2 WHERE dispatch_date_time >= '2011-01-01' AND dispatch_date_time\n    < '2012-01-01'\n- description: ''\n  format: SHP\n  name: Crime Incidents from 2010 (SHP)\n  url: https://phl.carto.com/api/v2/sql?filename=incidents_part1_part2&format=shp&skipfields=cartodb_id&q=SELECT\n    * FROM incidents_part1_part2 WHERE dispatch_date_time >= '2010-01-01' AND dispatch_date_time\n    < '2011-01-01'\n- description: ''\n  format: SHP\n  name: Crime Incidents from 2009 (SHP)\n  url: https://phl.carto.com/api/v2/sql?filename=incidents_part1_part2&format=shp&skipfields=cartodb_id&q=SELECT\n    * FROM incidents_part1_part2 WHERE dispatch_date_time >= '2009-01-01' AND dispatch_date_time\n    < '2010-01-01'\n- description: ''\n  format: SHP\n  name: Crime Incidents from 2008 (SHP)\n  url: https://phl.carto.com/api/v2/sql?filename=incidents_part1_part2&format=shp&skipfields=cartodb_id&q=SELECT\n    * FROM incidents_part1_part2 WHERE dispatch_date_time >= '2008-01-01' AND dispatch_date_time\n    < '2009-01-01'\n- description: ''\n  format: SHP\n  name: Crime Incidents from 2007 (SHP)\n  url: https://phl.carto.com/api/v2/sql?filename=incidents_part1_part2&format=shp&skipfields=cartodb_id&q=SELECT\n    * FROM incidents_part1_part2 WHERE dispatch_date_time >= '2007-01-01' AND dispatch_date_time\n    < '2008-01-01'\n- description: ''\n  format: SHP\n  name: Crime Incidents from 2006 (SHP)\n  url: https://phl.carto.com/api/v2/sql?filename=incidents_part1_part2&format=shp&skipfields=cartodb_id&q=SELECT\n    * FROM incidents_part1_part2 WHERE dispatch_date_time >= '2006-01-01' AND dispatch_date_time\n    < '2007-01-01'\n- description: ''\n  format: HTML\n  name: Crime Incidents - Full Dataset (API Documentation)\n  url: https://cityofphiladelphia.github.io/carto-api-explorer/#incidents_part1_part2\n- description: 2006 - Present\n  format: HTML\n  name: Crime Incidents (Metadata)\n  url: http://metadata.phila.gov/#home/datasetdetails/5543868920583086178c4f8e/representationdetails/570e7621c03327dc14f4b68d/\nschema: philadelphia\nsource: ''\ntags:\n- Philadelphia Police Department\ntime_period: null\ntitle: Crime Incidents\nusage: null\n---\n",
    "timestamp": "2025-05-23T16:34:39.434131",
    "tags": [],
    "severity": "high",
    "services_affected": [
      "api",
      "web",
      "database"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "postgresql",
      "grafana"
    ],
    "failure_pattern": null,
    "timeline_events": [],
    "blast_radius": "localized",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 0.52
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/mozilla/www.ccadb.org/blob/f165fb8c796da5941113b3ac85ca6061620e9d86/cas/incident-report.md",
    "title": "incident-report.md",
    "content": "# Incident Reporting Guidelines\n\n## Change History\n\n|Version|Effective Date|\n|-|-|\n|3.0 (current)|March 1, 2025| \n|[2.0](https://github.com/mozilla/www.ccadb.org/blob/master/incident_archive/ir_version_2_0.md)|October 17, 2023| \n|[1.0](https://github.com/mozilla/www.ccadb.org/blob/master/incident_archive/ir_version_1_0.md)|February 15, 2023|\n\n## Incident Reporting\n\nSystems, processes, and people aren't perfect. Omissions and deviations from expected outcomes can sometimes happen. However, when omissions or deviations are discovered, the underlying issues (i.e., root causes) need to be identified and remediated to discourage future recurrence. Formally documenting these cases, in the form of an Incident Report, promotes a thorough understanding of contributing factors and facilitates clear communication of remediation plans, while also fostering a culture of continuous improvement within the Web PKI ecosystem.\n\nThis page describes the CCADB Incident Reporting Framework and corresponding guidelines. For questions, contact support [at] ccadb [dot] org.\n\n### Definitions\n\nThe key words \"MUST\", \"MUST NOT\", \"REQUIRED\", \"SHALL\", \"SHALL NOT\", \"SHOULD\", \"SHOULD NOT\", \"RECOMMENDED\", \"MAY\", and \"OPTIONAL\" on this page are to be interpreted as described in [RFC 2119](https://datatracker.ietf.org/doc/html/rfc2119).\n\nUnless otherwise stated, \"certificate\" on this page refers to a final certificate, distinct from a precertificate (as described in [RFC 6962](https://datatracker.ietf.org/doc/html/rfc6962)).\n\n## Table of Contents\n\n[**Useful background**](#useful-background)\n- [What is considered an incident?](#what-is-considered-an-incident)\n- [What is considered an audit finding?](#what-is-considered-an-audit-finding)\n- [Why is public reporting important?](#why-is-public-reporting-important)\n- [What are the key characteristics of these reports?](#what-are-the-key-characteristics-of-these-reports)\n- [What does root cause analysis consider?](#what-does-root-cause-analysis-consider)\n\n[**Community participation in the reporting process**](#community-participation-in-the-reporting-process)\n- [Who can submit an Incident Report?](#who-can-submit-an-incident-report)\n- [Are there other ways to become involved in the reporting process?](#are-there-other-ways-to-become-involved-in-the-reporting-process)\n- [What Bugzilla account can I use?](#what-bugzilla-account-can-i-use)\n\n[**Report lifecycle management**](#report-lifecycle-management)\n- [How do I submit a report?](#how-do-i-submit-a-report)\n- [How are reports scoped?](#how-are-reports-scoped)\n- [What format is used?](#what-format-is-used)\n- [When are reports expected?](#when-are-reports-expected)\n- [When are reports updated?](#when-are-reports-updated)\n- [How are reports closed?](#how-are-reports-closed)\n  \n[**Report templates**](#report-templates)\n- [Preliminary Incident Report Template](#preliminary-incident-report)\n- [Full Incident Report Template](#full-incident-report)\n- [Report Closure Template](#closure-report)\n\n[**Report field definitions and expectations**](#report-field-definitions-and-expectations)\n- [Incident Reports](#incident-reports)\n- [Incident Closure Summary](#incident-closure-summary)\n\n[**Illustrative practices**](#illustrative-practices)\n- [Are there examples of \"good\" practices?](#are-there-examples-of-good-practices)\n- [Are there examples of \"bad\" practices?](#are-there-examples-of-bad-practices)\n- [Are there examples of \"good\" reports?](#are-there-examples-of-good-reports)\n\n\n### Useful background\n\n#### What is considered an incident?\n\nMinimally, a failure to meet the commitments described in any of the following policies is considered an incident:\n- a CA Owner's own policies (e.g., CP, CPS, or combined CP/CPS);\n- applicable requirements promulgated by the CA/Browser Forum;\n- the CCADB Policy; or\n- any applicable Root Store Operator policy.\n\nRoot Store Operator policies may further define what those individual programs consider incidents and/or outline additional incident reporting expectations.\n\nIt's important to note that the existence of an Incident Report does not generally indicate serious problems with a CA. \n\nFor publicly-trusted CA Owners, the number of incident reports filed in Bugzilla is less important than the content and quality of those reports.\n\n#### What is considered an audit finding?\n\nQualifications, non-conformities, and other deviations or omissions identified during audits are considered \"findings.\"\n\nThese items are commonly, but not exclusively, presented as either:\n- major non-conformities,\n- minor non-conformities,\n- qualifications,\n- qualified opinions, or\n- other matters.\n\n#### Why is public reporting important?\n\nIncident Reports provide lessons learned and transparency about the steps the CA Owner takes to address the immediate issue and prevent future issues. If the underlying problem goes unfixed, then other issues that share the same root cause will subsequently surface. \n\nThe public reporting process is important because it promotes continuous improvement, information sharing, and highlights opportunities to define and adopt improved practices, policies, and controls. Further, public reporting helps convey the implications and impact of an event so that affected stakeholders have an opportunity to assess risk and determine if it warrants further action. Together, these activities help build a more secure web. \n\n#### What are the key characteristics of these reports?\n\nReports are expected to:\n- be candid (i.e., focusing on honesty and forthrightness, even when revealing uncomfortable truths), timely (i.e., released without undue delay), and transparent (i.e., emphasizing open accessibility of information);\n- clearly (i.e., avoiding jargon, defining technical terms, adding useful background information) and objectively (i.e., supporting claims with data) communicate the scope, impact, and severity of an incident;\n- help community members understand the relevant architectures, implementations, operations, and external dependencies surrounding an incident;\n- demonstrate a detailed understanding of the root cause(s) of an incident;\n- unambiguously explain how systems, processes, and/or policies failed; \n- describe the circumstances that prevented the problem(s) from being detected earlier;\n- describe a clear timeline of a CA Owner's actions while responding to and remediating an incident;\n- include a detailed and measurable explanation of actions taken or planned by the CA Owner that demonstrate a substantive commitment of how the CA Owner's systems, policies, and/or processes will be made more robust (i.e., demonstrate continuous improvement); and\n- share lessons learned that could be helpful to all CA Owners in building better systems policies, and/or processes.\n\n#### What does Root Cause Analysis consider?\n\nEffective Root Cause Analysis (RCA) minimally considers the following points:\n\n1. **Focus on the \"why,\" not just the \"what\"**. RCAs go beyond identifying what went wrong and delve deeper into why it happened. This often involves looking past the immediate technical or policy failure and considers contributing factors like human error, process deficiencies, or system design flaws.\n\n2. **Use a systematic approach**. Employ structured methodologies like the following approaches to help ensure a thorough and organized investigation:\n   - [**Chesterton’s Fence**](https://fs.blog/chestertons-fence/): Before changing anything, understand why it's there. This helps avoid unintended consequences and ensures solutions address the root cause, not just symptoms.\n   - [**5 Whys**](https://en.wikipedia.org/wiki/Five_whys): Repeatedly ask \"why\" as many times as necessary to uncover the underlying cause of a problem. This simple technique helps drill down to the core issue and prevents superficial solutions.\n   - **Multi/Second Order Thinking** ([1](https://fs.blog/second-order-thinking/), [2](https://betterletter.substack.com/p/second-order-thinking), [3](https://medium.com/@noahmp/second-order-thinking-3fc2a224b131)): Think beyond immediate consequences. Consider the ripple effects of actions and potential downstream impacts to make more informed decisions.\n   - [**CATWOE**](https://www.toolshero.com/problem-solving/catwoe-analysis/): Analyze a problem from different perspectives (customers, actors, transformation, world view, owner, environmental constraints). This ensures a holistic understanding of the issue and its context.\n   - [**Cause and Effect / Fishbone or Ishikawa**](https://en.wikipedia.org/wiki/Ishikawa_diagram): Visually map potential causes of a problem, categorizing them to identify root causes and relationships. This promotes systematic exploration and prevents overlooking factors.\n   - [**Drilling Down**](https://sigma.software/about/media/problem-solving-techniques-part-two#2.-drill-down): Break complex problems into smaller, more manageable parts. This allows for focused investigation and helps identify specific areas for improvement.\n   - **SRE Handbook Guidance**: These chapters provide practical advice on managing incidents effectively, including communication, coordination, and postmortem analysis. They emphasize a blameless culture focused on learning and improvement.\n       - [Chapter 14](https://sre.google/sre-book/managing-incidents/)\n       - [Chapter 15](https://sre.google/sre-book/postmortem-culture/)\n\n4. **Consider all potential contributing factors**. RCAs consider a broad range of potential causes, including technical issues, policy issues, human factors, process breakdowns, and external influences. It's crucial to avoid jumping to conclusions or focusing solely on the most obvious cause(s).\n\n5. **Collect and analyze data**. Data is critical for supporting RCA conclusions and may include reviewing logs, monitoring metrics, internal incident reports, and other relevant information to identify patterns and anomalies.\n\n6. **Involve relevant stakeholders**. RCAs are a collaborative effort involving engineers, operators, support teams, and other relevant stakeholders to ensure a diverse range of perspectives and expertise is considered.\n\n7. **Prioritize action items**. The ultimate goal of an RCA is to prevent future incidents caused by the same failures; therefore, it's important to identify and prioritize actionable recommendations that address the identified root causes.\n\n8. **Focus on blameless postmortems**. Emphasize a blameless culture when conducting postmortems. The focus is on learning from the incident and improving systems, not on assigning blame or punishing individuals.\n\n9. **Continuously improve the process**. RCA is an iterative process where an organization continuously refines its approach based on lessons learned from previous incidents and evolving best practices.\n\n### Community participation in the reporting process\n\n#### Who can submit an Incident Report?\n\nAnyone should feel encouraged to submit an Incident Report that’s founded upon credible and well-substantiated evidence.\n\nSome Root Store Operator policies require CA Owners to submit an Incident Report as described on this page after self-discovering or being made aware of an Incident (e.g., receiving and corroborating an issue described in a [Certificate Problem Report](https://cabforum.org/working-groups/server/baseline-requirements/requirements/#161-definitions)).\n  \n#### Are there other ways to become involved in the reporting process?\n\nAbsolutely! There are many ways to participate in the incident reporting process beyond submitting new reports. Everyone is encouraged to actively contribute by commenting on existing reports and engaging in constructive discussions. This can include, but is not limited to:\n- providing additional information,\n- asking clarifying questions,\n- discussing technical aspects of the incident,\n- suggesting corrective actions,\n- highlighting opportunities for improvement,\n- contributing lints to open source linting projects to promote improved future issue detection/prevention, and\n- sharing lessons learned from past experiences.\n\nIndividuals representing CA Owners are especially encouraged to participate broadly in the reporting processes, extending their contributions beyond incidents involving only their own organization. Sharing insights and perspectives across organizational boundaries fosters a collaborative learning environment and strengthens the overall security posture of the Web PKI ecosystem.\n\nPlease keep all comments constructive, relevant, and in line with the [CCADB Code of Conduct](https://docs.google.com/document/d/19ALqEvHtTE6OUTz2FaOXrU9gruIdvia5EDh3hXeGpZA/edit#heading=h.cumc0pgd1s7c) to ensure productive dialogue.\n\n#### What Bugzilla account can I use?\n\n**For individuals affiliated with a Publicly-Trusted CA Owner:**\n- **To better encourage blamelessness**, when posting incident reports or responding to comments on reports for which they are affiliated, participants MAY respond from a Bugzilla account associated with one of the CA e-mail aliases disclosed to the CCADB, rather than an individual contributor’s account.\n- **To better respect a desire for individual privacy and potential risk of retaliation**, individuals participating in the reporting process MAY participate **responsibly** from an account that does not identify the individual posting or their organizational affiliation.\n\n**For everyone else:** Create a new Bugzilla account following [these](https://bugzilla.mozilla.org/createaccount.cgi) instructions. \n\n**Remember**, please keep all comments constructive, relevant to the corresponding report, and in line with the [CCADB Code of Conduct](https://docs.google.com/document/d/19ALqEvHtTE6OUTz2FaOXrU9gruIdvia5EDh3hXeGpZA/edit#heading=h.cumc0pgd1s7c).\n\n### Report lifecycle management\n\n#### How do I submit a report?\n\nCreate a new Bugzilla issue by filling out [this form](https://bugzilla.mozilla.org/enter_bug.cgi?format=__default__&product=CA%20Program&component=CA%20Certificate%20Compliance&bug_type=task). \n\n- The \"Summary\" field in Bugzilla (i.e., \"Subject line\") MUST begin with the CA Owner’s name, followed by a colon, and a brief title that highlights the type of incident being reported (e.g., \"EXAMPLE CA OWNER: Incorrect Subject RDN Encoding\"). The CA Owner's name SHOULD match exactly with the CA Owner value in the CCADB.\n- The \"Description\" field MAY contain a Preliminary or Full Incident Report (copied and pasted from the corresponding Markdown template, as explained [below](#report-templates)).\n\n#### How are reports scoped?\n\nThere SHOULD be a single Incident Report for each distinct matter, and CA Owners MUST submit an additional, separate Incident Report when:\n- policy requires the revocation of one or more certificates by a certain deadline, such as those in BR Section 4.9, but that deadline will not be or has not been met by the CA Owner (i.e., a delayed revocation Incident Report).\n- in the process of researching one incident, another incident with a distinct root cause and/or remediation is discovered.\n- after an incident is marked resolved in Bugzilla, the incident reoccurs.\n\nAll reports MUST be free-standing and not rely on the contents of other reports.  While reports MAY repeat information from discussions or Bugzilla comments, they SHOULD summarize previous findings.  CA Owners are responsible for compiling a complete report according to these guidelines, even if information exists elsewhere.\n\n#### What format is used?\n\nUse one of the templates below, depending on the type of report being disclosed:\n\n- [Preliminary Incident Report](#preliminary-incident-report) (for third party reporters and CA Owners submitting Preliminary Incident Reports)\n- [Full Incident Report](#full-incident-report) (for CA Owners submitting Full Incident Reports)\n\nReport content MUST be provided in Markdown (i.e., not in the form of an attachment) and SHOULD utilize Markdown's [formatting features](https://docs.github.com/en/get-started/writing-on-github/getting-started-with-writing-and-formatting-on-github/basic-writing-and-formatting-syntax) (headers, lists, emphasis, etc.) to ensure clarity and readability. Individuals submitting reports SHOULD use Bugzilla's \"preview\" feature to confirm rendering appears as expected before posting.\n\nLearn more about expected report content and a description of the fields included in the reporting templates [here](#report-field-definitions-and-expectations).\n\n#### When are reports expected?\n\nWithin 72 hours of a CA Owner becoming aware of an incident (i.e., the \"initial incident disclosure\") or an audit finding not previously disclosed in an Incident Report, the CA Owner MUST either:\n\n- disclose a Preliminary or Full Incident Report; or\n- respond to a Preliminary Incident Report previously created for the incident by a third party reporter.\n\nIn its initial report (i.e, Preliminary or Full Incident Report) or reply to a third-party report, the CA Owner MUST:\n\n- accurately disclose the impact of the incident (e.g., the corpus of then-known mis-issued certificates); and\n- describe whether the incident should be considered contained (e.g., because certificate issuance was stopped) or ongoing.\n\nIf the described impact of the incident is later found to be inaccurate, the CA Owner MUST clearly communicate a correction, identifying when each following change was detected, the circumstances that led to the inaccuracy, and how this will be avoided in the future.\n\nWhile Full Incident Reports SHOULD be posted as soon as possible, they MUST be posted within 14 days of the incident’s initial disclosure.\n\n#### When are reports updated?\n\nCA Owners should respond promptly to comments and questions, and MUST respond within 7 days, even if only to acknowledge the request and provide a timeline for a full response.\n\nOpen reports MUST be updated:\n- on or before the \"Next update\" date in the \"Whiteboard\" field of the bug (note: CA Owners MAY request the \"Next update\" Whiteboard field be set by a Root Store Operator to align with a specific date related to an open Action Item.);\n- within 7 days, if a \"Next update\" date is not recorded;\n- in response to community questions or comments as described above; or\n- when Action Items are changed, completed, or delayed.\n\nIn the case of Incident Reports with a Whiteboard field of \"revocation-delay\", reports SHOULD be updated every 3 days and MUST be updated no less frequently than every 7 days to describe a summary of: \n- the number of certificates that have been revoked;\n- the number of certificates that have not yet been revoked;\n- the number of certificates planned for revocation that have expired; and\n- an estimate for when all remaining revocations will be completed.\n\n#### How are reports closed?\n\nWhen all Action Items are complete and no outstanding comments or questions remain, CA Owners MUST request closure in a Bugzilla comment using the template [below](#incident-closure-summary). Upon doing so, a final call for comments will be made by a Bugzilla moderator, and the report will be closed accordingly.\n\n### Report Templates\n\nThe following templates MUST be used when submitting incident reports or requesting report closures.\n- [Preliminary Incident Report Template](#preliminary-incident-report)\n- [Full Incident Report Template](#full-incident-report)\n- [Report Closure Template](#closure-report)\n\nCA Owners submitting reports MUST complete all applicable fields in the relevant template.  Fields that are not applicable MUST still be included and marked 'N/A'.\n\nLearn more about expected report content and a description of the fields included in the templates [below](#incident-report-field-definitions-and-expectations).\n\n#### Preliminary Incident Report\n\n```markdown\n## Preliminary Incident Report\n\n### Summary\n- **Incident description:**\n- **Relevant policies:** \n- **Source of incident disclosure:** \n\n```\n\n#### Full Incident Report\n\n```markdown\n## Full Incident Report\n\n### Summary\n\n- **CA Owner CCADB unique ID:** \n- **Incident description:** \n- **Timeline summary:**\n   - **Non-compliance start date:** \n   - **Non-compliance identified date:** \n   - **Non-compliance end date:** \n- **Relevant policies:** \n- **Source of incident disclosure:** \n\n### Impact\n\n- **Total number of certificates:**\n- **Total number of \"remaining valid\" certificates:** \n- **Affected certificate types:** \n- **Incident heuristic:** \n- **Was issuance stopped in response to this incident, and why or why not?:** \n- **Analysis:** \n- **Additional considerations:** \n\n### Timeline\n\n### Related Incidents\n\n| Bug                                | Date                        | Description                                                            |\n|------------------------------------|-----------------------------|------------------------------------------------------------------------|\n| [Related Bug ID](Related Bug URL)  | Date Related Bug was opened | A description of how the subject Bug is related to the Bug referenced. |\n\n### Root Cause Analysis\n\n**Contributing Factor #: title**\n- **Description:** \n- **Timeline:** \n- **Detection:** \n- **Interaction with other factors:** \n- **Root Cause Analysis methodology used:**\n\n### Lessons Learned\n\n- **What went well:** \n- **What didn’t go well:** \n- **Where we got lucky:** \n- **Additional:** \n\n### Action Items\n\n| Action Item | Kind    | Corresponding Root Cause(s) | Evaluation Criteria | Due Date   | Status |\n| ----------- | ----    | --------------------------- | ------------------- | -----------| ------ |\n| Example     | Prevent | Root Cause # 1              | Criteria            | 2025-01-19 | Value  |\n\n### Appendix\n\n```\n\n#### Closure Report\n\n```markdown\n\n### Report Closure Summary\n\n- **Incident description:** \n- **Incident Root Cause(s):**  \n- **Remediation description:**\n- **Commitment summary:**  \n\nAll Action Items disclosed in this report have been completed as described, and we request its closure.\n\n```\n\n### Report field definitions and expectations\n\nThe following sections are intended to describe expected Incident Report content. All fields are mandatory for the corresponding report type, except when described below.\n\nIf submitted by the CA Owner corresponding with the report, all fields included in the relevant template MUST be completed. Fields that are not applicable MUST be included in the report and identified as 'N/A'.\n\n#### Incident Reports\n\n**Summary:** The Summary section contains a short description of the nature of the issue and useful background information. This provides just enough context for readers to understand the details in the rest of the report. \n\n| Field                           | Description                              |  \n|---------------------------------|------------------------------------------| \n| **CA Owner CCADB unique ID*** | The CCADB unique ID value (begins with \"A\" followed by a six-digit number) corresponding to the CA Owner's \"CA Owner/Certificate\" record disclosed in the CCADB.  |\n| **Incident description** | A short description of the nature of the issue. This provides just enough context for new readers to understand the details of the incident. |\n| **Timeline summary*** | Describe (1) when the non-compliance began (2), when the non-compliance was detected, and (3) when the non-compliance ended or is expected to end. |\n| **Relevant policies** | Describe the policy name(s), applicable version(s), and corresponding section(s) that result in this problem being diagnosed as an incident. |\n| **Source of incident disclosure*** | Choice of \"Self Reported\", \"Third Party Reported\", or \"Audit\". |\n\n*Note*: If notified of an incident by an external, third party reporter, please respect their privacy by *only* disclosing their name if affirmatively approved to do so (e.g., say \"we received a report from a community member\" instead of explicitly naming individuals). Fields marked with an asterisk (*) are not required in Preliminary Incident Reports if submitted by a third party reporter.\n\n**Impact:** The Impact section contains a description of the size and nature of the incident. For example: how many certificates, OCSP responses, or CRLs were affected; whether the affected objects share features (such as issuance time, signature algorithm, or validation type); and whether the CA Owner had to cease issuance during the incident. \n\nIf certificates are impacted, the Impact section MUST include the following information:  \n\n| Field                           | Description                              |  \n|---------------------------------|------------------------------------------| \n| **Total number of certificates** | The total count of all certificates affected by the issue(s) described in this Incident Report, including expired and revoked certificates. |\n| **Total number of \"remaining valid\" certificates** | The total count of certificates affected by the issue(s) described in this Incident Report, minus expired and revoked certificates. Minimally, this set of certificates MUST be disclosed in the Appendix section of this report. |\n| **Affected certificate types** |  A summary of the corresponding CA/Browser Forum policy OIDs (i.e., DV, IV, OV, and EV) that appear in the certificates affected by this incident (e.g., \"This incident affects DV and OV certificates.”) |\n| **Incident heuristic** | **EITHER:** <br><br>**(1)** describe a heuristic that would allow a third party to assemble the full corpus of affected certificates, if not provided in the Appendix (e.g., \"Any certificate containing policy OID 1.2.3.4.5.6 and issued between 11/13/2024 and 4/11/2024 is affected by this incident. Certificates that have been revoked or are expired are omitted from the certificate list disclosed in the Appendix.\") <br><br> **(2)** clearly explain why this isn't possible (e.g., \"This incident affected every certificate issued between 5/25/2023 and 6/15/2024 that relied upon BR Validation Method 3.2.2.4.19. Because the relied upon validation method is not described in a certificate, this heuristic cannot be used by a third party to assemble the full corpus of affected certificates. Certificates that have been revoked or expired have been omitted from the certificate list disclosed in the Appendix.), or <br><br> **(3)** the full corpus of affected certificates are disclosed in the Appendix.|\n| **Was issuance stopped in response to this incident, and why or why not?** | Yes/No with explanation (e.g., \"Yes. As described in the incident timeline, issuance was stopped after learning of this issue to correct the corresponding certificate profile.\") |\n| **Analysis** | Required when the Whiteboard field contains ‘revocation-delay’, the factors and rationales behind the decision to delay revocation (including detailed and substantiated explanations of how extensive harm would result to third parties–such as essential public services or widely relied-upon systems–and why the situation is exceptionally rare and unavoidable). |\n| **Additional considerations** | This field is optional. Share any additional considerations that might be useful in describing the size and nature of the incident. For example, if the issue affected precertificates and certificates differently, describe how and why in more detail here. |\n\n**Timeline:** The Timeline section includes a detailed timeline of all events and actions leading up to and taken during and after the incident. The timeline MUST include not just the actual discovery of the incident and subsequent events, but also relevant events occurring beforehand (e.g., something changed or was introduced). All times MUST be in UTC or UTC+local offset, and SHOULD have at least minute-level granularity.\n\nExpected Timeline elements:\n- All policy, process, and software changes that contributed to the Root Cause(s)\n- The time at which the incident began\n- The time at which the CA Owner became aware of the incident\n- The time at which the CA Owner received a Certificate Problem Report (if applicable)\n- The time at which the CA Owner provided a preliminary report on its findings to the entity who filed the Certificate Problem Report (if applicable)\n- The time at which the CA Owner provided a preliminary report on its findings to the affected Subscriber(s) (if applicable)\n- The time at which the CA Owner concluded and disclosed the scope and impact of the incident\n- The time at which the CA Owner updated the scope and impact of the incident (if applicable)\n- The time(s) at which the CA Owner is expected to complete revocation of affected certificates (if applicable, but required when Whiteboard field contains ‘revocation-delay’)\n- The time(s) at which the CA Owner actually completed revocation of affected certificates (if applicable, but required when Whiteboard field contains ‘revocation-delay’)\n- The time at which the incident ended\n- The times at which issuance ceased and resumed (if applicable)\n\n**Related Incidents:** The Related Incidents section includes a list of all incidents disclosed to the ['CA Certificate Compliance' Bugzilla Component](https://bugzilla.mozilla.org/buglist.cgi?product=CA%20Program&component=CA%20Certificate%20Compliance&resolution=---) related to this incident that have taken place minimally in the last two (2) years. \"Related Incidents\" MUST consider incidents beyond those corresponding to the CA Owner subject of this report.\n\n| Field                           | Description                              |  \n|---------------------------------|------------------------------------------| \n| **Related Bug ID** | The Bugzilla ID corresponding to the related incident. |\n| **Related Bug URL** | The Bugzilla URL corresponding to the related incident. |\n| **Opened date** | The date the related incident was opened. |\n| **Description** | A description of how the related incident is similar to the subject incident report. |\n\n**Root Causes:** The Root Causes section contains a detailed analysis of the conditions which combined to give rise to the issue. It is unusual for an incident to have a single root cause; often there is a confluence of several issues such as a software bug, insufficient checks, and a malformed request. Make sure that all contributing factors are identified and described, including noting when they first arose and how they avoided detection until they were discovered or identified.\n\n| Field                           | Description                              |  \n|---------------------------------|------------------------------------------| \n| **Description** | Describe the specific condition, event, or issue that contributed to the incident. Analyze its role in the incident's development. Consider when this factor first arose and its initial impact.  |\n| **Timeline** | Trace the timeline of the contributing factor from its inception to its role in the incident. When was it introduced or created? How did it evolve over time? |\n| **Detection** | Describe how the contributing factor was detected, and explain how it avoided detection prior to the incident. Were there inadequate safeguards, missed signals, or other factors that allowed it to persist? |\n| **Interaction with other factors** | Analyze how the contributing factor interacted with other identified factors to create the conditions for the incident. Did it amplify other issues or create new vulnerabilities? |\n| **Root Cause Analysis methodology used** | This field is optional, but recommended. A description of the methodology used to derive the issue described above (e.g., \"5-Whys\", Fishbone Diagram, Pareto Analysis, etc.) |\n\n**Lessons Learned:** The Lessons Learned section describes what the organization learned from the incident, including what they did well and what they need to improve.\n\n| Field                           | Description                              |  \n|---------------------------------|------------------------------------------| \n| **What went well?** | A list of things that caused the incident to have less impact than it otherwise could have, such as early detection, rapid response, or good safety mechanisms. This section provides an opportunity for others to learn from the good practices of this CA Owner. |\n| **What didn’t go well?** | A list of things that caused the incident to have more impact than it otherwise would have, such as missing checks or unclear documentation. Each item here MUST have at least one corresponding Action Item below and SHOULD provide opportunities for others to ensure they make similar improvements if they haven’t already. |\n| **Where we got lucky?** | A list of things that went well, but which cannot be relied upon, such as early detection by an external security researcher or limited impact simply due to a small number of requests. Items here SHOULD generally also have corresponding Action Items, so that the CA Owner doesn’t have to rely on luck in the future. |\n| **Other** | Any other type of \"lesson learned\" that does not otherwise fit in the above categories, e.g., internal/external circumstances or environmental conditions; discovery of problematic processes, policies, or workflows; communication gaps; resource challenges; task ownership; overlooked warning signs; underutilized tools; etc. Each item mentioned here MUST have at least one corresponding Action Item. |\n\n**Action Items:** The Action Items section contains a list of remediation items that will be undertaken to ensure that similar incidents do not reoccur in the future. For example, if the Whiteboard field contains ‘revocation-delay’, the Action Items list MUST include steps reasonably calculated to prevent or reduce future revocation delays. Note that it is not sufficient for these action items to simply stop this incident, they MUST create additional protections to prevent future incidents.\n  \n| Field                           | Description                              |  \n|---------------------------------|------------------------------------------| \n| **Action Item description** | A detailed description of the action to be taken. |\n| **Kind** | A classification of whether the action will help *Prevent* future incidents, *Mitigate* the impact of future incidents, or *Detect* future incidents. CA Owners are encouraged to propose action items in all three categories, with an emphasis on Prevent and Mitigate. |\n| **Corresponding Root Cause(s)** | The specific Root Cause that the Action intends to remediate (i.e., each problem/issue identified in the \"Root Cause Analysis\" and \"What didn't go well\" Sections MUST be mapped to at least one specific action item). |\n| **Evaluation criteria** | Describe how the CA Owner will measure the effectiveness of the Action Item in addressing the Root Cause. Include how the public can also measure this impact, if applicable. CA Owners SHOULD prioritize objective and publicly measurable evidence (i.e., evidence that can be independently verified by the public, such as through Certificate Transparency log data, audit statements, CA policy documents, and public communications (e.g., website content, surveys, etc.)). While external metrics are preferred, these Guidelines recognize that some Action Items may have limited measurable outcomes. When objective metrics are not readily available, CA Owners SHOULD provide a qualitative assessment of the Action Item's effectiveness and explain how they will monitor its impact. Even after an Incident Report has been closed, CA Owners are strongly encouraged to provide periodic updates (e.g., 3, 6, and 12 months post-closure, or at other determined appropriate intervals) related to the ongoing efficacy of the Action Item, as measured against the evaluation criteria. This helps demonstrate a continued commitment to improvement and transparency.\n| **Due date** | A date by which the action item will be complete. |\n| **Status** | Describe the status of the action item using either \"Ongoing\", \"Complete\", \"Delayed\", or \"Canceled\". |\n\n**Appendix:** The Appendix section is for all supporting data: log files, graphs and charts, etc. In the case of incidents that directly impact certificates (i.e., not only precertificates), the Appendix MUST disclose details related to the time-valid, including revoked, certificates affected by the incident.\n\nFor incidents affecting less than 10,000 certificates, a CA Owner MUST attach a comma separated listing of certificate details including the following fields for each:\n\n| Field                           | Description                              |  \n|---------------------------------|------------------------------------------| \n| **Precertificate SHA-256 hash** | The SHA-256 hash of the DER encoded precertificate. |\n| **Certificate SHA-256 hash** | The SHA-256 hash of the DER encoded certificate. |\n| **Subject** | The Subject field of the certificate. |\n| **Issuer** | The Issuer field of the certificate. |\n| **Not before** | The notBefore field of the certificate. |\n| **Not after** | The notAfter field of the certificate. |\n| **Serial #** | The Serial Number field of the certificate, in hex. |\n| **dNSNames** | The dNSName appearing in the certificate. |\n| **Is revoked?** | \"Yes\", \"Planned\",\"Delayed\", or \"N/A\" (for expired) |\n| **Revocation date** | Actual Date, Planned Date, or \"N/A\" |\n| **Revocation reason** | The reasonCode corresponding with the certificate's entry on the CRL. |\n\nFor incidents affecting 10,000 or more certificates, a CA Owner MAY instead attach a text file where each line is of the form https://crt.sh/?sha256=[sha256 fingerprint of the certificate].\n\nWhen the incident being reported involves an S/MIME certificate, if disclosure of personally identifiable information in the certificate MAY be contrary to applicable law, please provide at least the certificate serial number and SHA256 hash of the certificate.\n\n##### Incident Closure Summary\n\nThe Incident Closure Summary allows a CA Owner to signal they believe an incident is ready for closure.\n\n| Field                           | Description                              |  \n|---------------------------------|------------------------------------------| \n| **Incident description** | A few sentences summarizing the incident. |\n| **Incident Root Cause(s)** | A few sentences summarizing the root cause(s). |\n| **Remediation description** | A few sentences summarizing the incident's remediation. |\n| **Commitment summary** | A list of any ongoing commitments made in response to this incident beyond those described in the Action Items section. Ongoing commitments can be a useful representation of a CA Owner's continuous improvement efforts and should be considered distinct from, but complementary to Action Items included in the report given a broader scope and long-term or continuous timeframe that would otherwise result in the subject incident report being open for an extended period of time. |\n\n### Illustrative practices\n\n#### Are there examples of \"good\" practices?\n\n1. **Be detailed and precise**:\n   - Document, in detail, all findings and steps taken from discovery or initial notification through to remediation.\n   - Include precise timestamps, technical data, and decision rationales.\n   - Share relevant configurations, code snippets, or settings that were implicated, in compliance with security norms (i.e., do not disclose confidential or sensitive information).\n\n2. **Respond promptly**:\n   - Acknowledge receipt of the incident report quickly.\n   - Provide initial assessments and expected timelines for resolution to keep stakeholders informed.\n   - Respond to comments or questions within one business day.\n  \n3. **Be candid, transparent, and objective**:\n   - Doing so allows community members to better understand report content, while also promoting integrity and transparency.\n\n4. **Rely on comprehensive Root Cause Analysis frameworks**:\n   - Use structured methodologies like the \"Five Whys\" or fault tree analysis to trace back to underlying issues.\n   - Involve diverse teams (security, operations, engineering) to ensure a multi-faceted evaluation.\n\n5. **Be proactive and thorough**:\n   - Implement immediate fixes to mitigate any ongoing risks.\n   - Develop long-term solutions that might involve architectural changes or the integration of new security tools and practices.\n\n6. **Engage with the community**:\n   - Participate in Web PKI forums and email distributions (e.g., public@ccadb.org) to both learn from and contribute to community knowledge.\n   - Share incident learnings in a way that respects confidentiality but helps other organizations prevent similar issues.\n   - Read and adopt best practices found in the [Bugzilla Incident Reports filed by other CA Owners](https://bugzilla.mozilla.org/buglist.cgi?product=CA%20Program&component=CA%20Certificate%20Compliance&bug_status=__open__&list_id=17075089).\n\n7. **Share iterative updates**:\n   - Provide an initial response, followed by regular updates aligned with [\"When should Incident Reports be updated?\"](#when-should-incident-reports-be-updated) as new information becomes available or as fixes are deployed..\n   - Close the loop with a final summary once the issue is fully resolved, detailing the lessons learned and future prevention strategies.\n  \n8. **Respect external reporter privacy**:\n   - If notified of an incident by an external, third party reporter, please respect their privacy by *only* disclosing their name if affirmatively approved to do so (e.g. say \"we received a report from a community member\" instead of explicitly naming individuals).\n  \n9. **Use Markdown formatting**:\n   - Markdown formatting (e.g., headers, lists, bolding, italics, etc.) can promote clarity, readability, and accessability. Learn more about Markdown formatting [here](https://docs.github.com/en/get-started/writing-on-github/getting-started-with-writing-and-formatting-on-github/basic-writing-and-formatting-syntax).\n\n#### Are there examples of \"bad\" practices?\n\n1. **Generic or evasive responses**:\n   - Avoid generic statements that do not address specific issues raised in the report or in response to community questions or comments.\n   - Refrain from providing non-committal or ambiguous answers that might be interpreted as evasive.\n\n2. **Posturing**:\n   - Avoid blaming others or external factors.\n   - Resist downplaying the severity or implications of the incident.\n\n3. **Claims that are subjective, unqualified opinions, speculative, or impossible to substantiate**:\n   - Avoid making claims that are speculative or that cannot be corroborated (e.g. \"there is no security impact due to this issue.\")\n\n4. **Non-acknowledgment of responsibility**:\n   - Clearly accept responsibility where and when due, which helps in rebuilding trust and demonstrating accountability.\n\n5. **Superficial Root Cause Analysis**:\n   - Avoid superficial analyses that do not thoroughly explore all contributing factors.\n   - Ensure that the analysis is not prematurely concluded, missing deeper systemic issues.\n\n6. **Committing to opaque actions**:\n   - Ensure actions and follow-up work items are detailed and specific.\n   - Promote accountability by describing how the success of an action item can be evaluated as having been successful in addressing the root cause.\n\n7. **Inadequate monitoring post-report**:\n   - Establish mechanisms to monitor the long-term effectiveness of implemented changes.\n   - Be ready to revisit and revise solutions if subsequent issues indicate that the initial response was not entirely effective.\n  \n#### Are there examples of \"good\" reports?\n\nHere are some examples of good practice, where a CA Owner did most or all of the things recommended above:\n\n- [Serving invalid or incomplete CRLs](https://bugzilla.mozilla.org/show_bug.cgi?id=1900129)\n     - Clear Summary and Impact statements allow readers to quickly understand the scope of the incident\n     - Detailed and thorough evaluation of existing safeguards that failed, allowing for an understanding of why the the incident was allowed to take place\n     - Comments and questions from the community were responded to promptly.\n\n- [keyCompromise key blocking deviation from CP/CPS](https://bugzilla.mozilla.org/show_bug.cgi?id=1886876)\n     - Clear indication of Preliminary and Full Incident Reports.\n     - Detailed timeline that identifies all policy, process, and software changes that contributed to the root cause, and an indication of when the incident began and ended.\n     - Detailed Root Cause Analysis that offers background on the various conditions that gave rise to the issue.\n     - Timely updates in response to questions posed, continued analysis, and changes to Action Items.\n \n- [Failure to properly validate IP address](https://bugzilla.mozilla.org/show_bug.cgi?id=1876593)\n     - Significant amount of background information that informs the timeline of the incident.\n     - Clear identification of the contributing factors that contributed to the incident that notes how many of them avoided detection in the Root Cause Analysis.\n     - Action Items that prevent, mitigate, and detect what didn’t go well.\n     - Timely and detailed updates conveying Action Item status.\n\nUpon adoption of the updated report templates described on this page, examples of good practice will be updated.\n",
    "timestamp": "2025-05-23T16:34:39.845183",
    "tags": [],
    "severity": "high",
    "services_affected": [
      "api",
      "web",
      "database",
      "monitoring"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "aws",
      "postgresql",
      "elasticsearch",
      "prometheus",
      "jenkins"
    ],
    "failure_pattern": "dependency_failure",
    "timeline_events": [],
    "blast_radius": "global",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 1.0
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/zhangjxCS/CSKnowledgeHub/blob/6d7f0457d0746cb9cc51f15d8bcf5c3cd34a82f6/System%20Design/Incident%20Insights.md",
    "title": "Incident Insights.md",
    "content": "# Incident Insights\n\n## Requirments\n\n<img src=\"../Images/requirement.png\" alt=\"requirement\" style=\"zoom:50%;\" />\n\n- **User Authentication and Account Management:**\n  - Implement a secure user signup and login process.\n  - Allow users to create and manage their own accounts.\n  - Enable users to invite others to join their account with appropriate access controls and permissions.\n- **Data Integration with Ticketing Tools:**\n  - Develop integrations to ingest ticket data from various ticketing tools like PagerDuty, Opsgenie, etc.\n  - Ensure compatibility and secure data transfer protocols for these integrations.\n  - Provide options for users to customize the data they want to import from these tools.\n- **Data Analysis and Incident Clustering:**\n  - Design algorithms to analyze ticket data and cluster incidents based on patterns.\n  - Implement machine learning or statistical techniques to identify and categorize incident patterns.\n  - Develop functionality to update and refine clustering algorithms based on new data.\n- **Incident Trend Visualization:**\n  - Create a dashboard to visualize incident trends using charts and graphs.\n  - Allow users to filter, sort, and drill down into specific data points for detailed analysis.\n  - Provide options for users to customize the dashboard based on their preferences.\n- **Integration with GenAI for Command Generation:**\n  - Integrate with GenAI or similar services to generate debugging commands for incidents or clusters.\n  - Ensure that the integration securely handles data and respects user privacy.\n  - Provide users with options to refine or customize the command suggestions.\n- **Remote Command Execution Capability:**\n  - Develop a secure, remote command execution feature that allows users to run commands on their clusters, virtual machines, etc., directly from the app.\n  - Ensure robust authentication and authorization mechanisms to prevent unauthorized access.\n  - Include features to track and log command execution for auditing and troubleshooting purposes.\n- **User Interface and Experience:**\n  - Design an intuitive and user-friendly interface that allows easy navigation and access to all features.\n  - Ensure the application is responsive and accessible on various devices and browsers.\n  - Implement feedback mechanisms to gather user input for continuous improvement.\n- **Documentation and Support:**\n  - Provide comprehensive documentation on how to use the application, including guides for integration and troubleshooting.\n  - Set up a support system for users to report issues or seek help.\n\n## High-Level Design\n\n### Architecture\n\n<img src=\"../Images/Flowcharts.png\" alt=\"Flowcharts\" style=\"zoom: 67%;\" />\n\n1. **Web App:**The main interface that users interact with. It serves the client-side of your application, typically consisting of HTML, CSS, and JavaScript.\n2. **CDN (Content Delivery Network):**A distributed network of servers that delivers static content to users based on their geographic location to reduce latency.\n3. **DNS Server:**Translates domain names into IP addresses so browsers can load internet resources. It directs the user's request to the appropriate server.\n4. **Load Balancer:**Distributes incoming network traffic across multiple servers to ensure no single server becomes overwhelmed and to improve redundancy and reliability.\n5. **Web Proxy:**Acts as an intermediary between the users’ requests from the internet and the API server. It can also cache content and handle SSL termination.\n6. **API Server:**The server that processes API requests. It executes business logic, interacts with the database, and communicates with other services.\n7. **Message Queue:**Decouples processes by allowing them to communicate asynchronously. The API server sends messages to the queue, which are then processed by background workers.\n8. **Background Worker:**A service that processes jobs from the message queue. This can include tasks such as sending emails, processing files, or performing batch operations.\n9. **Database:**Stores and manages data. The API server queries the database to retrieve, update, or delete data as requested.\n10. **Cache:**Temporarily stores frequently accessed data to reduce database load and speed up response times.\n11. **Data Pipeline Orchestrator:**Manages and automates the flow of data between systems. It ensures that data processing tasks are executed in the correct order and manages dependencies between tasks.\n\n### Technology\n\n- **Web App:** React, Typescript\n- **CDN (Content Delivery Network):** AWS Cloudfront\n- **DNS Server:** AWS Route 53\n- **Load Balancer:** AWS Elastic Load Balancer (ELB)\n- **Web Proxy:** Nginx deployed on Kubernetes\n- **API Server:** Python Flask gunicorn deployed on Kubernetes\n- **Message Queue:** Redis Queue\n- **Background Worker:** Kubernetes pods listening on Redis Queue\n- **Database:** PostgreSQL\n- **Cache:** Redis\n- **Data Pipeline Orchestrator:** Airbyte\n- **Monitoring:** Sentry, Pagerduty, Prometheus\n- **CI/CD:** Github Action, ArgoCD\n- **Authorization:** Auth0\n\n## Deep Dive\n\n### Integrations\n\n<img src=\"../Images/Flowcharts (1)-3026409.png\" alt=\"Flowcharts (1)\" style=\"zoom:67%;\" />\n\n1. **Website:**\n   - A user provides credentials for their ticketing tool.\n   - These credentials are then verified by the system to ensure they are correct.\n   - Upon successful verification, a connection to the user's ticketing tool is established.\n2. **API Server:**\n   - The API server saves the integration details in database\n   - It can submit a job to message queue to load data steammingly.\n   - It can create a workflow in Airbyte, which is a data pipeline orchestrator.\n3. **Message Queue:**\n   - The message queue receives the data load job and holds it until a background worker is available to process it.\n4. **Data Pipeline Orchestrator:**\n   - The orchestrator schedules and manages the execution of data workflows.\n   - It performs the initial run of the workflow and schedules subsequent runs as necessary.\n5. **Background Worker:**\n   - A background worker picks up the data load job from the message queue. This worker is responsible for loading streaming incidents into the system.\n   - Another background worker can also be triggered from Data Pipeline Orchestrator to load history data or do incremental data update.\n   - Once the data load is finished, the data is saved into database.\n6. **Database:**\n   - The database serves as the persistent storage for all data related to tickets and integration details.\n   - It stores the processed ticket information from the streaming incidents and the integration details from the data pipeline orchestrator.\n7. **Cron Job:**\n   - The cron job kicks off every 15 minute to transform the new data in the database to the unified schema\n   - The unified schema unifies the schema from different ticketing tools\n\n### Runbooks\n\n<img src=\"../Images/Blank diagram-3028745.png\" alt=\"Blank diagram\" style=\"zoom:67%;\" />\n\n1. **Website:**\n   - Users input ticket data or prompts into the website.\n   - The website sends this data via an API request to the backend to initiate runbook generation or conduct a search.\n   - Periodically, the frontend makes API requests to check the status and results of the runbook generation job.\n   - Users can save the generated runbooks, prompting the frontend to send a save request to the backend.\n\n2. **API Server:**\n   - On receiving a request to generate a runbook, the server submits the task to the message queue and records the job status in the database.\n   - If it receives a save or delete runbook request, the server updates the runbook vector DB index with the new data or removes the existing data.\n\n3. **Message Queue:**\n   - Manages the queue of jobs for runbook generation, ensuring they're processed sequentially or based on priority.\n\n4. **Background Worker:**\n   - Listens to the message queue and dequeues jobs for processing.\n   - Interacts with OpenAI using the RAG approach, where it first retrieves relevant commands or content from the runbooks index and then generates a new runbook by sending prompts based on ticket data or user input to OpenAI.\n   - Saves the generated runbook or search results to the database and updates the job status to reflect completion.\n\n5. **Cache:**\n   - Stores frequently accessed data, like active runbook jobs and their statuses, to provide quicker access and reduce database load.\n\n6. **Database:**\n   - Holds temporary results of runbook generations and job statuses.\n   - Permanently stores runbooks if a user decides to save them.\n\n7. **Runbook Index:**\n   - A vector database that indexes the content of runbooks, allowing for efficient retrieval during the RAG process.\n   - Updated when runbooks are saved or deleted to maintain an accurate and searchable index.\n\n### Automations\n\n<img src=\"../Images/Blank diagram (1).png\" alt=\"Blank diagram (1)\" style=\"zoom:67%;\" />\n\n1. **Website:**\n   - Guides users through integrating with AWS, detailing how to set up roles with the necessary permissions to access AWS services like EKS, EC2, VPC, etc.\n   - Collects AWS credentials, including the role and AWS Lambda function names, from the user and securely transmits them to the API server.\n2. **User AWS Account:**\n   - The user follows the website's instructions to create a role within their AWS account, granting specific permissions needed for automation tasks.\n   - The user creates an AWS Lambda function intended for automation of tasks based on runbook instructions.\n   - Once set up, the user submits their AWS credentials to the web app, enabling it to execute actions on their AWS resources.\n3. **API Server:**\n   - Safely stores the received AWS user credentials in a secure manner adhering to best practices for handling sensitive information.\n   - Keeps a record of automation details, which include configurations and scripts that specify the automation tasks.\n4. **User Runbook:**\n   - Users compile runbooks with detailed instructions for automating tasks on AWS resources.\n   - Users configure triggers for runbooks, such as scheduled executions or event-based activations, and communicate these settings to the API server.\n5. **Lambda Function:**\n   - Stands by for execution, set to carry out the automation tasks as outlined in the user-defined runbook.\n6. **Database:**\n   - The database acts as the persistent storage for AWS credentials, automation configurations, and runbook details, facilitating quick retrieval and secure storage.\n7. **Workflow Triggers:**\n   - Users have the option to manually trigger runbooks, initiating the execution of the associated Lambda function.\n   - The API server orchestrates the automation workflow, which can automatically invoke the Lambda function with parameters derived from the runbook.\n   - The API server can programmatically trigger the user's Lambda function as outlined by the runbook's automation workflow.\n\n## Wrap up\n\n### Summary\n\n1. **User Authentication and Account Management**: Secure signup and login, account management, and invitation with access controls.\n2. **Data Integration with Ticketing Tools**: Ingesting data from ticketing tools, ensuring compatibility and customizable data import.\n3. **Data Analysis and Incident Clustering**: Using algorithms and machine learning to cluster and categorize incident patterns.\n4. **Incident Trend Visualization**: A dashboard for visualizing trends with customization options.\n5. **Integration with GenAI for Command Generation**: Generating debugging commands, ensuring secure data handling.\n6. **Remote Command Execution Capability**: Secure feature for running commands remotely with robust authentication and logging.\n\n### Improvement\n\n1. **Enhanced Machine Learning Models**: Refine the data analysis algorithms to improve accuracy in incident clustering and prediction.\n2. **Real-time Data Processing**: Implement real-time data analytics for faster incident response and trend detection.\n3. **Advanced Security Features**: Introduce additional layers of security, especially for the remote command execution feature.\n",
    "timestamp": "2025-05-23T16:34:40.764309",
    "tags": [],
    "severity": "high",
    "services_affected": [
      "api",
      "web",
      "database",
      "cache",
      "queue",
      "auth",
      "monitoring"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "kubernetes",
      "aws",
      "postgresql",
      "redis",
      "elasticsearch",
      "kafka",
      "rabbitmq",
      "nginx",
      "prometheus",
      "grafana",
      "jenkins"
    ],
    "failure_pattern": "resource_exhaustion",
    "timeline_events": [],
    "blast_radius": "localized",
    "detection_time": null,
    "mitigation_actions": [
      "on Kubernetes"
    ],
    "quality_score": 0.9400000000000001
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/knowledgesystems/knowledgesystems-k8s-deployment/blob/3e1e93c5170cc1b3426ecc184370fe16ff70a9de/docs/incidents-log.md",
    "title": "incidents-log.md",
    "content": "---\nicon: alert\n---\n# Incidents Log\n\n## 2023/05/24 Mongodb session service crash\n- Issue with session-service reported at 3.30PM\n- We identified that the mongo session service was down and had used up all disk space (20Gi) shortly. That same day we created a new session service with 100Gi storage but weren't able to recover all old sessions\n- On 2023/05/26 we were able to restore old sessions. We did lose two days of saved sessions (5/24-5/25)\n\n### Remediation\n\n#### Bring mongodb back\n- Take snapshot of existing EBS volume using AWS (no auto snapshots were set up)\n- Set up new mongo database with helm:\n    `helm install cbioportal-session-service-mongo-20230524 --version 7.3.1 --set image.tag=4.2,persistence.size=100Gi bitnami/mongodb`\n- Connect the session service to use that one (see [commit](https://github.com/knowledgesystems/knowledgesystems-k8s-deployment/commit/0042f9f1f0be26692032160fed82744d8f2a94dc))\n\n#### Bring session data back\nThe mongo data was stored in an AWS snapshot in mongo's binary format, so not immediately accessible for re-import into another database. First we had to bring that back.\n\nWhat didn't work:\n- Tried various approach of expanding existing k8s volume, but was tricky b/c volume expansion wasn't enabled for existing PersistenceVolumeClaims\n\nWhat did work:\n- Instead, started a new AWS EC2 instance with that volume attached. For whatever reason i couldn’t see the attached volume within ubuntu at first (had to use [lsblk and mount](https://stackoverflow.com/questions/22816878/my-mounted-ebs-volume-is-not-showing-up)). Might be something you always have to do\n- Once the volume was accessible, we ran `docker run bitnami/mongodb` with the correct mount location specified to load the data\n- From a separate shell used mongodump as described (cmds are described in cbioportal/README)\n- Now that we got the dump, we set up a new mongo database in the k8s cluster to load the data:\n    `helm install cbioportal-session-service-mongo-4dot2-20230525   --set image.tag=4.2,persistence.size=100Gi bitnami/mongodb`\n- Then we had to copy over the data into that k8s volume. Unf `kubectl cp` didn't work (some TCP timeout error). Instead we figured we could create a 2nd container int he mongodb pod with rsync to copy over the data into a container in the existing k8s deployment:\n    ```\n    kubectl edit deployment cbioportal-session-service-mongo-4dot2-20230525-mongodb\n    # add an ubuntu container\n       - args:\n         - infinity\n         command:\n         - sleep\n         image: ubuntu\n         imagePullPolicy: Always\n         name: ubuntu\n         resources: {}\n         terminationMessagePath: /dev/termination-log\n         terminationMessagePolicy: File\n         volumeMounts:\n         - mountPath: /bitnami/mongodb\n           name: datadir\n    # wait for it to be deployed\n    kubectl exec -it cbioportal-session-service-mongo-4dot2-20230525-mongodb-f6wp9vx -c ubuntu -- /bin/sh\n    # now you can apt-get install rsync, ssh, whatev into that container and rsync the mongo dump\n    # then re-import the mongo database dump using instructions in cbioportal/README\n",
    "timestamp": "2025-05-23T16:34:41.186679",
    "tags": [],
    "severity": "high",
    "services_affected": [
      "api",
      "database"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "kubernetes",
      "docker",
      "aws",
      "postgresql",
      "elasticsearch",
      "jenkins"
    ],
    "failure_pattern": "resource_exhaustion",
    "timeline_events": [],
    "blast_radius": "localized",
    "detection_time": null,
    "mitigation_actions": [
      "kubectl exec -it cbioportal-session-service-mongo-4dot2-20230525-mongodb-f6wp9vx -c ubuntu -- /bin/sh"
    ],
    "quality_score": 0.92
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/CrowdStrike/rusty-falcon/blob/69964d0c4b3658c5b49b767a8141bcfce1a20b13/docs/src/docs/IncidentsApi.md",
    "title": "IncidentsApi.md",
    "content": "# \\IncidentsApi\n\nAll URIs are relative to *<https://api.crowdstrike.com>*\n\nMethod | HTTP request | Description\n------------- | ------------- | -------------\n[**crowd_score**](IncidentsApi.md#crowd_score) | **GET** /incidents/combined/crowdscores/v1 | Query environment wide CrowdScore and return the entity data\n[**get_behaviors**](IncidentsApi.md#get_behaviors) | **POST** /incidents/entities/behaviors/GET/v1 | Get details on behaviors by providing behavior IDs\n[**get_incidents**](IncidentsApi.md#get_incidents) | **POST** /incidents/entities/incidents/GET/v1 | Get details on incidents by providing incident IDs\n[**perform_incident_action**](IncidentsApi.md#perform_incident_action) | **POST** /incidents/entities/incident-actions/v1 | Perform a set of actions on one or more incidents, such as adding tags or comments or updating the incident name or description\n[**query_behaviors**](IncidentsApi.md#query_behaviors) | **GET** /incidents/queries/behaviors/v1 | Search for behaviors by providing an FQL filter, sorting, and paging details\n[**query_incidents**](IncidentsApi.md#query_incidents) | **GET** /incidents/queries/incidents/v1 | Search for incidents by providing an FQL filter, sorting, and paging details\n\n## crowd_score\n\n> models::DomainPeriodMsaEnvironmentScoreResponse crowd_score(filter, offset, limit, sort)\nQuery environment wide CrowdScore and return the entity data\n\n### Parameters\n\nName | Type | Description  | Required | Notes\n------------- | ------------- | ------------- | ------------- | -------------\n**filter** | Option<**String**> | Optional filter and sort criteria in the form of an FQL query. For more information about FQL queries, see [our FQL documentation in Falcon](https://falcon.crowdstrike.com/support/documentation/45/falcon-query-language-feature-guide). |  |\n**offset** | Option<**i32**> | Starting index of overall result set from which to return ids. |  |\n**limit** | Option<**i32**> | The maximum records to return. [1-2500] |  |\n**sort** | Option<**String**> | The property to sort on, followed by a dot (.), followed by the sort direction, either \\\"asc\\\" or \\\"desc\\\". |  |\n\n### Return type\n\n[**models::DomainPeriodMsaEnvironmentScoreResponse**](domain.MsaEnvironmentScoreResponse.md)\n\n### Authorization\n\n[oauth2](../README.md#oauth2)\n\n### HTTP request headers\n\n- **Content-Type**: Not defined\n- **Accept**: application/json\n\n[[Back to top]](#) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to Model list]](../README.md#documentation-for-models) [[Back to README]](../README.md)\n\n## get_behaviors\n\n> models::DomainPeriodMsaExternalBehaviorResponse get_behaviors(body)\nGet details on behaviors by providing behavior IDs\n\n### Parameters\n\nName | Type | Description  | Required | Notes\n------------- | ------------- | ------------- | ------------- | -------------\n**body** | [**MsaPeriodIdsRequest**](MsaPeriodIdsRequest.md) |  | [required] |\n\n### Return type\n\n[**models::DomainPeriodMsaExternalBehaviorResponse**](domain.MsaExternalBehaviorResponse.md)\n\n### Authorization\n\n[oauth2](../README.md#oauth2)\n\n### HTTP request headers\n\n- **Content-Type**: application/json\n- **Accept**: application/json\n\n[[Back to top]](#) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to Model list]](../README.md#documentation-for-models) [[Back to README]](../README.md)\n\n## get_incidents\n\n> models::DomainPeriodMsaExternalIncidentResponse get_incidents(body)\nGet details on incidents by providing incident IDs\n\n### Parameters\n\nName | Type | Description  | Required | Notes\n------------- | ------------- | ------------- | ------------- | -------------\n**body** | [**MsaPeriodIdsRequest**](MsaPeriodIdsRequest.md) |  | [required] |\n\n### Return type\n\n[**models::DomainPeriodMsaExternalIncidentResponse**](domain.MsaExternalIncidentResponse.md)\n\n### Authorization\n\n[oauth2](../README.md#oauth2)\n\n### HTTP request headers\n\n- **Content-Type**: application/json\n- **Accept**: application/json\n\n[[Back to top]](#) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to Model list]](../README.md#documentation-for-models) [[Back to README]](../README.md)\n\n## perform_incident_action\n\n> models::DomainPeriodMsaIncidentPerformActionResponse perform_incident_action(body, update_detects, overwrite_detects)\nPerform a set of actions on one or more incidents, such as adding tags or comments or updating the incident name or description\n\n### Parameters\n\nName | Type | Description  | Required | Notes\n------------- | ------------- | ------------- | ------------- | -------------\n**body** | [**DomainPeriodEntityActionRequest**](DomainPeriodEntityActionRequest.md) | Incident Update request body containing minimum 1 and maximum 5000 Incident ID(s) and action param(s) to be performed action against. | [required] |\n**update_detects** | Option<**bool**> | If true, update assigned-to-uuid and or status of detections associated with the incident(s). Defaults to false |  |[default to false]\n**overwrite_detects** | Option<**bool**> | If true and update-detects is true, the assigned-to-uuid or status for ALL detections associated with the incident(s) will be overwritten. If false, only detects that have default values for assigned-to-uuid and/or status will be updated. Defaults to false. Ignored if 'update-detects' is missing or false. |  |[default to false]\n\n### Return type\n\n[**models::DomainPeriodMsaIncidentPerformActionResponse**](domain.MsaIncidentPerformActionResponse.md)\n\n### Authorization\n\n[oauth2](../README.md#oauth2)\n\n### HTTP request headers\n\n- **Content-Type**: application/json\n- **Accept**: application/json\n\n[[Back to top]](#) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to Model list]](../README.md#documentation-for-models) [[Back to README]](../README.md)\n\n## query_behaviors\n\n> models::MsaPeriodQueryResponse query_behaviors(filter, offset, limit, sort)\nSearch for behaviors by providing an FQL filter, sorting, and paging details\n\n### Parameters\n\nName | Type | Description  | Required | Notes\n------------- | ------------- | ------------- | ------------- | -------------\n**filter** | Option<**String**> | Optional filter and sort criteria in the form of an FQL query. For more information about FQL queries, see [our FQL documentation in Falcon](https://falcon.crowdstrike.com/support/documentation/45/falcon-query-language-feature-guide). |  |\n**offset** | Option<**i32**> | Starting index of overall result set from which to return ids. |  |\n**limit** | Option<**i32**> | The maximum records to return. [1-500] |  |\n**sort** | Option<**String**> | The property to sort on, followed by a dot (.), followed by the sort direction, either \\\"asc\\\" or \\\"desc\\\". |  |\n\n### Return type\n\n[**models::MsaPeriodQueryResponse**](msa.QueryResponse.md)\n\n### Authorization\n\n[oauth2](../README.md#oauth2)\n\n### HTTP request headers\n\n- **Content-Type**: Not defined\n- **Accept**: application/json\n\n[[Back to top]](#) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to Model list]](../README.md#documentation-for-models) [[Back to README]](../README.md)\n\n## query_incidents\n\n> models::DomainPeriodMsaIncidentQueryResponse query_incidents(sort, filter, offset, limit)\nSearch for incidents by providing an FQL filter, sorting, and paging details\n\n### Parameters\n\nName | Type | Description  | Required | Notes\n------------- | ------------- | ------------- | ------------- | -------------\n**sort** | Option<**String**> | The property to sort on, followed by a dot (.), followed by the sort direction, either \\\"asc\\\" or \\\"desc\\\". |  |\n**filter** | Option<**String**> | Optional filter and sort criteria in the form of an FQL query. For more information about FQL queries, see [our FQL documentation in Falcon](https://falcon.crowdstrike.com/support/documentation/45/falcon-query-language-feature-guide). |  |\n**offset** | Option<**i32**> | Starting index of overall result set from which to return ids. |  |\n**limit** | Option<**i32**> | The maximum records to return. [1-500] |  |\n\n### Return type\n\n[**models::DomainPeriodMsaIncidentQueryResponse**](domain.MsaIncidentQueryResponse.md)\n\n### Authorization\n\n[oauth2](../README.md#oauth2)\n\n### HTTP request headers\n\n- **Content-Type**: Not defined\n- **Accept**: application/json\n\n[[Back to top]](#) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to Model list]](../README.md#documentation-for-models) [[Back to README]](../README.md)\n",
    "timestamp": "2025-05-23T16:34:41.784847",
    "tags": [],
    "severity": "low",
    "services_affected": [
      "api",
      "web",
      "auth"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "aws",
      "elasticsearch"
    ],
    "failure_pattern": null,
    "timeline_events": [],
    "blast_radius": "localized",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 0.42000000000000004
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/preed/incident-lifecycle-model/blob/a8ae7918029a72e4c77d921dc204e9e7a7c23f21/2-incident-response.md",
    "title": "2-incident-response.md",
    "content": "# Incident Response\n\n|        | Language Used        | Behavior Displayed |\n| ------ | -------------------- | ------------------ |\n| **Novice** | <ol><li>Generalized statements regarding events/activities in progress, i.e. \"Something is wrong with the network!\"</li> <li>\"I have no idea what to do.\"</li> <li>\"Have you tried turning it off and turning it on again?\"</li> <li>No standard language.</li></ol> | <ol><li>_Team is **event-focused**; some (or all) of the team are \"**alarmed**\" by the occurrence of incidents and the actions taken in response_</li> <li>_The commencement of an incident is “fuzzy” and occurs primarily external to the team (manual NOC notification via “call-out” or email)_</li> <li>_Inconsistent response once incident has commenced_</li></ol> |\n| **Beginner** | <ol><li>\"I think there’s a problem with the database, network,\" etc.</li> <li>\"I think [specific person] is familiar with how that works; we need to find them\"</li> <li>Standardized language among the teams</li></ol> | <ol><li>_The team is **area-focused**, i.e. incidents involve specific system components; some (or all) of the team \"**fears**\" the occurrence of incidents_</li> <li>_Incident response based on \"tribal knowledge\" and usually requires specific people to effectively respond_</li> <li>_Incident remediation is inconsistent and based on the specific actors involved in the response_</li></ol> |\n| **Competent** | <ol><li>\"The deployment caused the database to hang.\"</li> <li>\"We've got a knowledge base article on how to handle this.\"</li> <li>Some team members are familiar with standardized Incident Management System terminology and may use it during incident responses.</li></ol> | <ol><li>_The team is **action-focused**; they are \"**aware**\" that incident occurrence is a normal side effect of system operations_</li> <li>_The commencement of incidents is well-defined and well-understood by the team; most incident response are triggered via automated alerting/monitoring_</li> <li>_The team has identified incident \"responders\" and those incident responders know what is expected of them_</li></ol> |\n| **Proficient** | <ol><li>\"Have the database, network and search on-calls perform a systems status and report back to the incident commander.\"</li> <li>Team is familiar with standardardized Incident Management System terminology</li></ol> | <ol><li>_The team is **technology-focused**; they \"**accept**\" that incident occurrence is a normal side effect of system operations_</li> <li>_Incident response becomes an aspect of organizational and team “culture”; incident response expectations and “how tos” are part of on-boarding/recurrent training_</li> <li>_Teams collaborate cross-functionally to determine overall plan for large-scale incident response coordination and resolution_</li></ol> |\n| **Advanced** | <ol><li>\"What parts of the service did not 'self-heal' and need manual intervention?\"</li> <li>\"System A on-call rep and System-B on-call rep both reported issues which may seem related? Are we sure those two groups are talking to each other? If not, let's put them in touch immediately.\"</li> <li>Team uses/values standardardized Incident Management System terminology</li></ol> | <ol><li>_The team is **systems-focused**; they \"**embrace**\" incidents as learning experiences and improvement opportunities_</li> <li>_Incident conclusion criteria and processes are documented and understood by incident responders and includes crew dissolution steps and inputs into the ongoing incident remediation process_</li> <li>_The organization considers outside-normal-business hours incident response or repeated business-hours incident response to be inhumane to system operators_</li></ol> |\n",
    "timestamp": "2025-05-23T16:34:42.213784",
    "tags": [],
    "severity": "low",
    "services_affected": [
      "web",
      "database",
      "monitoring"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "kubernetes",
      "postgresql",
      "elasticsearch",
      "prometheus",
      "grafana",
      "jenkins"
    ],
    "failure_pattern": "monitoring_blind_spot",
    "timeline_events": [],
    "blast_radius": "localized",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 0.8200000000000001
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/CiscoDevNet/terraform-provider-intersight/blob/49cdab3d1947af77147838d1f3fd07fe8337dc67/intersight_gosdk/docs/ServicenowIncidentResponse.md",
    "title": "ServicenowIncidentResponse.md",
    "content": "# ServicenowIncidentResponse\n\n## Properties\n\nName | Type | Description | Notes\n------------ | ------------- | ------------- | -------------\n**ObjectType** | **string** | A discriminator value to disambiguate the schema of a HTTP GET response body. | \n**Count** | Pointer to **int32** | The total number of &#39;servicenow.Incident&#39; resources matching the request, accross all pages. The &#39;Count&#39; attribute is included when the HTTP GET request includes the &#39;$inlinecount&#39; parameter. | [optional] \n**Results** | Pointer to [**[]MoTagKeySummary**](MoTagKeySummary.md) |  | [optional] \n\n## Methods\n\n### NewServicenowIncidentResponse\n\n`func NewServicenowIncidentResponse(objectType string, ) *ServicenowIncidentResponse`\n\nNewServicenowIncidentResponse instantiates a new ServicenowIncidentResponse object\nThis constructor will assign default values to properties that have it defined,\nand makes sure properties required by API are set, but the set of arguments\nwill change when the set of required properties is changed\n\n### NewServicenowIncidentResponseWithDefaults\n\n`func NewServicenowIncidentResponseWithDefaults() *ServicenowIncidentResponse`\n\nNewServicenowIncidentResponseWithDefaults instantiates a new ServicenowIncidentResponse object\nThis constructor will only assign default values to properties that have it defined,\nbut it doesn't guarantee that properties required by API are set\n\n### GetObjectType\n\n`func (o *ServicenowIncidentResponse) GetObjectType() string`\n\nGetObjectType returns the ObjectType field if non-nil, zero value otherwise.\n\n### GetObjectTypeOk\n\n`func (o *ServicenowIncidentResponse) GetObjectTypeOk() (*string, bool)`\n\nGetObjectTypeOk returns a tuple with the ObjectType field if it's non-nil, zero value otherwise\nand a boolean to check if the value has been set.\n\n### SetObjectType\n\n`func (o *ServicenowIncidentResponse) SetObjectType(v string)`\n\nSetObjectType sets ObjectType field to given value.\n\n\n### GetCount\n\n`func (o *ServicenowIncidentResponse) GetCount() int32`\n\nGetCount returns the Count field if non-nil, zero value otherwise.\n\n### GetCountOk\n\n`func (o *ServicenowIncidentResponse) GetCountOk() (*int32, bool)`\n\nGetCountOk returns a tuple with the Count field if it's non-nil, zero value otherwise\nand a boolean to check if the value has been set.\n\n### SetCount\n\n`func (o *ServicenowIncidentResponse) SetCount(v int32)`\n\nSetCount sets Count field to given value.\n\n### HasCount\n\n`func (o *ServicenowIncidentResponse) HasCount() bool`\n\nHasCount returns a boolean if a field has been set.\n\n### GetResults\n\n`func (o *ServicenowIncidentResponse) GetResults() []MoTagKeySummary`\n\nGetResults returns the Results field if non-nil, zero value otherwise.\n\n### GetResultsOk\n\n`func (o *ServicenowIncidentResponse) GetResultsOk() (*[]MoTagKeySummary, bool)`\n\nGetResultsOk returns a tuple with the Results field if it's non-nil, zero value otherwise\nand a boolean to check if the value has been set.\n\n### SetResults\n\n`func (o *ServicenowIncidentResponse) SetResults(v []MoTagKeySummary)`\n\nSetResults sets Results field to given value.\n\n### HasResults\n\n`func (o *ServicenowIncidentResponse) HasResults() bool`\n\nHasResults returns a boolean if a field has been set.\n\n### SetResultsNil\n\n`func (o *ServicenowIncidentResponse) SetResultsNil(b bool)`\n\n SetResultsNil sets the value for Results to be an explicit nil\n\n### UnsetResults\n`func (o *ServicenowIncidentResponse) UnsetResults()`\n\nUnsetResults ensures that no value is present for Results, not even an explicit nil\n\n[[Back to Model list]](../README.md#documentation-for-models) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to README]](../README.md)\n\n\n",
    "timestamp": "2025-05-23T16:34:42.651323",
    "tags": [],
    "severity": "low",
    "services_affected": [
      "api",
      "web"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "gcp"
    ],
    "failure_pattern": null,
    "timeline_events": [],
    "blast_radius": "localized",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 0.37
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/sodadata/docs/blob/a7e566c0dd2b70eaedb796c43de8f69f3c70ce87/_includes/create-incidents.md",
    "title": "create-incidents.md",
    "content": "1. Log in to your Soda Cloud account, then navigate to the **Checks** dashboard. \n2. For the check you wish to investigate, click the stacked dots at right, then select **Create Incident**. Provide a **Title**, **Severity**, and **Description** of your new incident, then save. \n3. In the **Incident** column of the check result, click the Incident link to access the Incident page where you can record the following details:\n* **Severity**: Minor, Major, or Critical\n* **Status**: Reported, Investigating, Fixing, Resolved\n* **Lead**: a list of team members from whom you can assign the Lead Investigator role\n4. Save your changes.\n5. If you have connected your Soda Cloud account to Slack, navigate to the **Integrations** tile, then click the auto-generated link that connects directly to a newly-created, public channel in your Slack workspace that is dedicated to the investigation and resolution of the incident and invite team members to the channel to collaborate on resolving the data quality issue. <br />If you have integrated Soda Cloud with [MS Teams]({% link soda/integrate-msteams.md %}) or another [third-party tool]({% link soda/integrate-webhooks.md %}), like Jira or ServiceNow, you can access those tools via auto-generated links in the **Integrations** tile, as well.",
    "timestamp": "2025-05-23T16:34:43.060654",
    "tags": [],
    "severity": "high",
    "services_affected": [],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "grafana"
    ],
    "failure_pattern": null,
    "timeline_events": [],
    "blast_radius": "localized",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 0.37
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/safetyfirstpdx/safetyfirstpdx.github.io/blob/e5a534e6a3fc5cc7488d799f98fe2e0fc3dbb185/resources/incident_response.md",
    "title": "incident_response.md",
    "content": "---\nlayout: topic\ntitle: Incident Response\n---\n\nYour incident response plan needs to be flexible enough for anything that could happen in your scope of activities, and specific enough that everyone involved knows what they need to do. You can [download our template](/training/code_of_conduct/TemplateIncidentResponseGuide.pdf) as a starting point.\n\n## Roles\n\nA community may have:\n\n- Participants\n- Volunteers\n- Staff members and organizers\n- Supporting organizations or boards\n\nYour **primary responders** should be people who can take responsibility for your community's response to an incident. You need to prevent conflicts of interest: no couples or family members working together. Don't take on this responsibility alone. Two or more people are needed to hold each other accountable, and an ideal group size is usually three to five responders. People will need to rotate in and out of the response group over time, and take turns being on call or in the lead position.\n\nDescribe what each set of participants and organizers is expected to do. There will be a [reporting]({% link resources/reporting.md %}) chain — maybe just two steps from \"participant\" to \"organizer/responder\" — and you may also be accountable to a parent or partner organization.\n\nThis is the time to think about how your ability to receive and respond to information about code of conduct violations fits into your [governance]({% link resources/governance.md %}) structure.\n\n### Examples of possible response teams\n\n- A three person group made up of a board member from the open source project's foundation plus two people who reflect under-represented backgrounds within the project. All three are involved in responding to any issues that are reported, and the board member coordinates with the rest of the board when necessary for legal or financial reasons. The board is also kept in the loop when public announcements are required.\n- Two user group leaders who handle most problems on the spot and through in-person conversations.\n- A five person team that includes a conference co-chair, the chair of the content committee, and three representative community members selected by the main conference committee. All five make decisions together about any issues that go above a minor impact/minor risk level.\n\n## Making a plan\n\nMap out what kinds of situations you've had in the past or are concerned about encountering. Decide in advance how you'd like to handle it. Common issues can be fully scripted out, and more unusual or complex issues will benefit from a more formal decision-making process. See the [template](/training/code_of_conduct/TemplateIncidentResponseGuide.pdf) for an example of how that can be handled.\n\n## Training\n\nPeople forget things in the middle of a chaotic situation. In addition to a written plan, it's highly beneficial to practice. You can attend one of our [community training sessions](/training/code_of_conduct) for this, or ask us about a custom workshop.\n\n## Communication\n\nAt in-person events, the plan should be available at key areas like volunteer rooms and info desks. Also include a cover page with the contact info for all responders, and the physical address of your event venue for when you need to call for emergency services. Online it should be easily accessible to all organizers and responders. Don't consider this a public document: you may need to include personal information for responders, or be planning for situations that would be worse if everyone had your notes on how you will respond.\n\nResponse teams should look for the greatest security possible when communicating with each other. Make use of a secure chat system like Signal, and refrain from putting sensitive information in your emails to each other.\n\n## Other resources\n\n- [Enforcing Your Code of Conduct: effective incident response](http://www.slideshare.net/aeschright/enforcing-your-code-of-conduct-effective-incident-response)\n- [Enforcing Your Code of Conduct video](http://confreaks.tv/videos/osfeels2015-enforcing-your-code-of-conduct-effective-incident-response)",
    "timestamp": "2025-05-23T16:34:43.485496",
    "tags": [],
    "severity": "high",
    "services_affected": [
      "api",
      "web"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "aws",
      "azure",
      "kafka"
    ],
    "failure_pattern": "resource_exhaustion",
    "timeline_events": [],
    "blast_radius": "localized",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 0.87
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/r9y-dev/r9y-map/blob/900ec11a60c8997168f359904dc593c2210b06fe/docs/Postmortem_reviews_actions.md",
    "title": "Postmortem_reviews_actions.md",
    "content": "# Postmortem reviews/actions\n\n**Postmortem Reviews/Actions:**\n\nPostmortem reviews are systematic analyses of incidents or outages to identify root causes and prevent future occurrences. They involve gathering data, analyzing events, and developing action plans to address the underlying issues.\n\n**Key Steps in Postmortem Reviews:**\n\n1. **Incident Identification:** Clearly define the incident or outage that triggered the review.\n\n2. **Data Collection:** Gather relevant data, such as logs, metrics, and eyewitness accounts, to understand the sequence of events.\n\n3. **Timeline Creation:** Construct a detailed timeline of events leading up to and during the incident.\n\n4. **Root Cause Analysis:** Identify the root cause(s) of the incident using techniques like the \"Five Whys\" or \"Fishbone Diagram.\"\n\n5. **Action Plan Development:** Formulate concrete actions to address the root causes and prevent similar incidents in the future.\n\n6. **Communication and Documentation:** Share the findings of the postmortem review with stakeholders and document the process and outcomes for future reference.\n\n**Examples and References:**\n\n* [Google Cloud Postmortem Culture](https://landing.google.com/sre/postmortem-culture): Google's approach to postmortem reviews, emphasizing the importance of learning from incidents.\n\n* [Netflix Chaos Engineering Postmortem](https://netflixtechblog.com/a-postmortem-on-netflixs-chaos-engineering-incident-part-1-introducing-the-blast-radius-53c77b3f0701): A detailed postmortem analysis of a major incident at Netflix, highlighting the value of chaos engineering in improving resilience.\n\n* [Etsy's Postmortem Process](https://codeascraft.com/2010/02/18/how-etsy-does-postmortems/): Etsy's postmortem process, focusing on gathering data, understanding the timeline, and identifying actionable insights.\n\n**Benefits of Postmortem Reviews:**\n\n* Improved incident response and recovery.\n* Identification of systemic issues and vulnerabilities.\n* Proactive prevention of future incidents.\n* Enhanced team collaboration and learning.\n* Increased confidence in systems and services.\n\nPostmortem reviews are a crucial part of building reliable and resilient systems. By conducting thorough analyses and taking appropriate actions, organizations can significantly reduce the likelihood and impact of future incidents.\n\n## Related Tools and Products\n\n**Tools and Products for Postmortem Reviews/Actions:**\n\n1. **Blameless:**\n\n   * [Website](https://blameless.com/)\n   * **Description:** Blameless is an incident management platform that helps teams conduct thorough postmortem reviews. It provides features like automated data collection, timeline creation, root cause analysis, and action tracking.\n\n2. **PagerDuty:**\n\n   * [Website](https://www.pagerduty.com/)\n   * **Description:** PagerDuty is an incident response and on-call management platform. It offers postmortem features such as incident retrospectives, blameless RCA, and automated documentation.\n\n3. **Honeycomb:**\n\n   * [Website](https://www.honeycomb.io/)\n   * **Description:** Honeycomb is an observability platform that enables detailed analysis of distributed systems. Its features include real-time tracing, profiling, and error tracking, which can be valuable during postmortem reviews.\n\n4. **xMatters:**\n\n   * [Website](https://www.xmatters.com/)\n   * **Description:** xMatters is an incident management and communication platform. It provides postmortem capabilities such as timeline reconstruction, RCA, and automated reporting.\n\n5. **Postmortem.io:**\n\n   * [Website](https://postmortem.io/)\n   * **Description:** Postmortem.io is a dedicated platform for conducting postmortem reviews. It offers guided templates, collaboration tools, and analytics to help teams analyze incidents and take corrective actions.\n\n6. **RCA.sh:**\n\n   * [Website](https://rca.sh/)\n   * **Description:** RCA.sh is an open-source tool specifically designed for root cause analysis. It provides a structured approach to identifying and addressing the underlying causes of incidents.\n\nThese tools and resources can assist teams in conducting effective postmortem reviews, facilitating collaboration, and implementing actionable insights to prevent future incidents.\n\n## Related Terms\n\n**Related Terms to Postmortem Reviews/Actions:**\n\n* **Incident Management:** The process of identifying, responding to, and resolving incidents or outages in a timely and effective manner.\n\n* **Root Cause Analysis (RCA):** The process of identifying the underlying causes of an incident or outage to prevent future occurrences.\n\n* **Systems Engineering:** An interdisciplinary approach to engineering that focuses on the design, development, and integration of complex systems.\n\n* **Reliability Engineering:** The branch of engineering that deals with the analysis, prediction, and improvement of the reliability of systems and components.\n\n* **Availability Engineering:** The branch of engineering that focuses on ensuring that systems and services are available to users when needed.\n\n* **Resilience Engineering:** The study of how systems can withstand and recover from disruptions, failures, and other challenges.\n\n* **Chaos Engineering:** The practice of intentionally introducing controlled failures into a system to identify weaknesses and improve resilience.\n\n* **Site Reliability Engineering (SRE):** A discipline that emphasizes the application of software engineering practices to infrastructure and operations tasks, including incident management and postmortem reviews.\n\n* **DevOps:** A set of practices and tools that emphasizes collaboration and communication between software developers and IT operations teams, often involving automated incident response and postmortem analysis.\n\n* **Incident Retrospectives:** A type of postmortem review that focuses on identifying lessons learned and improvements that can be made to prevent similar incidents in the future.\n\nThese related terms encompass the broader context of incident management, system reliability, and engineering practices that contribute to effective postmortem reviews and actions.\n\n## Prerequisites\n\nBefore conducting effective postmortem reviews and taking appropriate actions, several key elements need to be in place:\n\n* **Incident Management Process:** A well-defined incident management process ensures that incidents are identified, triaged, and resolved promptly. This process should include clear roles and responsibilities, communication channels, and escalation procedures.\n\n* **Data Collection and Analysis:** The ability to collect and analyze relevant data is crucial for postmortem reviews. This includes logs, metrics, traces, and eyewitness accounts. Having the necessary tools and infrastructure in place to gather and analyze this data is essential.\n\n* **Root Cause Analysis Methodology:** A structured approach to identifying the root causes of incidents is necessary to prevent future occurrences. This can involve techniques such as the \"Five Whys,\" \"Fishbone Diagram,\" or more formal methods like Fault Tree Analysis or Bayesian Network Analysis.\n\n* **Blameless Culture:** A culture that encourages open communication and learning from mistakes is essential for effective postmortem reviews. Teams should feel comfortable discussing incidents without fear of blame or retribution. This fosters a collaborative environment where the focus is on identifying systemic issues and implementing improvements.\n\n* **Stakeholder Involvement:** Involving key stakeholders, including engineers, operators, and management, is crucial for successful postmortem reviews. This ensures that diverse perspectives are considered and that the resulting actions are aligned with the organization's goals and priorities.\n\n* **Documentation and Communication:** Establishing a process for documenting and communicating the findings and action plans from postmortem reviews is essential. This helps ensure that lessons learned are shared across the organization and that necessary changes are implemented.\n\nHaving these elements in place sets the stage for conducting meaningful postmortem reviews that lead to actionable insights and improvements to prevent future incidents and enhance system reliability.\n\n## What's next?\n\nAfter conducting postmortem reviews and taking appropriate actions, several key steps should be taken to ensure continuous improvement and prevent similar incidents in the future:\n\n* **Follow Up and Monitoring:** Establish a process for following up on the implementation of action plans and monitoring their effectiveness. This ensures that corrective measures are implemented as intended and are having the desired impact.\n\n* **Share Lessons Learned:** Communicate the findings and lessons learned from postmortem reviews across the organization. This can be done through documentation, presentations, or knowledge-sharing sessions. The goal is to raise awareness and foster a culture of learning and improvement.\n\n* **Update Documentation and Processes:** Incorporate the lessons learned and best practices identified during postmortem reviews into documentation, standard operating procedures (SOPs), and training materials. This ensures that new and existing team members have access to the latest knowledge and insights.\n\n* **Review and Adapt Postmortem Process:** Periodically review and refine the postmortem process itself to ensure it is effective and efficient. This may involve incorporating new tools, techniques, or stakeholder feedback to continuously improve the quality and impact of postmortem reviews.\n\n* **Conduct Regular Retrospectives:** Hold regular retrospectives to assess the effectiveness of incident management and postmortem practices. This allows teams to identify areas for improvement, celebrate successes, and adapt to changing circumstances.\n\n* **Benchmark and Share Industry Best Practices:** Engage with industry peers and communities to share and learn from best practices in postmortem reviews and incident management. This fosters a collaborative environment and contributes to the overall improvement of industry standards.\n\nBy taking these steps after postmortem reviews, organizations can create a continuous cycle of learning and improvement, reducing the likelihood and impact of future incidents and enhancing the overall reliability and resilience of their systems.",
    "timestamp": "2025-05-23T16:34:47.014161",
    "tags": [],
    "severity": "high",
    "services_affected": [
      "web",
      "database",
      "monitoring"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "aws",
      "prometheus",
      "jenkins"
    ],
    "failure_pattern": "monitoring_blind_spot",
    "timeline_events": [],
    "blast_radius": "localized",
    "detection_time": null,
    "mitigation_actions": [
      "confidence in systems and services"
    ],
    "quality_score": 0.95
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/fga-eps-mds/2018.1-Dr-Down/blob/3423374360105b06ac2c57a320bf2ee8deaa08a3/docs/POSTMORTEM.md",
    "title": "POSTMORTEM.md",
    "content": "# POSTMORTEM\n\n## Positivos:\n\n- A equipe em si evoluiu bastante, principalmente MDS.\n  - A dedicação e vontade deles foi importante nesse crescimento.\n- MDS - Aprenderam a argumentar e a participar mais.\n  - para isso, EPS os encorajou, pois sabíamos a importância de ter o feedback e imput de todos tanto para pontuar as histórias quanto para a comunicação do grupo.\n- A comunicação entre todos melhorou bastante.\n  - Para isso, o encorajamento para todos se colocarem e destacar a importância de uma boa comunicação para o bom andamento das atividades foram essenciais nesse processo.\n- Participar deste projeto e trabalhar como grupo somou muito para o crescimento de todos.\n  - Foram muitos aprendizados, tanto do ponto de vista acadêmico quanto pessoal.\n- MDS e EPS viraram uma equipe e ficamos muito unidos.\n- Os papeis fixos de EPS no inicio do projeto deram certo e a passagem de conhecimento foi muito boa.\n  - Graças a isto, conseguimos fazer uma boa transição para a fase de circular os papéis durante a R2.\n- O conhecimento de todos foi compartilhado.\n  - No caso dos pareamentos, o fato desses terem muitas vezes sido feitos presencialmente ajudou muito MDS.\n- 100% de cobertura de testes unitários - Começamos a testar desde pas primeiras histórias da R1 e conseguimos manter até o fim.\n  - Termos optado por exigir os testes desde o começo foi muito benéfico no fim, mas foi estressante no começo para MDS.\n    - Esse estresse é algo que outros grupos que quiserem fazer o mesmo que nós devem ter em mente e terão que saber gerenciar e compreender, afinal de contas os membros de MDS possivelmente estarão fazendo isso pela primeira vez e por isso terão dificuldades.\n- O Cookiecutter ajudou muito.\n  - Ele pode ser uma boa opção para DevOps que envolvam o Django.\n- Aprendemos a usar componentes e microsserviço.\n  - Apanhamos com microsserviços para implementá-lo, por não ser algo simples ou que estávamos acostumados a fazer.\n- Conseguimos cumprir com o planejado do Roadmap do Projeto.\n  - Para isso, quando necessário e possível, adiantávamos ou postergávamos histórias previstas para a sprint atual e/ou futuras.\n    - Adaptávamos a escolha das histórias ao quanto a semana dos membros do grupo seria puxada ou não (com provas e trabalhos, por exemplo) fazendo com que evitássemos dívidas técnicas, ajudássemos a reduzir a carga em cima das pessoas do grupo e ainda mantivéssemos uma entrega contínua a cada sprint.\n- Dedicação e compromisso de todos os membros.\n  - Fomos muito felizes em termos um grupo com pessoas dedicadas e compromissadas com o projeto.\n\n## Negativos:\n\n- Tivemos algumas problemas entre membros do grupo, mas que foram solucionados.\n  - Para evitar que isto crescesse e se tornasse algo maior, foi importante tanto isso ter sido percebido e solucionado rapidamente quanto a vontade de todos de não querer que este desentendimento se tornasse algo maior.\n  - No final foi bom para o nosso crescimento.\n- Um dos clientes não deu valor ao grupo. Ele só queria saber do produto, mas aparecia apenas uma vez no mês ou nem aparecia, mesmo com o grupo procurando por ele.\n  - O fato de termos tido um documento que nos guiou quanto ao que devíamos fazer nos salvou de termos maiores problemas e atrasos no Roadmap do Projeto em virtude dessa falta de feedback.\n- Alguns membros ficaram doente durante o semestre, mas mesmo assim o projeto deu certo.\n  - Aos futuros grupos que estejam lendo isso: se preocupem não apenas com o andamento do projeto, mas também com a saúde física e mental de si e de seus membros da equipe.\n- O escopo era grande e dificil, mas foi tudo entregue.\n  - Para que isso fosse possível, a construção de um grupo unido, dedicado e compromissado foi essencial.\n\n## Frases: \n\n\"Eu só tinha amigo que me puxava pra baixo e encontrei o grupo de MDS que me ajudou bastante a crescer\"\n\n\"Seu nome não é Jobs?\" - Victor Arnaud, fazendo descobertas na última sprint.\n\n\"Faço isso numa cagada\" - Sconetto.\n\n\"Tenho memória de piriquito\" - Victor Arnaud\n\n\"Jobs, posso comer mais um?\" - E assim o Arnuad comeu 10 cachorros quentes.\n\n\"Tô com fome\" - Daniel\n\n\"Não vai dar não\" - Equipe\n\n\"Cuidado com o risco Moreno(a)\" - membros do grupo para a Gabriela\n\n\"Palhaçada isso\" - Gabriela\n\n\"Gente, eu quero ir embora\" - Daniel\n\n\"Nada, nada e não\" - Daniel na daily não presencial\n\n\"Vou falar pouco hoje\" - Sconetto\n\n\"Gabriela, por quê você votou X pontos?\" - Diego\n\n\"Foi mal pelo atraso\" - Diego\n\n\"Porque essa história não é um 3, mas também não é um 8\" - o motivo para o Daniel haver votado 5 pontos em uma história\n",
    "timestamp": "2025-05-23T16:34:47.853950",
    "tags": [],
    "severity": "low",
    "services_affected": [
      "api",
      "web",
      "database"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "kubernetes"
    ],
    "failure_pattern": null,
    "timeline_events": [],
    "blast_radius": "localized",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 0.37
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/synaptiai/prompt-decorators/blob/64a4078cffd0a6278aea6d19b8b475796bd4cc50/docs/api/decorators/PostMortem.md",
    "title": "PostMortem.md",
    "content": "# PostMortem Decorator\n\nCreates incident reviews and postmortem documents.\n\n**Category**: Developer Workflow\n\n## Parameters\n\n| Parameter | Type | Description | Default |\n|-----------|------|-------------|--------|\n| `format` | `enum` | Document structure | `comprehensive` |\n| `focus` | `enum` | Analysis emphasis | `balanced` |\n| `audience` | `enum` | Target readers | `team` |\n\n## Format Options\n\n- `timeline`: Structure the postmortem as a chronological timeline of events.\n- `5-whys`: Use the 5 Whys technique to identify the root cause by repeatedly asking why the problem occurred.\n- `fishbone`: Organize the analysis using a fishbone (Ishikawa) diagram approach to categorize potential causes.\n- `comprehensive`: Create a comprehensive postmortem covering timeline, root cause analysis, impact assessment, and future prevention.\n\n## Focus Options\n\n- `what-happened`: Focus primarily on documenting what happened during the incident in detail.\n- `why`: Emphasize root cause analysis and why the incident occurred.\n- `prevention`: Concentrate on preventive measures and future safeguards.\n- `balanced`: Provide balanced coverage of what happened, why it happened, and how to prevent recurrence.\n\n## Audience Options\n\n- `team`: Write for the technical team with appropriate technical details.\n- `leadership`: Format for leadership with executive summary and business impact.\n- `stakeholders`: Address concerns of all stakeholders with both technical and business perspectives.\n- `public`: Create a public-facing document that explains the incident without revealing sensitive details.\n\n## Examples\n\n### Basic postmortem for a database outage\n\n```\n+++PostMortem(format=comprehensive, focus=balanced, audience=team)\nCreate a postmortem for the database outage we experienced yesterday that caused 45 minutes of downtime.\n```\n\nA comprehensive postmortem document analyzing the database outage, including timeline, root cause analysis, impact assessment, and preventive measures, written for a technical team audience.\n\n### Executive-focused incident review\n\n```\n+++PostMortem(format=timeline, focus=prevention, audience=leadership)\nAnalyze the recent security breach that affected our customer data.\n```\n\nA timeline-based postmortem focused on prevention strategies, formatted for leadership with executive summary and business impact assessment.\n\n## Model-Specific Implementations\n\n### gpt-4-turbo\n\n**Instruction:** Create a detailed postmortem document for the incident. Include what happened, why it happened, and how to prevent it in the future.\n\n**Notes:** Simplified instruction for models with more limited context windows.\n\n\n## Implementation Guidance\n\n### Software development team\n\n**Original Prompt:**\n```\nCreate a postmortem for the database outage we experienced yesterday that caused 45 minutes of downtime.\n```\n\n**Transformed Prompt:**\n```\nCreate a detailed postmortem document that analyzes the incident, identifies root causes, and proposes preventive measures. Create a comprehensive postmortem covering timeline, root cause analysis, impact assessment, and future prevention. Provide balanced coverage of what happened, why it happened, and how to prevent recurrence. Write for the technical team with appropriate technical details.\n\nCreate a postmortem for the database outage we experienced yesterday that caused 45 minutes of downtime.\n```\n\n**Notes:** The decorator adds structure and guidance for creating a comprehensive postmortem document tailored to the technical team.\n\n## Transformation Details\n\n**Base Instruction:** Create a detailed postmortem document that analyzes the incident, identifies root causes, and proposes preventive measures.\n\n**Placement:** prepend\n\n**Composition Behavior:** override\n\n**Parameter Effects:**\n\n- `format`:\n  - When set to `timeline`: Structure the postmortem as a chronological timeline of events.\n  - When set to `5-whys`: Use the 5 Whys technique to identify the root cause by repeatedly asking why the problem occurred.\n  - When set to `fishbone`: Organize the analysis using a fishbone (Ishikawa) diagram approach to categorize potential causes.\n  - When set to `comprehensive`: Create a comprehensive postmortem covering timeline, root cause analysis, impact assessment, and future prevention.\n\n- `focus`:\n  - When set to `what-happened`: Focus primarily on documenting what happened during the incident in detail.\n  - When set to `why`: Emphasize root cause analysis and why the incident occurred.\n  - When set to `prevention`: Concentrate on preventive measures and future safeguards.\n  - When set to `balanced`: Provide balanced coverage of what happened, why it happened, and how to prevent recurrence.\n\n- `audience`:\n  - When set to `team`: Write for the technical team with appropriate technical details.\n  - When set to `leadership`: Format for leadership with executive summary and business impact.\n  - When set to `stakeholders`: Address concerns of all stakeholders with both technical and business perspectives.\n  - When set to `public`: Create a public-facing document that explains the incident without revealing sensitive details.\n\n## Compatibility\n\n- **Requires**: None\n- **Conflicts**: None\n- **Compatible Models**: gpt-4-turbo, gpt-4o, claude-3-7-sonnet-latest, llama-3.2\n- **Standard Version**: 1.0.0 - 2.0.0\n\n## Related Decorators\n\n- **RootCauseAnalysis**: Enhances PostMortem RootCauseAnalysis can enhance the 'why' aspect of PostMortem analysis.\n- **TechnicalDocumentation**: Enhances PostMortem TechnicalDocumentation can improve the structure and clarity of the postmortem document.\n",
    "timestamp": "2025-05-23T16:34:49.041348",
    "tags": [],
    "severity": "high",
    "services_affected": [
      "web",
      "database"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "aws",
      "postgresql"
    ],
    "failure_pattern": null,
    "timeline_events": [],
    "blast_radius": "localized",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 0.6
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/CDCgov/dibbs-ecr-viewer/blob/c01d93c164a4da6be8f72d0e3225f15ee9739c77/docs/Postmortems/_postmortem_template.md",
    "title": "_postmortem_template.md",
    "content": "# YYYY-MM-DD Title\n\n**Postmortem Owner:** Your name goes here.\n\n**Meeting Scheduled For:** Schedule the meeting on the \"Incident Postmortem Meetings\" shared calendar, for within 5 business days after the incident. Put the date/time here.\n\n## Overview\n\nInclude a short sentence or two summarizing the contributing factors, timeline summary, and the impact. E.g. \"On the morning of August 99th, we suffered a 1 minute SEV-1 due to a runaway process on our primary database machine. This slowness caused roughly 0.024% of alerts that had begun during this time to be delivered out of SLA.\"\n\n## Contributing Factors\n\nInclude a description of any conditions that contributed to the issue. If there were any actions taken that exacerbated the issue, also include them here with the intention of learning from any mistakes made during the resolution process.\n\n## Resolution\n\nInclude a description of what solved the problem. If there was a temporary fix in place, describe that along with the long-term solution.\n\n## Impact\n\nBe very specific here and include exact numbers.\n\n## Timeline\n\nSome important times to include:\n\n1. time the contributing factor began\n1. time of the page\n1. time that the status page was updated (i.e. when the incident became public)\n1. time of any significant actions\n1. time the SEV-2/1 ended\n1. links to tools/logs that show how the timestamp was arrived at.\n\n|    **Time (ET)**    |             **Event**             |\n| :-----------------: | :-------------------------------: |\n| 12-10-2021 12:31 PM | Description of an important event |\n\n## How’d We Do?\n\nAll the following sections should be filled out together as a team during the postmortem meeting.\n\n### What Went Well?\n\n- List anything the team did well and want to call out.\n\n### Where Did We Get Lucky?\n\n- List anything we got lucky on.\n\n### What Didn’t Go So Well?\n\n- List anything that could have gone better. The intent is that we should follow up on all points here to improve our processes.\n\n### What Did We Learn?\n\n- List any findings that came out of the incident.\n\n## Potential Action Items\n\nExplore potential action items grouped by the themes discussed in What Didn’t Go So Well.\n\nExamples:\n\n1. any fixes required to prevent the contributing factor in the future\n2. any preparedness tasks that could help mitigate the problem if it came up again\n3. any improvements to our incident response process (pages, alert thresholds, etc).\n\n## Action Items\n\nThe action items we are committing to from the potential action Items. Each action item should be in the form of a Zenhub ticket.\n\n## Messaging\n\n### Internal\n\nThis is a follow-up for employees. It should be sent out right after the postmortem meeting is over. It only needs a short paragraph summarizing the incident and a link to this wiki page.\n\n### External\n\nWhat are we telling customers, including an apology? (The apology should be genuine, not rote.)\n",
    "timestamp": "2025-05-23T16:34:50.375702",
    "tags": [],
    "severity": "medium",
    "services_affected": [
      "web",
      "database",
      "queue",
      "monitoring"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "postgresql"
    ],
    "failure_pattern": null,
    "timeline_events": [],
    "blast_radius": "localized",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 0.43
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/ChromeDevTools/devtools-frontend/blob/c67d1c724ab9dcf466346f2e95b92bd0012982bc/docs/contributing/issues.md",
    "title": "issues.md",
    "content": "# Chromium DevTools Issues Guidelines\n\n[goo.gle/chromium-devtools-issues](https://goo.gle/chromium-devtools-issues)\n\nThis document explains how Chromium DevTools (related) issues are tracked in the\n`Chromium>Platform>DevTools` component tree of [crbug], how we define and manage\npriorities and Service Level Objectives (SLOs), as well as the overall bug life\ncycle.\n\n[TOC]\n\nIn 2024 the Chromium project migrated [crbug] to the [Google Issue Tracker], called\n[Buganizer] internally. While most of the functionality is generally available\nto all Chromium contributors, some of it is limited to Googlers, and can only\nbe accessed via [Buganizer] internally.\n\n## Bug reporting guidelines\n\nThe process for reporting a bug in Chromium DevTools follows the Chromium-wide\n[Bug Life Cycle and Reporting Guidelines], and we encourage you to first read\nthrough the [How to file a good browser bug] article. Proceed according to the\ncheck list below:\n\n1.  Try to verify that it is indeed a bug and not the intended behavior of a\n    certain feature.\n1.  Check if there is already a bug report for it, by searching in the list of\n    [Open Chromium DevTools Bugs]. If you find an existing bug report, click\n    the **+1** button in the upper-right corner of the page to indicate that\n    you are also affected by this.\n1.  If there's no existing bug report that matches your issue, start reporting\n    a new bug.\n\n### Report the bug\n\nYou can use the shortlink [goo.gle/devtools-bug] or the **Help > Report a\nDevTools issue** menu item to start a new bug report.\n\n![Report a DevTools Issues](./images/issues-report-a-devtools-issue.png)\n\nYou might need to login to the [Google Issue Tracker] first with a Google\naccount in order to proceed from there. Afterwards the **Defect from user**\ntemplate opens, where you can describe the bug. Note that the template defaults\nto Markdown (with a preview below the text input box).\n\n![Create Issue Template](./images/issues-report-template.png)\n\n1.  Please enter a meaningful title.\n1.  Replace `<from chrome://version/>` and `<OS version>` with the relevant\n    version information.\n1.  Outline exact steps to reproduce the problem. Make sure to provide steps\n    that are easy and accessible. Ideally create a minified test case on\n    [glitch.com](http://glitch.com) or [GitHub](http://github.com). Also\n    make sure to include screenshots and videos that help us to reproduce\n    and understand the problem you are facing.\n\n## Overview\n\nCheck out the [Issues Overview] for a general introduction to the [Google Issue\nTracker]. This section provides an overview of the Chromium DevTools specifics.\n\n### Issue types\n\n[crbug] supports a wide range of different issue types, with ambiguous semantics.\nFor Chromium DevTools we explicitly limit the set of types we use and give them\nwell-defined semantics:\n\n| Issue Type           | Meaning                                    |\n| -------------------- | ------------------------------------------ |\n| **Bug**              | The behavior does not match what is supposed to occur or what is documented. The product does not work as expected. |\n| **Feature Request**  | The product works as intended but could be improved. |\n| **Internal Cleanup** | This is typically a maintenance issue. The issue has no effect on the behavior of a product, but addressing it may allow more intuitive interaction. |\n| **Vulnerability**    | Security vulnerabilities subject to the handling outlined in Google's [Vulnerability Priority Guidelines](http://go/vulnerability-slo). |\n| **Privacy Issue**    | Privacy issues subject to the handling outlined in Google's [Privacy Issue Bugs](http://go/pib-slo). |\n| **Task**             | A small unit of work.                      |\n| **Project**          | A goal-driven effort with a finite start and end, focused on creating a unique product, service, or result. |\n| **Feature**          | A collection of work that provides a specific value to the user. |\n\nThe first 6 (**Bug** to **Task**) are used for day-to-day work and for issues\nreported by users. The last 2 (**Project** and **Feature**) are used to organize\nthe other types of issues for the purpose of planning (ahead). We explicitly\ndon't use Customer Issue, Process, Milestone, Epic, and Story within Chrome DevTools.\n\n*** promo\n**BEST PRACTICE:** Limit the nesting of **Project** and **Feature** to the bare\nminimum needed, and use **Task** for small chunks of work.\n***\n\n### Parent-Child Relationships and Blocking\n\n*** note\n**TL;DR:**\n\n-  Prefer parent-child relationships to split work into smaller chunks.\n-  Prefer blocking to express dependencies between independent / adjacent\nissues.\n***\n\nWhen splitting up work into smaller chunks or when scoping a project that\nencompasses multiple bugs or feature requests, favor to express this via a\nparent-child relationship. Consider the example of a CSS Nesting:\n\n1.  This should start with an issue of type Feature which is about adding CSS\n    Nesting support to Chromium DevTools.\n1.  This Feature has child issues of type Task, which are concerned with adding\n    CSS Nesting support to the various parts of DevTools involved, for example\n    the CDP (Chrome DevTools Protocol), the Elements panel, the Sources panel,\n    and so forth.\n1.  Over the course of the project there'll likely also be Feature Requests and\n    Bugs from internal and external developers, which should also be parented\n    under the CSS Nesting Feature issue.\n\n### Priorities\n\nBelow is a table to guide how to think about priorities, aligned with Chromium's\n[Triage Best Practices]:\n\n| Priority                                  | Timeline                       | Description                             |\n| ----------------------------------------- | ------------------------------ | --------------------------------------- |\n| `P0` <br> **(emergency)**                 | Requires immediate resolution. | Regressions which are substantially      impacting existing users, partners, or developers. <br> High-risk security issues affecting the stable channel.<br> Situations that create large, urgent, legal or financial risks for Google.\n| `P1` <br> **(priority engineering work)** | Needed for target milestone.   | Major Regressions. <br> Work requiring prompt resolution.<br>Work that has to get done before the targeted release.\n| `P2` <br> **(active engineering  work)**  | Wanted for target milestone.   | Non-urgent issues. <br> Important issues that are worked on as best effort, without a milestone. <br>Polish or bug fixing work in areas where the team has decided we want to invest.\n| `P3` <br> **(later, want to do)**         | Not time sensitive.            | Something we want to do, but not right now. <br> Legitimate issues that we will work on when we have the cycles to do so.\n| `P4` <br> **(later, maybe never)**        | Some day... or never.          | Nice to have, but also fine not to have.\n\n### Components\n\nThe following components in [crbug] are owned by the Chrome DevTools team.\n\n| Component                                                | Description                                                   |\n| -------------------------------------------------------- | ------------------------------------------------------------- |\n| `Chromium>Platform>DevTools`                             | Issues that don't fit any specific category                   |\n| `Chromium>Platform>DevTools>Accessibility`               | DevTools' accessibility                                       |\n| `Chromium>Platform>DevTools>AI`                          | Console Insights and AI Assistance panel                      |\n| `Chromium>Platform>DevTools>Animations`                  | Animations panel                                              |\n| `Chromium>Platform>DevTools>Application`                 | Application panel                                             |\n| `Chromium>Platform>DevTools>Browser Automation`          | Browser Automation issues                                     |\n| `Chromium>Platform>DevTools>Browser Automation>Headless` | Chrome Headless issues                                        |\n| `Chromium>Platform>DevTools>Console`                     | Console panel                                                 |\n| `Chromium>Platform>DevTools>Elements`                    | Elements panel                                                |\n| `Chromium>Platform>DevTools>Infra`                       | Issues related to DevTools' infrastructure                    |\n| `Chromium>Platform>DevTools>Issues`                      | Issues panel                                                  |\n| `Chromium>Platform>DevTools>Lighthouse`                  | Lighthouse panel                                              |\n| `Chromium>Platform>DevTools>Memory`                      | Heap/Memory Profiling, Memory Analysis                        |\n| `Chromium>Platform>DevTools>Mobile`                      | Mobile Emulation / Debugging                                  |\n| `Chromium>Platform>DevTools>Network`                     | Network, Network conditions,  Network request blocking panels |\n| `Chromium>Platform>DevTools>Performance`                 | Performance, Performance Monitor, Performance Insights panels |\n| `Chromium>Platform>DevTools>Extensions`                  | Issues related to DevTools extensions and extensibility       |\n| `Chromium>Platform>DevTools>Recorder`                    | Recorder panel                                                |\n| `Chromium>Platform>DevTools>Security`                    | Security panel                                                |\n| `Chromium>Platform>DevTools>Sources`                     | Sources panel                                                 |\n| `Chromium>Platform>DevTools>UX`                          | Usability and interface issues                                |\n| `Chromium>Platform>DevTools>WebAssembly`                 | WebAssembly issues                                            |\n\n### Hotlists\n\nThe [Chrome DevTools TaskFlow Hotlists] bookmark group contains all the hotlists\nrelevant to issue management for Chromium DevTools (in particular via the Google\ninternal Chrome DevTools [TaskFlow]).\n\nIn particular we use the following Chromium-wide hotlists.\n\n| Hotlist                                            | Description\n| -------------------------------------------------- | -----------\n| [`Chromium-Regression`](http://issues.chromium.org/hotlists/5438261) | Hotlist used to track user-noticeable regressions across Chromium.\n| [`Needs-Feedback`](http://issues.chromium.org/hotlists/5433459)      | Used by the TEs and the [Triage Gardeners](triage-gardener.md) to request more feedback on an issue. The [Chrome Blintz service](http://go/chrome-blintz-user-guide) will automatically remove the label once the reporter provides more feedback.\n| [`TE-NeedsTriageHelp`](http://issues.chromium.org/hotlists/5681652)  | Used by TEs when they cannot confirm a new issue and request help from the engineering team.\n| [`Unconfirmed`](http://issues.chromium.org/hotlists/5437934)         | All user reported issue start their life on this hotlist. TEs do a first level triage and try to reproduce the problem, and afterwards either close the issue, or remove it from this hotlist, and therefore forward it to our [TaskFlow Inbox].\n| [`User-Submitted`](http://issues.chromium.org/hotlists/5562135)      | Part of the `DevTools Issue` template, all user reported issues start life on this hotlist.\n\n*** note\n**Note**: We don't actively monitor or utilize the\n[`Available`](http://issues.chromium.org/hotlists/5438642) hotlist, however,\nmeaning that we aren't fully aligned with the [Chromium-wide triage guidelines].\nIn particular, for Chromium-wide dashboards that utilize\n[`Available`](http://issues.chromium.org/hotlists/5438642) as an indicator for\nthe triage status, Chromium DevTools might show up with a high percentage of\nuntriaged issues due to this fact.\n***\n\n### T-Shirt Sizes\n\nWe use the T-Shirt sizes approach to estimate effort for the `Chromium>Platform>DevTools`\ncomponent tree, based on the following guidelines:\n\n| Size | Description                                 | Examples                                                                                                                                                      |\n| :--- | :------------------------------------------ | :------------------------------------------------------------------------------------------------------------------------------------------------------------ |\n| S | Small CL | [Styles bar loses focus in Chrome OS DevTools](http://crbug.com/338348417), [Add 20x CPU throttling preset](https://crbug.com/324978881), [Remove 'Consistent source map variable experiment'](http://crbug.com/40944633), [Autofill tab breaks with phone numbers starting with '+'](https://b.corp.google.com/issues/335409093) |\n| M | Medium-sized CL or series of trivial CLs | [Local overrides for New Tab Page misses one \"/\" in folder name](http://crbug.com/328210785), [Memory tool should highlight common problems and opportunities](http://crbug.com/337094903), [Improve the developer experience of using compression dictionaries](http://crbug.com/333756098) |\n| L | Large-sized CL or series of non-trivial CLs | [Excluding sensitive data from HARs (HTTP Archives) by default](https://crbug.com/361717594), [Exceptions in promise constructor should be treated as promise rejection](http://crbug.com/40283985) |\n| XL | quarter-long single-person or larger project | [Performance Insights](http://crbug.com/40810111), [Replace regex-matching in the StylesSidebarPane](http://crbug.com/40945390), [MPArch migration](http://crbug.com/40238399), [GM3 adoption](http://crbug.com/40273199)  |\n\n## SLOs\n\nIn order to deliver a better product experience for developers using Chromium\nDevTools we want to\n\n1. reduce the number of regressions that ship to the (Chrome) Stable channel, and\n2. reduce the number of bugs overall.\n\nThe following SLOs (Service Level Objectives) apply to issues of type Bug,\nVulnerability, and Privacy Issue. other types of issues such as Feature Request\nor Task are out of scope for SLOs (with the notable exception of Postmortem action\nitems, where Chrome also enforces SLOs for non-bug issues). We also explicitly\nrestrict these SLOs to bugs in [crbug], and are not concerned with bugs that are\ntracked in other places such as GitHub. Below is a high level summary of our SLOs\n(Googlers can check the [Chrome DevTools SLO Policy] and [Chrome SLO Policy] for\nmore details):\n\n|      | Assignment     | Response           | Closure\n| ---- | -------------- | ------------------ | --------\n| `P0` | 1 business day | Every business day | 1 week\n| `P1` | 1 week         | 1 week             | 4 weeks\n| `P2` | 2 months       | -                  | 6 months\n| `P3` | 1 year         | -                  | -\n\nThe first two rows are identical to [go/chrome-slo], with the last two rows being\nspecific to Chrome DevTools. [crbug] provides a **Nearest SLO** column that\nsurfaces SLO violations easily:\n\n![Nearest SLO in crbug](./images/issues-nearestslo.png \"Nearest SLO in crbug\")\n\n-   [SLO violations for Chrome DevTools](https://issues.chromium.org/issues?q=status:open%20componentid:1457055%2B%20type:(bug%7Cvulnerability%7Cprivacy_issue)%20nearestslo:10000d)\n\n\n### Release Blocking Issues\n\nIn accordance with go/chrome-slo there are special SLOs for issues that are\nsevere enough to block a release shipping to users (see [go/chrome-release-slos]).\nThey apply to bug types in the same way as the above SLOs.\n\n|                                                                    | Assignment | Response     | Closure\n| ------------------------------------------------------------------ | ---------- | ------------ | -------\n| [Urgent](http://go/chrome-release-slos#bookmark=id.2wgnoi9mltcx)   | 1 day      | Every day    | 2 days\n| [Standard](http://go/chrome-release-slos#bookmark=id.bksmb4ip8mav) | 2 days     | Every 2 days | 10 days\n\n### Email Reports\n\n_Googlers only:_ [Buganizer] provides a nice feature that allows you to subscribe to\n[Email Reports](http://go/buganizer/guides/slo-reporting#email-reports) for your\nSLO (violations). Just go to **Settings** in Buganizer and enable **Subscribe to\nyour own reports** under **SLO Reports**.\n\n![Subscribe to SLO Email Reports](./images/issues-slo-reports-settings.png \"Subscribe to SLO Email Reports\")\n\nThis will get you a daily email (or whichever cadence you prefer) from Buganizer\nin your Inbox that shows you up to 25 P0 and P1 out-of-SLO issues.\n\n### Dashboard\n\n_Googlers only:_ You can use the [Buganizer SLO Compliance] dashboard, which is\nrefreshed every 2-4 hours, to see SLO compliance for a given lead.\n\n  [crbug]: https://crbug.com\n  [Google Issue Tracker]: https://issuetracker.google.com/\n  [Buganizer]: http://buganizer/\n  [Issues Overview]: https://developers.google.com/issue-tracker/concepts/issues\n  [Chrome DevTools TaskFlow Hotlists]: https://issues.chromium.org/bookmark-groups/895270\n  [Chromium-wide triage guidelines]: https://www.chromium.org/for-testers/bug-reporting-guidelines/#bug-life-cycle\n  [Triage Best Practices]: https://www.chromium.org/for-testers/bug-reporting-guidelines/triage-best-practices\n  [Bug Life Cycle and Reporting Guidelines]: https://www.chromium.org/for-testers/bug-reporting-guidelines\n  [How to file a good browser bug]: https://web.dev/articles/how-to-file-a-good-bug\n  [Open Chromium DevTools Bugs]: https://issues.chromium.org/issues?q=status:open%20componentid:1457055%2B%20type:bug\n  [goo.gle/devtools-bug]: https://goo.gle/devtools-bug\n  [Chrome DevTools SLO Policy]: https://b.corp.google.com/slos/61348\n  [Chrome SLO Policy]: https://b.corp.google.com/slos/1834\n  [go/chrome-slo]: http://go/chrome-slo\n  [go/chrome-release-slos]: http://go/chrome-release-slos\n  [Buganizer SLO Compliance]: go/b-slo-compliance\n  [TaskFlow]: http://go/chrome-devtools:taskflow\n  [TaskFlow Inbox]: http://go/chrome-devtools:taskflow/inbox\n",
    "timestamp": "2025-05-23T16:34:55.725353",
    "tags": [],
    "severity": "high",
    "services_affected": [
      "api",
      "web",
      "database",
      "auth"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "aws",
      "azure",
      "elasticsearch",
      "grafana"
    ],
    "failure_pattern": "resource_exhaustion",
    "timeline_events": [],
    "blast_radius": "localized",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 0.96
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/OBS-DevOps24/whoknows-legacy/blob/c00502ffea0a36bd9b55ccaa1f2df189525b2277/docs/mandatory-2/5_Postmortem.md",
    "title": "5_Postmortem.md",
    "content": "# Postmortem\n\n## Overview\n\nBetween November 26th and 28th, our database experienced an outage due to insufficient memory on the database VM. This resulted in all requests dependent on the database failing with status code 500. The incident was identified through our monitoring stack, which provided critical insights into the issue.\n\n## Incident Timeline\n\n- **November 26th:** The database began experiencing memory issues, leading to service disruptions.\n- **November 27th:** Continued failures as the database container attempted to restart but failed with status code 137, indicating insufficient memory.\n- **November 28th:** The issue persisted until manual intervention was performed.\n\n## Visual Evidence\n\n### Request Duration\n![Request Duration](./assets/request-duration.png)\n\n### Error Rate\n![Error Rate](./assets/error-rate.png)\n\nThese graphs show the spike in request durations and error rates during the incident period, to the point of requests failing.\n\n## Root Cause\n\nThe root cause of the outage was a lack of memory for the database VM.\n\n## Resolution\n\n- **Immediate Actions:**\n  - Restarted the server and the database container, which seemed to work for a while, hence the normal data at a period between the 26th and 27th (and slow response time, once again).\n  - Planned on making a swap memory to stabilize the virtual machine.\n\n- **Long-term Solution:**\n  - After repeated failure of the database, we decided to scale vertically, using a more powerful virtual machine (Azure B2s instance).\n\n## Lessons Learned\n\n- **Monitoring Effectiveness:**\n  - Our monitoring stack was instrumental in identifying the issue.\n  - However, the lack of automated alerting delayed our response time.\n\n## How to prevent this in the future\n\n1. **Implement Alerting:**\n   - Set up Grafana alerts to notify us of critical issues, such as low memory, high CPU usage, etc.",
    "timestamp": "2025-05-23T16:34:56.948136",
    "tags": [],
    "severity": "high",
    "services_affected": [
      "api",
      "database",
      "monitoring"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "docker",
      "azure",
      "postgresql",
      "prometheus",
      "grafana"
    ],
    "failure_pattern": "monitoring_blind_spot",
    "timeline_events": [],
    "blast_radius": "localized",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 0.8999999999999999
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/evmos/mainnet/blob/f407ec770cb73e1f574e0921b8ca97e44bda3c0b/incidents/postmortem-3.md",
    "title": "postmortem-3.md",
    "content": "# Evmos - Adding Feesplit module upgrade\n\n## Authors\n\nDaniel Burckhardt (evmos.org)\n\n## Date\n\n2022-10-12\n\n## Brief Overview\n\n- There is a bug in the Evmos `v8.1.0` upgrade. The upgrade registers an outdated upgrade name, so that the feesplit module is added without running the store upgrade. Without this store upgrade, new modules that are added to the chain don't work.\n- Impact: Feesplit module queries and transactions are unsuccessful. Other modules are unaffected.\n\n## Timeline\n\n### August 17, 2022\n\nValidators perfom a [scheduled Evmos Testnet](https://testnet.mintscan.io/evmos-testnet/proposals/66) Software upgrade at block [4,600,000](https://testnet.mintscan.io/evmos-testnet/blocks/4600000) from Evmos `v7.0.0` to `v8.0.0`. This upgrade registers the correct [upgrade handler](https://github.com/evmos/evmos/blob/v8.0.0/app/app.go#L1089) and the necessary [store upgrade](https://github.com/evmos/evmos/blob/v8.0.0/app/app.go#L1121) to introduce the new feesplit module. After the upgrade, we test the feesplit functionality successfully by registering contracts for feesplits on Testnet and confirming the fee destribution when interacting with registered contracts using the CLI.\n\n### August 22, 2022\n\nBased on successful testing on Testnet, we propose a [Mainnet Software upgrade](https://www.mintscan.io/evmos/proposals/50) from `v7.0.0` to `v8.0.0`.\n\n### August 25, 2022\n\nOur team reports that frontend applications cannot use the feesplit module on Testnet. It is discovered that `v8.0.0` does not support signing transactions with eip712 for feesplit messages and cannot be implemented in [evmosjs](https://github.com/evmos/evmosjs) due to the lack of registering the amino codec for these messages.\n\nWe decide that this is a blocker for upgrading Mainnet to `v8.0.0` and recommend to validators and the community to reject the active proposal.\n\nTaken from Evmos Discord #mainnet-announcements:\n\n> @Validators  @Future Validators Hey everyone, we discovered on Testnet that the feesplit registration does not support signing transactions with eip712 on version v8.0.0.\n>\n> We already implemented the required changes on Ethermint(https://github.com/evmos/ethermint/pull/1288) and Evmos(https://github.com/evmos/evmos/pull/859) (which we will create a new release for) and would like to delay the Mainnet upgrade to deliver the full experience to you on Mainnet.\n>\n> To delay the upgrade we need your action! Please vote \"no\" on the Mainnet upgrade proposal (https://www.mintscan.io/evmos/proposals/50) 🙏\n\n### August 27, 2022\n\nThe voting time for the Mainnet [v8.0.0 upgrade proposal](https://www.mintscan.io/evmos/proposals/50) ends with a final status: \"rejected\".\n\n### September 1, 2022\n\nValidators perform a [scheduled Evmos Testnet](https://testnet.mintscan.io/evmos-testnet/proposals/72) Software upgrade at block [5,320,000](https://testnet.mintscan.io/evmos-testnet/blocks/5320000) from Evmos `v8.0.0` to `v8.1.0`. This upgrade adds a state machine breaking change to register the missing amino codec for the feesplit module.\n\nAfter changing the evmosd version to `v8.1.0`, validators discovered that the node couldn't start because they were getting a database error. After debugging the issue with members of the SDK team, we found a quick fix changing the pruning settings to `nothing`. After applying that change the node started to work correctly. The `v8.0.0` also included some database changes so we didn't know if the problem was related to database changes or anything else.\n\n### September 21, 2022\n\nValidators perform a [scheduled Evmos Mainnet](https://www.mintscan.io/evmos/proposals/50) software upgrade at block [3,620,000](https://www.mintscan.io/evmos/blocks/3620000) from Evmos `v7.0.0` to `v8.1.0`.\n\nThis upgrade registers the correct [upgrade handler](https://github.com/evmos/evmos/blob/v8.1.0/app/app.go#L1097) but **does not** include the correct upgrade name for the necessary store upgrade to introduce the new feesplit module. Instead of `v8.1.0`, the upgrade name is set to [`v8.0.0`](https://github.com/evmos/evmos/blob/v8.1.0/app/app.go#L1130), so that the store upgrade logic is not performed on Mainnet. Before this upgrade, Mainnet was running on v7.0.0 and hadn't introduced the feesplit module yet. This means, a new module has been added to Mainnet without upgrading the store.\n\nOn the same day, the missing store upgrade is disclosed to the Evmos team within a telegram chat including Cosmos SDK contributors.\n\n### September 23, 2022\n\nAfter close evaluation on how to add the missing store upgrade on Mainnet, we discover that the cleanest solution is to rename the module on Mainnet by planning an upgrade that deletes the `feesplit` module and adds it as `revenue` module.\n\nAfter running our upgrade tests locally, we release Evmos v8.2.0 which includes the [rename and the store upgrade](https://github.com/evmos/evmos/blob/v8.2.0/app/app.go#L1146). The testing precedure is extended to perform the planned upgrade locally and perform queries and transactions for the new module on the upgraded local node.\n\nIn order to fix the broken module on Mainnet we decide to perform an upgrade to v8.2.0 using a [Hard Fork procedure](https://docs.evmos.org/validators/upgrades/overview.html#hard-forks).\n\nTo schedule the hard fork, we release a non-breaking release `v.8.1.1` that sets the upgrade height for the v8.2.0 emergency Mainnet upgrade. This procedure automatically applies the changes from an upgrade plan at given block height without the need for a governance proposal.\n\n### September 26, 2022\n\nValidators perform a [scheduled hard fork on Evmos Mainnet](https://www.mintscan.io/evmos/proposals/50) at block [4,888,000](https://www.mintscan.io/evmos/blocks/4888000) from Evmos `v8.1.1` to `v8.2.0`. This release successfully registers the now renamed revenue module.\n\n## Five Whys\n\n> Use the [root cause identification technique](https://en.wikipedia.org/wiki/Five_whys). Start with the impact and ask why it happened and why it have the impact it did. Continue asking why until you arrive at the root cause. Document your \"whys\" as a list here or in a diagram attached to the issue.\n\n### Problem: Feesplit module queries and transactions are unsuccessful after upgrading Mainnet to `v8.1.0`.\n\n**Why did the new feesplit module not work on Mainnet?**\n\nThe upgrade was missing a store upgrade, because we registered the wrong update name.\n\n**Why did we register the wrong store upgrade name?**\n\nBecause our upgrade testing process wasn't sufficient and the diversion of  upgrade history on Testnet and Mainnet made communication prone to errors.\n\n**Why wasn't the upgrade tested sufficiently?**\n\nBecause our upgrade testing is run manually the testing expectation hadn't been adjusted to test the functionalities of a new module with an upgraded local node.\n\n**Why wasn't the testing expectation adjusted?**\n\nBecause we added a new module for the first time after launch and there is no process in place for aligning on the exact testing expectation for upgrades.\n\n## What went well/Where we got lucky\n\n* Once the issue was disclosed to us, we reacted quickly investigate  the most straight*forward solution and confirmed with advisors to the team on how to proceed.\n* Only the newly added module was affected. Everything else worked fine.\n\n## What went poorly\n\n* The upgrade handler Pull Request review could have caught the wrong store upgrade.\n* We could have communicated better our expectations on how to test the upgrade.\n\n## Remediation\n\n### Testnet\n\n* Upgrade Testnet v8.1.0 => 8.2.3 to rename the feesplit to revenue module. Currently there are no registered contracts on Testnet. Even if there are contracts registered, the upgrade works successfully.\n\n### Release Versioning: Should we achieve parity between Testnet and Mainnet?\n\nThere are two options to consider:\n\n* introduce release (e.g. `v8-rc1` or similar) candidates on Testnet until we are ready on Mainnet, but this wouldn't allow parity\n* introduce release candidates on localnet and only move to Testnet once we are confident about it.",
    "timestamp": "2025-05-23T16:35:02.616337",
    "tags": [],
    "severity": "high",
    "services_affected": [
      "web",
      "database"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "azure",
      "postgresql"
    ],
    "failure_pattern": "data_corruption",
    "timeline_events": [],
    "blast_radius": "localized",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 0.84
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/observability-ui/development-tools/blob/ad7b672e2d178b9d4177494c777687c74349ecb9/incidents/enable-incidents-data.md",
    "title": "enable-incidents-data.md",
    "content": "# Incidents \n###  Add incidents data like this:\nClone down:\nhttps://github.com/openshift/cluster-health-analyzer/tree/main\n\nUpload incidents:\n---\noc apply -f manifests/backend -f manifests/frontend\ngo run ./main.go simulate\npromtool tsdb create-blocks-from openmetrics cluster-health-analyzer-openmetrics.txt\nfor d in data/*; do\n echo $d\n kubectl cp $d openshift-monitoring/prometheus-k8s-0:/prometheus -c prometheus\ndone\n---\n\nthe prometheus-k8s-0 name comes from the cluster you have open\n\nReference https://redhat-internal.slack.com/archives/C07RV4GPQSV/p1737561323553629",
    "timestamp": "2025-05-23T16:35:06.844656",
    "tags": [],
    "severity": "high",
    "services_affected": [
      "web",
      "database",
      "monitoring"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "kubernetes",
      "elasticsearch",
      "prometheus"
    ],
    "failure_pattern": "monitoring_blind_spot",
    "timeline_events": [],
    "blast_radius": "localized",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 0.67
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/yujunz/gitlab.com-runbooks/blob/270d66d3798307991399ce20aaccb93921f71715/incidents/general_incidents.md",
    "title": "general_incidents.md",
    "content": "# Incidents\n\nFirst: don't panic\n\nIf you are feeling overwhelmed, escalate to the [IMOC or CMOC](https://about.gitlab.com/handbook/engineering/infrastructure/incident-management/#roles).  \nWhoever is in that role can help you get other people to help with whatever is needed.  Our goal is to resolve the incident in a timely manner, but sometimes that means slowing down and making sure we get the right people involved.  Accuracy is as important or more than speed.\n\nRoles for an incident can be found in the [incident management section of the handbook](https://about.gitlab.com/handbook/engineering/infrastructure/incident-management/)\n\nIf you need to start an incident, you can post in the #incident channel(https://gitlab.slack.com/messages/CB7P5CJS1)\nIf you use /start-incident - a bot will make and issue/google doc and zoom link for you.\n\n## Communication Tools\n\nIf you do end up needing to post and update about an incident, we use [Status.io](https://status.io)\n\nOn status.io, you can [Make an incident](https://app.status.io/dashboard/5b36dc6502d06804c08349f7/incident/create) and Tweet, post to Slack, IRC, Webhooks, and email via checkboxes on creating or updating the incident.\n\nThe incident will also have an affected infrastructure section where you can pick components of the GitLab.com application and the underlying services/containers should we have an incident due to a provider.\n\nYou can update incidents with the Update Status button on an existing incident, again you can tweet, etc from that update point.\n\nRemember to close out the incident when the issue is resolved.  Also, when possible, put the issue and/or google doc in the post mortem link.\n",
    "timestamp": "2025-05-23T16:35:08.412305",
    "tags": [],
    "severity": "high",
    "services_affected": [
      "database"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "docker",
      "grafana"
    ],
    "failure_pattern": "resource_exhaustion",
    "timeline_events": [],
    "blast_radius": "localized",
    "detection_time": null,
    "mitigation_actions": [],
    "quality_score": 0.72
  },
  {
    "source": "github:codesearch",
    "url": "https://github.com/spikehq/docs.spike.sh/blob/8a3c2642ff6a57901a15186c8b57d64525eb2941/incidents/incident-lifecycle.md",
    "title": "incident-lifecycle.md",
    "content": "---\ndescription: Lifecycle of an incident.\n---\n\n# Incident lifecycle\n\n## Incident lifecycle\n\nIncidents can have one of these statuses -\n\n1. **Triggered**\n2. **Acknowledged**\n3. **Resolved**\n\n_Learn more about what these states in the next page_\n\n![](<../.gitbook/assets/Incident lifecycle.png>)\n\n### 1. Triggering incidents\n\nYour added integrations will create an incident on Spike. Every integration on one or more services are treated uniquely. This would mean that you can have multiple AWS integrations and they will all be treated uniquely to make sure that incidents are triggered.\n\nBefore the incident is created, Spike checks for similar incidents for this integration. If it exists then _a new incident is not created but an event is logged for the same incident which is not resolved._\n\n{% hint style=\"info\" %}\n**Avoiding duplication of incidents**.\n\nSimilar incidents in resolved state are ignored. Only the incidents which are **open (acknowledged or triggered state)** will be checked.\n{% endhint %}\n\n### 2. Automatic escalations\n\nOn Spike, you have the freedom to assign a separate escalation policy to each of your integration. This gives you the flexibility to operate with ease knowing which alerts to prioritise over others.\n\n![Example escalation policy on spike.sh](<../.gitbook/assets/screenshot-2020-06-24-at-10.48.37-am (1).png>)\n\nSpike alerts based on the escalation policy. For the newly created incident, the first alert is sent in the order of responders in the policy. In the above example, the first alert is being sent to the **Slack channel #incidents** along with alerting dev member Kaushik and email to another member.\n\nSpike waits for 5 minutes for the any of the responders to acknowledge or resolve the incident. If there is no action taken, spike automatically escalates and alerts the responders on the next level.\n\nIn the above examples, there are 2 responders who will be alerted via phone, also at the same time we alert to **Slack channel #dev-team**.\n\n### 3. Acknowledge timeout\n\nFor every integration, you can choose a set a timeout for incidents acknowledged but not resolved. After this timeout, Spike resumes the escalations and start sending alerts to the next escalation level. If it's the end of escalation then it's repeated automatically.\n",
    "timestamp": "2025-05-23T16:35:12.943743",
    "tags": [],
    "severity": "low",
    "services_affected": [
      "monitoring"
    ],
    "root_cause": null,
    "resolution_time": null,
    "infrastructure_components": [
      "aws",
      "prometheus",
      "grafana"
    ],
    "failure_pattern": "network_partition",
    "timeline_events": [],
    "blast_radius": "localized",
    "detection_time": null,
    "mitigation_actions": [
      ", spike automatically escalates and alerts the responders on the next level"
    ],
    "quality_score": 0.77
  }
]