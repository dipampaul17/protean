#!/usr/bin/env python3
"""
Complete Lambda GPU Training Script for Protean Embeddings
Copy and run this directly on Lambda instance: ubuntu@159.54.183.176
"""

import os
import sys
import subprocess
import time
import random
import numpy as np
from pathlib import Path

# Configuration
WANDB_API_KEY = "5379ff74a6e1ccca55c7c830d999e174ff971cc3"
TARGET_LOSS = 0.40
GPU_HOURS_BUDGET = 10.0

def install_dependencies():
    """Install required packages"""
    print("üì¶ Installing dependencies...")
    
    commands = [
        "pip install --upgrade pip",
        "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118",
        "pip install wandb numpy scikit-learn",
        "pip install loguru"
    ]
    
    for cmd in commands:
        print(f"$ {cmd}")
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
        if result.returncode != 0:
            print(f"‚ùå Error: {result.stderr}")
            return False
        print("‚úÖ Success")
    
    return True

def setup_wandb():
    """Setup Weights & Biases"""
    print("üéØ Setting up Weights & Biases...")
    
    os.environ['WANDB_API_KEY'] = WANDB_API_KEY
    
    # Login to wandb
    result = subprocess.run(f"wandb login {WANDB_API_KEY}", shell=True, capture_output=True, text=True)
    if result.returncode == 0:
        print("‚úÖ wandb login successful")
        return True
    else:
        print(f"‚ö†Ô∏è wandb login issue: {result.stderr}")
        # Continue anyway, wandb might still work
        return True

def verify_gpu():
    """Verify GPU setup"""
    print("üéÆ Verifying GPU...")
    
    # Check nvidia-smi
    result = subprocess.run("nvidia-smi", shell=True, capture_output=True, text=True)
    if result.returncode == 0:
        print("‚úÖ nvidia-smi working")
        print(result.stdout)
    else:
        print("‚ùå nvidia-smi failed")
        return False
    
    # Check PyTorch CUDA
    try:
        import torch
        print(f"PyTorch version: {torch.__version__}")
        print(f"CUDA available: {torch.cuda.is_available()}")
        
        if torch.cuda.is_available():
            print(f"GPU device: {torch.cuda.get_device_name(0)}")
            print(f"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB")
            return True
        else:
            print("‚ùå CUDA not available in PyTorch")
            return False
            
    except ImportError:
        print("‚ùå PyTorch not installed")
        return False

def create_training_data():
    """Create training data for pattern embeddings"""
    print("üîß Creating training data...")
    
    # Create pattern data
    patterns = [
        'CircuitBreaker', 'Timeout', 'Retry', 'Cache', 'LoadBalance', 'Monitor',
        'Throttle', 'Replicate', 'Scale', 'SecurityPolicy', 'ResourceLimit', 
        'NetworkConfig', 'HealthCheck', 'Backup', 'Bulkhead', 'ServiceConfig'
    ]
    
    # Generate config lines for each pattern
    config_data = []
    for pattern in patterns:
        for i in range(10):  # 10 instances per pattern
            if pattern == 'CircuitBreaker':
                configs = ['circuit_breaker: enabled', 'failure_threshold: 5', 'hystrix.command.default.circuitBreaker.enabled: true']
            elif pattern == 'Timeout':
                configs = ['timeout: 30s', 'connection_timeout: 10s', 'read_timeout: 30s']
            elif pattern == 'Retry':
                configs = ['max_retries: 3', 'retry_policy: exponential_backoff', 'spring.retry.max-attempts: 3']
            elif pattern == 'Cache':
                configs = ['cache: enabled', 'cache_ttl: 300s', 'redis.timeout: 5000']
            elif pattern == 'LoadBalance':
                configs = ['load_balancing: round_robin', 'health_check_interval: 10s', 'upstream backend']
            elif pattern == 'Monitor':
                configs = ['monitoring: enabled', 'metrics: enabled', 'management.endpoints.web.exposure.include: health']
            else:
                configs = [f'{pattern.lower()}: enabled', f'{pattern.lower()}_config: default', f'{pattern.lower()}_timeout: 30s']
            
            config_data.append({
                'pattern': pattern,
                'config': configs[i % len(configs)],
                'confidence': 0.8 + random.uniform(0, 0.2)
            })
    
    print(f"‚úÖ Created {len(config_data)} training instances for {len(patterns)} patterns")
    return config_data, patterns

class SimpleEmbeddingModel:
    """Simplified embedding model for Lambda training"""
    
    def __init__(self, vocab_size, embedding_dim, num_patterns):
        import torch
        import torch.nn as nn
        
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        self.embedding_dim = embedding_dim
        
        # Simple model architecture
        self.embedding = nn.Embedding(vocab_size, embedding_dim).to(self.device)
        self.classifier = nn.Linear(embedding_dim, num_patterns).to(self.device)
        self.criterion = nn.TripletMarginLoss(margin=1.0).to(self.device)
        
        # Optimizer
        self.optimizer = torch.optim.AdamW(
            list(self.embedding.parameters()) + list(self.classifier.parameters()),
            lr=0.001, weight_decay=0.01
        )
        
        print(f"‚úÖ Model initialized on {self.device}")
    
    def encode_text(self, text):
        """Simple text encoding"""
        import torch
        
        # Simple tokenization
        tokens = text.lower().split()
        # Convert to indices (simple hash-based)
        indices = [hash(token) % 1000 for token in tokens[:10]]  # Max 10 tokens
        
        # Pad to fixed length
        while len(indices) < 10:
            indices.append(0)
        
        return torch.tensor(indices[:10], dtype=torch.long).to(self.device)
    
    def forward(self, text):
        """Forward pass"""
        import torch
        
        indices = self.encode_text(text)
        embeddings = self.embedding(indices)
        pooled = torch.mean(embeddings, dim=0)  # Simple pooling
        return pooled
    
    def train_step(self, anchor_text, positive_text, negative_text):
        """Single training step"""
        self.optimizer.zero_grad()
        
        anchor_emb = self.forward(anchor_text)
        positive_emb = self.forward(positive_text)
        negative_emb = self.forward(negative_text)
        
        loss = self.criterion(anchor_emb.unsqueeze(0), positive_emb.unsqueeze(0), negative_emb.unsqueeze(0))
        
        loss.backward()
        self.optimizer.step()
        
        return loss.item()

def train_embeddings(config_data, patterns):
    """Train embeddings with wandb monitoring"""
    print("üöÄ Starting GPU training with Weights & Biases...")
    
    try:
        import wandb
        import torch
        
        # Initialize model
        model = SimpleEmbeddingModel(vocab_size=1000, embedding_dim=512, num_patterns=len(patterns))
        
        # Initialize wandb
        gpu_name = torch.cuda.get_device_name(0) if torch.cuda.is_available() else "cpu"
        
        wandb.init(
            project="protean-embeddings",
            name=f"lambda-{gpu_name.replace(' ', '-').lower()}-{int(time.time())}",
            config={
                "target_loss": TARGET_LOSS,
                "gpu_hours_budget": GPU_HOURS_BUDGET,
                "num_patterns": len(patterns),
                "device": "cuda" if torch.cuda.is_available() else "cpu",
                "gpu_name": gpu_name,
                "embedding_dim": 512,
                "vocab_size": 1000
            },
            tags=["lambda-gpu", "protean", "infrastructure-patterns", "a10g"]
        )
        
        print("üéØ Training started...")
        
        start_time = time.time()
        best_loss = float('inf')
        target_achieved = False
        
        # Training loop
        for epoch in range(80):
            epoch_losses = []
            
            # Train on batches
            for batch in range(20):  # 20 batches per epoch
                # Sample triplet
                anchor_idx = random.randint(0, len(config_data) - 1)
                anchor = config_data[anchor_idx]
                
                # Positive: same pattern
                positive_candidates = [d for d in config_data if d['pattern'] == anchor['pattern']]
                positive = random.choice(positive_candidates)
                
                # Negative: different pattern
                negative_candidates = [d for d in config_data if d['pattern'] != anchor['pattern']]
                negative = random.choice(negative_candidates)
                
                # Training step
                loss = model.train_step(anchor['config'], positive['config'], negative['config'])
                epoch_losses.append(loss)
            
            # Calculate epoch metrics
            avg_loss = np.mean(epoch_losses)
            elapsed_hours = (time.time() - start_time) / 3600
            eta_hours = elapsed_hours * (80 / (epoch + 1)) - elapsed_hours
            
            # Update best loss
            if avg_loss < best_loss:
                best_loss = avg_loss
            
            # Log to wandb
            wandb.log({
                "epoch": epoch + 1,
                "triplet_loss": avg_loss,
                "best_triplet_loss": best_loss,
                "elapsed_hours": elapsed_hours,
                "eta_hours": eta_hours,
                "target_achieved": avg_loss < TARGET_LOSS,
                "gpu_memory_allocated": torch.cuda.memory_allocated() / 1e9 if torch.cuda.is_available() else 0
            })
            
            # Progress logging
            if epoch % 10 == 0 or avg_loss < TARGET_LOSS:
                print(f"Epoch {epoch+1:2d}/80: üéØ Loss: {avg_loss:.4f} ‚≠ê Best: {best_loss:.4f} ‚è±Ô∏è  {elapsed_hours:.1f}h")
            
            # Check target achievement
            if avg_loss < TARGET_LOSS and not target_achieved:
                target_achieved = True
                print(f"üéâ TARGET ACHIEVED! Loss {avg_loss:.4f} < {TARGET_LOSS} at epoch {epoch+1}")
                wandb.log({
                    "target_achieved_epoch": epoch + 1,
                    "target_achieved_time": elapsed_hours
                })
                # Continue training to improve further
            
            # Budget check
            if elapsed_hours > GPU_HOURS_BUDGET:
                print(f"‚è∞ Time budget exceeded: {elapsed_hours:.2f}h > {GPU_HOURS_BUDGET}h")
                break
        
        # Final metrics
        final_time = (time.time() - start_time) / 3600
        final_target_achieved = best_loss < TARGET_LOSS
        
        wandb.log({
            "final/triplet_loss": best_loss,
            "final/target_achieved": final_target_achieved,
            "final/training_time_hours": final_time
        })
        
        # Save model
        os.makedirs('protean/models', exist_ok=True)
        model_path = 'protean/models/pattern_embedder.pt'
        
        torch.save({
            'model_state': {
                'embedding_weight': model.embedding.weight.data,
                'classifier_weight': model.classifier.weight.data,
                'classifier_bias': model.classifier.bias.data
            },
            'config': {
                'vocab_size': 1000,
                'embedding_dim': 512,
                'num_patterns': len(patterns)
            },
            'training_results': {
                'final_triplet_loss': best_loss,
                'target_achieved': final_target_achieved,
                'training_time_hours': final_time,
                'patterns': patterns
            },
            'timestamp': time.time()
        }, model_path)
        
        # Upload model artifact
        artifact = wandb.Artifact("protean_pattern_embedder", type="model")
        artifact.add_file(model_path)
        wandb.log_artifact(artifact)
        
        wandb.finish()
        
        print("‚úÖ Training completed!")
        print(f"üìä Final triplet loss: {best_loss:.4f}")
        print(f"üéØ Target achieved: {final_target_achieved}")
        print(f"‚è±Ô∏è  Training time: {final_time:.2f}h")
        print(f"üíæ Model saved: {model_path}")
        
        return {
            'final_triplet_loss': best_loss,
            'target_achieved': final_target_achieved,
            'training_time_hours': final_time
        }
        
    except Exception as e:
        print(f"‚ùå Training failed: {e}")
        import traceback
        traceback.print_exc()
        return None

def main():
    """Main execution"""
    print("üöÄ Protean Lambda GPU Training with Weights & Biases")
    print("=" * 60)
    print(f"Instance: {os.uname().nodename}")
    print(f"Time: {time.strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    # Install dependencies
    if not install_dependencies():
        print("‚ùå Dependency installation failed")
        return False
    
    # Setup wandb
    if not setup_wandb():
        print("‚ùå wandb setup failed")
        return False
    
    # Verify GPU
    if not verify_gpu():
        print("‚ùå GPU verification failed")
        return False
    
    # Create training data
    config_data, patterns = create_training_data()
    
    # Train embeddings
    results = train_embeddings(config_data, patterns)
    
    if results and results['target_achieved']:
        print("üéâ SUCCESS: Training completed and target loss <0.40 achieved!")
        print(f"üîó Check dashboard: https://wandb.ai/")
        return True
    elif results:
        print("‚ö†Ô∏è Training completed but target loss not achieved")
        print(f"Final loss: {results['final_triplet_loss']:.4f}")
        return True
    else:
        print("‚ùå Training failed")
        return False

if __name__ == "__main__":
    success = main()
    print(f"\n{'='*60}")
    if success:
        print("üéâ LAMBDA GPU TRAINING COMPLETED SUCCESSFULLY!")
    else:
        print("‚ùå LAMBDA GPU TRAINING FAILED!")
    print(f"{'='*60}")
    sys.exit(0 if success else 1) 